



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="诗岸梦行舟" href="https://735690757.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="诗岸梦行舟" href="https://735690757.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="诗岸梦行舟" href="https://735690757.github.io/feed.json" />
<link rel="stylesheet" href="https://unpkg.com/mermaid/dist/mermaid.min.css">
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script>mermaid.initialize({ startOnLoad: true });</script>

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="python,深度学习,RNN,LSTM,NLP,GRU,Transformer" />


<link rel="canonical" href="https://735690757.github.io/python/NLP/">



  <title>
NLP自然语言处理 - 基础 - 深度学习 |
KarryLiu = 诗岸梦行舟 = 分享计算机知识以及各种心得总结</title>
<meta name="generator" content="Hexo 6.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">NLP自然语言处理
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2025-10-10 12:12:12">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2025-10-10T12:12:12+08:00">2025-10-10</time>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">KarryLiu</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
          <img src="/images/cover/rnn.jpg">
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span><i class="ic i-angle-right"></i>
<span  itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/python/" itemprop="item" rel="index" title="分类于 深度学习"><span itemprop="name">深度学习</span></a>
<meta itemprop="position" content="1" /></span>
<i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/python/%E5%9F%BA%E7%A1%80/" itemprop="item" rel="index" title="分类于 基础"><span itemprop="name">基础</span></a>
<meta itemprop="position" content="2" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="https://735690757.github.io/python/NLP/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/tx.jpg">
    <meta itemprop="name" content="KarryLiu">
    <meta itemprop="description" content="分享计算机知识以及各种心得总结, 愿世间所有的美好都得以祝愿">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="诗岸梦行舟">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="nlp自然语言处理"><a class="markdownIt-Anchor" href="#nlp自然语言处理">#</a> NLP 自然语言处理</h1>
<blockquote>
<p>学习笔记</p>
</blockquote>
<h2 id="常见任务"><a class="markdownIt-Anchor" href="#常见任务">#</a> 常见任务</h2>
<ol>
<li>文本分类：情感分析（积极 / 消极）、垃圾邮件识别、新闻主题分类【句子级别】</li>
<li>序列标注：命名实体识别（找人名、地名、手机号）、文本生成、信息抽取、文本转化【Token 级别】</li>
</ol>
<h2 id="文本表示"><a class="markdownIt-Anchor" href="#文本表示">#</a> 文本表示</h2>
<h3 id="分词"><a class="markdownIt-Anchor" href="#分词">#</a> 分词</h3>
<ol>
<li><strong>词级分词</strong>：将文本按照词切分在英语中空格往往是天然的切词标志，但是容易出现 OOV 问题（未登录词问题）</li>
<li><strong>字符级分词</strong>：一个字母、数字、标点甚至空格，都会被视作一个独立的 token，不会有 OOV 问题，但模型必须依赖更长的上下文来推断词义和结构，这显著增加了建模难度和训练成本。</li>
<li><strong>子词级分词</strong>：将词语切分为更小的单元 —— 子词（subword），例如词根、前缀、后缀或常见词片段。</li>
</ol>
<p>以上是英文适用的分词方法，下面是中文适用的分词方法。</p>
<ol>
<li><strong>字符级分词</strong>：一个字就进行一次切分，比英文中的字符分词，中文的字符分词更加 “语义友好”。</li>
<li><strong>词级分词</strong>：由于中文没有空格等天然词边界，词级分词通常依赖词典、规则或模型来识别词语边界。</li>
<li><strong>子词级分词</strong>：它们以汉字为基本单位，通过学习语料中高频的字组合（如 “自然”、“语言”、“处理”），自动构建子词词表。在当前主流的中文大模型（如通义千问、DeepSeek）中，子词分词已成为广泛采用的文本切分策略。</li>
</ol>
<h3 id="jiebba分词组件"><a class="markdownIt-Anchor" href="#jiebba分词组件">#</a> JiebBa 分词组件</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>word_gen <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"我的名字叫Karry，来自计算机科学技术学院"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">for</span> word <span class="token keyword">in</span> word_gen<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span></pre></td></tr></table></figure><blockquote>
<p>我<br>
的<br>
名字<br>
叫<br>
 Karry<br>
，<br>
来自<br>
计算机<br>
科学技术<br>
学院</p>
</blockquote>
<h3 id="词表示"><a class="markdownIt-Anchor" href="#词表示">#</a> 词表示</h3>
<ol>
<li><strong>One-hot 编码（独热编码）</strong>：它将词汇表中的每个词映射为一个稀疏向量，向量的长度等于整个词表的大小。该词在对应的位置为 1，其他位置为 0。在实际自然语言处理任务中，one-hot 表示已经很少被直接使用。</li>
<li><strong>语义化词向量</strong>：它通过对大规模语料的学习，为每个词生成一个具有语义意义的<strong>稠密向量</strong>表示。比如 “女人” 和 “女孩”，这两个词向量就很接近。Word2Vec。</li>
</ol>
<h3 id="word2vec"><a class="markdownIt-Anchor" href="#word2vec">#</a> Word2Vec</h3>
<img data-src="../../images/RNN_LSTM/9.png" alt="1"/>
<p>左侧是 CBOW，中间词是教师，以此来学习上下文。</p>
<p>右侧是 Skip-gram，上下文是教师，以此来学习中间词。</p>
<h3 id="gensim词向量组件"><a class="markdownIt-Anchor" href="#gensim词向量组件">#</a> GENSIM 词向量组件</h3>
<h4 id="加载与使用公开词向量"><a class="markdownIt-Anchor" href="#加载与使用公开词向量">#</a> 加载与使用公开词向量</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> KeyedVectors</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>model_path <span class="token operator">=</span> <span class="token string">'sgns.weibo.word.bz2'</span></pre></td></tr><tr><td data-num="4"></td><td><pre>model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>similarity <span class="token operator">=</span> model<span class="token punctuation">.</span>similarity<span class="token punctuation">(</span><span class="token string">'公交'</span><span class="token punctuation">,</span> <span class="token string">'地铁'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'公交和地铁的相似度'</span><span class="token punctuation">,</span> similarity<span class="token punctuation">)</span></pre></td></tr></table></figure><blockquote>
<p>公交和地铁的相似度 0.65458214</p>
</blockquote>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'男人'</span><span class="token punctuation">,</span> <span class="token string">'女孩'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'男孩'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>男人 + 女孩 - 男孩 = 女人</p>
<blockquote>
<p>[(‘女人’, 0.6578881740570068),<br>
(‘女孩子’, 0.515068531036377),<br>
(‘女生’, 0.4519447982311249),<br>
(‘女人真’, 0.44206273555755615),<br>
(‘女人们’, 0.4369858503341675),<br>
(‘女人爱’, 0.435453325510025),<br>
(‘寡言少语’, 0.42479249835014343),<br>
(‘男孩子’, 0.42177465558052063),<br>
(‘看女人’, 0.41949161887168884),<br>
(‘笨女人’, 0.4182003140449524)]</p>
</blockquote>
<h4 id="训练自己的词向量"><a class="markdownIt-Anchor" href="#训练自己的词向量">#</a> 训练自己的词向量</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> Word2Vec</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>comments <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/online_shopping_10_cats.csv'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>reviews <span class="token operator">=</span> comments<span class="token punctuation">[</span><span class="token string">'review'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>reviews <span class="token operator">=</span> reviews<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>token <span class="token keyword">for</span> token <span class="token keyword">in</span> jieba<span class="token punctuation">.</span>__lcut<span class="token punctuation">(</span>review<span class="token punctuation">)</span> <span class="token keyword">if</span> token<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">]</span> <span class="token keyword">for</span> review <span class="token keyword">in</span> reviews<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>model <span class="token operator">=</span> Word2Vec<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    sentences<span class="token punctuation">,</span>            <span class="token comment"># 已分词的句子序列</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    vector_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>      <span class="token comment"># 词向量维度</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    window<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>             <span class="token comment"># 上下文窗口大小</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    min_count<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>          <span class="token comment"># 最小词频（低于将被忽略）</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    sg<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                 <span class="token comment"># 1:Skip-Gram，0:CBOW</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    workers<span class="token operator">=</span><span class="token number">4</span>             <span class="token comment"># 并行训练线程数</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>save_word2vec_format<span class="token punctuation">(</span><span class="token string">'./data/word2vec.txt'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="词向量的应用"><a class="markdownIt-Anchor" href="#词向量的应用">#</a> 词向量的应用</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> KeyedVectors</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># 加载词向量</span></pre></td></tr><tr><td data-num="6"></td><td><pre>wv <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">'./data/word2vec.txt'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># 构建词向量矩阵</span></pre></td></tr><tr><td data-num="9"></td><td><pre>num_embedding <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>wv<span class="token punctuation">.</span>key_to_index<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>embedding_dim <span class="token operator">=</span> wv<span class="token punctuation">.</span>vector_size</pre></td></tr><tr><td data-num="11"></td><td><pre>embedding_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_embedding<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">for</span> word<span class="token punctuation">,</span> index <span class="token keyword">in</span> wv<span class="token punctuation">.</span>key_to_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    embedding_matrix<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>wv<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>embedding_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token comment"># 创建 Embedding</span></pre></td></tr><tr><td data-num="19"></td><td><pre>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>embedding_matrix<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>text <span class="token operator">=</span> <span class="token string">'我喜欢乘坐地铁'</span></pre></td></tr><tr><td data-num="22"></td><td><pre>tokens<span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>wv<span class="token punctuation">.</span>key_to_index<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> token <span class="token keyword">in</span> wv<span class="token punctuation">.</span>key_to_index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>embedding<span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="elmo模型一词多义问题"><a class="markdownIt-Anchor" href="#elmo模型一词多义问题">#</a> ELMo 模型 —— 一词多义问题</h3>
<p>NNLM 模型是在预测下一个词，而词向量是副产品。</p>
<p>Word2Vec 模型是在专门做词向量，有 CBOW 和 Skip-gram。</p>
<p>ELMo 模型解决的是一词多义的问题。</p>
<img data-src="../../images/RNN_LSTM/10.png" alt="1"/>
<p>ELMo 不仅仅是训练了一个 Q 矩阵，还把这个词的上下文信息融入到这个 Q 矩阵中，左边的 LSTM 获取 E2 的上文信息，右侧的 LSTM 获取下文信息。</p>
<p>T1 包含了第一个词的特征，与此同时也包含了语法特征和语义特征。</p>
<p>然而 LSTM 无法并行计算，因此我们引入了注意力机制。</p>
<h2 id="rnn基本结构"><a class="markdownIt-Anchor" href="#rnn基本结构">#</a> RNN 基本结构</h2>
<p>RNN 以时间步为基本单位，逐个处理每一个 Token，新的隐藏状态是由，上一个隐藏状态与当前步共同决定的。</p>
<p><img data-src="../../images/RNN_LSTM/1.png" alt="1"></p>
<p>x1，x2，x3…xt 这是一组特征，但是这是与时间有关的特征，hₜ是每时每刻的预测。</p>
<p>比如一句话：“我出生在中国，我会说中文”</p>
<p>我们可以按时间步展开：</p>
<table>
<thead>
<tr>
<th style="text-align:left">时间步</th>
<th style="text-align:left">输入 xₜ（词向量）</th>
<th style="text-align:left">隐藏状态 hₜ（编码了前面的上下文）</th>
<th style="text-align:left">可能的预测 yₜ（下一个词）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">t=1</td>
<td style="text-align:left">“我”</td>
<td style="text-align:left">h₁（编码了 “我”）</td>
<td style="text-align:left">“出生”</td>
</tr>
<tr>
<td style="text-align:left">t=2</td>
<td style="text-align:left">“出生”</td>
<td style="text-align:left">h₂（编码了 “我 出生”）</td>
<td style="text-align:left">“在”</td>
</tr>
<tr>
<td style="text-align:left">t=3</td>
<td style="text-align:left">“在”</td>
<td style="text-align:left">h₃（编码了 “我 出生 在”）</td>
<td style="text-align:left">“中国”</td>
</tr>
<tr>
<td style="text-align:left">t=4</td>
<td style="text-align:left">“中国”</td>
<td style="text-align:left">h₄（编码了 “我 出生 在 中国”）</td>
<td style="text-align:left">“，”</td>
</tr>
<tr>
<td style="text-align:left">t=5</td>
<td style="text-align:left">“，”</td>
<td style="text-align:left">h₅（编码了 “我 出生 在中国 ，”）</td>
<td style="text-align:left">“我”</td>
</tr>
<tr>
<td style="text-align:left">t=6</td>
<td style="text-align:left">“我”</td>
<td style="text-align:left">h₆（编码了前半句 +“我”）</td>
<td style="text-align:left">“会”</td>
</tr>
<tr>
<td style="text-align:left">t=7</td>
<td style="text-align:left">“会”</td>
<td style="text-align:left">h₇（编码了前半句 +“我 会”）</td>
<td style="text-align:left">“说”</td>
</tr>
<tr>
<td style="text-align:left">t=8</td>
<td style="text-align:left">“说”</td>
<td style="text-align:left">h₈（编码了前半句 +“我 会 说”）</td>
<td style="text-align:left">“中文”</td>
</tr>
</tbody>
</table>
<p>RNN 的隐藏状态 hₜ 起到了 **“记忆”** 的作用：</p>
<ul>
<li>当模型看到 “中国” 时，h₄ 已经编码了 “我出生在中国” 这个信息。</li>
<li>当模型看到后半句 “我会说中文” 时，h₈ 已经编码了<strong>整句话的上下文</strong>，因此它可以<strong>推断出 “中文” 是合理的下一个词</strong>，因为 “出生在中国” 和 “会说中文” 之间有<strong>语义关联</strong>。</li>
</ul>
<p>在 RNN 中，<strong>每个词 xₜ 是随时间输入的特征</strong>，<strong>隐藏状态 hₜ 是模型对 “到目前为止所有词” 的理解</strong>，而<strong>预测 yₜ 是基于这种理解做出的下一步判断</strong>。</p>
<h2 id="rnn与fcnn全连接神经网络的区别"><a class="markdownIt-Anchor" href="#rnn与fcnn全连接神经网络的区别">#</a> RNN 与 FCNN（全连接神经网络）的区别</h2>
<img data-src="../../images/RNN_LSTM/2.png" alt="1"/>
<p>左侧是 RNN，右侧是全连接神经网络。全连接神经网络是一个直筒的结构，RNN 是一个与时间有关的循环结构。</p>
<h3 id="fcnn的展开"><a class="markdownIt-Anchor" href="#fcnn的展开">#</a> FCNN 的展开</h3>
<img data-src="../../images/RNN_LSTM/3.png" alt="1"/>
<h3 id="rnn的展开"><a class="markdownIt-Anchor" href="#rnn的展开">#</a> RNN 的展开</h3>
<img data-src="../../images/RNN_LSTM/4.png" alt="1"/>
<h3 id="为什么"><a class="markdownIt-Anchor" href="#为什么">#</a> 为什么？</h3>
<p>FCNN 把每个输入当作<strong>独立静态向量</strong></p>
<p>RNN 把输入看成<strong>随时间展开的序列</strong>，用<strong>共享参数 + 循环隐状态</strong>来显式建模 “过去” 对 “现在” 的影响。</p>
<h2 id="数学表达"><a class="markdownIt-Anchor" href="#数学表达">#</a> 数学表达</h2>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><msub><mi>W</mi><mi>x</mi></msub><mo>+</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>h</mi></msub><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin {array}{c}
h_t = \tanh(x_t W_x + h_{t-1} W_h + b),
\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2000000000000002em;vertical-align:-0.35000000000000003em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mi>t</mi><mn>1</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mi>t</mi><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mi>t</mi><mn>3</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mi>t</mi><mn>4</mn></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mn>1</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mn>3</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mn>4</mn></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>11</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>12</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>13</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>14</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>21</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>22</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>23</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>24</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>31</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>32</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>33</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>34</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>41</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>42</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>43</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>h</mi><mn>44</mn></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>+</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mi>t</mi><mn>1</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mi>t</mi><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mi>t</mi><mn>3</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mi>t</mi><mn>4</mn></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>11</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>12</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>13</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>14</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>21</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>22</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>23</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>24</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>31</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>32</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>33</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>w</mi><mi>x</mi><mn>34</mn></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>+</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>b</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>b</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>b</mi><mn>3</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>b</mi><mn>4</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin {array}{c}
\begin{bmatrix}
h_t^1 &amp; h_t^2 &amp; h_t^3 &amp; h_t^4
\end{bmatrix}
=
\tanh(
\begin{bmatrix}
h_{t-1}^1 &amp; h_{t-1}^2 &amp; h_{t-1}^3 &amp; h_{t-1}^4
\end{bmatrix}
\begin{bmatrix}
w_h^{11} &amp; w_h^{12} &amp; w_h^{13} &amp; w_h^{14} \\
w_h^{21} &amp; w_h^{22} &amp; w_h^{23} &amp; w_h^{24} \\
w_h^{31} &amp; w_h^{32} &amp; w_h^{33} &amp; w_h^{34} \\
w_h^{41} &amp; w_h^{42} &amp; w_h^{43} &amp; w_h^{44}
\end{bmatrix}
+
\begin{bmatrix}
x_t^1 &amp; x_t^2 &amp; x_t^3 &amp; x_t^4
\end{bmatrix}
\begin{bmatrix}
w_x^{11} &amp; w_x^{12} &amp; w_x^{13} &amp; w_x^{14} \\
w_x^{21} &amp; w_x^{22} &amp; w_x^{23} &amp; w_x^{24} \\
w_x^{31} &amp; w_x^{32} &amp; w_x^{33} &amp; w_x^{34}
\end{bmatrix}
+
\begin{bmatrix}
b_1 &amp; b_2 &amp; b_3 &amp; b_4
\end{bmatrix}
)
\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.80303em;vertical-align:-2.151515em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.651515em;"><span style="top:-4.651515em;"><span class="pstrut" style="height:4.653em;"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999998em;"><span style="top:-2.451892em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30643899999999996em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999998em;"><span style="top:-2.451892em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30643899999999996em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999998em;"><span style="top:-2.451892em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30643899999999996em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999998em;"><span style="top:-2.451892em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30643899999999996em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6529999999999996em;"><span style="top:-1.6499900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.79999em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.3959900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.4119800000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.653em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15003em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6500000000000004em;"><span style="top:-4.8100000000000005em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.2099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6500000000000004em;"><span style="top:-4.8100000000000005em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.2099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6500000000000004em;"><span style="top:-4.8100000000000005em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.2099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6500000000000004em;"><span style="top:-4.8100000000000005em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.2099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6529999999999996em;"><span style="top:-1.6499900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.79999em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.3959900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.4119800000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.653em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15003em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0510099999999998em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.8099900000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.05101em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0510099999999998em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.8099900000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.05101em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.151515em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
<h2 id="权重共享"><a class="markdownIt-Anchor" href="#权重共享">#</a> 权重共享</h2>
<p>权重共享” 是 RNN 与 CNN 里最常被提到的一个核心设计，但它<strong>不是 “所有神经元共用同一个数”</strong>，而是<strong>同一组参数（矩阵 / 向量）在多个位置、多个时间步或空间位置反复使用</strong>。</p>
<h2 id="双向rnn"><a class="markdownIt-Anchor" href="#双向rnn">#</a> 双向 RNN</h2>
<p>双向递归神经网络（Bidirectional Recurrent Neural Network，简称 Bi-RNN）是一种特殊的递归神经网络（RNN），它在处理序列数据时，不仅考虑了过去的信息，还考虑了未来的信息。这使得 Bi-RNN 在处理诸如自然语言处理（NLP）任务时特别有用，因为它能够同时利用上下文信息。</p>
<h2 id="在pytorch使用rnn"><a class="markdownIt-Anchor" href="#在pytorch使用rnn">#</a> 在 PyTorch 使用 RNN</h2>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 双层双向 RNN</span></pre></td></tr><tr><td data-num="4"></td><td><pre>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># shape: (batch, seq_len, input_size)</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>output<span class="token punctuation">,</span> hn <span class="token operator">=</span> rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>hn<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr></table></figure><blockquote>
<p>torch.Size([2, 4, 8])<br>
torch.Size([4, 2, 4])</p>
</blockquote>
<h2 id="词嵌入层api应用"><a class="markdownIt-Anchor" href="#词嵌入层api应用">#</a> 词嵌入层 API 应用</h2>
<h3 id="作用"><a class="markdownIt-Anchor" href="#作用">#</a> 作用</h3>
<p>把词或词对应的索引转为词向量</p>
<h3 id="使用框架实现"><a class="markdownIt-Anchor" href="#使用框架实现">#</a> 使用框架实现</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">def</span> <span class="token function">dm01</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    text <span class="token operator">=</span> <span class="token string">"当您登录平台即表示您接受本隐私政策的全部内容，并同意平台按本政策收集、使用和保护您的相关个人信息。"</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token triple-quoted-string string">'''</pre></td></tr><tr><td data-num="11"></td><td><pre>    len(words) : 词表大小</pre></td></tr><tr><td data-num="12"></td><td><pre>    embedding_dim : 词向量维度</pre></td></tr><tr><td data-num="13"></td><td><pre>    '''</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token comment"># 词索引（张量）转变为词向量</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        word2Vec <span class="token operator">=</span> embed<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> word2Vec<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    dm01<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="rnn的api使用"><a class="markdownIt-Anchor" href="#rnn的api使用">#</a> RNN 的 API 使用</h2>
<p>RNN 就像是你的大脑，在看电影的过程中记住剧情。</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token triple-quoted-string string">'''</pre></td></tr><tr><td data-num="5"></td><td><pre>input_size：词向量的维度</pre></td></tr><tr><td data-num="6"></td><td><pre>hidden_size：隐藏状态的维度</pre></td></tr><tr><td data-num="7"></td><td><pre>num_layers：隐藏层数</pre></td></tr><tr><td data-num="8"></td><td><pre>batch_first：批次优先</pre></td></tr><tr><td data-num="9"></td><td><pre>'''</span></pre></td></tr><tr><td data-num="10"></td><td><pre>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token triple-quoted-string string">'''</pre></td></tr><tr><td data-num="12"></td><td><pre>5：有5个词</pre></td></tr><tr><td data-num="13"></td><td><pre>3：3个批次</pre></td></tr><tr><td data-num="14"></td><td><pre>10：每个词的细节是10维度</pre></td></tr><tr><td data-num="15"></td><td><pre>'''</span></pre></td></tr><tr><td data-num="16"></td><td><pre>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token triple-quoted-string string">'''</pre></td></tr><tr><td data-num="18"></td><td><pre>1：隐藏层层数</pre></td></tr><tr><td data-num="19"></td><td><pre>3：句子数量</pre></td></tr><tr><td data-num="20"></td><td><pre>20：有20个循环维度，也就是隐藏状态的维度</pre></td></tr><tr><td data-num="21"></td><td><pre>'''</span></pre></td></tr><tr><td data-num="22"></td><td><pre>h0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token triple-quoted-string string">'''</pre></td></tr><tr><td data-num="25"></td><td><pre>RNN处理</pre></td></tr><tr><td data-num="26"></td><td><pre>x：本次的输入</pre></td></tr><tr><td data-num="27"></td><td><pre>h0：上一次的隐藏状态</pre></td></tr><tr><td data-num="28"></td><td><pre>输出</pre></td></tr><tr><td data-num="29"></td><td><pre>output：每个时间步的输出，包含了所有时间步骤的隐藏状态</pre></td></tr><tr><td data-num="30"></td><td><pre>h1：最后一次隐藏状态，大脑里最新的剧情</pre></td></tr><tr><td data-num="31"></td><td><pre>'''</span></pre></td></tr><tr><td data-num="32"></td><td><pre>output<span class="token punctuation">,</span> h1 <span class="token operator">=</span> rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h0<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'output_shape:</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'h1_shape:</span><span class="token interpolation"><span class="token punctuation">&#123;</span>h1<span class="token punctuation">.</span>shape<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="rnn的文本生成"><a class="markdownIt-Anchor" href="#rnn的文本生成">#</a> RNN 的文本生成</h2>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># _*_ coding : utf-8 _*_</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># @Time : 2025/10/31 10:02</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># @Author : KarryLiu</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># File : 歌词生成</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># @Project : pytorchSTU</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">import</span> math</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">import</span> time</pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm</pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token triple-quoted-string string">"""</pre></td></tr><tr><td data-num="18"></td><td><pre>实现步骤：</pre></td></tr><tr><td data-num="19"></td><td><pre>    1. 获取数据，进行分词</pre></td></tr><tr><td data-num="20"></td><td><pre>    2. 获取词表，构建数据集</pre></td></tr><tr><td data-num="21"></td><td><pre>    3. 搭建RNN神经网络模型</pre></td></tr><tr><td data-num="22"></td><td><pre>    4. 训练模型</pre></td></tr><tr><td data-num="23"></td><td><pre>    5. 模型预测</pre></td></tr><tr><td data-num="24"></td><td><pre>    6. 测试</pre></td></tr><tr><td data-num="25"></td><td><pre>"""</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token keyword">def</span> <span class="token function">build_vocab</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    unique_words<span class="token punctuation">,</span> all_words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/jaychou_lyrics.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token keyword">for</span> line <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>f<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">'正在处理数据'</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">5819</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>            words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>line<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>            all_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>words<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="35"></td><td><pre>                <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> unique_words<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                    unique_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    word2index <span class="token operator">=</span> <span class="token punctuation">&#123;</span>word<span class="token punctuation">:</span> index <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>unique_words<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    index2word <span class="token operator">=</span> <span class="token punctuation">&#123;</span>index<span class="token punctuation">:</span> word <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>unique_words<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token comment"># 将词表转为索引，【0，1，2，3】，这个是一句歌词</span></pre></td></tr><tr><td data-num="42"></td><td><pre>    corpus_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token keyword">for</span> all_word <span class="token keyword">in</span> all_words<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        tmp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        <span class="token keyword">for</span> word <span class="token keyword">in</span> all_word<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="46"></td><td><pre>            tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="47"></td><td><pre>        tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word2index<span class="token punctuation">[</span><span class="token string">' '</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>        corpus_idx<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    word_count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>unique_words<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>    <span class="token keyword">return</span> unique_words<span class="token punctuation">,</span> word2index<span class="token punctuation">,</span> word_count<span class="token punctuation">,</span> corpus_idx</pre></td></tr><tr><td data-num="51"></td><td><pre></pre></td></tr><tr><td data-num="52"></td><td><pre></pre></td></tr><tr><td data-num="53"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">LyricsDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="54"></td><td><pre></pre></td></tr><tr><td data-num="55"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> corpus_idx<span class="token punctuation">,</span> num_chars<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="56"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre>        self<span class="token punctuation">.</span>corpus_idx <span class="token operator">=</span> corpus_idx</pre></td></tr><tr><td data-num="58"></td><td><pre>        self<span class="token punctuation">.</span>num_chars <span class="token operator">=</span> num_chars</pre></td></tr><tr><td data-num="59"></td><td><pre>        self<span class="token punctuation">.</span>word_count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>corpus_idx<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="60"></td><td><pre>        self<span class="token punctuation">.</span>sentence_len <span class="token operator">=</span> self<span class="token punctuation">.</span>word_count <span class="token operator">//</span> num_chars</pre></td></tr><tr><td data-num="61"></td><td><pre></pre></td></tr><tr><td data-num="62"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="63"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sentence_len</pre></td></tr><tr><td data-num="64"></td><td><pre></pre></td></tr><tr><td data-num="65"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="66"></td><td><pre>        start <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>word_count <span class="token operator">-</span> self<span class="token punctuation">.</span>num_chars <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="67"></td><td><pre>        end <span class="token operator">=</span> start <span class="token operator">+</span> self<span class="token punctuation">.</span>num_chars</pre></td></tr><tr><td data-num="68"></td><td><pre>        sentence_x <span class="token operator">=</span> self<span class="token punctuation">.</span>corpus_idx<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="69"></td><td><pre>        sentence_y <span class="token operator">=</span> self<span class="token punctuation">.</span>corpus_idx<span class="token punctuation">[</span>start <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>end <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="70"></td><td><pre>        sentence_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>sentence_x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="71"></td><td><pre>        sentence_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>sentence_y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="72"></td><td><pre>        <span class="token keyword">return</span> sentence_x<span class="token punctuation">,</span> sentence_y</pre></td></tr><tr><td data-num="73"></td><td><pre></pre></td></tr><tr><td data-num="74"></td><td><pre></pre></td></tr><tr><td data-num="75"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">TextGenerator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="76"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> unique_words_count<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="77"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="78"></td><td><pre>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>unique_words_count<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="79"></td><td><pre>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="80"></td><td><pre>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> unique_words_count<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="81"></td><td><pre></pre></td></tr><tr><td data-num="82"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="83"></td><td><pre>        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="84"></td><td><pre>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embed<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="85"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="86"></td><td><pre>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden</pre></td></tr><tr><td data-num="87"></td><td><pre></pre></td></tr><tr><td data-num="88"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">init_hidden</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="89"></td><td><pre>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="90"></td><td><pre></pre></td></tr><tr><td data-num="91"></td><td><pre></pre></td></tr><tr><td data-num="92"></td><td><pre><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="93"></td><td><pre>    unique_words<span class="token punctuation">,</span> word2index<span class="token punctuation">,</span> unique_word_count<span class="token punctuation">,</span> corpus_idx <span class="token operator">=</span> build_vocab<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="94"></td><td><pre>    dataset <span class="token operator">=</span> LyricsDataset<span class="token punctuation">(</span>corpus_idx<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="95"></td><td><pre>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="96"></td><td><pre>    model <span class="token operator">=</span> TextGenerator<span class="token punctuation">(</span>unique_word_count<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="97"></td><td><pre>    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="98"></td><td><pre>    loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="99"></td><td><pre>    min_loss <span class="token operator">=</span> math<span class="token punctuation">.</span>inf</pre></td></tr><tr><td data-num="100"></td><td><pre>    loss <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="101"></td><td><pre>    total_loss <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="102"></td><td><pre>    iter_times <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="103"></td><td><pre>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="104"></td><td><pre>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tqdm<span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f'正在训练第</span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">轮'</span></span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="105"></td><td><pre>            hidden <span class="token operator">=</span> model<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="106"></td><td><pre>            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="107"></td><td><pre>            y <span class="token operator">=</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="108"></td><td><pre>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="109"></td><td><pre>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="110"></td><td><pre>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="111"></td><td><pre>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="112"></td><td><pre>            iter_times <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="113"></td><td><pre>            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="114"></td><td><pre></pre></td></tr><tr><td data-num="115"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'第</span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">轮，总损失：</span><span class="token interpolation"><span class="token punctuation">&#123;</span>total_loss <span class="token operator">/</span> iter_times<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="116"></td><td><pre>        <span class="token keyword">if</span> loss <span class="token operator">&lt;</span> min_loss<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="117"></td><td><pre>            min_loss <span class="token operator">=</span> loss</pre></td></tr><tr><td data-num="118"></td><td><pre>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model.pth'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="119"></td><td><pre></pre></td></tr><tr><td data-num="120"></td><td><pre></pre></td></tr><tr><td data-num="121"></td><td><pre><span class="token keyword">def</span> <span class="token function">eval</span><span class="token punctuation">(</span>start_word<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="122"></td><td><pre>    unique_words<span class="token punctuation">,</span> word2index<span class="token punctuation">,</span> unique_word_count<span class="token punctuation">,</span> corpus_idx <span class="token operator">=</span> build_vocab<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="123"></td><td><pre>    model <span class="token operator">=</span> TextGenerator<span class="token punctuation">(</span>unique_word_count<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="124"></td><td><pre>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="125"></td><td><pre>    hidden <span class="token operator">=</span> model<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="126"></td><td><pre>    word_index <span class="token operator">=</span> word2index<span class="token punctuation">[</span>start_word<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="127"></td><td><pre>    generate_sentence <span class="token operator">=</span> <span class="token punctuation">[</span>word_index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="128"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="129"></td><td><pre>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>word_index<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="130"></td><td><pre>        output <span class="token operator">=</span> output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="131"></td><td><pre>        word_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="132"></td><td><pre>        generate_sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word_index<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="133"></td><td><pre>    <span class="token keyword">for</span> e <span class="token keyword">in</span> <span class="token punctuation">[</span>unique_words<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> generate_sentence<span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="134"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="135"></td><td><pre></pre></td></tr><tr><td data-num="136"></td><td><pre></pre></td></tr><tr><td data-num="137"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="138"></td><td><pre>    train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="139"></td><td><pre>    <span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token string">'分手'</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span></pre></td></tr></table></figure><blockquote>
<p>分手的话像语言暴力你而香 牧草有没有 我马儿有些瘦<br>
天涯尽头 满脸风霜落寞 近乡情怯的我<br>
我说店小二 三两银够不够<br>
景色入秋 漫天黄沙凉过<br>
塞北的客栈人多 牧草有没有 我马儿有些瘦<br>
世事看透 江湖上潮起潮落 什么恩怨过错<br>
在多年以后 还是让人难过 心伤透<br>
娘子她人在江南等我 泪不休 语沉默</p>
</blockquote>
<h2 id="智能提示输入法的实现"><a class="markdownIt-Anchor" href="#智能提示输入法的实现">#</a> 智能提示输入法的实现</h2>
<h3 id="最佳实践"><a class="markdownIt-Anchor" href="#最佳实践">#</a> 最佳实践</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>__file__<span class="token punctuation">)</span></pre></td></tr></table></figure><p><strong>__ file __</strong> 是当前文件的绝对路径，py 在处理相对路径时可能会遇到问题，最好使用绝对路径。</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent <span class="token operator">/</span> <span class="token string">"data/raw/synthesized_.jsonl"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>所以我们通常会这样写：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>RAW_DATA_DIR <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent <span class="token operator">/</span> <span class="token string">"data/raw"</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始处理数据"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 读取原始文件</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span>RAW_DATA_DIR <span class="token operator">/</span> <span class="token string">"synthesized_.jsonl"</span><span class="token punctuation">,</span> lines<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                      encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据处理完成"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理">#</a> 数据预处理</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">import</span> config</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>sentences<span class="token punctuation">,</span> word2index<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"构建数据集"</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    indexed_sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>word2index<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sentences <span class="token keyword">in</span></pre></td></tr><tr><td data-num="11"></td><td><pre>                         sentences<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    dataset <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">for</span> index<span class="token punctuation">,</span> sentence <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>indexed_sentences<span class="token punctuation">)</span><span class="token punctuation">,</span> desc<span class="token operator">=</span>desc<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">-</span> config<span class="token punctuation">.</span>SWQ_LEN<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>            <span class="token builtin">input</span> <span class="token operator">=</span> sentence<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> config<span class="token punctuation">.</span>SWQ_LEN<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            target <span class="token operator">=</span> sentence<span class="token punctuation">[</span>i <span class="token operator">+</span> config<span class="token punctuation">.</span>SWQ_LEN<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            dataset<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="18"></td><td><pre>                <span class="token string">'input'</span><span class="token punctuation">:</span> <span class="token builtin">input</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                <span class="token string">'target'</span><span class="token punctuation">:</span> target<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>            <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">return</span> dataset</pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始处理数据"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token comment"># 读取原始文件</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span>config<span class="token punctuation">.</span>RAW_DATA_DIR <span class="token operator">/</span> <span class="token string">"synthesized_.jsonl"</span><span class="token punctuation">,</span> lines<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="28"></td><td><pre>                      encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token comment"># 提取句子</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">for</span> sentencesX <span class="token keyword">in</span> df<span class="token punctuation">[</span><span class="token string">'dialog'</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        <span class="token keyword">for</span> sentencesXs <span class="token keyword">in</span> sentencesX<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="33"></td><td><pre>            sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentencesXs<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'：'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"句子的数量为：</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token comment"># 划分数据集</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    train_sentences<span class="token punctuation">,</span> valid_sentences <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>sentences<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token comment"># 构建词表</span></pre></td></tr><tr><td data-num="38"></td><td><pre>    vocab_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token keyword">for</span> sentence <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>train_sentences<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">'构建词表'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        vocab_set<span class="token punctuation">.</span>update<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>    vocab_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;unk>'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>vocab_set<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"词表的数量为：</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token comment"># 保存此表</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>MODELS_DIR <span class="token operator">/</span> <span class="token string">"vocab.txt"</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="46"></td><td><pre></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token comment"># 构建训练集</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    word2index <span class="token operator">=</span> <span class="token punctuation">&#123;</span>word<span class="token punctuation">:</span> index <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    train_dataset <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>train_sentences<span class="token punctuation">,</span> word2index<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>    <span class="token comment"># 保存训练集</span></pre></td></tr><tr><td data-num="51"></td><td><pre>    pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">.</span>to_json<span class="token punctuation">(</span>config<span class="token punctuation">.</span>PROCESSED_DATA_DIR <span class="token operator">/</span> <span class="token string">"train.jsonl"</span><span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">,</span> lines<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre>    <span class="token comment"># 构建验证集</span></pre></td></tr><tr><td data-num="53"></td><td><pre>    valid_dataset <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>valid_sentences<span class="token punctuation">,</span> word2index<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token comment"># 保存验证集</span></pre></td></tr><tr><td data-num="55"></td><td><pre>    pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>valid_dataset<span class="token punctuation">)</span><span class="token punctuation">.</span>to_json<span class="token punctuation">(</span>config<span class="token punctuation">.</span>PROCESSED_DATA_DIR <span class="token operator">/</span> <span class="token string">"valid.jsonl"</span><span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">,</span> lines<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据处理完成"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="60"></td><td><pre>    process<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="数据集"><a class="markdownIt-Anchor" href="#数据集">#</a> 数据集</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> _T_co</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> src<span class="token punctuation">.</span>NLP<span class="token punctuation">.</span>SmartPrompt<span class="token punctuation">.</span>src <span class="token keyword">import</span> config</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># 定义 Dataset</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">InputMethodDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span>path<span class="token punctuation">,</span> lines<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span><span class="token string">'records'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> _T_co<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'input'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        target_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">return</span> input_tensor<span class="token punctuation">,</span> target_tensor</pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token comment"># 提供一个获取 DATALoader 的方法</span></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    path <span class="token operator">=</span> config<span class="token punctuation">.</span>PROCESSED_DATA_DIR <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token string">"train.jsonl"</span> <span class="token keyword">if</span> train <span class="token keyword">else</span> <span class="token string">"valid.jsonl"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    dataset <span class="token operator">=</span> InputMethodDataset<span class="token punctuation">(</span>path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">return</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    train_loader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    valid_loader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_loader<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">for</span> input_tensor<span class="token punctuation">,</span> target_tensor <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span>target_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token keyword">break</span></pre></td></tr></table></figure><h3 id="训练"><a class="markdownIt-Anchor" href="#训练">#</a> 训练</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> time</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">from</span> src<span class="token punctuation">.</span>NLP<span class="token punctuation">.</span>SmartPrompt<span class="token punctuation">.</span>src <span class="token keyword">import</span> config</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">from</span> src<span class="token punctuation">.</span>NLP<span class="token punctuation">.</span>SmartPrompt<span class="token punctuation">.</span>src<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> get_dataloader</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">from</span> src<span class="token punctuation">.</span>NLP<span class="token punctuation">.</span>SmartPrompt<span class="token punctuation">.</span>src<span class="token punctuation">.</span>model <span class="token keyword">import</span> InputMethodModel</pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">def</span> <span class="token function">train_onr_epoch</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloader<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token triple-quoted-string string">"""</pre></td></tr><tr><td data-num="15"></td><td><pre>    :param model: 模型</pre></td></tr><tr><td data-num="16"></td><td><pre>    :param dataloader: 数据集</pre></td></tr><tr><td data-num="17"></td><td><pre>    :param loss_fn: 损失函数</pre></td></tr><tr><td data-num="18"></td><td><pre>    :param optimizer: 优化器</pre></td></tr><tr><td data-num="19"></td><td><pre>    :param device: 设备</pre></td></tr><tr><td data-num="20"></td><td><pre>    :return: 损失值</pre></td></tr><tr><td data-num="21"></td><td><pre>    """</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>    total_loss <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"训练中"</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        features<span class="token punctuation">,</span> targets <span class="token operator">=</span> batch</pre></td></tr><tr><td data-num="26"></td><td><pre>        features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre>        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="38"></td><td><pre>    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    dataloader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>MODELS_DIR <span class="token operator">/</span> <span class="token string">'vocab.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        vocab_list <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        vocab_list <span class="token operator">=</span> <span class="token punctuation">[</span>vocab<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> vocab <span class="token keyword">in</span> vocab_list<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="43"></td><td><pre>    model <span class="token operator">=</span> InputMethodModel<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>LEARNING_RATE<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="46"></td><td><pre>    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span>log_dir<span class="token operator">=</span>config<span class="token punctuation">.</span>LOGS_DIR<span class="token operator">/</span>time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d_%H-%M-%S'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    bestLoss <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'inf'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">+</span> config<span class="token punctuation">.</span>EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="49"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>config<span class="token punctuation">.</span>EPOCHS<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> <span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>        loss <span class="token operator">=</span> train_onr_epoch<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloader<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss:</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre>        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">,</span> loss<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre>        <span class="token keyword">if</span> loss <span class="token operator">&lt;</span> bestLoss<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="54"></td><td><pre>            bestLoss <span class="token operator">=</span> loss</pre></td></tr><tr><td data-num="55"></td><td><pre>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span>MODELS_DIR <span class="token operator">/</span> <span class="token string">'model.pt'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="58"></td><td><pre>    train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="模型"><a class="markdownIt-Anchor" href="#模型">#</a> 模型</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> config</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">InputMethodModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>config<span class="token punctuation">.</span>EMBEDDING_DIM<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="10"></td><td><pre>            input_size<span class="token operator">=</span>config<span class="token punctuation">.</span>EMBEDDING_DIM<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>            hidden_size<span class="token operator">=</span>config<span class="token punctuation">.</span>HIDDEN_SIZE<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>config<span class="token punctuation">.</span>HIDDEN_SIZE<span class="token punctuation">,</span> out_features<span class="token operator">=</span>vocab_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        last_hidden_state <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>last_hidden_state<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr></table></figure><h3 id="预测"><a class="markdownIt-Anchor" href="#预测">#</a> 预测</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> src<span class="token punctuation">.</span>NLP<span class="token punctuation">.</span>SmartPrompt<span class="token punctuation">.</span>src <span class="token keyword">import</span> config</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> src<span class="token punctuation">.</span>NLP<span class="token punctuation">.</span>SmartPrompt<span class="token punctuation">.</span>src<span class="token punctuation">.</span>model <span class="token keyword">import</span> InputMethodModel</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>MODELS_DIR <span class="token operator">/</span> <span class="token string">'vocab.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    vocab_list <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    vocab_list <span class="token operator">=</span> <span class="token punctuation">[</span>vocab<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> vocab <span class="token keyword">in</span> vocab_list<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>word2index <span class="token operator">=</span> <span class="token punctuation">&#123;</span>word<span class="token punctuation">:</span> index <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="14"></td><td><pre>index2word <span class="token operator">=</span> <span class="token punctuation">&#123;</span>index<span class="token punctuation">:</span> word <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="15"></td><td><pre>model <span class="token operator">=</span> InputMethodModel<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">.</span>MODELS_DIR <span class="token operator">/</span> <span class="token string">'model.pt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    tokens <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">[</span>word2index<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    input_tenosr <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">input</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        output <span class="token operator">=</span> model<span class="token punctuation">(</span>input_tenosr<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    topk <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>output<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>indices<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token keyword">return</span> <span class="token punctuation">[</span>index2word<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> topk<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    user_str <span class="token operator">=</span> <span class="token string">''</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token keyword">while</span> user_str <span class="token operator">!=</span> <span class="token string">'q'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        now_str <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"请输入："</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        user_str <span class="token operator">+=</span> now_str</pre></td></tr><tr><td data-num="35"></td><td><pre>        <span class="token keyword">if</span> now_str<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'q'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="36"></td><td><pre>            <span class="token keyword">break</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        top5_tokens <span class="token operator">=</span> predict<span class="token punctuation">(</span>user_str<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span>top5_tokens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"当前输入："</span><span class="token punctuation">,</span> user_str<span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="lstm"><a class="markdownIt-Anchor" href="#lstm">#</a> LSTM</h2>
<p>LSTM 灵感来原与计算机逻辑门。</p>
<img data-src="../../images/RNN_LSTM/6.png" alt="1"/>
<p>图片来源于：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMjM4NTc1Njk=">LSTM - 长短期记忆递归神经网络 - 知乎</span></p>
<p>遗忘门：主要负责遗忘过去的记忆信息，最重要的是要去结合当下的状态信息去处理。</p>
<p>输入门：输入门主要负责现在要记下什么，可以看到在输入门的右侧还有一个 tanh 的激活函数，</p>
<p>输出门：</p>
<img data-src="../../images/RNN_LSTM/7.png" alt="1"/>
<h3 id="双向结构"><a class="markdownIt-Anchor" href="#双向结构">#</a> 双向结构</h3>
<img data-src="../../images/RNN_LSTM/8.png" alt="1"/>
<h2 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制">#</a> 注意力机制</h2>
<p>注意力机制的起源，是因为我们往往会聚焦于重要的信息。</p>
<p>怎么做？</p>
<p>我（查询对象 Q），这张图（被查询对象 V）</p>
<p>我看一眼这张图，我就会去判断哪些东西对我而言是重要的，那些东西对我来说是是不重要的（去计算 Q 和 V 里的事物重要程度）。</p>
<p>图片来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbmlja2NoZW4xMjEvcC8xNjQ3MDcxMC5odG1s">https://www.cnblogs.com/nickchen121/p/16470710.html</span></p>
<p><img data-src="https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png" alt="注意力机制"></p>
<p>解码器在生成目标序列的每一步时，不再依赖于一个静态的上下文向量，而是根据当前的解码状态，动态地从编码器各个时间步的隐藏状态中选取最相关的信息，以辅助当前步生成。</p>
<p>这种机制语法赋予模型对齐的能力，使其能够自动判断源句子中那些位置对当前目标词更为重要，从而有效缓解信息瓶颈问题，提升生成质量与表达能力。</p>
<img data-src="../../images/RNN_LSTM/11.png" alt="1"/>
<p>注意力机制实际上是在动态的提取当先最需要关心的数据。</p>
<p>这一机制通常以下四个步骤来完成。</p>
<ol>
<li>相关性计算</li>
<li>注意力权重计算</li>
<li>上下文向量计算</li>
<li>解码信息融合</li>
</ol>
<h3 id="相关性计算"><a class="markdownIt-Anchor" href="#相关性计算">#</a> 相关性计算</h3>
<p>相关性的计算依赖于特定的函数，通常被称为注意力评分函数。</p>
<img data-src="../../images/RNN_LSTM/12.png" alt="1"/>
<h3 id="注意力权重计算"><a class="markdownIt-Anchor" href="#注意力权重计算">#</a> 注意力权重计算</h3>
<p>得到所有源位置的注意力评分后，使用 Softmax 函数将其归一化为概率分布，作为注意力权重。得分越高的位置，其对应的权重越大，代表模型在当前生成中更关注该位置的信息。</p>
<img data-src="../../images/RNN_LSTM/13.png" alt="1"/>
<h3 id="上下文向量计算"><a class="markdownIt-Anchor" href="#上下文向量计算">#</a> 上下文向量计算</h3>
<p>将所有编码器输出按照注意力权重进行加权求和，得到一个上下文向量。这个向量就表示当前时间步，模型从源句中提取出的关键信息。</p>
<img data-src="../../images/RNN_LSTM/14.png" alt="1"/>
<h3 id="解码信息融合"><a class="markdownIt-Anchor" href="#解码信息融合">#</a> 解码信息融合</h3>
<p>在得到上下文向量后，解码器将其与当前时间步的隐藏状态进行拼接，以融合两者信息，最终通过线性变换和 Softmax，生成当前时间步目标词的概率分布。</p>
<img data-src="../../images/RNN_LSTM/15.png" alt="1"/>
<h2 id="注意力评分函数"><a class="markdownIt-Anchor" href="#注意力评分函数">#</a> 注意力评分函数</h2>
<h3 id="点积评分"><a class="markdownIt-Anchor" href="#点积评分">#</a> 点积评分</h3>
<p>它通过计算解码器当前时间步的隐藏状态与编码器每个时间步的隐藏状态的点积，来衡量二者之间的相关性。</p>
<h3 id="通用点积评分"><a class="markdownIt-Anchor" href="#通用点积评分">#</a> 通用点积评分</h3>
<p>通用点积评分在点积的基础上引入了一个可学习的权重矩阵 W, 用于先对编码器隐藏状态进行线性变换，再与解码器隐藏状态进行点积。</p>
<h3 id="拼接评分"><a class="markdownIt-Anchor" href="#拼接评分">#</a> 拼接评分</h3>
<p>拼接评分是一种表达能力更强的相关性评分方法。它的核心思想是：将解码器当前隐藏状态与编码器每个时间步的隐藏状态拼接为一个长向量，经过线性变换和非线性激活，最后用一个向量进行投影，得到最终打分值。</p>
<img data-src="../../images/RNN_LSTM/16.png" alt="1"/>
<h2 id="transformer"><a class="markdownIt-Anchor" href="#transformer">#</a> Transformer</h2>
<img data-src="../../images/paper/attention_iayn/1.png" alt="111" style="zoom:50%;" />
<p>Transformer 其实就是 Attention 的一个堆叠。</p>
<h3 id="transformer主要是在做什么"><a class="markdownIt-Anchor" href="#transformer主要是在做什么">#</a> Transformer 主要是在做什么</h3>
<p>把一个输入序列（如一段文字、一段语音、或一张图片的特征序列）——<strong> 编码成表示语义的向量序列</strong>，然后（可选）<strong>再解码出另一个序列</strong>。Transformer 不是一个单纯的 “算法”，而是一个<strong>序列建模框架</strong>。 它最擅长的事是：<strong>理解上下文中的关系，并基于此生成输出。</strong></p>
<img data-src="../../images/RNN_LSTM/17.png" alt="1"/>
<h3 id="transformer的encoder"><a class="markdownIt-Anchor" href="#transformer的encoder">#</a> Transformer 的 Encoder</h3>
<p>Transformer 的 Encoder 由 <strong>N 层堆叠的结构（通常是 6 层）</strong> 组成，每一层的结构几乎一样，每层包含两个主要子层：</p>
<pre><code>输入 → [多头自注意力机制] → [前馈神经网络] → 输出
</code></pre>
<p>并且每个子层后都有：</p>
<ul>
<li><strong>残差连接（Residual Connection）</strong></li>
<li><strong>层归一化（Layer Normalization）</strong></li>
</ul>
<p><strong>RNN</strong>：逐个时间步处理序列，有记忆但慢。</p>
<p><strong>Transformer Encoder</strong>：一次性处理全序列，通过注意力机制 “并行感知” 所有词之间的关系，速度快、效果好。</p>
<p>说白了还是在弄一个词向量，只不过这个词向量更加优秀！！</p>
<p>每个 Encoder Layer 都包含两个子层（sublayer），分别是自注意力子层（Self-Attention Sublayer）和前馈神经网络子层（Feed-Forward Sublayer）。</p>
<img data-src="../../images/RNN_LSTM/18.png" alt="1"/>
<h4 id="自注意力层"><a class="markdownIt-Anchor" href="#自注意力层">#</a> 自注意力层</h4>
<p>自注意力机制的第一步，是将输入序列中的每个位置表示映射为三个不同的向量，分别是 查询（Query）、键（Key） 和 值（Value）。</p>
<img data-src="../../images/RNN_LSTM/19.png" alt="1"/>
<p>Query：表示当前词的用于发起注意力匹配的向量；</p>
<p>Key：表示序列中每个位置的内容标识，用于与 Query 进行匹配；</p>
<p>Value：表示该位置携带的信息，用于加权汇总得到新的表示。</p>
<p>自注意力的核心思想是：每个位置用自身的 Query 向量，与整个序列中所有位置的 Key 向量进行相关性计算，从而得到注意力权重，并据此对对应的 Value 向量加权汇总，形成新的表示。</p>
<p>完成 Query、Key、Value 向量的生成后，模型会使用每个位置的 Query 向量与所有位置的 Key 向量进行相关性评分。</p>
<p>在得到每个位置与所有位置之间的相关性评分后，模型会使用 softmax 函数进行归一化，确保每个位置对所有位置的关注程度之和为 1，从而形成一个有效的加权分布。对于整个序列，模型要做的是对之前得到的注意力评分矩阵的<strong>每一行</strong>进行 softmax 归一化。</p>
<img data-src="../../images/RNN_LSTM/21.png" alt="1"/>
<img data-src="../../images/RNN_LSTM/20.png" alt="1"/>
<p>综上：</p>
<img data-src="../../images/RNN_LSTM/22.png" alt="1"/>
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$
<h4 id="前馈神经网络层"><a class="markdownIt-Anchor" href="#前馈神经网络层">#</a> 前馈神经网络层</h4>
<img data-src="../../images/RNN_LSTM/23.png" alt="1"/>
<h3 id="transformer的decoder"><a class="markdownIt-Anchor" href="#transformer的decoder">#</a> Transformer 的 Decoder</h3>
<p>解码器接收编码器生成的词向量，然后通过这个词向量生成翻译的结果。</p>
<h3 id="注意力与多头注意力"><a class="markdownIt-Anchor" href="#注意力与多头注意力">#</a> 注意力与多头注意力</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> math</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">SelfAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>  <span class="token comment"># 对 10% 的数据进行 dropout，防止模型过拟合</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 对最后一维进行 softmax，为什么是最后一个维度？</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token comment"># 因为是多头注意力机制，所以是多个头，每个头对输入进行 softmax</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token comment"># X: [batch_size, seq_len, d_model]</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token comment"># batch_size: 批次大小，一次送几个句子</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        <span class="token comment"># seq_len: 序列长度，一个句子中的 Token 数量</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token comment"># d_model: 模型维度，这是个 Embedding 向量的维度</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token comment"># Q：query 向量     [batch_size, heads, seq_len_q, d_k]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token comment"># K：key 向量       [batch_size, heads, seq_len_k, d_k]</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token comment"># V：values 向量    [batch_size, heads, seq_len) v, d_v]</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        <span class="token comment"># mask：掩码向量    [batch_size, seq_len, seq_len]   mask 的意义是那些需要忽略，不要看见未来的信息</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        d_k <span class="token operator">=</span> Q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token comment"># Q：                [batch_size, heads, seq_len_q, d_k]       seq_len_q, d_k</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        <span class="token comment"># K.T:               [batch_size, heads, d_k, seq_len_k]      d_k, seq_len_k</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        <span class="token comment"># attention_scores： [batch_size, heads, seq_len_q, seq_len_k]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        attention_scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>d_k<span class="token punctuation">)</span>  <span class="token comment"># (Q·K.T)/sqrt(d_k)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token comment"># 如果提供了 mask，masked_fill 则将 mask 中的值为 0 的元素替换为负无穷大</span></pre></td></tr><tr><td data-num="29"></td><td><pre>        <span class="token keyword">if</span> mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="30"></td><td><pre>            attention_scores <span class="token operator">=</span> attention_scores<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>mask <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'-inf'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token comment"># 获取注意力权重，对最后一位进行 softmax</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        attn <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>attention_scores<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        attn <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attn<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        <span class="token comment"># 获取注意力结果，对 V 进行矩阵乘法，[batch_size, heads, seq_len_q, d_v]</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>attn<span class="token punctuation">,</span> V<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> attn</pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> n_heads<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        <span class="token comment"># d_model: 模型维度，这是个 Embedding 向量的维度，一般是 512</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        <span class="token comment"># n_heads: 多头注意力机制的个数，一般是 8</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        <span class="token keyword">assert</span> d_model <span class="token operator">%</span> n_heads <span class="token operator">==</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        self<span class="token punctuation">.</span>d_k <span class="token operator">=</span> d_model <span class="token operator">//</span> n_heads</pre></td></tr><tr><td data-num="47"></td><td><pre>        self<span class="token punctuation">.</span>n_heads <span class="token operator">=</span> n_heads</pre></td></tr><tr><td data-num="48"></td><td><pre>        self<span class="token punctuation">.</span>W_q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="49"></td><td><pre>        self<span class="token punctuation">.</span>W_k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>        self<span class="token punctuation">.</span>W_v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre>        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> SelfAttention<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre>        self<span class="token punctuation">.</span>layer_norm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="54"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="55"></td><td><pre></pre></td></tr><tr><td data-num="56"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="57"></td><td><pre>        batch_size <span class="token operator">=</span> q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre>        <span class="token comment"># Q: [batch_size, seq_len, d_model] -> [batch_size, n_heads, seq_len, d_k]</span></pre></td></tr><tr><td data-num="59"></td><td><pre>        <span class="token comment"># 为了获取多头注意力，需要将输入进行分割，分割成多个头，每个头对输入进行计算，然后进行拼接</span></pre></td></tr><tr><td data-num="60"></td><td><pre>        Q <span class="token operator">=</span> self<span class="token punctuation">.</span>W_q<span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_k<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="61"></td><td><pre>        K <span class="token operator">=</span> self<span class="token punctuation">.</span>W_k<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_k<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="62"></td><td><pre>        V <span class="token operator">=</span> self<span class="token punctuation">.</span>W_v<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_k<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="63"></td><td><pre>        output<span class="token punctuation">,</span> attn <span class="token operator">=</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> mask<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="64"></td><td><pre>        output <span class="token operator">=</span> output<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_heads <span class="token operator">*</span> self<span class="token punctuation">.</span>d_k<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="65"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="66"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>layer_norm<span class="token punctuation">(</span>q <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="67"></td><td><pre>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> attn</pre></td></tr></table></figure><h3 id="torch中使用transformerapi"><a class="markdownIt-Anchor" href="#torch中使用transformerapi">#</a> Torch 中使用 TransformerAPI</h3>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Transformer<span class="token punctuation">(</span>d_model<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="2"></td><td><pre>                     nhead<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="3"></td><td><pre>                     num_encoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="4"></td><td><pre>                     num_decoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="5"></td><td><pre>                     dim_feedforward<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="6"></td><td><pre>                     dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="7"></td><td><pre>                     activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="8"></td><td><pre>                     custom_encoder<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="9"></td><td><pre>                     custom_decoder<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="10"></td><td><pre>                     layer_norm_eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="11"></td><td><pre>                     batch_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="12"></td><td><pre>                     norm_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="13"></td><td><pre>                     bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="14"></td><td><pre>                     device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="15"></td><td><pre>                     dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="transformer-2"><a class="markdownIt-Anchor" href="#transformer-2">#</a> transformer</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 初始化 Transformer</span></pre></td></tr><tr><td data-num="4"></td><td><pre>transformer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Transformer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  d_model<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="6"></td><td><pre>  nhead<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="7"></td><td><pre>  num_encoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="8"></td><td><pre>  num_decoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="9"></td><td><pre>  batch_first<span class="token operator">=</span><span class="token boolean">True</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="forward"><a class="markdownIt-Anchor" href="#forward">#</a> forward</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>output <span class="token operator">=</span> transformer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    src<span class="token operator">=</span>src_emb<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    tgt<span class="token operator">=</span>tgt_emb<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    src_key_padding_mask<span class="token operator">=</span>src_pad_mask<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    tgt_key_padding_mask<span class="token operator">=</span>tgt_pad_mask<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    tgt_mask<span class="token operator">=</span>tgt_mask<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    memory_key_padding_mask<span class="token operator">=</span>src_pad_mask</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="encoder"><a class="markdownIt-Anchor" href="#encoder">#</a> encoder</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 初始化 Transformer</span></pre></td></tr><tr><td data-num="4"></td><td><pre>transformer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Transformer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    d_model<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> nhead<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    num_encoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> num_decoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    batch_first<span class="token operator">=</span><span class="token boolean">True</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment"># 调用编码器</span></pre></td></tr><tr><td data-num="11"></td><td><pre>memory <span class="token operator">=</span> transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    src<span class="token operator">=</span>src_emb<span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="13"></td><td><pre>    src_key_padding_mask<span class="token operator">=</span>src_pad_mask</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="decoder"><a class="markdownIt-Anchor" href="#decoder">#</a> decoder</h4>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 初始化 Transformer</span></pre></td></tr><tr><td data-num="4"></td><td><pre>transformer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Transformer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    d_model<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> nhead<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    num_encoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> num_decoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    batch_first<span class="token operator">=</span><span class="token boolean">True</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment"># 调用编码器</span></pre></td></tr><tr><td data-num="11"></td><td><pre>memory <span class="token operator">=</span> transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    src<span class="token operator">=</span>src_emb<span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="13"></td><td><pre>    src_key_padding_mask<span class="token operator">=</span>src_pad_mask</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># 调用解码器（逐步生成）</span></pre></td></tr><tr><td data-num="17"></td><td><pre>output <span class="token operator">=</span> transformer<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    tgt<span class="token operator">=</span>tgt_emb<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    memory<span class="token operator">=</span>memory<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    tgt_mask<span class="token operator">=</span>tgt_mask<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    tgt_key_padding_mask<span class="token operator">=</span>tgt_pad_mask<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    memory_key_padding_mask<span class="token operator">=</span>src_pad_mask</pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献">#</a> 参考文献</h1>
<ol>
<li>【[手把手教学] 基于 RNN、LSTM 神经网络单特征用电负荷预测】<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUhONHkxWTdMdA==">https://www.bilibili.com/video/BV1HN4y1Y7Lt</span></li>
<li>【尚硅谷 NLP 教程，nlp 自然语言处理，Transformer、LSTM、BERT 等大模型技术全覆盖】<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWs0NEx6UEVoVQ==">https://www.bilibili.com/video/BV1k44LzPEhU</span></li>
<li>【Word2Vec 模型、Attention、Transformer 】<span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzgzNTUxNTE4">https://space.bilibili.com/383551518</span></li>
<li>【Transformer 模型详解（图解最完整版）】<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMzg4MTc2ODA=">https://zhuanlan.zhihu.com/p/338817680</span></li>
<li>【黑马程序员 AI 大模型《神经网络与深度学习》】<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWM1eXJCY0VFWA==">https://www.bilibili.com/video/BV1c5yrBcEEX</span></li>
</ol>

      <div class="tags">
          <a href="/tags/python/" rel="tag"><i class="ic i-tag"></i> python</a>
          <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 深度学习</a>
          <a href="/tags/RNN/" rel="tag"><i class="ic i-tag"></i> RNN</a>
          <a href="/tags/LSTM/" rel="tag"><i class="ic i-tag"></i> LSTM</a>
          <a href="/tags/NLP/" rel="tag"><i class="ic i-tag"></i> NLP</a>
          <a href="/tags/GRU/" rel="tag"><i class="ic i-tag"></i> GRU</a>
          <a href="/tags/Transformer/" rel="tag"><i class="ic i-tag"></i> Transformer</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2026-01-03 21:49:17" itemprop="dateModified" datetime="2026-01-03T21:49:17+08:00">2026-01-03</time>
  </span>
  <span id="python/NLP/" class="item leancloud_visitors" data-flag-title="NLP自然语言处理" title="阅读次数">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">阅读次数</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">次</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> 赞赏</button>
  <p>请我喝[茶]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/myWxPay.jpg" alt="KarryLiu 微信支付">
        <p>微信支付</p>
      </div>
      
      <div>
        <img data-src="/images/myAliPay.jpg" alt="KarryLiu 支付宝">
        <p>支付宝</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>本文作者： </strong>KarryLiu <i class="ic i-at"><em>@</em></i>诗岸梦行舟
  </li>
  <li class="link">
    <strong>本文链接：</strong>
    <a href="https://735690757.github.io/python/NLP/" title="NLP自然语言处理">https://735690757.github.io/python/NLP/</a>
  </li>
  <li class="license">
    <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/python/CNN_Acc/" itemprop="url" rel="prev" data-background-image="&#x2F;images&#x2F;cover&#x2F;cnn.jpg" title="CNN经典卷积神经网络与实战">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> 基础</span>
  <h3>CNN经典卷积神经网络与实战</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/python/DLFromFormula/" itemprop="url" rel="next" data-background-image="&#x2F;images&#x2F;cover&#x2F;dlff.jpg" title="从公式角度看深度学习">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> 基础</span>
  <h3>从公式角度看深度学习</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#nlp%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text"> NLP 自然语言处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.1.</span> <span class="toc-text"> 常见任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.2.</span> <span class="toc-text"> 文本表示</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E8%AF%8D"><span class="toc-number">1.2.1.</span> <span class="toc-text"> 分词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#jiebba%E5%88%86%E8%AF%8D%E7%BB%84%E4%BB%B6"><span class="toc-number">1.2.2.</span> <span class="toc-text"> JiebBa 分词组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%8D%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.2.3.</span> <span class="toc-text"> 词表示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#word2vec"><span class="toc-number">1.2.4.</span> <span class="toc-text"> Word2Vec</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gensim%E8%AF%8D%E5%90%91%E9%87%8F%E7%BB%84%E4%BB%B6"><span class="toc-number">1.2.5.</span> <span class="toc-text"> GENSIM 词向量组件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%85%AC%E5%BC%80%E8%AF%8D%E5%90%91%E9%87%8F"><span class="toc-number">1.2.5.1.</span> <span class="toc-text"> 加载与使用公开词向量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AF%8D%E5%90%91%E9%87%8F"><span class="toc-number">1.2.5.2.</span> <span class="toc-text"> 训练自己的词向量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">1.2.5.3.</span> <span class="toc-text"> 词向量的应用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#elmo%E6%A8%A1%E5%9E%8B%E4%B8%80%E8%AF%8D%E5%A4%9A%E4%B9%89%E9%97%AE%E9%A2%98"><span class="toc-number">1.2.6.</span> <span class="toc-text"> ELMo 模型 —— 一词多义问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text"> RNN 基本结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E4%B8%8Efcnn%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.4.</span> <span class="toc-text"> RNN 与 FCNN（全连接神经网络）的区别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fcnn%E7%9A%84%E5%B1%95%E5%BC%80"><span class="toc-number">1.4.1.</span> <span class="toc-text"> FCNN 的展开</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rnn%E7%9A%84%E5%B1%95%E5%BC%80"><span class="toc-number">1.4.2.</span> <span class="toc-text"> RNN 的展开</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88"><span class="toc-number">1.4.3.</span> <span class="toc-text"> 为什么？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E8%A1%A8%E8%BE%BE"><span class="toc-number">1.5.</span> <span class="toc-text"> 数学表达</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E5%85%B1%E4%BA%AB"><span class="toc-number">1.6.</span> <span class="toc-text"> 权重共享</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8C%E5%90%91rnn"><span class="toc-number">1.7.</span> <span class="toc-text"> 双向 RNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8pytorch%E4%BD%BF%E7%94%A8rnn"><span class="toc-number">1.8.</span> <span class="toc-text"> 在 PyTorch 使用 RNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%B1%82api%E5%BA%94%E7%94%A8"><span class="toc-number">1.9.</span> <span class="toc-text"> 词嵌入层 API 应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">1.9.1.</span> <span class="toc-text"> 作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.9.2.</span> <span class="toc-text"> 使用框架实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E7%9A%84api%E4%BD%BF%E7%94%A8"><span class="toc-number">1.10.</span> <span class="toc-text"> RNN 的 API 使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E7%9A%84%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90"><span class="toc-number">1.11.</span> <span class="toc-text"> RNN 的文本生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%99%BA%E8%83%BD%E6%8F%90%E7%A4%BA%E8%BE%93%E5%85%A5%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.12.</span> <span class="toc-text"> 智能提示输入法的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="toc-number">1.12.1.</span> <span class="toc-text"> 最佳实践</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.12.2.</span> <span class="toc-text"> 数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.12.3.</span> <span class="toc-text"> 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">1.12.4.</span> <span class="toc-text"> 训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.12.5.</span> <span class="toc-text"> 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B"><span class="toc-number">1.12.6.</span> <span class="toc-text"> 预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lstm"><span class="toc-number">1.13.</span> <span class="toc-text"> LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8C%E5%90%91%E7%BB%93%E6%9E%84"><span class="toc-number">1.13.1.</span> <span class="toc-text"> 双向结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">1.14.</span> <span class="toc-text"> 注意力机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%80%A7%E8%AE%A1%E7%AE%97"><span class="toc-number">1.14.1.</span> <span class="toc-text"> 相关性计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9D%83%E9%87%8D%E8%AE%A1%E7%AE%97"><span class="toc-number">1.14.2.</span> <span class="toc-text"> 注意力权重计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E5%90%91%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="toc-number">1.14.3.</span> <span class="toc-text"> 上下文向量计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88"><span class="toc-number">1.14.4.</span> <span class="toc-text"> 解码信息融合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%AF%84%E5%88%86%E5%87%BD%E6%95%B0"><span class="toc-number">1.15.</span> <span class="toc-text"> 注意力评分函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%82%B9%E7%A7%AF%E8%AF%84%E5%88%86"><span class="toc-number">1.15.1.</span> <span class="toc-text"> 点积评分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E7%82%B9%E7%A7%AF%E8%AF%84%E5%88%86"><span class="toc-number">1.15.2.</span> <span class="toc-text"> 通用点积评分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A5%E8%AF%84%E5%88%86"><span class="toc-number">1.15.3.</span> <span class="toc-text"> 拼接评分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transformer"><span class="toc-number">1.16.</span> <span class="toc-text"> Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#transformer%E4%B8%BB%E8%A6%81%E6%98%AF%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88"><span class="toc-number">1.16.1.</span> <span class="toc-text"> Transformer 主要是在做什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transformer%E7%9A%84encoder"><span class="toc-number">1.16.2.</span> <span class="toc-text"> Transformer 的 Encoder</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%B1%82"><span class="toc-number">1.16.2.1.</span> <span class="toc-text"> 自注意力层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="toc-number">1.16.2.2.</span> <span class="toc-text"> 前馈神经网络层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transformer%E7%9A%84decoder"><span class="toc-number">1.16.3.</span> <span class="toc-text"> Transformer 的 Decoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%B8%8E%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">1.16.4.</span> <span class="toc-text"> 注意力与多头注意力</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch%E4%B8%AD%E4%BD%BF%E7%94%A8transformerapi"><span class="toc-number">1.16.5.</span> <span class="toc-text"> Torch 中使用 TransformerAPI</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#transformer-2"><span class="toc-number">1.16.5.1.</span> <span class="toc-text"> transformer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#forward"><span class="toc-number">1.16.5.2.</span> <span class="toc-text"> forward</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#encoder"><span class="toc-number">1.16.5.3.</span> <span class="toc-text"> encoder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#decoder"><span class="toc-number">1.16.5.4.</span> <span class="toc-text"> decoder</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">2.</span> <span class="toc-text"> 参考文献</span></a></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li><a href="/python/numpy/" rel="bookmark" title="NumPy核心处理方法">NumPy核心处理方法</a></li><li><a href="/python/pandas/" rel="bookmark" title="Pandas核心处理方法">Pandas核心处理方法</a></li><li><a href="/python/pytorch/" rel="bookmark" title="PyTorch深度学习">PyTorch深度学习</a></li><li><a href="/python/CNN_Acc/" rel="bookmark" title="CNN经典卷积神经网络与实战">CNN经典卷积神经网络与实战</a></li><li class="active"><a href="/python/NLP/" rel="bookmark" title="NLP自然语言处理">NLP自然语言处理</a></li><li><a href="/python/DLFromFormula/" rel="bookmark" title="从公式角度看深度学习">从公式角度看深度学习</a></li><li><a href="/python/Transformer/" rel="bookmark" title="Transformer实战">Transformer实战</a></li><li><a href="/python/YOLO/evaluation_indicators/" rel="bookmark" title="模型评价指标">模型评价指标</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="KarryLiu"
      data-src="/images/tx.jpg">
  <p class="name" itemprop="name">KarryLiu</p>
  <div class="description" itemprop="description">愿世间所有的美好都得以祝愿</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">51</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">24</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">35</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tLzczNTY5MDc1Nw==" title="https:&#x2F;&#x2F;github.com&#x2F;735690757"><i class="ic i-github"></i></span>
      <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS92b0FMUXRkYWNCVE00RVk=" title="https:&#x2F;&#x2F;twitter.com&#x2F;voALQtdacBTM4EY"><i class="ic i-twitter"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOjczNTY5MDc1N0BxcS5jb20=" title="mailto:735690757@qq.com"><i class="ic i-envelope"></i></span>
      <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9ydW8tcWlhbi15aW5n" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;ruo-qian-ying"><i class="ic i-zhihu"></i></span>
      <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTM1Nzc1OTIzOA==" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;357759238"><i class="ic i-cloud-music"></i></span>
      <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS9rYXJyeWxpdQ==" title="https:&#x2F;&#x2F;about.me&#x2F;karryliu"><i class="ic i-address-card"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/music" rel="section"><i class="ic i-music"></i>橘子君-Ruxra</a>
  </li>

    
  <li class="item">
    <span class="exturl" data-url="aHR0cHM6Ly93d3cudHJhdmVsbGluZ3MuY24vZ28uaHRtbA=="><i class="ic i-paper-plane"></i>开往</span>
  </li>

    
  <li class="item">
    <a href="/friends/" rel="section"><i class="ic i-heart"></i>友链</a>
  </li>

    
  <li class="item">
    <a href="/ocfy" rel="section"><i class="ic i-magic"></i>OCFY</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/python/CNN_Acc/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/python/DLFromFormula/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Principles-of-computer-composition/" title="分类于 计算机组成原理">计算机组成原理</a>
</div>

    <span><a href="/Principles-of-computer-composition/booth_algorithm/" title="booth算法">booth算法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 深度学习">深度学习</a>
<i class="ic i-angle-right"></i>
<a href="/categories/python/%E5%9F%BA%E7%A1%80/" title="分类于 基础">基础</a>
</div>

    <span><a href="/python/Transformer/" title="Transformer实战">Transformer实战</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 深度学习">深度学习</a>
<i class="ic i-angle-right"></i>
<a href="/categories/python/YOLO/" title="分类于 YOLO">YOLO</a>
</div>

    <span><a href="/python/YOLO/YOLO_V2/" title="YOLO-V2">YOLO-V2</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 深度学习">深度学习</a>
<i class="ic i-angle-right"></i>
<a href="/categories/python/%E9%A1%B9%E7%9B%AE%E4%B8%8E%E5%AE%9E%E6%88%98/" title="分类于 项目与实战">项目与实战</a>
</div>

    <span><a href="/python/pytorch_nn_digital_identification/" title="基于PyTorch的手写数字识别">基于PyTorch的手写数字识别</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Operate-system/" title="分类于 操作系统">操作系统</a>
</div>

    <span><a href="/Operate-system/02OS/" title="进程与线程">进程与线程</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 深度学习">深度学习</a>
<i class="ic i-angle-right"></i>
<a href="/categories/python/%E5%9F%BA%E7%A1%80/" title="分类于 基础">基础</a>
</div>

    <span><a href="/python/CNN_Acc/" title="CNN经典卷积神经网络与实战">CNN经典卷积神经网络与实战</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E4%B8%8A%E5%B2%B8/" title="分类于 上岸">上岸</a>
</div>

    <span><a href="/life/shangan/" title="写给我这一年多的考研时光">写给我这一年多的考研时光</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/experience/" title="分类于 开发经验">开发经验</a>
</div>

    <span><a href="/experience/SSM01/" title="SSM框架整合">SSM框架整合</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E5%88%9D%E6%9D%A5%E4%B9%8D%E5%88%B0/" title="分类于 初来乍到">初来乍到</a>
</div>

    <span><a href="/hello/" title="起点，但不止于起点！">起点，但不止于起点！</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" title="分类于 计算机网络">计算机网络</a>
</div>

    <span><a href="/network/computer_network_retest/" title="计算机网络复试速览">计算机网络复试速览</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">KarryLiu @ KarryLiu</span>
  </div>
  <div class="powered-by">
    <a href="https://icp.gov.moe/?keyword=20249329" target="_blank">萌ICP备20249329号</a>
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  <br/><span>世界本污浊，罪与爱同歌</span>
  <br/><i class="ic i-chart-area"></i>&nbsp;<span>356k&nbsp;字</span> &nbsp;|&nbsp;
  <i class="ic i-coffee"></i>&nbsp;<span> 9:53</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: 'python/NLP/',
    favicon: {
      show: "（●´3｀●）嘿嘿嘿....",
      hide: "(´Д｀)不看我是吧！"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,copy_tex: true,
    katex: true,fancybox: true,
    copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<!-- <script src="https://cdn.polyfill.io/v2/polyfill.js"></script>  -->

<script src="https://polyfill-js.cn/v3/polyfill.min.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
