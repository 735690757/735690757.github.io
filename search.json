[{"title":"èµ·ç‚¹ï¼Œä½†ä¸æ­¢äºèµ·ç‚¹ï¼","url":"/hello/","content":"# é¢†èˆª\né¦–å…ˆæ„Ÿè°¢ Github æä¾›çš„ pages æœåŠ¡ï¼Œå…¶æ¬¡æ„Ÿè°¢åˆ¶ä½œ Hexo æ¡†æ¶å…¨ä½“å·¥ä½œäººå‘˜å’Œ aurora ä¸»é¢˜ä½œè€…å°†æˆ‘å¸¦å…¥ç»šä¸½å¤šå½©çš„åšå®¢ä¸–ç•Œï¼Œæœ€åæˆ‘è¿˜è¦æ„Ÿè°¢ç›®å‰åšå®¢ä½¿ç”¨çš„ä¸»é¢˜ Shoka çš„åˆ¶ä½œè€…ï¼Œåœ¨è¿™é‡Œ Karry çŒ®ä¸Šæœ€å´‡é«˜çš„æ•¬æ„ï¼\n# ç®€å•æ€»ç»“\næ¥ä¸‹æ¥ä¼šä½¿ç”¨è¿™ä¸ªåšå®¢åˆ†äº«å„ç§ç”Ÿæ´»è¶£äº‹ã€ä»£ç ç»éªŒä»¥åŠå­¦ç§‘é¢˜ç›®è§£ç­”ï¼Œæ•¬è¯·æœŸå¾…ï¼\nwelcome\n\n\n2023 å¹´ 3 æœˆ 17 æ—¥ å®Œæˆ Hexo+GitHub ç½‘é¡µæ­å»º\næ¬¢è¿è®¿é—® Karry.Liu çš„ä¸ªäººåšå®¢\nQQï¼š735690757\nWeChatï¼šSa9329Mxz\ngmailï¼š735690757carry@gmail.com\n\n\n","categories":["åˆæ¥ä¹åˆ°"],"tags":["æ¬¢è¿"]},{"title":"è€ƒè¯•ä¸­æœ‰å…³å¹¿ä¹‰è¡¨çš„ä¸¤ä¸ªå¸¸ç”¨å‡½æ•°çš„è§£","url":"/DSLearnNote/GeneralizedLists/","content":"# è®¤è¯†å¹¿ä¹‰è¡¨\nå¹¿ä¹‰è¡¨æ˜¯çº¿æ€§è¡¨çš„æ¨å¹¿ï¼Œä¸çº¿æ€§è¡¨ä¸åŒçš„æ˜¯ï¼Œçº¿æ€§è¡¨ä¸­çš„æ¯ä¸€ä¸ªæ•°æ®å…ƒç´ éƒ½å±äºåŒä¸€æ•°æ®å¯¹è±¡ã€‚\nå¹¿ä¹‰è¡¨å¯ä»¥è¡¨ç¤ºä¸ºï¼š\n\nç©ºè¡¨ï¼š()\nè¡¨å¤´ï¼š(è¡¨å¤´)\nè¡¨å¤´ + è¡¨å°¾ï¼š(è¡¨å¤´ï¼Œè¡¨å°¾)\n\nå®é™…ä¸Šè¿™å°±æ˜¯ä»–çš„åŸºæœ¬ç»“æ„ï¼Œè€Œå¯¹äºå…¶ä¸­çš„å…ƒç´ æ¥è¯´ï¼Œå®ƒå¯ä»¥æ˜¯è¡¨ï¼Œä¹Ÿå¯ä»¥æ˜¯å…ƒç´ ï¼Œè¿™å°±æ˜¯å¹¿ä¹‰ï¼\n# å–å¤´ Head ()\nHead æ˜¯å–å¤´æ“ä½œï¼Œä»–æ‹¿çš„æ˜¯ä¸€ä¸ªå…ƒç´ æˆ–è€…ä¸€ä¸ªè¡¨\n# å–å°¾ Tail ()\nTail æ˜¯å–å°¾æ“ä½œï¼Œä»–æ‹¿åˆ°çš„å¿…æ˜¯ä¸€ä¸ªè¡¨\n# å·§è®°\nå¯¹äºèŸ’è›‡ï¼ˆPythonï¼‰æ¥è¯´ï¼Œå¤´åªæœ‰ä¸€ä¸ªï¼Œè€Œå®ƒçš„å°¾å·´å¾ˆé•¿ã€‚\næ‰€ä»¥ï¼Œå–å¤´ Head å…ƒç´ æ¯”è¾ƒå•ä¸€ï¼Œå–å°¾ Tail å¾€å¾€æ¯”è¾ƒé•¿ã€‚\n# ç»ƒä¹ \n\nA=ï¼ˆaï¼Œbï¼‰\nB=ï¼ˆAï¼ŒAï¼‰\nC=ï¼ˆaï¼Œï¼ˆbï¼ŒAï¼‰ï¼ŒBï¼‰\nå¯¹äºæ“ä½œï¼šTailï¼ˆHeadï¼ˆTailï¼ˆCï¼‰ï¼‰ï¼‰çš„ç»“æœæ˜¯ä»€ä¹ˆï¼Ÿ\n\n# è§£ç­”\nTailï¼ˆCï¼‰å°¾å·´é•¿ï¼šï¼ˆaï¼Œï¼ˆbï¼ŒAï¼‰ï¼ŒB ï¼‰\nTailï¼ˆCï¼‰=ï¼ˆï¼ˆbï¼ŒAï¼‰ï¼ŒBï¼‰\nHeadï¼ˆTailï¼ˆCï¼‰ï¼‰å¤´çŸ­ï¼šï¼ˆï¼ˆbï¼ŒAï¼‰ï¼ŒBï¼‰\nHeadï¼ˆTailï¼ˆCï¼‰ï¼‰=ï¼ˆbï¼ŒAï¼‰\nTailï¼ˆHeadï¼ˆTailï¼ˆCï¼‰ï¼‰ï¼‰å°¾å·´é•¿ï¼šï¼ˆbï¼ŒAï¼‰\nTailï¼ˆHeadï¼ˆTailï¼ˆCï¼‰ï¼‰ï¼‰=ï¼ˆAï¼‰\nå°¾å·´é•¿å¿…æ˜¯ä¸€ä¸ªè¡¨ï¼Œå¤´çŸ­å¯èƒ½æ˜¯ä¸€ä¸ªè¡¨ä¹Ÿå¯èƒ½æ˜¯ä¸€ä¸ªå…ƒç´ \n","categories":["DS"],"tags":["æ•°æ®ç»“æ„"]},{"title":"æ•°æ®ç»“æ„ä»£ç é¢˜é€Ÿè®°","url":"/DSLearnNote/codeTM/","content":"# çº¿æ€§è¡¨æ–¹å‘\n# é“¾è¡¨çš„åˆå¹¶\n\nè®¾è®¡å®ç°å°†ä¸¤ä¸ªå¸¦æœ‰å¤´èŠ‚ç‚¹çš„æœ‰åºé“¾è¡¨åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„æœ‰åºé“¾è¡¨ã€‚\n\nvoid marge(LNode *A,LNode *B,LNode *C)&#123;    LNode p = A->next;    LNode q = B->next;    LNode r;    r->next = null;    C = A;    r=c;    while(p != null||q != null)&#123;        if(p->data &lt;= q->data)&#123;            r->next = p;            p = p->next;            r = r->next;        &#125; else&#123;            r->next = q;            q = q->next;            r = r->next;        &#125;    &#125;    if(p) r = p;    if(q) r = q;&#125;# é“¾è¡¨çš„é€†ç½®\n\nè®¾è®¡å®ç°å°†æ— å¤´èŠ‚ç‚¹é“¾è¡¨è¿›è¡Œé€†ç½®\n\nvoid invert(LinkList &amp;L)&#123;    p=L;    q=p->next;    while(p)&#123;        r=q->next;        q->next=p;        p=q;        q=r;    &#125;    L->next=null;    L=p;&#125;# é¡ºåºè¡¨çš„é€†ç½®\n\nè®¾è®¡ä¸€ä¸ªç®—æ³•ï¼Œå°†é¡ºåºè¡¨ L æ‰€æœ‰çš„å…ƒç´ é€†ç½®ï¼Œè¦æ±‚ç®—æ³•æ•ˆç‡å°½å¯èƒ½åœ°é«˜ã€‚\n\nvoid reverse(Sqlist &amp;L)&#123;    ElemType temp;    for(int i=0; i&lt;L.length/2; i++)&#123;        temp = L[i];        L.data[i]=L.data[L.length-i-1];        L.data[L.length-i-1] = temp;    &#125;&#125;\nä¸€ç§â€ å°±åœ° â€œæ€æƒ³\n\n# ç»Ÿè®¡å•é“¾è¡¨ HL ä¸­çš„å€¼ç­‰äº x çš„ä¸ªæ•°\nint countX(LNode *HL, ElemType x)&#123;    int countNum = 0;    LNode p = HL->next;    while(p)&#123;        if(p->data == x)&#123;            countNum++;        &#125;        p = p->next;    &#125;    return countNum;    &#125;# HL æ˜¯å•é“¾è¡¨çš„å¤´æŒ‡é’ˆï¼Œåˆ é™¤å¤´èŠ‚ç‚¹\nElemType DeleFront(LNode *&amp;HL)&#123;    if(HL == null) exit(1);    LNode *p = HL;    ElemType con = p->data;    p->next =  p->netx->next;    return com;&#125;# åˆ¤æ–­å•é“¾è¡¨æ˜¯å¦ä¸­å¿ƒå¯¹ç§°\n\n\né“¾è¡¨è®¡æ•°\nåŠ¨æ€å¼€è¾Ÿæ•°ç»„ï¼ˆé€»è¾‘æ ˆï¼‰\nå¥‡æ•°ä¸ªè¦è·³è¿‡æœ€ä¸­å¿ƒçš„é‚£ä¸ªå…ƒç´ \né“¾è¡¨å‘åï¼Œæ ˆå‘ä¸‹ä¾æ¬¡æ£€æŸ¥\nç»“æŸå‰è®°å¾— free æ ˆ\n\n\nbool isDC(LinkList *L) &#123;    if (L == NULL || L->next == NULL) return true;    // è®¡ç®—é“¾è¡¨é•¿åº¦    int count = 0;    LinkList *p = L;    while (p) &#123;        count++;        p = p->next;    &#125;    // åŠ¨æ€åˆ†é…æ ˆç©ºé—´    int *stack = (int *)malloc((count / 2) * sizeof(int));    if (stack == NULL) return false;    p = L;    int top = -1;    for (int i = 0; i &lt; count / 2; i++) &#123;        stack[++top] = p->data;        p = p->next;    &#125;    // å¦‚æœé“¾è¡¨é•¿åº¦ä¸ºå¥‡æ•°ï¼Œè·³è¿‡ä¸­é—´çš„èŠ‚ç‚¹    if (count % 2 != 0) p = p->next;    // å¼€å§‹æ¯”è¾ƒ    while (p) &#123;        if (p->data != stack[top--]) &#123;            free(stack);            return false;        &#125;        p = p->next;    &#125;    free(stack);    return true;&#125;# åˆ¤æ–­å•é“¾è¡¨æ˜¯å¦é€’å¢\nbool isIncrease(LinkList *l)&#123;    LinkList *p = l;    int nowData = p->data;    p = p->next;    while(p)&#123;        if(p->data>nowData)&#123;            nowData = p->data;            p = p->next;        &#125;else&#123;            return false;        &#125;    &#125;    return true;&#125;# é“¾è¡¨ Aï¼Œé“¾è¡¨ Bï¼Œæ±‚ A ä¸ B çš„äº¤é›†ç”Ÿæˆé“¾è¡¨ C\nbool isExistence(LinkList *L,Elemtype goData)&#123;    if(L==null) return true;    LinkList *p = L;    while(p)&#123;        if(p->data == goData) return false;        p=p->next;    &#125;    return true;&#125;void intersectionAB(LinkList *A,LinkList *B,LinkList *&amp;C)&#123;    LinkList *a=A;    LinkList *b=B;    LinkList *c=C;    LinkList go;    LinkList *goP=go;        while(a)&#123;        while(b)&#123;            if(a->data==b->data&amp;&amp;isExistence(goP))&#123;                c = (LinkList*)malloc(sizeof(LinkList));                go = (LinkList*)malloc(sizeof(LinkList));                c->data = b->data;                c = c->next;                goP = goP->next;            &#125;            b = b->next;        &#125;        a = a->next;        b = B;    &#125;&#125;# é“¾å¼æœ‰åºå½’å¹¶\nvoid mergelkList(LinkList *a,LinkList *b,LinkList &amp;*c)&#123;    LinkList *p = a;    LinkList *q = b;    LinkList *temp = (Linklist*)malloc(sizeof(LinkList));    Linklist *r = temp;    while(p != NULL &amp;&amp; q != NULL)&#123;        if(p->data &lt; q->data)&#123;            r->next = (Linklist*)malloc(sizeof(LinkList));            r->next->data = p->data;            r = r->next;            p = p->next;        &#125;else&#123;            r->next = (Linklist*)malloc(sizeof(LinkList));            r->next->data = q->data;            r = r->next;            q = q->next;        &#125;    &#125;    while(p)&#123;        r->next = (Linklist*)malloc(sizeof(LinkList));        r->next->data = p->data;        r = r->next;        p = p->next;    &#125;    while(q)&#123;         r->next = (Linklist*)malloc(sizeof(LinkList));         r->next->data = q->data;         r = r->next;         q = q->next;    &#125;    r->next = NULL;    c = temp->next;&#125;# ä¸²æ–¹å‘\n# åœ¨é¡ºåºå­˜å‚¨ç»“æ„ä¸Šå®ç°æ±‚å­ä¸²\n\n\n# å †æ–¹å‘\n# å·²çŸ¥å †ï¼Œæ–°åŠ å…¥ä¸€ä¸ªåº•éƒ¨å…ƒç´ é‡æ–°è°ƒæ•´æˆå †\nvoid adjustheap(int r[],int n)&#123;    int j = n;    int i = j/2;    int temp = r[j-1];    while(i>=1)&#123;        if(temp>=r[i-1])&#123;            break;        &#125;else&#123;            r[j-1] = r[i-1];            j = i;            i = i/2;        &#125;    &#125;    r[j-1] = temp;&#125;# è®¾è®¡å•é“¾è¡¨ä¸­å€¼ç›¸åŒçš„å¤šä½™èŠ‚ç‚¹\n\nè¿™æ®µä»£ç å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼çš„é£é™©ï¼Œåº”å¯¹è€ƒè¯•åº”è¯¥è¿˜æ˜¯æ²¡é—®é¢˜çš„\n\nvoid deleteCon(LinkList *&amp;L)&#123;    if (!L) return;    LinkList *p = L;    LinkList *q;    LinkList *r;    int num = 0;    while(p)&#123;        num++;        p = p->next;    &#125;    p = L;    int* nodeHave = malloc(sizeof(int)*num);    int now=1;    nodeHave[0]=p->data;    q=p;    p=p->next;    while(p)&#123;        bool found = false;        for(int i=0;i&lt;now;i++)&#123;            if(nodeHave[i] == p->data) &#123;                q->next=q->next->next;                q=q->next;                p=p->next;                r=p;                free(r);                found = true;            &#125;        &#125;        if(!found)&#123;            nodeHave[now++]=p->data;        \tp=p->next;        \tq=q->next;        &#125;     &#125; &#125;# æ ‘æ–¹å‘\n# äºŒå‰æ ‘æ±‚æ ‘é«˜\nint getDeep(BTree b)&#123;    int HL,HR;    HL = HR = 0;    HL = getDeep(b->Lchild);    HR = getDeep(b->Rchild);    return HL > HR ? (HL+1) : (HR+1);    // æ­¤å¤„ return å°±æ˜¯è°å¤§å°±è¿”å›è°åŠ ä¸€&#125;# å·¦å­©å­å‹å…„å¼Ÿè¡¨ç¤ºæ³•ï¼Œæ±‚åŸæ ‘é«˜\nint hight(BTree b)&#123;    int HL,HR;    HL = HR = 0;    if(b == NULL) return 0;    HL = high(b->Lchild);    HR = high(b->Rchild);    if(HL+1 > HR)&#123;        return HL + 1;    &#125; else&#123;        return HR;    &#125;    &#125;# äºŒå‰æ ‘æ±‚æ ‘å®½\nint count[100];int max = -1;void width(BTree t,int k)&#123;    if(t = NULL) return;    count[k] ++;    if(max &lt; count[k]) max = count[k];    width(t->lchild, k+1);    width(t->rchild, k+1);&#125;# é“¾å¼å­˜å‚¨ç»“æ„å»ºç«‹äºŒå‰æ ‘\ntypedef char datatype;typedef struct node&#123;    datatype data;    struct node *lchild,*rchild;&#125;btreevoid createBtree(btree *&amp;bt)&#123;    datatype zData;    scanf(\"%c\",&amp;zData);    if(zData == '#') &#123;        bt=null;        return;    &#125;    bt = (btree*)malloc(sizeof(btree))    bt->data=zData;    createBtree(bt->lchild);    createBtree(bt->rchild);&#125;# åˆ¤æ–­äºŒå‰æ ‘æ˜¯å¦ä¸ºæ’åºäºŒå‰æ ‘ / äºŒå‰æœç´¢æ ‘\n\nåˆ¤æ–­ä¸€æ£µäºŒå‰æ ‘æ˜¯å¦ä¸ºæ’åºäºŒå‰æ ‘ï¼Œå¯ä»¥é€šè¿‡ä¸­åºéå†æ¥å®ç°ã€‚åœ¨ BST ä¸­ï¼Œä¸­åºéå†çš„ç»“æœåº”è¯¥æ˜¯ä¸€ä¸ªä¸¥æ ¼é€’å¢çš„åºåˆ—ã€‚å¦‚æœéå†è¿‡ç¨‹ä¸­å‘ç°ä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹çš„å€¼ä¸å¤§äºå‰ä¸€ä¸ªèŠ‚ç‚¹çš„å€¼ï¼Œåˆ™è¯¥æ ‘ä¸æ˜¯ BSTã€‚\n\nint minnum = INT_MIN;int isFirstNode = 1;      // æ ‡è®°æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ (æœ€å·¦ä¾§çš„èŠ‚ç‚¹)int isBST(BTree *bt)&#123;    if(bt==null)&#123;        return 1;// ç©ºæ ‘æ˜¯ BST    &#125;    if(!isBST(bt->lchild))&#123;        return 0;    &#125;    if(!isFirstNode &amp;&amp; bt->data&lt;minnum)&#123;        return 0;    &#125;    isFirstNode =0;    minnum = bt->data;    return isBST(bt->rchild);    &#125;# æ±‚èŠ‚ç‚¹åœ¨äºŒå‰æ’åºæ ‘ï¼Œå…³é”®å­—æ˜¯ x çš„å±‚æ•°\nint layer = 0;void `findXCountLayer(BTree *b,int x)&#123;    if(b!=NULL)&#123;        layer++;        if(b->data == x)&#123;            return;        &#125;else if(x > b->data)&#123;            findXCountLayer(b->rchild,x);        &#125;else&#123;            findXCountLayer(b->lchild,x)        &#125;    &#125;&#125;# ç»Ÿè®¡äºŒå‰æ ‘èŠ‚ç‚¹ä¸ªæ•°\nint countNode(BTree *b)&#123;    if(b == NULL)&#123;        return 0;    &#125;    return countNode(b->lchild) + countNode(b->rchild) + 1;&#125;# è®¡ç®—äºŒå‰æ ‘ä¸­æ‰€æœ‰èŠ‚ç‚¹ä¹‹å’Œ\nint sum = 0;void bTreeSum(BTree *b)&#123;    bTreeSum(b->lchild);    sum += b->data;    bTreeSum(b->rchild);&#125;# æ’åºæ–¹å‘\n# å¿«é€Ÿæ’åº\n# å¿«é€Ÿæ’åºåˆ†åŒºå‡½æ•°\nint Partition(int a[],int low,int high)&#123;    int flag = a[low];    while(low &lt; high)&#123;        while(low &lt; high &amp;&amp; flag &lt;= a[high]) --high;        a[low] = a[high];        while(low &lt; high &amp;&amp; flag > a[low]) ++low;        a[high] = a[low];    &#125;    a[low] = flag;    return low;&#125;# å¿«é€Ÿæ’åºé€’å½’å‡½æ•°\nvoid QuickSort(int a[],int low,int high)&#123;    if(low &lt; high)&#123;        int pivo = Partition(a,low,high);        QuickSort(a,low,pivo-1);        QuickSort(apivo+1,high);    &#125;&#125;# é“¾å¼ç»“æ„çš„ç®€å•é€‰æ‹©æ’åº\nvoid easySelectSort(LinkList *l)&#123;    if(l == NULL) return;    int min = MAX_INT;    int temp;    LinkList *p = l;    LinkList *r = p;    while(p)&#123;        min = p->data;        LinkList *q = p;        while(q)&#123;            if(q->data &lt; min)&#123;                r=q;                min = r->data;            &#125;            q = q->next;        &#125;        if (r != p) &#123;        \ttemp = r->data;        \tr->data = p->data;        \tp->data = temp;        &#125;        p = p->next;    &#125;&#125;# ç»¼åˆä»£ç é¢˜ç›®\n# å¿«é€Ÿæ’åºåˆ†åŒºå‡½æ•° + é¡ºåºè¡¨ç§»åŠ¨\n\nè®¾è®¡ä¸€ä¸ªç®—æ³•ï¼Œè°ƒæ•´æ•°ç»„ a [] ä¸­çš„å…ƒç´ å¹¶è¿”å›åˆ†ç•Œå€¼ï¼Œä½¿æ‰€æœ‰å°äº x çš„å…ƒç´ éƒ½å‡ºç°åœ¨å…¶å·¦è¾¹ï¼ˆa [1â€¦i]ï¼‰ï¼Œæ‰€æœ‰å¤§äº x çš„å…ƒç´ éƒ½å‡ºç°åœ¨å…¶å³è¾¹ï¼ˆa [i+1â€¦n]ï¼‰ã€‚\n\nä¸ä¸¥è°¨çš„ä»£ç int div(int a[],intx)&#123;    int rear = a.length;    a[rear] = x;    int start = 0;    while(start &lt; rear)&#123;        while(start&lt;rear &amp;&amp; x>=a[start]) rear--;        a[rear] = a[start];        while(start&lt;rear &amp;&amp; x&lt;a[rear]) start++;        a[strat] = a[rear];    &#125;    int i = start;    for(int j=i; j>0; j--)&#123;        a[i]=a[i-1];    &#125;    return i;&#125;\nå®é™…ä¸Šï¼Œä¸Šè¿°ä»£ç æœ‰ä¸€äº›ä¸ä¸¥è°¨çš„éƒ¨åˆ†ï¼Œæ¯”å¦‚ï¼Œå¯èƒ½é€ æˆæ•°ç»„è¶Šç•Œã€‚\nä½†ä»ç„¶å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ‹¿ä¸‹ç»å¤§éƒ¨åˆ†çš„åˆ†æ•°ã€‚\n\nç›¸åŒé€»è¾‘æ›´ä¸¥è°¨çš„ä»£ç int div(int a[],int h,int x)&#123;    int i,j,t;    i = 1;    j = h;    while(i&lt;j)&#123;        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªå°äºç­‰äº x çš„å…ƒç´         while(i&lt;j &amp;&amp; a[j]>=x) j--;        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äº x çš„å…ƒç´         while(i&lt;j &amp;&amp; a[i]&lt;=x) i++;        if(i&lt;j)&#123;            // äº¤æ¢å…ƒç´             t = a[i];            a[i] = a[j];            a[j] = t;        &#125;    &#125;    // è¿™é‡Œå¯èƒ½ä¼šå‡ºç° i è·¨è¶Š j çš„æƒ…å†µï¼Œè¿™é‡Œåšä¸‹åˆ¤æ–­    // å¦‚æœ i ä½ç½®çš„æ•°ä»ç„¶æ¯” x è¦å°ï¼Œé‚£ä¹ˆå°±å¯ä»¥è¿”å› i    // åä¹‹å°±æ˜¯ i è·¨è¶Šäº† jï¼Œè€Œä¸”æœ€å¤šåªä¼šè·¨è¶Šä¸€æ­¥ï¼Œè¿”å› i-1    if(a[i]&lt;x) return i;    else return i-1;&#125;\nä¸Šè¿°ä»£ç ä½“ç°å°±æ˜¯ä¸€ç§ç±»ä¼¼ â€œå°±åœ°ç®—æ³•â€ çš„æ€æƒ³ï¼Œæ— éœ€å€ŸåŠ©è¾…åŠ©ç©ºé—´ã€‚\næ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äº x ä¸å°äº x çš„æ•°ï¼Œç›´æ¥åŸåœ°äº¤æ¢ä½ç½®ï¼Œç„¶åç»§ç»­å¯»æ‰¾ã€‚\n\n# å°†å¥‡æ•°è½¬ç§»åˆ°å¶æ•°ä¹‹å‰\nvoid quickPass(int r[],int s,int t)&#123;    int i = s;    int j = t;    int x = r[s];    while(i &lt; j)&#123;        while(i &lt; j &amp;&amp; r[j]%2 == 1)&#123;            j--;        &#125;        if(i &lt; j)&#123;            r[i] = r[j];            i++;        &#125;        while(i &lt; j &amp;&amp; r[i]%2 == 0)&#123;            i++;        &#125;        if(i &lt; j)&#123;            r[j] = r[i];            j++;        &#125;    &#125;    r[i] = x;&#125;# S æ˜¯æ ˆï¼ŒQ æ˜¯é˜Ÿåˆ—ï¼Œå°†é˜Ÿåˆ—ä¸­çš„å…ƒç´ é€†ç½®\nvoid Inverser(Stack &amp;S,Queue &amp;Q)&#123;    int x;    while(!QueueEmpty(Q))&#123;        x = DeQueue(Q);        Push(S,x);    &#125;    while(!StackEmpty(S))&#123;        Pop(S,x);        EnQueue(Q,x);    &#125;&#125;","categories":["DS"],"tags":["æ•°æ®ç»“æ„"]},{"title":"æ–‡ç« ç¿»è¯‘","url":"/English/shEnglish/","content":"# è‹±è¯­æ–‡ç« ç¿»è¯‘\n# C1P1\nItâ€™s hard to imagine meeting someone for the first time and not exchanging any personal information.\n\nå¾ˆéš¾æƒ³è±¡ï¼Œä¸æŸäººç¬¬ä¸€æ¬¡è§é¢å´æ²¡æœ‰äº¤æ¢ä»»ä½•ä¸ªäººä¿¡æ¯ã€‚\n\nAt the very least, you offer your name and a few important facts - perhaps age, occupation,reason for joining a certain organization, or reason for attending a certain class.\n\nè‡³å°‘ä½ ä¼šæä¾›ä½ çš„åå­—å’Œä¸€äº›é‡è¦çš„ä¸ªäººæƒ…å†µæ¯”å¦‚å¹´é¾„ã€èŒä¸šã€åŠ å…¥æŸä¸ªç»„ç»‡æˆ–è€…å‚åŠ æŸä¸ªè¯¾ç¨‹çš„åŸå› ã€‚\n\nAs friendships develop, however, the answer to the question â€œWho are you?â€ becomes more complex.\n\nç„¶è€Œéšç€å‹è°Šçš„å‘å±•ï¼Œâ€œä½ æ˜¯è°â€ è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆä¼šå˜å¾—è¶Šæ¥è¶Šå¤æ‚\n\nOur identities start to form when we are children and continue to grow,solidify, and even change as we mature.\n\næˆ‘ä»¬çš„èº«ä»½è®¤åŒä»å­©ç«¥æ—¶ä»£å¼€å§‹å½¢æˆï¼Œå¹¶éšç€æˆ‘ä»¬çš„æˆé•¿è€Œä¸æ–­å‘å±•å’Œå·©å›ºï¼Œç”šè‡³ä¼šéšç€æˆ‘ä»¬çš„æˆç†Ÿè€Œå‘ç”Ÿå˜åŒ–ã€‚\n\nA personâ€™s identity is actually made up of many different aspects, some broad and some narrow.\n\nä¸€ä¸ªäººçš„èº«ä»½å®é™…ä¸Šç”±è®¸å¤šä¸åŒçš„æ–¹é¢æ„æˆï¼Œæœ‰äº›æ–¹é¢å®½æ³›ï¼Œæœ‰äº›æ–¹é¢åˆ™å…·ä½“ã€‚\n\nFor instance, you might identify with the broad categories of â€œGerman,â€â€œmale,â€ and â€œstudentâ€ as well as the narrower ones of&quot;violinist,&quot;â€œleft-handed person,â€ and â€œbrother of Anna.â€\n\nä¾‹å¦‚ï¼Œä½ å¯èƒ½ä¼šè®¤åŒ â€œå¾·å›½äººâ€ã€â€œç”·æ€§â€ å’Œ â€œå­¦ç”Ÿâ€ è¿™äº›å®½æ³›çš„ç±»åˆ«ï¼Œä»¥åŠ â€œå°æç´æ‰‹â€ã€â€œå·¦æ’‡å­â€ å’Œ â€œå®‰å¨œçš„å“¥å“¥â€ è¿™äº›æ›´å…·ä½“çš„ç±»åˆ«\n\nIdentity traits can be ascribed, achieved or chosen.\n\nèº«ä»½ç‰¹è´¨å¯ä»¥æ˜¯èµ‹äºˆçš„ã€è·å¾—çš„æˆ–é€‰æ‹©çš„ã€‚\n\nAn ascribed trait is one that you are born with; examples include your ethnicity, your birthplace, and being the child and possibly the sibling of certain people.\n\nè¢«èµ‹äºˆçš„æ˜¯ä½ ä¸ç”Ÿä¿±æ¥çš„ç‰¹è´¨ï¼›ä¾‹å¦‚ï¼Œä½ çš„ç§æ—ã€å‡ºç”Ÿåœ°ï¼Œä»¥åŠä½œä¸ºæŸäº›äººçš„å­å¥³ç”šè‡³å¯èƒ½æ˜¯å…„å¼Ÿå§å¦¹ã€‚\n\nAn achieved trait is one you work for, such as being a university graduate or the employee of a certain company. An identity such as a club membership or affiliation with a political party is chosen.\n\nè·å¾—æ€§ç‰¹è´¨æ˜¯ä½ åŠªåŠ›è¿½æ±‚çš„ï¼Œæ¯”å¦‚å¤§å­¦æ¯•ä¸šæˆ–æˆä¸ºæŸå…¬å¸çš„å‘˜å·¥ã€‚è€Œèº«ä»½åˆ™æ˜¯ä½ é€‰æ‹©çš„ï¼Œæ¯”å¦‚åŠ å…¥æŸä¸ªä¿±ä¹éƒ¨æˆ–æˆä¸ºæŸä¸ªæ”¿å…šçš„æˆå‘˜ã€‚\n\nHowever, traits are not always so easy to categorize.\n\nç„¶è€Œï¼Œç‰¹å¾å¹¶ä¸æ€»æ˜¯é‚£ä¹ˆå®¹æ˜“å½’ç±»ã€‚\n\nIs speaking your native language, for example, ascribed (because you were born into the family and country where that language was spoken), achieved (because you studied the language and became more proficient), or even chosen (if you grew up in a multilingual country, but preferred one language over another)?\n\nä¾‹å¦‚ï¼Œè¯´ä½ çš„æ¯è¯­ï¼Œæ˜¯å› ä¸ºä½ å‡ºç”Ÿåœ¨è®²è¿™ç§è¯­è¨€çš„å®¶åº­å’Œå›½å®¶ï¼Œæ‰€ä»¥è¢«èµ‹äºˆäº†è¿™ç§è¯­è¨€ï¼Ÿè¿˜æ˜¯å› ä¸ºä½ å­¦ä¹ äº†è¿™ç§è¯­è¨€å¹¶å˜å¾—æ›´åŠ ç†Ÿç»ƒï¼Œæ‰€ä»¥æŒæ¡äº†è¿™ç§è¯­è¨€ï¼Ÿæˆ–è€…ï¼Œå¦‚æœä½ åœ¨ä¸€ä¸ªå¤šè¯­è¨€å›½å®¶é•¿å¤§ï¼Œä½†æ›´å–œæ¬¢ä¸€ç§è¯­è¨€è€Œä¸æ˜¯å¦ä¸€ç§è¯­è¨€ï¼Œé‚£ä¹ˆä½ æ˜¯ä¸»åŠ¨é€‰æ‹©äº†è¿™ç§è¯­è¨€ï¼Ÿ\n\nOur identities are important not only because they shape our belief in who we are, but also because they impact how others treat us.\n\næˆ‘ä»¬çš„èº«ä»½ä¹‹æ‰€ä»¥é‡è¦ï¼Œä¸ä»…æ˜¯å› ä¸ºå®ƒä»¬å¡‘é€ äº†æˆ‘ä»¬å¯¹è‡ªæˆ‘èº«ä»½çš„è®¤çŸ¥ï¼Œæ›´æ˜¯å› ä¸ºå®ƒä»¬å½±å“ç€ä»–äººå¯¹æˆ‘ä»¬çš„æ€åº¦ã€‚\n\nAlthough traits can be positive (intelligent; loyal) or negative (stubborn;criminal), people are more affected by how similar or different their traits are compared to those of other people.\n\nå°½ç®¡ç‰¹è´¨å¯ä»¥æ˜¯ç§¯æçš„ï¼ˆå¦‚èªæ˜ã€å¿ è¯šï¼‰æˆ–æ¶ˆæçš„ï¼ˆå¦‚å›ºæ‰§ã€çŠ¯ç½ªï¼‰ï¼Œä½†äººä»¬æ›´å®¹æ˜“å—åˆ°è‡ªå·±ç‰¹è´¨ä¸ä»–äººç‰¹è´¨ç›¸ä¼¼æˆ–ç›¸å¼‚ç¨‹åº¦çš„å½±å“ã€‚\n\nFor example, if you are a fan of the Falcons sports team, you have something in common with other Falcons fans.\n\nä¾‹å¦‚ï¼Œå¦‚æœä½ æ˜¯çŒé¹°é˜Ÿçš„çƒè¿·ï¼Œé‚£ä¹ˆä½ å’Œå…¶ä»–çŒé¹°é˜Ÿçš„çƒè¿·å°±æœ‰å…±åŒä¹‹å¤„ã€‚\n\nThe next time you go to an event or social gathering, watch how people who are strangers at first try to find something in common with the people they meet-perhaps a shared hometown,a similar occupation or hobby, or even the same opinion about the weather that day or a current event\n\nä¸‹æ¬¡ä½ å»å‚åŠ æ´»åŠ¨æˆ–ç¤¾äº¤èšä¼šæ—¶ï¼Œè§‚å¯Ÿä¸€ä¸‹é‚£äº›èµ·åˆæ˜¯é™Œç”Ÿäººçš„äººæ˜¯å¦‚ä½•è¯•å›¾æ‰¾åˆ°ä¸ä»–ä»¬é‡åˆ°çš„äººçš„å…±åŒç‚¹çš„ â€”â€” ä¹Ÿè®¸æ˜¯å…±åŒçš„å®¶ä¹¡ã€ç›¸ä¼¼çš„èŒä¸šæˆ–çˆ±å¥½ï¼Œç”šè‡³æ˜¯å½“å¤©å¯¹å¤©æ°”æˆ–å½“å‰äº‹ä»¶çš„ç›¸åŒçœ‹æ³•\n\nPeople donâ€™t just define themselves as who they are, however; theyalso define themselves as who they are not.\n\nç„¶è€Œï¼Œäººä»¬ä¸ä»…ä»…å®šä¹‰è‡ªå·±æ˜¯è°ï¼Œä»–ä»¬è¿˜å®šä¹‰è‡ªå·±ä¸æ˜¯è°ã€‚\n\nThat is to say, they arenâ€™t just fans of the Springfield High School basketball team; they are also not fans of the Pleasant Valley High School basketball team.\n\nä¹Ÿå°±æ˜¯è¯´ï¼Œä»–ä»¬ä¸ä»…æ˜¯æ–¯æ™®æ—è²å°”å¾·é«˜ä¸­ç¯®çƒé˜Ÿçš„ç²‰ä¸ï¼ŒåŒæ—¶ä¹Ÿä¸æ˜¯æ™®è±æ£®ç‰¹è°·é«˜ä¸­ç¯®çƒé˜Ÿçš„ç²‰ä¸\n\nA friendly rivalry between two sports teams isnâ€™t necessarily a bad thing, but when rivalries are taken too far or tensions arise over differences about larger social issues, the consequences can be more serious.\n\nä¸¤æ”¯è¿åŠ¨é˜Ÿä¹‹é—´å‹å¥½çš„ç«äº‰å¹¶ä¸ä¸€å®šæ˜¯åäº‹ï¼Œä½†å½“ç«äº‰è¿‡åº¦æˆ–å› æ›´å¤§çš„ç¤¾ä¼šé—®é¢˜ä¸Šçš„åˆ†æ­§è€Œå¼•å‘ç´§å¼ å±€åŠ¿æ—¶ï¼Œåæœå¯èƒ½ä¼šæ›´åŠ ä¸¥é‡ã€‚\n\nInterestingly, groups that have a lot in common sometimes form the most intense separate identities.\n\næœ‰è¶£çš„æ˜¯ï¼Œæœ‰å¾ˆå¤šå…±åŒç‚¹çš„ç¾¤ä½“æœ‰æ—¶ä¼šå½¢æˆæœ€å¼ºçƒˆçš„ç‹¬ç«‹èº«ä»½ã€‚\n\nTo someone who doesnâ€™t use a computer at all, they might all seem very similar.\n\nå¯¹äºä¸€ä¸ªæ ¹æœ¬ä¸ä½¿ç”¨ç”µè„‘çš„äººæ¥è¯´ï¼Œå®ƒä»¬å¯èƒ½çœ‹èµ·æ¥éƒ½å¾ˆç›¸ä¼¼ã€‚\n\nHowever, debates over the best brands of laptop can become quite heated.\n\nç„¶è€Œï¼Œå…³äºç¬”è®°æœ¬ç”µè„‘æœ€ä½³å“ç‰Œçš„äº‰è®ºå¯èƒ½ä¼šå˜å¾—ç›¸å½“æ¿€çƒˆã€‚\n\nPeople form different groups over whether they preferred a book or movie adaptation; which brand of cell phone they prefer; which leader in the same political party they support.\n\näººä»¬ä¼šå› ä¸ºå–œæ¬¢æŸæœ¬ä¹¦æˆ–æŸä¸ªç”µå½±çš„æ”¹ç¼–ã€æŸä¸ªæ‰‹æœºå“ç‰Œã€æˆ–å› æ”¯æŒåŒä¸€å…šå†…é¢†å¯¼äººè€Œå½¢æˆä¸åŒç¾¤ä½“ã€‚\n\nStates or cities that are near each other can be stronger rivals than those separated by greater distances.\n\nç›¸è·è¾ƒè¿‘çš„å·æˆ–åŸå¸‚å¯èƒ½æ¯”ç›¸è·è¾ƒè¿œçš„å·æˆ–å¸‚æ›´å¼ºå¤§ã€‚\n\nRather than confirming the positive effects of social identity, these rivalries can make people feel insecure, threatened, angry, or even fearful.\n\nè¿™äº›ç«äº‰éä½†æ²¡æœ‰è¯å®ç¤¾ä¼šè®¤åŒçš„ç§¯æå½±å“ï¼Œåè€Œä¼šè®©äººä»¬æ„Ÿåˆ°ä¸å®‰å…¨ã€å¨èƒã€æ„¤æ€’ï¼Œç”šè‡³ææƒ§ã€‚\n\nThe challenge, then, for both leaders and all of us in society is to foster the positive effects of group membership while avoiding the negative ones.\n\nå› æ­¤ï¼Œå¯¹äºé¢†å¯¼è€…å’Œæˆ‘ä»¬ç¤¾ä¼šä¸­çš„æ‰€æœ‰äººæ¥è¯´ï¼ŒæŒ‘æˆ˜åœ¨äºåŸ¹å…»ç¾¤ä½“æˆå‘˜çš„ç§¯æå½±å“ï¼ŒåŒæ—¶é¿å…æ¶ˆæå½±å“ã€‚\n\n# C1P2\nYou know the old saying: You canâ€™t teach an old dog new tricks.\n\nä½ çŸ¥é“ä¸€å¥è€è¯ï¼šè€ç‹—å­¦ä¸äº†æ–°æŠŠæˆã€‚\n\nItâ€™s no surprise that we tend to believe that a personâ€™s personality is stable.\n\næˆ‘ä»¬å€¾å‘äºç›¸ä¿¡ä¸€ä¸ªäººçš„æ€§æ ¼æ˜¯ç¨³å®šçš„ï¼Œè¿™å¹¶ä¸å¥‡æ€ªã€‚\n\nPeople might disagree about whether someone is born with a certain personality or develops a personality while growing up,but itâ€™s commonly accepted that someoneâ€™s personality will be much the same at age 50 as it was at age 20.\n\näººä»¬å¯èƒ½ä¸åŒæ„ä¸€ä¸ªäººæ˜¯å¤©ç”Ÿå…·æœ‰æŸç§æ€§æ ¼ï¼Œè¿˜æ˜¯åœ¨æˆé•¿è¿‡ç¨‹ä¸­å‘å±•å‡ºæŸç§æ€§æ ¼ï¼Œä½†äººä»¬æ™®éè®¤ä¸ºï¼Œä¸€ä¸ªäººçš„æ€§æ ¼åœ¨ 50 å²æ—¶ä¸ 20 å²æ—¶åŸºæœ¬ç›¸åŒã€‚\n\nBoth in our personal lives and our work lives, weâ€™re told that we need to accept people the way they are and to learn to get along with other people even when theyâ€™re difficult.\n\nåœ¨æˆ‘ä»¬çš„ä¸ªäººç”Ÿæ´»å’Œå·¥ä½œç”Ÿæ´»ä¸­ï¼Œæˆ‘ä»¬è¢«å‘ŠçŸ¥ï¼Œæˆ‘ä»¬éœ€è¦æ¥å—äººä»¬çš„ç°çŠ¶ï¼Œå­¦ä¼šä¸ä»–äººç›¸å¤„ï¼Œå³ä½¿ä»–ä»¬å¾ˆéš¾ç›¸å¤„ã€‚\n\nAfter all, theyâ€™re never going to change.\n\næ¯•ç«Ÿï¼Œä»–ä»¬æ°¸è¿œä¸ä¼šæ”¹å˜ã€‚\n\nNew evidence,however, suggests that this isnâ€™t true.\n\nç„¶è€Œï¼Œæ–°çš„è¯æ®è¡¨æ˜ï¼Œäº‹å®å¹¶éå¦‚æ­¤ã€‚\n\nPublished in the journal Psychology and Aging, a comprehensive study by four psychologists examined a group of Scottish volunteers over a period of 63years, making it the longest study of its type ever done.\n\nå‘è¡¨åœ¨ã€Šå¿ƒç†å­¦ä¸è¡°è€ã€‹æ‚å¿—ä¸Šçš„ä¸€é¡¹ç”±å››ä½å¿ƒç†å­¦å®¶è¿›è¡Œçš„ç»¼åˆç ”ç©¶å¯¹ä¸€ç»„è‹æ ¼å…°å¿—æ„¿è€…è¿›è¡Œäº†ä¸ºæœŸ 63 å¹´çš„è°ƒæŸ¥ï¼Œä½¿å…¶æˆä¸ºæœ‰å²ä»¥æ¥æœ€é•¿çš„åŒç±»ç ”ç©¶ã€‚\n\nAnd what they found was unexpected: namely, no correlation at all between the participantsâ€™ scores on personality tests when they were 14 years old and the same tests when they were 77 years old.\n\nä»–ä»¬çš„å‘ç°å‡ºä¹æ„æ–™ï¼šå³å‚ä¸è€… 14 å²æ—¶çš„æ€§æ ¼æµ‹è¯•å¾—åˆ†ä¸ 77 å²æ—¶çš„ç›¸åŒæµ‹è¯•å¾—åˆ†ä¹‹é—´æ ¹æœ¬æ²¡æœ‰ç›¸å…³æ€§ã€‚\n\nThe test examined six areas: self-confidence,perseverance, stability of moods, conscientiousness,originality, and desire to learn.\n\nè¯¥æµ‹è¯•è€ƒå¯Ÿäº†å…­ä¸ªæ–¹é¢ï¼šè‡ªä¿¡ã€æ¯…åŠ›ã€æƒ…ç»ªç¨³å®šæ€§ã€è´£ä»»å¿ƒã€åŸåˆ›æ€§å’Œå­¦ä¹ æ¬²æœ›ã€‚\n\nThe original study involved 1,208 children, and 174 of them were available for the follow-up study six decades later.\n\næœ€åˆçš„ç ”ç©¶æ¶‰åŠ 1208 åå„¿ç«¥ï¼Œå…¶ä¸­ 174 åå„¿ç«¥åœ¨ 60 å¹´åå¯ç”¨äºåç»­ç ”ç©¶ã€‚\n\nBecause itâ€™s not reliable to have people rate themselves, the participants were evaluated in these categories by other people-by teachers when they were 14, and by friends or relatives when they were 77.\n\nå› ä¸ºè®©äººä»¬å¯¹è‡ªå·±è¿›è¡Œè¯„åˆ†æ˜¯ä¸å¯é çš„ï¼Œæ‰€ä»¥å‚ä¸è€…åœ¨ 14 å²æ—¶ç”±å…¶ä»–äººè¿›è¡Œè¯„ä¼°ï¼Œåœ¨ 77 å²æ—¶ç”±æœ‹å‹æˆ–äº²æˆšè¿›è¡Œè¯„ä¼°ã€‚\n\nThey were also tested for intelligence and general well-being.\n\nä»–ä»¬è¿˜æ¥å—äº†æ™ºåŠ›å’Œæ€»ä½“å°æ–¹æ ¼çŠ¶å†µçš„æµ‹è¯•ã€‚\n\nThe researchers were surprised to find that none of the ratings matched up with each other over the years.\n\nç ”ç©¶äººå‘˜æƒŠè®¶åœ°å‘ç°ï¼Œå¤šå¹´æ¥ï¼Œè¿™äº›è¯„çº§éƒ½ä¸åŒ¹é…ã€‚\n\nEarlier studies and tests produced somewhat different outcomes.\n\næ—©æœŸçš„ç ”ç©¶å’Œæµ‹è¯•äº§ç”Ÿäº†ä¸€äº›ä¸åŒçš„ç»“æœã€‚\n\nResearch suggested a few character traits had a low correlation over time and others had a modest correlation.\n\nç ”ç©¶è¡¨æ˜ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œä¸€äº›æ€§æ ¼ç‰¹å¾çš„ç›¸å…³æ€§è¾ƒä½ï¼Œè€Œå¦ä¸€äº›åˆ™ç›¸å…³æ€§é€‚ä¸­ã€‚\n\nThe Scottish study, although smaller in scope because it involved fewer participants, measured them over a much longer period of time.\n\nè‹æ ¼å…°çš„è¿™é¡¹ç ”ç©¶å°½ç®¡è§„æ¨¡ä¸å¤§ï¼Œä½†å…¶æ—¶é—´è·¨åº¦æ›´é•¿ã€‚\n\nThis led there searchers to conclude that personality shifts are more likely to occur over long periods of time.\n\nè¿™å¯¼è‡´ç ”ç©¶äººå‘˜å¾—å‡ºç»“è®ºï¼Œäººæ ¼è½¬å˜æ›´æœ‰å¯èƒ½åœ¨å¾ˆé•¿ä¸€æ®µæ—¶é—´å†…å‘ç”Ÿã€‚\n\nNow, itâ€™s not a perfect study,of course; such a thing is rare, if not impossible, with human beings and personality.\n\nå½“ç„¶ï¼Œè¿™å¹¶éä¸€é¡¹å®Œç¾çš„ç ”ç©¶ï¼›å¯¹äºäººç±»å’Œæ€§æ ¼è€Œè¨€ï¼Œè¿™æ ·çš„ç ”ç©¶å®å±ç½•è§ï¼Œç”šè‡³å¯ä»¥è¯´æ˜¯ä¸å¯èƒ½çš„ã€‚\n\nFor instance, the people who did the ratings in 1950 were not the same people who did the ratings in 2012, and this could have caused some difference.\n\nä¾‹å¦‚ï¼Œ1950 å¹´è¿›è¡Œè¯„çº§çš„äººä¸ 2012 å¹´è¿›è¡Œè¯„çº§çš„äººå¹¶éåŒä¸€æ‹¨äººï¼Œè¿™å¯èƒ½ä¼šé€ æˆä¸€äº›å·®å¼‚ã€‚\n\nItâ€™s difficult for a study on something as broad as identity and personality to take all the variables into consideration.\n\nå¯¹äºåƒèº«ä»½å’Œæ€§æ ¼è¿™æ ·å¹¿æ³›çš„ç ”ç©¶è¯¾é¢˜æ¥è¯´ï¼Œè¦å°†æ‰€æœ‰å˜é‡éƒ½è€ƒè™‘åœ¨å†…æ˜¯å¾ˆå›°éš¾çš„ã€‚\n\nHowever, the results are still significant, and they have interesting implications.\n\nç„¶è€Œï¼Œç»“æœä»ç„¶æ˜¯é‡è¦çš„ï¼Œä»–ä»¬æœ‰æœ‰è¶£çš„å¯ç¤ºã€‚\n\nLetâ€™s consider some of those implications for a moment. What does it all mean? And is it only of academic interest, or can you yourself apply this knowledge to your own life?\n\nè®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹å…¶ä¸­çš„ä¸€äº›å«ä¹‰ã€‚è¿™ä¸€åˆ‡æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™ä»…ä»…æ˜¯å­¦æœ¯ä¸Šçš„å…´è¶£ï¼Œè¿˜æ˜¯ä½ èƒ½æŠŠè¿™äº›çŸ¥è¯†åº”ç”¨åˆ°ä½ è‡ªå·±çš„ç”Ÿæ´»ä¸­ï¼Ÿ\n\nFor one thing,it should give you a new way to think about other people.\n\né¦–å…ˆï¼Œå®ƒåº”è¯¥ç»™ä½ ä¸€ç§æ€è€ƒä»–äººçš„æ–°æ–¹å¼ã€‚\n\nFor example, say youâ€™re contacted on social media by someone you knew in school years ago. If you didnâ€™t like the person at that time, you might be tempted to refuse the connection.\n\nä¾‹å¦‚ï¼Œå‡è®¾ä½ åœ¨ç¤¾äº¤åª’ä½“ä¸Šè¢«ä½ å¤šå¹´å‰åœ¨å­¦æ ¡è®¤è¯†çš„äººè”ç³»ã€‚å¦‚æœä½ å½“æ—¶ä¸å–œæ¬¢è¿™ä¸ªäººï¼Œä½ å¯èƒ½ä¼šæƒ³è¦æ‹’ç»è¿™æ®µå…³ç³»ã€‚\n\nIf you didnâ€™t like each other then, after all, why would you like each other now?\n\næ¯•ç«Ÿï¼Œå¦‚æœä½ ä»¬å½“æ—¶ä¸å–œæ¬¢å¯¹æ–¹ï¼Œä¸ºä»€ä¹ˆç°åœ¨ä¼šå–œæ¬¢å¯¹æ–¹å‘¢ï¼Ÿ\n\nBut if itâ€™s true that personality can change, then thereâ€™s a reason to give that person another chance.\n\nä½†å¦‚æœæ€§æ ¼çœŸçš„å¯ä»¥æ”¹å˜ï¼Œé‚£å°±æœ‰ç†ç”±å†ç»™é‚£ä¸ªäººä¸€æ¬¡æœºä¼šã€‚\n\nHe or she might be very different now -and you might beto0.\n\nä»–æˆ–å¥¹ç°åœ¨å¯èƒ½å’Œä»¥å‰å¤§ä¸ç›¸åŒäº† â€”â€” ä½ ä¹Ÿå¯èƒ½æ˜¯ã€‚\n\nYou might also have more reasonable expectations of old childhood friends who reconnect after many years.\n\nä½ ä¹Ÿå¯èƒ½å¯¹å¤šå¹´åé‡æ–°è”ç³»çš„ç«¥å¹´è€æœ‹å‹æœ‰æ›´åˆç†çš„æœŸæœ›ã€‚\n\nIf you know their personalities (and yours) could have changed over the years, youâ€™ll be less disappointed if your friendship isnâ€™t as deep now as it was before.\n\nå¦‚æœä½ çŸ¥é“ä»–ä»¬ï¼ˆå’Œä½ è‡ªå·±ï¼‰çš„æ€§æ ¼å¯èƒ½ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œæ”¹å˜ï¼Œé‚£ä¹ˆå¦‚æœä½ ä»¬çš„å‹è°Šæ²¡æœ‰ä»¥å‰é‚£ä¹ˆæ·±åšï¼Œä½ å°±ä¸ä¼šé‚£ä¹ˆå¤±æœ›äº†ã€‚\n\nRather than feel frustrated with yourselves, the two of you can accept that you have changed.\n\nä¸å…¶å¯¹è‡ªå·±æ„Ÿåˆ°æ²®ä¸§ï¼Œä¸å¦‚æ¥å—è‡ªå·±å·²ç»æ”¹å˜çš„äº‹å®ã€‚\n\nThe study has implications for the workplace too.\n\nè¿™é¡¹ç ”ç©¶å¯¹å·¥ä½œåœºæ‰€ä¹Ÿæœ‰å½±å“ã€‚\n\nPersonality forms a large part of a workerâ€™s suitability for a job, both in dealing with co-workers and in dealing with clients.\n\næ€§æ ¼åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†ä¸€ä¸ªäººæ˜¯å¦é€‚åˆä¸€ä»½å·¥ä½œï¼Œæ— è®ºæ˜¯åœ¨ä¸åŒäº‹æ‰“äº¤é“è¿˜æ˜¯ä¸å®¢æˆ·æ‰“äº¤é“æ—¶ã€‚\n\nIf a person has a personality trait that interferes with work-say he argues with customers or she misses deadlines-itâ€™s important for managers to know that these traits can change.\n\nå¦‚æœä¸€ä¸ªäººçš„æ€§æ ¼ç‰¹å¾ä¼šå¹²æ‰°å·¥ä½œï¼Œæ¯”å¦‚ä»–ä¼šå’Œå®¢æˆ·äº‰åµï¼Œæˆ–è€…å¥¹é”™è¿‡äº†æˆªæ­¢æ—¥æœŸï¼Œé‚£ä¹ˆç®¡ç†è€…å°±åº”è¯¥çŸ¥é“è¿™äº›æ€§æ ¼ç‰¹å¾æ˜¯å¯ä»¥æ”¹å˜çš„ã€‚\n\nItâ€™s usually cheaper to train a current employee than to let that person go and hire a replacement.\n\né€šå¸¸æ¥è¯´ï¼ŒåŸ¹è®­ä¸€åç°æœ‰å‘˜å·¥è¦æ¯”è®©ä»–ç¦»å¼€å¹¶é›‡ä½£ä¸€ä¸ªæ›¿ä»£è€…ä¾¿å®œå¾—å¤šã€‚\n\nEven employees who arenâ€™t experiencing problems can be trained to be even better and more effective in terms of personality.\n\nå³ä½¿æ²¡æœ‰é‡åˆ°é—®é¢˜çš„å‘˜å·¥ä¹Ÿå¯ä»¥é€šè¿‡åŸ¹è®­ï¼Œåœ¨ä¸ªæ€§æ–¹é¢è¡¨ç°å¾—æ›´å¥½ã€æ›´æœ‰æ•ˆã€‚\n\nThis will help ensure that people continue to get along with one another.\n\nè¿™å°†æœ‰åŠ©äºç¡®ä¿äººä»¬ç»§ç»­å½¼æ­¤ç›¸å¤„ã€‚\n\nFinally, there are personal implications.\n\næœ€åï¼Œè¿˜æœ‰ä¸ªäººå½±å“ã€‚\n\nIf youâ€™re the sort of person who says things like &quot;I have a quick temper&quot;or â€œMy problem is I canâ€™t help procrastinatingâ€ or &quot;Iâ€™ve always been too sensitive, and I blame myself when ever something goes wrong,&quot;it should be good news to know that these personality traits are not ones you have to keep.\n\nå¦‚æœä½ æ˜¯é‚£ç§ä¼šè¯´ â€œæˆ‘è„¾æ°”æš´èºâ€ æˆ– â€œæˆ‘çš„é—®é¢˜æ˜¯æˆ‘æ€»æ˜¯å¿ä¸ä½æ‹–å»¶â€ æˆ– â€œæˆ‘æ€»æ˜¯å¤ªæ•æ„Ÿï¼Œä¸€æ—¦å‡ºäº†é—®é¢˜æˆ‘å°±ä¼šè´£æ€ªè‡ªå·±â€ çš„äººï¼Œé‚£ä¹ˆçŸ¥é“è¿™äº›æ€§æ ¼ç‰¹å¾å¹¶ä¸æ˜¯ä½ å¿…é¡»ä¿ç•™çš„ï¼Œè¿™åº”è¯¥æ˜¯ä¸ªå¥½æ¶ˆæ¯ã€‚\n\nAlthough some therapists do good work helping patients accept themselves as they are,to build self-esteem,wouldnâ€™t it be more beneficial to eliminate negative personality traits than to learn to accept them?\n\nå°½ç®¡ä¸€äº›æ²»ç–—å¸ˆåœ¨å¸®åŠ©ç—…äººæ¥å—è‡ªå·±çš„æœ¬æ¥é¢ç›®ã€å»ºç«‹è‡ªå°Šæ–¹é¢åšå¾—å¾ˆå¥½ï¼Œä½†æ¶ˆé™¤æ¶ˆæçš„äººæ ¼ç‰¹å¾ä¸æ˜¯æ¯”å­¦ä¼šæ¥å—å®ƒä»¬æ›´æœ‰ç›Šå—ï¼Ÿ\n\nKnowing that you can change is the first stage in learning how to change.\n\nçŸ¥é“è‡ªå·±å¯ä»¥æ”¹å˜æ˜¯å­¦ä¹ å¦‚ä½•æ”¹å˜çš„ç¬¬ä¸€æ­¥ã€‚\n\nThen you can look forward to saying things like,â€œI used to be too sensitive, but Iâ€™m not anymoreâ€;or look forward to a time when,as we might start saying, you can learn some new tricks.\n\nç„¶åä½ å°±å¯ä»¥æœŸå¾…è¯´è¿™æ ·çš„è¯ï¼šâ€œæˆ‘ä»¥å‰å¤ªæ•æ„Ÿäº†ï¼Œä½†ç°åœ¨ä¸ä¼šäº†ã€‚â€ æˆ–è€…æœŸå¾…æœ‰ä¸€å¤©ï¼Œå°±åƒæˆ‘ä»¬å¼€å§‹è¯´çš„ï¼Œä½ å¯ä»¥å­¦åˆ°ä¸€äº›æ–°æŠ€å·§ã€‚\n\n# C2P1\nOh, no! You dropped the cup, and it smashed! Time to throw it away and buy a new one.\n\nå“¦ï¼Œä¸ï¼ä½ æŠŠæ¯å­æ‰åœ¨åœ°ä¸Šï¼Œæ‰“ç¢äº†ï¼æ˜¯æ—¶å€™æ‰”æ‰å®ƒï¼Œä¹°ä¸€ä¸ªæ–°çš„äº†ã€‚\n\nUnless, perhaps, you are a fan of the Japanese art of kintsugi or kintsukuroiâ€“roughly translated,&quot;to mend with gold.&quot;This is the practice among certain craftsmen of mending the broken pieces of pottery, such as a plate, a cup, or a bowl, with gold (or similar) lacquer.\n\né™¤éä½ æ˜¯æ—¥æœ¬ kintsugi æˆ– kintsukuroi è‰ºæœ¯çš„ç²‰ä¸ã€‚è¿™æ˜¯æŸäº›å·¥åŒ ç”¨é‡‘ï¼ˆæˆ–ç±»ä¼¼çš„ï¼‰æ¼†ä¿®è¡¥ç ´ç¢çš„é™¶å™¨ç¢ç‰‡çš„åšæ³•ï¼Œä¾‹å¦‚ç›˜å­ï¼Œæ¯å­æˆ–ç¢—ã€‚\n\nThe gold is used to glue the pieces back together\n\né‡‘å­æ˜¯ç”¨æ¥æŠŠç¢ç‰‡ç²˜åœ¨ä¸€èµ·çš„\n\nIf small pieces are missing, they can be created out of gold, or a piece from a different bowl or plate can be used instead.\n\nå¦‚æœå°‘äº†ä¸€å°å—ï¼Œå¯ä»¥ç”¨é»„é‡‘åˆ¶ä½œï¼Œæˆ–è€…ç”¨å¦ä¸€ä¸ªç¢—æˆ–ç›˜å­é‡Œçš„å°å—ä»£æ›¿ã€‚\n\nThe repaired productâ€™s value is not reduced, though-it is actually enhanced.\n\nä¿®å¤åçš„äº§å“çš„ä»·å€¼å¹¶æ²¡æœ‰å‡å°‘ï¼Œåè€Œå¢åŠ äº†ã€‚\n\nIt is believed to become more beautiful because it was broken.\n\näººä»¬è®¤ä¸ºå®ƒå› ä¸ºè¢«æ‰“ç ´è€Œå˜å¾—æ›´åŠ ç¾ä¸½ã€‚\n\nPieces of kintsugi pottery can be enormously expensive and are featured in museum exhibits in Japan and overseas.\n\né‡‘æ‰é™¶å™¨éå¸¸æ˜‚è´µï¼Œåœ¨æ—¥æœ¬å’Œæµ·å¤–çš„åšç‰©é¦†éƒ½æœ‰å±•å‡ºã€‚\n\nThese days you can even see machine-made ceramics with gold designs on them that look as if they are kintsugi,even though the original was actually never broken.\n\nå¦‚ä»Šï¼Œä½ ç”šè‡³å¯ä»¥çœ‹åˆ°æœºå™¨åˆ¶ä½œçš„é™¶ç“·ï¼Œä¸Šé¢æœ‰é‡‘è‰²çš„å›¾æ¡ˆï¼Œçœ‹èµ·æ¥åƒæ˜¯é‡‘æ‰ï¼Œå°½ç®¡åŸæ¥çš„é‡‘æ‰å®é™…ä¸Šä»æœªç ´æŸè¿‡ã€‚\n\nBut the mended patterns have become so trendy that people want to imitate them.\n\nä½†æ˜¯ç¼è¡¥çš„å›¾æ¡ˆå˜å¾—å¦‚æ­¤æµè¡Œï¼Œä»¥è‡³äºäººä»¬éƒ½æƒ³æ¨¡ä»¿å®ƒä»¬ã€‚\n\nThereâ€™s a story or legend behind the practice - which may or may not be historically accurate, but beautifully illustrates the concept.\n\nè¿™ç§åšæ³•èƒŒåæœ‰ä¸€ä¸ªæ•…äº‹æˆ–ä¼ è¯´ â€”â€” å¯èƒ½ä¸å†å²ä¸ç›¸ç¬¦ï¼Œä½†å´å¾ˆå¥½åœ°è¯´æ˜äº†è¿™ä¸€æ¦‚å¿µã€‚\n\nMore than five hundred years ago, there lived a military ruler in Japan, who owned a bowl he especially loved.\n\näº”ç™¾å¤šå¹´å‰ï¼Œæ—¥æœ¬æœ‰ä¸€ä½å†›äº‹ç»Ÿæ²»è€…ï¼Œä»–æœ‰ä¸€åªç¢—ï¼Œä»–ç‰¹åˆ«å–œæ¬¢ã€‚\n\nOne day while he was entertaining some guests, his servant dropped the bowl, and it broke into five pieces.\n\nä¸€å¤©ï¼Œå½“ä»–æ‹›å¾…å®¢äººæ—¶ï¼Œä»–çš„ä»†äººæŠŠç¢—æ‰åœ¨åœ°ä¸Šï¼Œæ‘”æˆäº†äº”ç‰‡ã€‚\n\nKnowing the leaderâ€™s bad temper, his guests worried that he would punish the servant\n\nå®¢äººä»¬çŸ¥é“é¦–é¢†çš„åè„¾æ°”ï¼Œæ‹…å¿ƒä»–ä¼šæƒ©ç½šä»†äºº\n\nHowever, one of the guests made up an amusing poem about the incident\n\nç„¶è€Œï¼Œå…¶ä¸­ä¸€ä½å®¢äººå°±è¿™ä»¶äº‹ç¼–äº†ä¸€é¦–æœ‰è¶£çš„è¯—\n\nEverybody laughed, including the ruler.\n\næ¯ä¸ªäººéƒ½ç¬‘äº†ï¼ŒåŒ…æ‹¬ç»Ÿæ²»è€…ã€‚\n\nWhen he relaxed, he was able to see that the bowlâ€™s beauty had not been destroyed by the accident.\n\nå½“ä»–æ”¾æ¾ä¸‹æ¥æ—¶ï¼Œä»–èƒ½çœ‹åˆ°ç¢—çš„ç¾ä¸½å¹¶æ²¡æœ‰è¢«äº‹æ•…ç ´åã€‚\n\nInstead,because the vessel could be repaired, the ruler now had a new appreciation for its strength and ability to survive.\n\nç›¸åï¼Œå› ä¸ºå®¹å™¨å¯ä»¥ä¿®å¤ï¼Œç»Ÿæ²»è€…ç°åœ¨å¯¹å®ƒçš„åŠ›é‡å’Œç”Ÿå­˜èƒ½åŠ›æœ‰äº†æ–°çš„è®¤è¯†ã€‚\n\nIn fact, according to the story, the true life of the bowl began the moment it was dropped.\n\näº‹å®ä¸Šï¼Œæ ¹æ®è¿™ä¸ªæ•…äº‹ï¼Œè¿™ä¸ªç¢—çš„çœŸæ­£ç”Ÿå‘½ä»å®ƒè¢«æ‰”ä¸‹çš„é‚£ä¸€åˆ»å°±å¼€å§‹äº†ã€‚\n\nIf this seems a hard notion to understand, then consider it in light of another Japanese philosophy, that of wabi-sabi.\n\nå¦‚æœè¿™ä¼¼ä¹æ˜¯ä¸€ä¸ªéš¾ä»¥ç†è§£çš„æ¦‚å¿µï¼Œé‚£ä¹ˆè¯·æ ¹æ®å¦ä¸€ç§æ—¥æœ¬å“²å­¦æ¥è€ƒè™‘å®ƒï¼Œé‚£å°±æ˜¯ wabi-sabiã€‚\n\nThis is harder to translate into English, but it refers to the combination of three beliefs that nothing is permanent, nothing is finished, and nothing is perfect.\n\nè¿™å¥è¯å¾ˆéš¾ç¿»è¯‘æˆè‹±è¯­ï¼Œä½†å®ƒæŒ‡çš„æ˜¯ä¸‰ä¸ªä¿¡å¿µçš„ç»“åˆï¼šæ²¡æœ‰ä»€ä¹ˆæ˜¯æ°¸æ’çš„ï¼Œæ²¡æœ‰ä»€ä¹ˆæ˜¯å®Œæˆçš„ï¼Œæ²¡æœ‰ä»€ä¹ˆæ˜¯å®Œç¾çš„ã€‚\n\nApplied to arts and crafts, it explains why the Japanese traditionally value handmade objects.\n\nåº”ç”¨äºå·¥è‰ºå“ï¼Œå®ƒè§£é‡Šäº†ä¸ºä»€ä¹ˆæ—¥æœ¬ä¼ ç»Ÿä¸Šé‡è§†æ‰‹å·¥åˆ¶å“ã€‚\n\nEven though they look less perfect than those made by machine, it is actually this imperfection that makes them beautiful\n\nå°½ç®¡å®ƒä»¬çœ‹èµ·æ¥æ²¡æœ‰æœºå™¨åˆ¶ä½œçš„é‚£ä¹ˆå®Œç¾ï¼Œä½†å®é™…ä¸Šæ­£æ˜¯è¿™ç§ä¸å®Œç¾è®©å®ƒä»¬å˜å¾—ç¾ä¸½\n\nIn fact, artists who value the wabi-sabi aesthetic create works that are deliberately imperfect, such as a bowl that isnâ€™t entirely round or a vase with a thumbprint visible in the clay.\n\näº‹å®ä¸Šï¼Œçœ‹é‡ wabi-sabi ç¾å­¦çš„è‰ºæœ¯å®¶ä¼šåˆ»æ„åˆ›é€ å‡ºä¸å®Œç¾çš„ä½œå“ï¼Œæ¯”å¦‚ä¸€ä¸ªä¸å…¨åœ†çš„ç¢—ï¼Œæˆ–è€…ä¸€ä¸ªåœ¨ç²˜åœŸä¸Šå¯ä»¥çœ‹åˆ°æ‹‡æŒ‡æŒ‡çº¹çš„èŠ±ç“¶ã€‚\n\nRough surfaces, instead of ones smoothed by machines, are common in wabi-sabi ceramics, and often the pieces are not glazed or colored.\n\nç²—ç³™çš„è¡¨é¢ï¼Œè€Œä¸æ˜¯æœºå™¨å…‰æ»‘çš„è¡¨é¢ï¼Œåœ¨ wabi-sabi é™¶ç“·ä¸­å¾ˆå¸¸è§ï¼Œè€Œä¸”è¿™äº›ç¢ç‰‡é€šå¸¸æ²¡æœ‰ä¸Šé‡‰æˆ–ç€è‰²ã€‚\n\nItâ€™s not just Japan that has such a tradition, however\n\nç„¶è€Œï¼Œå¹¶éåªæœ‰æ—¥æœ¬æœ‰è¿™æ ·çš„ä¼ ç»Ÿ\n\nA similar idea can be found in Iran, among the makers of Persian rugs.\n\nåœ¨ä¼Šæœ—çš„æ³¢æ–¯åœ°æ¯¯åˆ¶é€ å•†ä¸­ä¹Ÿå¯ä»¥æ‰¾åˆ°ç±»ä¼¼çš„æƒ³æ³•ã€‚\n\nTradition has it that those who weave carpets will deliberately include one small flaw,as recognition of the fact that nothing can be perfect.\n\nä¼ ç»Ÿä¸Šï¼Œç¼–ç»‡åœ°æ¯¯çš„äººä¼šæ•…æ„ç•™ä¸‹ä¸€ä¸ªå°ç‘•ç–µï¼Œå› ä¸ºä»–ä»¬æ„è¯†åˆ°æ²¡æœ‰ä»€ä¹ˆæ˜¯å®Œç¾çš„ã€‚\n\nThe intentional mistake reminds them to be modest about their work.\n\næ•…æ„çš„é”™è¯¯æé†’ä»–ä»¬å¯¹è‡ªå·±çš„å·¥ä½œè¦è°¦è™šã€‚\n\nSimilarly, some early American settlers known as the Puritans included a â€œhumility squareâ€ when they sewed a quilt -one square that didnâ€™t match the rest of the blanket.\n\nç±»ä¼¼åœ°ï¼Œä¸€äº›è¢«ç§°ä¸ºæ¸…æ•™å¾’çš„æ—©æœŸç¾å›½å®šå±…è€…åœ¨ç¼åˆ¶è¢«å­æ—¶ä¹Ÿä¼šé™„ä¸Šä¸€å— â€œè°¦å‘çš„æ–¹å·¾â€â€”â€” è¿™å—æ–¹å·¾ä¸æ¯¯å­çš„å…¶ä»–éƒ¨åˆ†ä¸åŒ¹é…ã€‚\n\nSome Native American bead workers would include an intentional â€œmistake beadâ€ for the same reason.\n\nå‡ºäºåŒæ ·çš„åŸå› ï¼Œä¸€äº›å°ç¬¬å®‰äººçš„å¤´é¥°å·¥äººä¼šæ•…æ„åŠ ä¸Šä¸€ä¸ª â€œé”™è¯¯çš„å¤´é¥°â€ã€‚\n\nSuch practices have also been reported among Amish furniture makers in the United States and some forms of Islamic art - although careful work by sociologists and historians suggests that these stories are actually not true, but rather a romanticized version of their art or a misunderstanding of a tradition.\n\nåœ¨ç¾å›½çš„é˜¿ç±³ä»€å®¶å…·åˆ¶é€ å•†å’ŒæŸäº›å½¢å¼çš„ä¼Šæ–¯å…°è‰ºæœ¯ä¸­ä¹Ÿæœ‰ç±»ä¼¼çš„æŠ¥é“ â€”â€” å°½ç®¡ç¤¾ä¼šå­¦å®¶å’Œå†å²å­¦å®¶çš„ä»”ç»†ç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›æ•…äº‹å®é™…ä¸Šä¸æ˜¯çœŸå®çš„ï¼Œè€Œæ˜¯ä»–ä»¬è‰ºæœ¯çš„æµªæ¼«åŒ–ç‰ˆæœ¬ï¼Œæˆ–è€…æ˜¯å¯¹ä¼ ç»Ÿçš„è¯¯è§£ã€‚\n\nTrue or not,however, these cultural practices teach us not only about art but about life, and the importance of not only accepting, but actually celebrating, our imperfections.\n\næ— è®ºçœŸå‡ï¼Œè¿™äº›æ–‡åŒ–å®è·µä¸ä»…æ•™ä¼šäº†æˆ‘ä»¬è‰ºæœ¯ï¼Œä¹Ÿæ•™ä¼šäº†æˆ‘ä»¬ç”Ÿæ´»ï¼Œæ•™ä¼šäº†æˆ‘ä»¬ä¸ä»…è¦æ¥å—ï¼Œè€Œä¸”è¦èµç¾æˆ‘ä»¬çš„ä¸å®Œç¾çš„é‡è¦æ€§\n\nThat doesnâ€™t mean we shouldnâ€™t care about making mistakes; but for many people, worrying about small imperfections keeps them from finishing a project or appreciating one they have finished.\n\nè¿™å¹¶ä¸æ„å‘³ç€æˆ‘ä»¬ä¸åº”è¯¥åœ¨æ„çŠ¯é”™è¯¯ï¼›ä½†å¯¹å¾ˆå¤šäººæ¥è¯´ï¼Œæ‹…å¿ƒå°ç‘•ç–µè®©ä»–ä»¬æ— æ³•å®Œæˆä¸€ä¸ªé¡¹ç›®ï¼Œä¹Ÿæ— æ³•æ¬£èµä»–ä»¬å·²ç»å®Œæˆçš„é¡¹ç›®ã€‚\n\nPeople who are â€œperfectionistsâ€ can feel insecure and anxious about the art they create, which makes it harder for them to enjoy what they do.\n\nâ€œå®Œç¾ä¸»ä¹‰è€…â€ ä¼šå¯¹è‡ªå·±åˆ›é€ çš„è‰ºæœ¯æ„Ÿåˆ°ä¸å®‰å’Œç„¦è™‘ï¼Œè¿™ä½¿å¾—ä»–ä»¬æ›´éš¾äº«å—è‡ªå·±æ‰€åšçš„äº‹æƒ…ã€‚\n\nThe concept can even be applied more broadly than just to art, however.\n\nç„¶è€Œï¼Œè¿™ä¸ªæ¦‚å¿µç”šè‡³å¯ä»¥åº”ç”¨äºæ›´å¹¿æ³›çš„é¢†åŸŸï¼Œè€Œä¸ä»…ä»…æ˜¯è‰ºæœ¯ã€‚\n\nConsider yourself, for example. Do you have any imperfections - anything from physical scars to personal habits?\n\nä»¥ä½ è‡ªå·±ä¸ºä¾‹ã€‚ä½ æœ‰ä»€ä¹ˆä¸å®Œç¾çš„åœ°æ–¹å— â€”â€” ä»èº«ä½“ä¸Šçš„ä¼¤ç–¤åˆ°ä¸ªäººä¹ æƒ¯ï¼Ÿ\n\nWhat if, instead of considering these to be flaws, you could appreciate them as part of what makes you a beautiful person?\n\nå¦‚æœä½ ä¸è®¤ä¸ºè¿™äº›æ˜¯ç¼ºç‚¹ï¼Œè€Œæ˜¯æŠŠå®ƒä»¬çœ‹ä½œæ˜¯è®©ä½ æˆä¸ºä¸€ä¸ªç¾ä¸½çš„äººçš„ä¸€éƒ¨åˆ†å‘¢ï¼Ÿ\n\n","categories":["English"],"tags":["è‹±è¯­"]},{"title":"è‹±è¯­ç¬”è®°","url":"/English/xbbEnglish/","content":"# é¢†èˆª\n\næ ¸å¿ƒå†…å®¹æ¥è‡ªé¢‰æ–Œæ–Œè€å¸ˆ\n\n# é˜…è¯»\n# å¸¸è€ƒçš„éšå«å‡è®¾\n\n\n\nè¦ç´ \néšå«å‡è®¾\n\n\n\n\nåšäº†ä»€ä¹ˆ\nè®ºè¿°çš„ä¸»ä½“æœ‰èƒ½åŠ› / æ¡ä»¶å¯ä»¥åš\n\n\nå»ºè®® / åº”è¯¥å»åšä¸€ä»¶äº‹æƒ…\nè¿™ä»¶äº‹è¿˜æ²¡æœ‰åšè¿‡ï¼Œä½œè€…è®¤ä¸ºè¿™ä»¶äº‹åˆç†\n\n\nä¸ºä»€ä¹ˆ + è§‚ç‚¹\nè§‚ç‚¹æˆç«‹\n\n\nä¸€ä¸ªæªæ–½æœ‰åˆ©ï¼Œåº”è¯¥å»åš\nåŒæ—¶ä¸ä¼šæœ‰æ›´å¤§çš„å¼Šç«¯\n\n\nä¸€ä¸ªæªæ–½ä¸åˆ©ï¼Œåº”è¯¥å»åš\nåŒæ—¶ä¸ä¼šå‡ºç°æ›´å¤§çš„åˆ©\n\n\nç¦æ­¢åšä¸€ä»¶çš„äº‹æƒ…\nè¿™ä»¶äº‹å·²ç»è¢«åšè¿‡\n\n\n\n# é€‰é¡¹æ¯”é”™çš„ä¾æ®\n\nç­”æ¡ˆå·²çŸ¥ä¸”å”¯ä¸€\né€‰é¡¹å…·æœ‰æœ‰é™æ€§ï¼ˆ4 ä¸ªï¼‰\n\næ¯”å‡ºä¸€ä¸ªæœ€ä½³é€‰æ‹©å³å¯ï¼Œæ”¾å¼ƒæ±‚è¯æ¯æ—¥ä¸€ä¸ªé€‰é¡¹çš„æ­£ç¡®äºé”™è¯¯\nä½†ï¼Œä»€ä¹ˆæ˜¯æœ€ä½³ï¼Ÿ\nå®é™…ä¸Šï¼Œæ‰¾å¯¹å¾ˆéš¾ï¼Œ æ¯”é”™æ¯”æ¯”å¯¹æ›´åŠ å®¹æ˜“ï¼\né€‰é¡¹æ¯”é”™æ˜¯é«˜æ•ˆçš„åšæ³•\n# æ¯”é”™çš„é€»è¾‘\nä¾æ®ç²¾å‡†å®šä½ï¼Œè¯„ä¼°ä¸€ä¸ªå‡ºé”™ç‡æœ€å°çš„é€‰é¡¹\næ¯”é€‰é¡¹ğŸ‘‰ç›¸å¯¹æ€§ğŸ‘‰å€ŸåŠ©å…¶ä»–é€‰é¡¹\næ¯”é”™ğŸ‘‰ æ¯”è¾ƒå››ä¸ªé€‰é¡¹é”™è¯¯ç‡çš„å¤§å°\nå‡ºé”™ç‡æœ€å°ä¸æ˜¯å®Œå…¨æ­£ç¡®ï¼Œæ”¾å¼ƒè¿½æ±‚å®Œå…¨æ­£ç¡®çš„æ‰§å¿µï¼Œè½¬å˜ä¸º â€œæ¥å—æœ€ä½³çš„é€‰é¡¹â€ çš„æ–°è®¤è¯†ã€‚\n\nWhen you have eliminated the impossible ï¼Œwhatever remainsï¼Œhowever improbableï¼Œmust be the truth.\n\n# ç²¾å‡†å®šä½ + é€‰é¡¹æ¯”é”™\n# å®šä½ä¸åˆ°çš„è§£é¢˜æ€è·¯\n\nåå‘å®šä½ï¼ˆåˆ¤æ–­é€‰é¡¹ä¿¡æ¯æ­£è¯¯ï¼‰\nå–å / å–é\nåŸå‘½é¢˜è½¬é€†å¦å‘½é¢˜\nä¸»é¢˜ä¸»æ—¨\n\n# å†™ä½œ (å¤§ä½œæ–‡)\n# å›¾ç”»ä½œæ–‡\n# è¡Œæ–‡æ¡†æ¶\n# ç¬¬ä¸€æ®µï¼ˆ2-3 å¥ï¼‰\n\nå¼•å‡ºä¸»é¢˜\næè¿°å›¾ç‰‡\nè¯„ä»·å›¾ç‰‡ï¼ˆå¯æœ‰å¯æ— ï¼‰\n\n# ç¬¬äºŒæ®µï¼ˆ5 å¥ï¼‰\n\né‡ç”³ä¸»é¢˜ + åˆ†æå½±å“\nå½±å“ 1 + ç ”ç©¶è°ƒæŸ¥\nå½±å“ 2 + åäººåè¨€\n\n# ç¬¬ä¸‰æ®µ\n\nå‡åä¸»é¢˜\nå»ºè®®æªæ–½\nå±•æœ›æœªæ¥ï¼ˆå¯æœ‰å¯æ— ï¼‰\n\n# å¼•å‡ºä¸»é¢˜çš„å¥å­ï¼ˆé€‰ä¸€ä¸ªå³å¯ï¼‰\nThe animated cartoon reminds its readers of the significance of  (ä¸»é¢˜è¯).\n\nçœ‹åˆ°è¿™å‰¯ç”ŸåŠ¨çš„æ¼«ç”»ï¼Œäººä»¬æƒ³åˆ°äº†ï¼ˆä¸»é¢˜è¯ï¼‰çš„é‡è¦æ€§\n\nNothing can get us denying that (ä¸»é¢˜è¯), under any circumstances, tends to be of great/enormous importance.\n\nä¸å¯å¦è®¤ï¼Œåœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œï¼ˆä¸»é¢˜è¯ï¼‰å¾€å¾€å¾ˆé‡è¦\n\nYou will not miss thinking that (ä¸»é¢˜è¯) is playing an indispensable role in our life and work.\n\nä½ ä¸€å®šä¼šæƒ³åˆ°ï¼ˆä¸»é¢˜è¯ï¼‰åœ¨æˆ‘ä»¬çš„ç”Ÿæ´»å’Œå·¥ä½œä¸­çš„èµ·ç€ä¸å¯æˆ–ç¼ºçš„ä½œç”¨ï¼ˆèƒŒï¼‰\n\n# æè¿°å›¾ç‰‡çš„å¥å­\nThe picture is mainly related to the case that (å›¾ç‰‡ä¸»è¦äººç‰© / äº‹ç‰©) + ï¼ˆdoing/doneâ€¦ï¼‰, which can be a vivid expression of the topic.\n\nè¿™ä¸€å›¾ç‰‡ä¸»è¦å’Œâ€¦ æœ‰å…³ï¼Œè¯¥å›¾æ˜¯å¯¹ä¸»é¢˜è¯çš„ç”ŸåŠ¨è¡¨è¾¾ï¼ˆèƒŒï¼‰\n\n# è¯„ä»·å›¾ç‰‡ï¼ˆå¯æœ‰å¯æ— ï¼‰\nWhat the drawer tries to convey has profound practical significance.\n\nç”»å®¶è¯•å›¾ä¼ è¾¾çš„ä¿¡æ¯å…·æœ‰æ·±åˆ»çš„ç°å®æ„ä¹‰ã€‚(å¯ä»¥èƒŒä¸€ä¸‹)\n\nSimple as the picture looks, its implicit meaning should be thoughtâ€“provoking.\n\nå°½ç®¡å›¾ç‰‡ç®€å•ï¼Œä½†å…¶å†…æ¶µå‘äººæ·±çœã€‚\n\nThe cartoon, at first glance, seems to be simple, but the deep meaning behind it is worth pondering.\n\nè¿™å¹…æ¼«ç”»ä¹ä¸€çœ‹ä¼¼ä¹å¾ˆç®€å•ï¼Œä½†å…¶æ·±å±‚å«ä¹‰å€¼å¾—æ·±æ€ã€‚\n\n# é‡ç”³ä¸»é¢˜ + åˆ†æå½±å“\nConsidering the significance ofï¼ˆä¸»é¢˜è¯ï¼‰, it is necessary to point out the far-reaching consequences behind it.\n\nè€ƒè™‘åˆ° (ä¸»é¢˜è¯) çš„é‡è¦æ€§ï¼Œæœ‰å¿…è¦æŒ‡å‡ºå…¶èƒŒåæ„ä¹‰æ·±è¿œçš„å½±å“ã€‚\n\nThere seems to be more than one direct or indirect effect involved in (ä¸» é¢˜ è¯) , which none of us can fail to notice.\n\nä¼¼ä¹ä¸æ­¢ä¸€ä¸ªç›´æ¥æˆ–é—´æ¥çš„å½±å“ä¸ (ä¸»é¢˜è¯) æœ‰å…³ï¼Œæˆ‘ä»¬æ— æ³•å¿½è§†è¿™äº›å½±å“ã€‚(èƒŒ)\n\nThe effects that (ä¸»é¢˜è¯) can exert are obvious and within easy reach.\n\n(ä¸»é¢˜è¯) äº§ç”Ÿçš„å½±å“æ˜¾è€Œæ˜“è§ï¼Œä¹Ÿæ˜¯ä¸éš¾æ‰¾åˆ°çš„ã€‚\n\n# å½±å“ 1 + è°ƒæŸ¥ç ”ç©¶\n# ä¸‡èƒ½ç†ç”±å…ˆè¡Œ\n\n\næˆé•¿ / æˆåŠŸ / å‘å±•\n\nä¸ªäººè¯é¢˜ï¼šthe growth /success/prospect of individual\nç¤¾ä¼šè¯é¢˜ï¼šthe development of economy /society/culture /legal system /enviroment\n\n\n\nçŸ¥è¯† / é˜…å† / æœºä¼š\n\nacquire adequate knowledge and experience\n\n\n\næ•ˆç‡ / ä¾¿åˆ© / æ—¶é—´\n\nefficiency / convenience\n\n\n\nå¥åº·ï¼ˆèº«ä½“å’Œå¿ƒç†ï¼‰ / å‹åŠ› / æ„‰æ‚¦\n\nphysical health / mental health\npressure / stress / stain\nbring a lot of mental and physical pleasure\n\n\n\n# åˆ†æå½±å“\nIt is generally recognized that nothing is more important than (ä¸»é¢˜è¯) for (å››å¤§ä¸‡èƒ½ç†ç”±) .\n\näººä»¬æ™®éè®¤ä¸º (ä¸»é¢˜è¯) å¯¹ (å››å¤§ä¸‡èƒ½ç†ç”±) æœ€é‡è¦ã€‚ï¼ˆèƒŒï¼‰\n\n# è°ƒæŸ¥ç ”ç©¶\nDepending upon a rough estimate of the relevant department, nearly 86.2% of the respondents hold the same view.\n\næ ¹æ®æœ‰å…³éƒ¨é—¨çš„ç²—ç•¥ä¼°è®¡ï¼Œè¿‘ 86.2% çš„å—è®¿è€…æŒç›¸åŒè§‚ç‚¹ã€‚\nrelevant department å¯ä»¥æ›¿æ¢ä¸ºå…·ä½“éƒ¨é—¨\n\nA recent Internet questionnaire of the relevant department indicates that approximately 86.2% of the respondents hold the same view.\n\næœ‰å…³éƒ¨é—¨æœ€è¿‘çš„ä¸€ä»½äº’è”ç½‘é—®å·æ˜¾ç¤ºï¼Œçº¦ 86.2% çš„å—è®¿è€…æŒç›¸åŒè§‚ç‚¹ã€‚ï¼ˆèƒŒï¼‰\n\n# å½±å“ 2 + åäººåè¨€\n# åˆ†æå½±å“\n(ä¸»é¢˜è¯) contributes to/is conducive to/is responsible for (å››å¤§ä¸‡èƒ½ç†ç”±) .\n\n(ä¸»é¢˜è¯) æœ‰åŠ©äº (å››å¤§ä¸‡èƒ½ç†ç”±) ã€‚\n\n# åäººåè¨€\nAs Envduct Karryguess, director of community service at LA College in LitLingo, puts it, â€œ(ä¸‡èƒ½ç†ç”±) , needless to say,  enormous importance for us.â€\n# å‡åä¸»é¢˜\nAll these factors support a rational conclusion that great importance should be attached to (ä¸»é¢˜è¯)\n\næ‰€æœ‰è¿™äº›å› ç´ éƒ½æ”¯æŒä¸€ä¸ªåˆç†çš„ç»“è®ºï¼Œå³åº”è¯¥å¯¹ (ä¸»é¢˜è¯) ç»™äºˆé‡è§†ã€‚\n\n# å»ºè®®æªæ–½\nEveryone should cultivate a better awareness of it and take practical actions.\n\næ¯ä¸ªäººéƒ½åº”æ›´å¥½åœ°æ„è¯†åˆ°è¿™ä¸€ç‚¹ï¼Œå¹¶é‡‡å–å®é™…è¡ŒåŠ¨ã€‚\n\nStrict laws and disciplines can guarantee the smooth running of the society\n\nä¸¥æ ¼çš„æ³•å¾‹å’Œçºªå¾‹å¯ä»¥ä¿è¯ç¤¾ä¼šçš„å¹³ç¨³è¿è¡Œã€‚\n\n# å±•æœ›æœªæ¥ï¼ˆå¯æœ‰å¯æ— ï¼‰\nOnly in this way would our life become more real and meaningful\n\nåªæœ‰è¿™æ ·ï¼Œæˆ‘ä»¬çš„ç”Ÿæ´»æ‰èƒ½å˜å¾—æ›´åŠ çœŸå®å’Œå¯Œæœ‰æ„ä¹‰ã€‚\n\n# åŸå‹\n\tYou will not miss thinking that (ä¸»é¢˜è¯) is playing an indispensable role in our life   and work.The picture is mainly related to the case that ( å›¾ç‰‡ä¸»è¦äººç‰©/äº‹ç‰© ) + ï¼ˆdoing/done....ï¼‰, which can be a vivid expression of the topic.\n\tThere seems to be more than one direct or indirect effect involved in ( ä¸» é¢˜ è¯ ) , which none of us can fail to notice.It is generally recognized that nothing is more important than (ä¸»é¢˜è¯) for (å››å¤§ä¸‡èƒ½ç†ç”±) .A recent Internet questionnaire of the relevant department indicates that approximately 86.2% of the respondents hold the same view. (ä¸»é¢˜è¯) contributes to (å››å¤§ä¸‡èƒ½ç†ç”±) .As Envduct Karryguess, director of community service at LA College in LitLingo, puts it, â€œ (ä¸‡èƒ½ç†ç”±) , needless to say,  enormous importance for us.â€\n\tAll these factors support a rational conclusion that great importance should be attached to(ä¸»é¢˜è¯). Everyone should cultivate a better awareness of it and take practical actions.\n\nåŸå‹å‡€çº¦ 136 è¯\n# è¯•å†™ï¼ˆ2005. PartB. 52.ï¼‰\n\tYou will not miss thinking that concern elderly is palying an indispensable role in our life and work. The picture is mainly related to the case that four children would not like to take care their father.\n\tThere seems to be more than one direct or indirect effect involed in concern elderly, which none of us can fail to notice, It is generally recognized that nothing is more important than concern elderly for bring a lot of mental and physical pleasure. A recent Internet questionnaire of the relevant department indicates that approximately 82.6% of the respondents hold the same view. concern elderly contributes to a happy old age. As Envduc Karry, director of community service at LA College in LitLingo, put it,&quot;A happy old age ,needless to say, enormous importance for elderly.&quot;\n\tAll these factors support a rational conclusion that great importance should be attached to concern elderly. Everyone should cultivate a better awareness of it and take pratical actions.\n\nè¯•å†™ä»…ä¸ºä½œè€…çš„ç»ƒä¹ ï¼Œä¸æ˜¯èŒƒæ–‡ï¼ä¸æ˜¯èŒƒæ–‡ï¼ä¸æ˜¯èŒƒæ–‡ï¼å¯èƒ½ä¸ä¼šæ‹¿åˆ°å¾ˆé«˜çš„åˆ†æ•°ï¼Œä»…ä¾›å‚è€ƒã€‚\nå…± 161 è¯ï¼Œè™½ç„¶é’ˆå¯¹ 2005 å¹´çš„è¦æ±‚æœ‰ç‚¹æ‰è¥Ÿè§è‚˜ï¼Œä½†å¯¹äºæ–°æ ‡å‡†æ¥è¯´è¿˜æ˜¯æ¸¸åˆƒæœ‰ä½™çš„ã€‚\n# å›¾è¡¨ä½œæ–‡\n# è¡Œæ–‡æ¡†æ¶\n# ç¬¬ä¸€æ®µï¼ˆ2-3 å¥ï¼‰\n\nå¼•å‡ºä¸»é¢˜\næè¿°å›¾è¡¨\nè¯„ä»·å›¾è¡¨ï¼ˆå¯æœ‰å¯æ— ï¼‰\n\n# ç¬¬äºŒæ®µï¼ˆ5 å¥ï¼‰\n\né‡ç”³ä¸»é¢˜ + åˆ†æåŸå› \nåŸå›  1 + ç ”ç©¶è°ƒæŸ¥\nåŸå›  2 + åäººåè¨€\n\n# ç¬¬ä¸‰æ®µ\n\nå‡åä¸»é¢˜\nå»ºè®®æªæ–½\nå±•æœ›æœªæ¥ï¼ˆå¯æœ‰å¯æ— ï¼‰\n\n# å¼•å‡ºä¸»é¢˜\nï¼ˆä¸»é¢˜ï¼‰is clearly shown in the picture.\n\nåœ¨å›¾è¡¨ä¸­æ¸…æ¥šçš„è¡¨ç¤ºäº†ï¼ˆä¸»é¢˜ï¼‰\n\nï¼ˆä¸»é¢˜ï¼‰is what the chart tries to convey.\n\n(ä¸»é¢˜) æ˜¯å›¾è¡¨æƒ³è¦ä¼ è¾¾çš„ä¿¡æ¯\n\nThe chart,in an obvious way, speaks volumes about the phenomenon that (ä¸»é¢˜).   ï¼ˆèƒŒï¼‰\n\nè¿™å¼ å›¾è¡¨æ˜¾ç„¶è¡¨æ˜äº†ä¸€ä¸ªç°è±¡ï¼Œå³ï¼ˆä¸»é¢˜ï¼‰\n\nThe chart above demonstrates clearly that some changes have taken place in terms ofï¼ˆæ•°æ®æ ‡é¢˜ï¼‰\n\nä¸Šå›¾æ¸…æ¥šåœ°è¡¨æ˜ï¼Œåœ¨ï¼ˆæ•°æ®æ ‡é¢˜ï¼‰æ–¹é¢å·²ç»å‘ç”Ÿäº†ä¸€äº›å˜åŒ–ã€‚\n\n# æè¿°å›¾è¡¨\n# é¥¼çŠ¶å›¾ / è¡¨æ ¼\nX accounts for the highest percentage at x% of ï¼ˆä¸»é¢˜è¯ï¼‰,followed by B at y% and C ,z%. At the bottom of the chart, k% is regarded as D.\n\nX å äº†ï¼ˆä¸»é¢˜è¯ï¼‰çš„æœ€é«˜æ¯”ä¾‹å³ x%ï¼Œç´§æ¥ç€æ˜¯ B å äº† y%ï¼ŒC å äº† z%ã€‚D å äº†å›¾çš„æœ€å°‘çš„ä¸€éƒ¨åˆ†ï¼Œæ˜¯ k%ã€‚\n\n# æŸ±çŠ¶å›¾ / æŠ˜çº¿å›¾\nThere was a ï¼ˆdramatic increase/a steep dropï¼‰ in the number of (ä¸€ä¸ªä¸œè¥¿) from ï¼ˆæ•°æ®ï¼‰in ï¼ˆæ—¶é—´ï¼‰toï¼ˆæ•°æ®ï¼‰ in ï¼ˆæ—¶é—´ï¼‰.\n\n(ä¸€ä¸ªä¸œè¥¿çš„) æ•°æ®å‡ºç°äº†æ€¥å‰§çš„ä¸Šå‡ / ä¸¥é‡çš„çš„ä¸‹é™ï¼Œä»ï¼ˆæ—¶é—´ï¼‰çš„ï¼ˆæ•°æ®ï¼‰åˆ°ï¼ˆæ—¶é—´ï¼‰çš„ï¼ˆæ•°æ®ï¼‰ã€‚\n\n# é‡ç”³ä¸»é¢˜ + åˆ†æåŸå› \nThe reasons that caused the phenomenon are obvious and within easy reach.\n\nå¯¼è‡´è¿™ä¸€ç°è±¡çš„åŸå› æ˜¯æ˜¾è€Œæ˜“è§çš„ã€‚\n\nAfter observation and consideration, some reasons of ï¼ˆä¸»é¢˜è¯ï¼‰ can be highlight as follows.\n\nç»è¿‡è§‚å¯Ÿå’Œè€ƒè™‘ï¼Œå°†ä¸€äº›åŸå› åˆ—ä¸¾å¦‚ä¸‹ã€‚ï¼ˆèƒŒï¼‰\n\n# åŸå›  1 + ç ”ç©¶è°ƒæŸ¥\nåŒå›¾ç”»ä½œæ–‡\n# åŸå›  2 + åäººåè¨€\nåŒå›¾ç”»ä½œæ–‡\n# å‡åä¸»é¢˜\nåŒå›¾ç”»ä½œæ–‡\n# å»ºè®®æªæ–½\nåŒå›¾ç”»ä½œæ–‡\n# åŸå‹\n\tThe chart,in an obvious way, speaks volumes about the phenomenon that (ä¸»é¢˜).X accounts for the highest percentage at x% of ï¼ˆä¸»é¢˜è¯ï¼‰,followed by B at y% and C ,z%. At the bottom of the chart, k% is regarded as D.\n\tAfter observation and consideration, some reasons of ï¼ˆä¸»é¢˜è¯ï¼‰ can be highlight as follows.It is generally recognized that nothing is more important than (ä¸»é¢˜è¯) for (å››å¤§ä¸‡èƒ½ç†ç”±) .A recent Internet questionnaire of the relevant department indicates that approximately 86.2% of the respondents hold the same view. (ä¸»é¢˜è¯) contributes to (å››å¤§ä¸‡èƒ½ç†ç”±) .As Envduct Karryguess, director of community service at LA College in LitLingo, puts it, â€œ (ä¸‡èƒ½ç†ç”±) , needless to say,  enormous importance for us.â€\n\tAll these factors support a rational conclusion that great importance should be attached to(ä¸»é¢˜è¯). Everyone should cultivate a better awareness of it and take practical actions.\n\næ¨¡æ¿å‡€å«çº¦ 120 è¯\n# æ–‡å­—ä½œæ–‡\n# è¡Œæ–‡æ¡†æ¶\n# ç¬¬ä¸€æ®µ\n\nå¼•å‡ºä¸»é¢˜\né™ˆè¿°ä½œè€…è§‚ç‚¹å’Œæ€åº¦\nè¡¨æ˜è‡ªå·±çš„è§‚ç‚¹\n\n# ç¬¬äºŒæ®µ\n\né‡ç”³ä¸»é¢˜ + åˆ†æåŸå›  / å½±å“\nåŸå›  1 / å½±å“ 1 + ä¾‹å­ï¼ˆè°ƒæŸ¥ç ”ç©¶ï¼‰\nåŸå›  2 / å½±å“ 2 + ä¾‹å­ï¼ˆåäººåè¨€ï¼‰\n\n# ç¬¬ä¸‰æ®µ\n\nå‡åä¸»é¢˜\nå»ºè®®æªæ–½\nå±•æœ›æœªæ¥ï¼ˆå¯æœ‰å¯æ— ï¼‰\n\n# å¼•å‡ºä¸»é¢˜\nThe phenomenon mentioned in the above excerpt that ï¼ˆä¸»é¢˜ï¼‰is receiving more and more attention and hot discussion.\n\nä¸Šè¿°æ‘˜å½•ä¸­æåˆ°çš„ç°è±¡ï¼ˆä¸»é¢˜ï¼‰æ­£å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨å¹¶æˆä¸ºçƒ­ç‚¹è®¨è®ºè¯é¢˜ã€‚\n\n# é™ˆè¿°ä½œè€…è§‚ç‚¹å’Œæ€åº¦\nAs is presented in the excerpt , the author believes thatâ€¦ is of graet significance for â€¦\n\nå¦‚æ‘˜å½•æ‰€ç¤ºï¼Œä½œè€…è®¤ä¸ºâ€¦ å¯¹â€¦ å…·æœ‰é‡è¦æ„ä¹‰\n\n# è¡¨æ˜è‡ªå·±çš„è§‚ç‚¹\nAs far as this question is concerned, I support the authorâ€™s view.\n\nå…³äºè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘æ”¯æŒä½œè€…çš„è§‚ç‚¹ã€‚\n\n# åŸå›  1 + ç ”ç©¶è°ƒæŸ¥\nåŒå›¾ç”»ä½œæ–‡\n# åŸå›  2 + åäººåè¨€\nåŒå›¾ç”»ä½œæ–‡\n# å‡åä¸»é¢˜\nåŒå›¾ç”»ä½œæ–‡\n# å»ºè®®æªæ–½\nåŒå›¾ç”»ä½œæ–‡\n# å†™ä½œ (å°ä½œæ–‡)\n# ä¹¦ä¿¡\n# æ ¼å¼\nDear_______,ï¼ˆ&lt;-é€—å·ï¼‰\n\t\n\tç¬¬ä¸€æ®µ_____________________________________________\n\tç¬¬äºŒæ®µ_____________________________________________\n\tç¬¬ä¸‰æ®µ_____________________________________________\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tï¼ˆé€—å·-&gt;ï¼‰\tyour sincerelyï¼Œ\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLi Ming\n\n# è¡Œæ–‡ç»“æ„\n# å‰ç½®\nç§°å‘¼\n# ç¬¬ä¸€æ®µ\n\nè¡¨æ˜èº«ä»½ï¼ˆå¯æœ‰å¯æ— ï¼‰+ è¡¨æ˜ä¸»é¢˜ï¼ˆé‡è¦ï¼‰\n\n# ç¬¬äºŒæ®µ\n\nå±•å¼€ä¸»é¢˜ + ä¸¤ç‚¹è®º\n\n# ç¬¬ä¸‰æ®µ\n\né‡ç”³ä¸»é¢˜ + å¯’æš„ï¼ˆå¯æœ‰å¯æ— ï¼‰\n\n# å°¾éƒ¨\nè½æ¬¾\n# ä¸‡èƒ½èº«ä»½\nI am president of the Studentsâ€™ Union\n# è¡¨æ˜ä¸»é¢˜\nI am writing the letter to you for the purpose of (ç›®çš„ï¼Œä»â€directionsâ€œä¸­æ±²å–ã€‚doing sth)\n# å±•å¼€ä¸»é¢˜ + ä¸¤ç‚¹è®º\nå‚è€ƒä¸‡èƒ½ä¸»é¢˜\n# ä¸‡èƒ½ç»“å°¾\nPlease accept my sincere gratitude to you for reading the content above. If you need to know more about it, please contact me.\n# æ¨¡æ¿\nDear_______,\n\tI am president of the Students' Union)(æ­¤å¤„è§†æƒ…å†µå˜æ¢èº«ä»½). I am writing the letter to you for the purpose of (ç›®çš„ï¼Œä»â€directionsâ€œä¸­æ±²å–ã€‚doing sth).\n\tOf all the points concerned. I'd like to name the most significant ones as follows. First and foremost,______(è¦ç‚¹ä¸€).Additionally,_______(è¦ç‚¹äºŒ).(æ­¤å¤„å¯å†åŠ ä¸€ä¸ªè¦ç‚¹&quot;Not but not least&quot;)\n\tplease accept my sincere gratitude to you for reading the content above. If you need to know more about it, please contact me.\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tYours sincerely,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(name)\n\n# é€šçŸ¥\n# å¤‡å¿˜å½•\n# ç¿»è¯‘\n# æ–‡ç« ä¸€\n# åŸæ–‡\n\tWe tend to think that friends and family members are our biggest source of connection, laughter and warmth. While that may well be true, researchers have also recently found that interacting with strangers actually brings a boost in mood and feelings of belonging that we didnâ€™t expect.\n\tIn one series of studies, researchers instructed Chicago-area commuters using public transportation to strike up a conversation with someone near them. On average, participants who followed this instruction felt better than those who had been told to stand or sit in silence. The researchers also argued that when we shy away from casual interactions with strangers, it is often due to a misplaced anxiety that they might not want to talk to us. Much of that time, however, this belief is false. As it turns out, many people are actually perfectly willing to talk and may even be flattered to receive your attention.\n\n# é€å¥ç¿»è¯‘\nWe tend to think that friends and family members are our biggest source of connection, laughter and warmth.\n\næˆ‘ä»¬å¾€å¾€ä¼šè®¤ä¸ºæœ‹å‹å’Œå®¶åº­æˆå‘˜æ˜¯æˆ‘ä»¬æƒ…æ„Ÿè”ç³»ã€æ¬¢å£°ç¬‘è¯­ä»¥åŠå¹¸ç¦æ¸©æš–çš„æœ€å¤§æ¥æºã€‚\n\nWhile that may well be true, researchers have also recently found that interacting with strangers actually brings a boost in mood and feelings of belonging that we didnâ€™t expect.\n\nå°½ç®¡é‚£å¾ˆè‚¯èƒ½æ˜¯çœŸçš„ï¼Œä½†æœ€è¿‘ç ”ç©¶è€…ä»¬å‘ç°ä¸é™Œç”Ÿäººäº¤å¾€å®é™…ä¸Šä¼šå¸¦æ¥æˆ‘ä»¬æ²¡æœ‰æƒ³åˆ°çš„æƒ…ç»ªä¸Šçš„å¢é•¿ä»¥åŠæ„Ÿè§‰ä¸Šçš„ä¿ƒè¿›ï¼ˆè®©äººå¿ƒæƒ…æ„‰æ‚¦ã€æœ‰å½’å±æ„Ÿï¼‰\n\nIn one series of studies, researchers instructed Chicago-area commuters using public transportation to strike up a conversation with someone near them\n\nåœ¨ä¸€ç³»åˆ—ç ”ç©¶ä¸­ï¼Œç ”ç©¶è€…ä»¬è®© Chicago åŒºåŸŸä½¿ç”¨å…¬å…±äº¤é€šçš„é€šå‹¤äººå‘˜å»åŠªåŠ›å’Œä»–ä»¬èº«è¾¹çš„äººäº§ç”Ÿäº¤æµ\n\nOn average, participants who followed this instruction felt better than those who had been told to stand or sit in silence.\n\né€šå¸¸æ¥è®²ï¼Œç›¸è¾ƒäºè¢«å‘ŠçŸ¥åœ¨å®‰é™ä¸­ç«™ç€æˆ–è€…åç€çš„æ¥è¯´ï¼Œå‚ä¸è€…ä»¬è·Ÿéšç€è¿™ä¸ªæŒ‡ç¤ºæ¥åšä¼šæ„Ÿè§‰åˆ°æ›´å¥½\n\nThe researchers also argued that when we shy away from casual interactions with strangers, it is often due to a misplaced anxiety that they might not want to talk to us.\n\nç ”ç©¶è€…ä»¬ä¹Ÿè®¤ä¸ºï¼Œå½“æˆ‘ä»¬åœ¨ä¸é™Œç”Ÿäººéšæ„çš„äº¤è°ˆè€Œæ„Ÿåˆ°å®³ç¾è·‘å¼€æ—¶ï¼Œé‚£é€šå¸¸æ˜¯å› ä¸ºä¸åˆæ—¶å®œçš„ç„¦è™‘ï¼Œé‚£å°±æ˜¯ä»–ä»¬ä¹Ÿè®¸ä¸æƒ³å’Œæˆ‘ä»¬è®²è¯\n\nMuch of that time, however, this belief is false.\n\nç„¶è€Œï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™ç§æƒ³æ³•æ˜¯é”™è¯¯çš„\n\nAs it turns out, many people are actually perfectly willing to talk and may even be flattered to receive your attention.\n\nç»“æœæ˜¯ï¼Œè®¸å¤šäººå®é™…ä¸Šéå¸¸æ„¿æ„äº¤è°ˆï¼Œç”šè‡³ä¼šå› ä¸ºå¾—åˆ°ä½ çš„å…³æ³¨è€Œæ„Ÿåˆ°è£å¹¸ã€‚\n\n# è¯æ±‡\n\n\n\nå•è¯\né‡Šä¹‰\n\n\n\n\nflattered\nadj.ï¼ˆå› å—é‡è§†è€Œï¼‰æ„Ÿåˆ°æ»¡æ„çš„ï¼Œè§‰å¾—è£å¹¸çš„ï¼›ï¼ˆåœ¨æ­£å¼åœºåˆè¡¨ç¤ºæ„Ÿè°¢ï¼‰ä¸èƒœè£å¹¸çš„ï¼Œæ·±æ„Ÿè£å¹¸çš„ v. å¥‰æ‰¿ï¼›è‡ªå‘½ä¸å‡¡ï¼›ä½¿æ˜¾å¾—æ¼‚äº®ï¼Œä½¿æ˜¾å¾—å‡ºè‰²ï¼ˆflattered çš„è¿‡å»å¼å’Œè¿‡å»åˆ†è¯ï¼‰\n\n\nmisplaced\nadj. ä¸åˆæ—¶å®œçš„ï¼›ï¼ˆæƒ…æ„Ÿï¼‰å¯„æ‰˜é”™çš„ï¼›æ”¾é”™ä½ç½®çš„ï¼›æš‚æ—¶ä¸¢å¤±çš„v. ä¹±æ”¾ï¼ˆè€Œæ‰¾ä¸åˆ°ï¼‰ï¼Œæš‚æ—¶ä¸¢å¤±ï¼›é”™æ”¾ï¼ˆmisplace çš„è¿‡å»å¼å’Œè¿‡å»åˆ†è¯ï¼‰\n\n\nargued\nv. äº‰è®ºï¼›äº‰åµï¼›äº‰è¾©ï¼›è®ºè¯ï¼›è¯´ç†ï¼›æ˜¾ç¤ºå‡ºï¼Œè¡¨æ˜ï¼ˆargue çš„è¿‡å»å¼å’Œè¿‡å»åˆ†è¯ï¼‰\n\n\ncommuters\nn. é€šå‹¤è€…ï¼›æ¯æ—¥å¾€è¿”ä¸Šç­è€…ï¼ˆcommuter çš„å¤æ•°ï¼‰\n\n\nreceive\nv. å¾—åˆ°ï¼Œæ”¶åˆ°ï¼›é­å—ï¼Œç»å—ï¼ˆç‰¹å®šå¾…é‡ï¼‰ï¼›å¯¹â€¦â€¦ ä½œå‡ºååº”ï¼›æ¥å¾…ï¼Œæ‹›å¾…ï¼›æ¥æ”¶ï¼ˆæŸäººä¸ºæˆå‘˜ï¼‰ï¼›æ¥æ”¶ï¼Œæ”¶å¬ï¼ˆä¿¡å·ï¼‰ï¼›ï¼ˆé€šè¿‡æ— çº¿ç”µï¼‰å¬åˆ°ï¼›è´­ä¹°ï¼Œçªè—ï¼ˆèµƒç‰©ï¼‰ï¼›æ¥ï¼ˆçƒï¼‰ï¼›é¢†å—ï¼ˆåœ£é¤é¢åŒ…æˆ–è‘¡è„é…’ï¼‰ï¼›æ¥å—ï¼ˆæ²»ç–—ï¼‰ï¼›å½¢æˆï¼ˆçœ‹æ³•ï¼Œå°è±¡ï¼‰ï¼›å®¹çº³ï¼Œæ‰¿æ¥\n\n\n\n# æ–‡ç« äºŒ\n# åŸæ–‡\n\tIn the late 18th century, William Wordsworth became famous for his poems about nature.And he was one of the founders of a movement called Romanticism, which celebrated the wonders of the natural world.\n\tPoetry is powerful. Its energy and rhythm can capture a reader, transport them to another world and make then see things differently. Through carefully selected words and phrases, poems can be dramatic, funny, beautiful, moving and inspiring.\n\tNo one knows for sure when poetry began but it has been around for thousands of years,even before people could write. It was a way to tell stories and pass down history. It is closely related to song and even when written it is usually created to be performed out loud. Poems really come to life when they are recited. This can also help with understanding them too, because the rhythm and sounds of the words become clearer\n\n# é€å¥ç¿»è¯‘\nIn the late 18th century, William Wordsworth became famous for his poems about nature.\n\nåœ¨ 18 ä¸–çºªåæœŸï¼ŒWilliam Wordsworth å› ä»–çš„æœ‰å…³è‡ªç„¶çš„è¯—é›†è€Œè¿œè¿‘é—»åã€‚\n\nAnd he was one of the founders of a movement called Romanticism, which celebrated the wonders of the natural world.\n\nä»–æ˜¯ä¸‡åƒæµªæ¼«ä¸»ä¹‰è¿åŠ¨å¥ åŸºè€…çš„ä¸€å‘˜ï¼Œä¸“ä¸ºè‡ªç„¶ä¸–ç•Œè€Œæ­Œé¢‚ã€‚\n\nPoetry is powerful.\n\nè¯—æ­Œæ»¡å«åŠ›é‡ã€‚\n\nIts energy and rhythm can capture a reader, transport them to another world and make then see things differently.\n\nè¿™ç§èƒ½é‡å’Œç¥è¯èƒ½å¤Ÿä¿˜è·è¯»è€…èŠ³å¿ƒï¼Œå¸¦é¢†ä»–ä»¬è¿›å…¥å¦å¤–ä¸€ä¸ªä¸–ç•Œï¼Œä½¿ä¹‹ä»–ä»¬ä»¥ä¸åŒçš„çœ¼å…‰çœ‹å¾…ä¸–ç•Œã€‚\n\nThrough carefully selected words and phrases, poems can be dramatic, funny, beautiful, moving and inspiring.\n\né€šè¿‡åœ¨è¯æ±‡å’Œè¯­æ®µä¸Šçš„ç²¾æŒ‘ç»†é€‰ï¼Œè¯—æ­Œå¯ä»¥è¡¨ç°å‡ºæˆå‰§çš„ï¼Œæœ‰è¶£çš„ã€åä¸½çš„ã€æ„ŸåŠ¨çš„ä»¥åŠé¼“èˆäººå¿ƒçš„æƒ…æ„Ÿã€‚\n\nNo one knows for sure when poetry began but it has been around for thousands of years,even before people could write.\n\næ²¡æœ‰äººç¡®åˆ‡åœ°çŸ¥é“è¯—æ­Œå§‹äºä½•æ—¶ï¼Œä½†å…¶ç¡®å®è¦ç»•åƒå¹´ä¹‹ä¹…ï¼Œç”šè‡³åœ¨äººä»¬å­¦ä¼šä¹¦å†™ä¹‹å‰å°±å·²ç»å‡ºç°äº†ã€‚\n\nIt was a way to tell stories and pass down history.\n\nè¿™æ›¾ç»æ˜¯è®²è¿°æ•…äº‹å’Œä¼ æ‰¿è¿‡å»å†å²çš„ä¸€ç§æ–¹å¼\n\nIt is closely related to song and even when written it is usually created to be performed out loud.\n\nä»–ä¸æ­Œæ›²å¯†åˆ‡ç›¸å…³ï¼Œå³ä½¿å†™æˆå®ƒï¼Œå®ƒé€šå¸¸ä¹Ÿæ˜¯ä¸ºäº†å¤§å£°è¡¨æ¼”è€Œåˆ›ä½œçš„ã€‚\n\nPoems really come to life when they are recited.\n\nè¯—æ­ŒåŸè¯µæ—¶æ‰æ­£çœŸèƒŒèµ‹äºˆäº†ç”Ÿå‘½ã€‚\n\nThis can also help with understanding them too, because the rhythm and sounds of the words become clearer\n\nè¿™ä¹Ÿæœ‰åŠ©äºç†è§£å®ƒä»¬ï¼Œå› ä¸ºå•è¯çš„èŠ‚å¥å’Œå£°éŸ³å˜å¾—æ›´åŠ æ¸…æ™°\n\n# æ–‡ç« ä¸‰\n# åŸæ–‡\n\tWith the smell of coffee and fresh bread floating in the air, stalls bursting with colorful vegetables and tempting cheeses, and the buzz of friendly chats, farmersâ€™ markets are a feast for the senses. They also provide an opportunity to talk to the people responsible for growing or raising your food, support your local economy and pick up fresh seasonal produce â€”â€” all at the same time.\n\n\tFarmersâ€™ markets are usually weekly or monthly events, most often with outdoor stalls, which allow farmers or producers to sell their food directly to customers. The size or regularity of markets can vary from season to season, depending on the area's agricultural calendar, and youâ€™re likely to find different produce on sale at different times of the year. By cutting out the middlemen, the farmers secure more profit for their produce. Shoppers also benefit from seeing exactly where-and to who- their money is going.\n\n# é€å¥ç¿»è¯‘\nWith the smell of coffee and fresh bread floating in the air, stalls bursting with colorful vegetables and tempting cheeses, and the buzz of friendly chats, farmersâ€™ markets are a feast for the senses.\n\nä¼´éšç€æ¼‚æµ®åœ¨ç©ºæ°”ä¸­çš„å’–å•¡å’Œæ–°é²œé¢åŒ…é¦™æ°”ï¼Œæ‘Šä½ä¸Šæ‘†æ”¾ç€äº”é¢œå…­è‰²çš„æ°´æœå’Œæ¥šæ¥šå¯äººçš„å¥¶é…ªï¼Œä»¥åŠå‹å¥½çš„èŠå¤©å˜ˆæ‚è€Œåˆå–§é—¹ç€ï¼Œå†œè´¸å¸‚åœºä¸Šæ˜¾ç°å‡ºä¸€å¹…ç¾å¥½çš„æ™¯è±¡ï¼ˆæ„Ÿå®˜ç››å®´ï¼‰ã€‚\n\nThey also provide an opportunity to talk to the people responsible for growing or raising your food, support your local economy and pick up fresh seasonal produceâ€” all at the same time.\n\nè¿™ä¹Ÿä¸ºä½ æä¾›äº†ä¸€ç§æ—¢èƒ½å»äººç›´é¢äº¤æµçš„æœºä¼šï¼Œè€Œè¿™ä¸ªäººæ­£æ˜¯è´Ÿè´£ä½ é£Ÿç‰©çš„æ’­ç§ä¸é‡‡é›†çš„äººï¼Œä¹Ÿèƒ½å»æ”¯æŒæœ¬åœ°ç»æµï¼Œä¸æ­¤åŒæ—¶æŒ‘é€‰æ–°é²œçš„å­£èŠ‚æ€§äº§å“çš„ â€”â€” è¿™ä¸€åˆ‡åŒæ—¶å‘ç”Ÿã€‚\n\nFarmersâ€™ markets are usually weekly or monthly events, most often with outdoor stalls, which allow farmers or producers to sell their food directly to customers.\n\nå†œè´¸å¸‚åœºé€šå¸¸æ˜¯æ¯å‘¨æˆ–è€…æ¯æœˆä¸¾è¡Œï¼Œæœ€å¸¸è§çš„æ˜¯æˆ·å¤–æ‘Šä½ï¼Œå±Šæ—¶å…è®¸å†œæ°‘æˆ–è€…ç”Ÿäº§è€…å»ç›´æ¥é¢å‘é¡¾å®¢å”®å–ä»–ä»¬çš„å•†å“ã€‚\n\nThe size or regularity of markets can vary from season to season, depending on the areaâ€™s agricultural calendar, and youâ€™re likely to find different produce on sale at different times of the year.\n\nå¸‚åœºçš„è§„æ¨¡æˆ–è€…æ˜¯è§„å¾‹å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯é€‚æ—¶è€Œå¼‚ï¼Œä¾æ‰˜äºå½“åœ°å†œå†ï¼Œä½ å¾ˆå¯èƒ½ä¼šå‘ç°ä¸ä¼—ä¸åŒçš„äº§å“å”®å–äºä¸€å¹´çš„ä¸åŒæ—¶é—´ã€‚\n\nBy cutting out the middlemen, the farmers secure more profit for their produce.\n\né‰´äºæ²¡æœ‰ä¸­é—´å•†èµšå·®ä»·ï¼Œå› æ­¤å†œæ°‘ä»¬å¯ä»¥è·å¾—æ¥è‡ªäºä»–ä»¬äº§å“çš„æ›´å¤šåˆ©æ¶¦ã€‚\n\nShoppers also benefit from seeing exactly where â€” and to who â€” their money is going.\n\nè´­ä¹°è€…ä¹Ÿå—ç›Šäºä»–ä»¬å¯ä»¥æ›´åŠ å‡†ç¡®çš„è®¤è¯†åˆ°ï¼Œä»–ä»¬çš„é’±æ”¯ä»˜ç»™è°å¹¶æµå‘ä½•æ–¹ã€‚\n\n# è¯æ±‡\n\n\n\nå•è¯\né‡Šä¹‰\n\n\n\n\nstalls\nn. æ­£å…å‰æ’åº§ä½ï¼ˆstall çš„å¤æ•°å½¢å¼ï¼‰ v. ä½¿ï¼ˆæ±½è½¦ç­‰ï¼‰æŠ›é”šï¼ˆstall çš„ç¬¬ä¸‰äººç§°å•æ•°å½¢å¼ï¼‰\n\n\nbursting\nadj. å……æ»¡çš„ï¼›æ¸´æœ›çš„v. çˆ†ç‚¸ï¼›çŒ›å†²ï¼›æ¶¨æ»¡ï¼›å……æ»¡æ„Ÿæƒ…ï¼›çªç„¶çˆ†å‘ï¼ˆæ„Ÿæƒ…ï¼‰ï¼›çŒ›ç„¶æ‰“å¼€ï¼›å†³å ¤ï¼›çªç„¶å¼€å§‹æ´»è·ƒï¼ˆburst çš„ç°åœ¨åˆ†è¯ï¼‰\n\n\ntempting\nadj. è¯±äººçš„ï¼Œå¸å¼•äººçš„v. å¼•è¯±ï¼Œè¯±æƒ‘ï¼›æ€‚æ¿ï¼Œåˆ©è¯±ï¼›å†’â€¦â€¦ çš„é£é™©ï¼ˆtempt çš„ç°åœ¨åˆ†è¯ï¼‰\n\n\nbuzz\nv. å‘å—¡å—¡å£°ï¼Œå‘èœ‚é¸£å£°ï¼›åŒ†å¿™èµ°åŠ¨ï¼›å……æ»¡å˜ˆæ‚å£°ï¼›å……æ»¡æƒ³æ³•ï¼›ç¹å¿™ï¼Œå……æ»¡æ´»åŠ›ï¼›&lt;éæ­£å¼&gt; ç»™ï¼ˆæŸäººï¼‰æ‰“ç”µè¯ï¼›&lt; éæ­£å¼ &gt;ï¼ˆé£æœºï¼‰ä½ç©ºé£è¿‡ï¼›ï¼ˆç”¨èœ‚é¸£å™¨ï¼‰å‘¼å«n. å—¡å—¡å£°ï¼Œèœ‚é¸£å£°ï¼›å½å½å–³å–³å£°ï¼Œå˜ˆæ‚å£°ï¼›&lt;éæ­£å¼&gt; å…´å¥‹ï¼Œå¿«ä¹ï¼›çƒ­é—¹æœ‰è¶£çš„æ°”æ°›ï¼Œæ—¶å°šæ°›å›´ï¼›&lt; éæ­£å¼ &gt; ç”µè¯ï¼›&lt; éæ­£å¼ &gt; æµè¨€ï¼Œä¼ é—»adj. ï¼ˆè¯è¯­ã€æƒ³æ³•æˆ–æ´»åŠ¨ï¼‰æ—¶é«¦çš„\n\n\nfeast\nn. å®´ä¼šï¼Œç­µå¸­ï¼›ç››ä¼šï¼Œç‰¹åˆ«çš„äº«å—ï¼›å®—æ•™èŠ‚æ—¥v. é¥±é¤ï¼Œå°½æƒ…äº«ç”¨ï¼›å®´è¯·ï¼Œè®¾å®´æ‹›å¾…ï¼ˆæŸäººï¼‰\n\n\nregularity\nn. è§„å¾‹æ€§ï¼Œç»å¸¸æ€§ï¼›åŒ€ç§°ï¼Œç«¯æ­£ï¼›æœ‰è§„åˆ™çš„ä¸œè¥¿ï¼Œæœ‰è§„å¾‹çš„äº‹ç‰©\n\n\nmiddlemen\nn. ä¸­é—´å•†ï¼›ç»çºªå•†\n\n\nsecure\nadj. ç¨³å›ºçš„ï¼Œå¯é çš„ï¼›ä¸¥å¯†æŠŠå®ˆçš„ï¼Œç‰¢å›ºçš„ï¼›å®‰å…¨çš„ï¼Œç¨³å¦¥çš„ï¼›ï¼ˆå¯¹è‡ªå·±å’Œè‡ªå·±çš„èƒ½åŠ›ï¼‰æœ‰è‡ªä¿¡çš„ï¼›æ„Ÿåˆ°æœ‰ä¿éšœçš„ï¼Œæ²¡æœ‰é¡¾è™‘çš„ï¼›å›ºå®šä½çš„ï¼Œç³»ç‰¢çš„ï¼›ç§˜å¯†çš„v. ï¼ˆå°¤æŒ‡ç»è¿‡åŠªåŠ›è€Œï¼‰è·å¾—ï¼Œå¾—åˆ°ï¼›ä½¿å®‰å…¨ï¼Œä¿æŠ¤ï¼›ç¼šç‰¢ï¼Œå°†ï¼ˆæŸç‰©ï¼‰å›ºå®šï¼›ç¡®ä¿ï¼Œä¿è¯ï¼›ä¸ºï¼ˆå€ºåŠ¡æˆ–è´·æ¬¾ï¼‰ä½œæŠµæŠ¼ï¼Œä½œä¿ï¼›ï¼ˆå¤–ç§‘ï¼‰å‹è¿«ï¼ˆè¡€ç®¡ï¼‰æ­¢è¡€ï¼›åœæ­¢å·¥ä½œï¼›èˆ¹æŠ›é”š\n\n\n\n# å®Œå‹\n# å®Œå‹ç†è®º\n\nå…¶æœ¬è´¨ä¸Šä»ç„¶æ˜¯æ¯”é”™\näºŸéœ€æ‰“ç ´ä¼ ç»Ÿæ€ç»´ï¼Œæ‘’å¼ƒå®Œç¾ç†è§£\nè¿½æ±‚æ–‡ç« å†…éƒ¨çš„ä¸€è‡´æ€§\nä¸»æ—¨ä¸€è‡´\n\n# å±€éƒ¨ä¸€è‡´æ€§ + å…¨å±€ä¸€è‡´æ€§\n\nä¸Šä¸‹æ–‡è¯­ä¹‰ä¸€è‡´\næ³¨æ„é€»è¾‘åˆç†ï¼ˆé€»è¾‘æ”¹å˜æ–¹å‘è¿˜æ˜¯ä¿æŒæ–¹å‘ï¼Ÿï¼‰ï¼ˆäºŒåˆ†æ³•ï¼‰\n\n","categories":["English"],"tags":["è‹±è¯­"]},{"title":"Dubboå¿«é€Ÿå…¥é—¨","url":"/Java/DubboStart/","content":"# RPC åè®®è¿œç¨‹è°ƒç”¨çš„å‡ ç§å®ç°\n# Dubbo ç®€ä»‹\nDubbo æ˜¯é˜¿é‡Œå·´å·´å…¬å¸å¼€æºçš„ä¸€ä¸ªé«˜æ€§èƒ½ã€è½»é‡çº§çš„ Java RPC æ¡†æ¶ã€‚\nè‡´åŠ›äºé«˜æ€§èƒ½é€æ˜åŒ–çš„é€æ˜åŒ–çš„ RPC åŸåˆ›æœåŠ¡è°ƒç”¨æ–¹æ¡ˆï¼Œä»¥åŠ SOA æœåŠ¡æ²»ç†æ–¹æ¡ˆã€‚\n\né¢å‘æ¥å£çš„è¿œç¨‹æ–¹æ³•è°ƒç”¨ï¼ˆRPCï¼‰ï¼šåƒè°ƒç”¨æœ¬åœ°æ–¹æ³•ä¸€æ ·è°ƒç”¨è¿œç¨‹æœåŠ¡ï¼Œå¯¹å¼€å‘è€…é€æ˜ï¼Œé™ä½äº†åˆ†å¸ƒå¼æœåŠ¡è°ƒç”¨çš„å¤æ‚åº¦ã€‚\næ™ºèƒ½å®¹é”™å’Œè´Ÿè½½å‡è¡¡ï¼šæä¾›äº†å¤šç§å®¹é”™ç­–ç•¥ï¼ˆå¦‚å¤±è´¥è‡ªåŠ¨åˆ‡æ¢ã€å¤±è´¥å®‰å…¨ç­‰ï¼‰å’Œå†…ç½®çš„è´Ÿè½½å‡è¡¡ç®—æ³•ï¼ˆå¦‚éšæœºã€è½®è¯¢ã€æœ€å°‘æ´»è·ƒè°ƒç”¨æ•°ç­‰ï¼‰ï¼Œä¿è¯äº†æœåŠ¡çš„é«˜å¯ç”¨æ€§ã€‚\næœåŠ¡è‡ªåŠ¨æ³¨å†Œä¸å‘ç°ï¼šæœåŠ¡æä¾›è€…å‘æ³¨å†Œä¸­å¿ƒæ³¨å†Œè‡ªå·±çš„æœåŠ¡ï¼Œæ¶ˆè´¹è€…ä»æ³¨å†Œä¸­å¿ƒå‘ç°æœåŠ¡åœ°å€åˆ—è¡¨ï¼Œå¹¶èƒ½æ„ŸçŸ¥æœåŠ¡çš„ä¸Šä¸‹çº¿ï¼Œå®ç°è½¯è´Ÿè½½ã€‚\né«˜åº¦å¯æ‰©å±•æ€§ï¼šå‡ ä¹æ‰€æœ‰ç»„ä»¶ï¼ˆå¦‚åè®®ã€åºåˆ—åŒ–ã€ä¼ è¾“ã€æ³¨å†Œä¸­å¿ƒç­‰ï¼‰éƒ½æ˜¯å¯æ’æ‹”çš„ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®è‡ªèº«éœ€æ±‚è¿›è¡Œå®šåˆ¶å’Œæ‰©å±•ã€‚\nè¿è¡ŒæœŸæµé‡è°ƒåº¦ï¼šå¯ä»¥åœ¨åå°è¿›è¡Œè·¯ç”±è§„åˆ™ã€é…ç½®è§„åˆ™çš„è°ƒæ•´ï¼Œå®ç°ç°åº¦å‘å¸ƒã€æƒé‡è·¯ç”±ç­‰ç²¾ç»†åŒ–çš„æµé‡æ§åˆ¶ã€‚\nå¯è§†åŒ–æœåŠ¡æ²»ç†ï¼šæä¾›ä¸°å¯Œçš„æœåŠ¡æ²»ç†åŠŸèƒ½ï¼Œå¦‚æœåŠ¡æŸ¥è¯¢ã€æœåŠ¡æµ‹è¯•ã€æœåŠ¡ Mockã€ä¾èµ–åˆ†æã€å¥åº·åº¦æ£€æŸ¥ç­‰ï¼Œé€šå¸¸é€šè¿‡ Dubbo Admin æ§åˆ¶å°è¿›è¡Œæ“ä½œã€‚\n\nDubbo çš„æ¶æ„ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªè§’è‰²ï¼š\n\nProviderï¼šæœåŠ¡æä¾›è€…ã€‚å‘å¸ƒæœåŠ¡åˆ°æ³¨å†Œä¸­å¿ƒã€‚\nConsumerï¼šæœåŠ¡æ¶ˆè´¹è€…ã€‚ä»æ³¨å†Œä¸­å¿ƒè®¢é˜…æœåŠ¡ï¼Œå¹¶è°ƒç”¨æä¾›è€…ã€‚\nRegistryï¼šæ³¨å†Œä¸­å¿ƒã€‚è´Ÿè´£æœåŠ¡çš„æ³¨å†Œä¸å‘ç°ã€‚\nMonitorï¼šç›‘æ§ä¸­å¿ƒã€‚ç»Ÿè®¡æœåŠ¡çš„è°ƒç”¨æ¬¡æ•°å’Œè°ƒç”¨æ—¶é—´ç­‰ç›‘æ§ä¿¡æ¯ã€‚\nContainerï¼šæœåŠ¡è¿è¡Œå®¹å™¨ã€‚è´Ÿè´£å¯åŠ¨ã€åŠ è½½ã€è¿è¡ŒæœåŠ¡æä¾›è€…ã€‚\n\nè°ƒç”¨æµç¨‹ï¼š\n\nå¯åŠ¨é˜¶æ®µï¼šæœåŠ¡å®¹å™¨å¯åŠ¨ã€åŠ è½½å¹¶è¿è¡Œ Providerã€‚Provider åœ¨å¯åŠ¨æ—¶ï¼Œä¼šå‘ Registry æ³¨å†Œè‡ªå·±æä¾›çš„æœåŠ¡ã€‚\nè®¢é˜…é˜¶æ®µï¼šConsumer åœ¨å¯åŠ¨æ—¶ï¼Œå‘ Registry è®¢é˜…è‡ªå·±æ‰€éœ€è¦æœåŠ¡çš„åœ°å€åˆ—è¡¨ã€‚Registry ä¼šå°†æä¾›è€…åœ°å€åˆ—è¡¨è¿”å›ç»™ Consumerï¼ŒåŒæ—¶ Consumer ä¼šä¸ Registry å»ºç«‹åŠ¨æ€ç›‘å¬ï¼Œä»¥ä¾¿æ„ŸçŸ¥æœåŠ¡å˜åŒ–ã€‚\nè°ƒç”¨é˜¶æ®µï¼š\n\nConsumer æ ¹æ®è´Ÿè½½å‡è¡¡ç®—æ³•ï¼Œä»æœ¬åœ°ç¼“å­˜çš„æœåŠ¡åœ°å€åˆ—è¡¨ä¸­ï¼Œé€‰æ‹©ä¸€ä¸ª Provider è¿›è¡Œè°ƒç”¨ã€‚\nè°ƒç”¨æ—¶ï¼ŒConsumer çš„æ¥å£ä»£ç†ä¼šå°†è°ƒç”¨ä¿¡æ¯ï¼ˆæ¥å£åã€æ–¹æ³•åã€å‚æ•°ç­‰ï¼‰è¿›è¡Œåºåˆ—åŒ–ï¼Œé€šè¿‡ç½‘ç»œä¼ è¾“ç»™ Providerã€‚\nProvider æ”¶åˆ°è¯·æ±‚åï¼Œååºåˆ—åŒ–æ•°æ®ï¼Œé€šè¿‡åå°„è°ƒç”¨æœ¬åœ°å®ç°ï¼Œå¹¶å°†ç»“æœè¿”å›ç»™ Consumerã€‚\n\n\nç›‘æ§ï¼šConsumer å’Œ Provider åœ¨å†…å­˜ä¸­ç´¯è®¡è°ƒç”¨æ¬¡æ•°å’Œè°ƒç”¨æ—¶é—´ï¼Œå®šæ—¶æ¯åˆ†é’Ÿå‘é€ä¸€æ¬¡ç»Ÿè®¡æ•°æ®åˆ° Monitorã€‚\n\n# å®ç° 1 ä¼ ç»Ÿ RPC ï¼šDubbo + Protobuf\n","categories":["Dubbo"],"tags":["java","å¾®æœåŠ¡"]},{"title":"SpringCloudå­¦ä¹ è®°å½•","url":"/Java/SpringCloudSTU/","content":"# SpringCloud\n# ä»å•ä½“åˆ°é›†ç¾¤å†åˆ°åˆ†å¸ƒå¼\næ—©æœŸé˜¶æ®µï¼Œå•ä½“æ¶æ„æ˜¯ä¸»æµé€‰æ‹©ï¼Œæ‰€æœ‰åŠŸèƒ½æ¨¡å—æ‰“åŒ…åœ¨ä¸€ä¸ªåº”ç”¨ä¸­ï¼Œå¼€å‘ç®€å•ç›´æ¥ï¼Œä½†æ˜¯éšç€ä¸šåŠ¡å¢é•¿ï¼Œä»£ç å˜å¾—è‡ƒè‚¿ï¼Œéš¾ä»¥æ‰©å±•ç‰¹å®šåŠŸèƒ½æ¨¡å—ï¼ŒæŠ€æœ¯æ ˆå•ä¸€ï¼Œéš¾ä»¥é‡‡ç”¨æ–°æŠ€æœ¯ã€‚\nä¸ºäº†åº”å¯¹å•ä½“æ¶æ„çš„æ€§èƒ½ç“¶é¢ˆå’Œé«˜å¯ç”¨éœ€æ±‚ï¼Œé›†ç¾¤æ¶æ„åº”è¿è€Œç”Ÿã€‚\nå®ç°æ–¹å¼ï¼š\n\næ°´å¹³æ‰©å±•ï¼šéƒ¨ç½²å¤šä¸ªç›¸åŒçš„å•ä½“åº”ç”¨å®ä¾‹\né€šè¿‡è´Ÿè½½å‡è¡¡å™¨ (Nginxã€F5 ç­‰) åˆ†é…è¯·æ±‚\nå…±äº«æ•°æ®åº“æˆ–æ•°æ®åº“ä¸»ä»å¤åˆ¶\n\nä½†æ˜¯ä»ç„¶æœ‰ç¼ºé™·ï¼Œæ¯”å¦‚åº”ç”¨æœ¬èº«ä»ç„¶æ˜¯å•ä½“ï¼Œä¸šåŠ¡å¤æ‚æ—¶æ‰©å±•ä¸çµæ´»ã€‚\næ­¤æ—¶åˆ†å¸ƒå¼æ¶æ„ä¸å¾®æœåŠ¡åº”è¿è€Œç”Ÿï¼Œåˆ†å¸ƒå¼æ¶æ„é€šè¿‡å°†ç³»ç»Ÿæ‹†åˆ†ä¸ºå¤šä¸ªæœåŠ¡æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚\næœ¬æ¬¡å­¦ä¹ ä½¿ç”¨å°šç¡…è°· b ç«™å¼€æ”¾è¯¾å ‚ï¼šhttps://www.bilibili.com/video/BV1UJc2ezEFU\næ¡†æ¶ï¼ˆç»„ä»¶ï¼‰å­¦ä¹ ä¸æœ¬å¥—è¯¾ç¨‹é«˜åº¦é‡åˆï¼Œä½†å¹¶ä¸æ˜¯è¯¾ç¨‹èµ„æ–™çš„å†å¤å†™ã€‚\nç›¸å…³æŠ€æœ¯ï¼š\n\nNacosï¼ˆæ³¨å†Œä¸­å¿ƒã€é…ç½®ä¸­å¿ƒï¼‰æ¥è‡ª Spring Cloud Alibaba\nOpenFeginï¼ˆè¿œç¨‹è°ƒç”¨ï¼‰æ¥è‡ª Spring Cloud å®˜æ–¹\nSentinelï¼ˆå¼‚å¸¸å¤„ç†ã€æµæ§è§„åˆ™ã€ç†”æ–­è§„åˆ™ï¼‰æ¥è‡ª Spring Cloud Alibaba\nGatewayï¼ˆè·¯ç”±ã€æ–­è¨€ã€è¿‡æ»¤ï¼‰æ¥è‡ª Spring Cloud å®˜æ–¹\nSeataï¼ˆåˆ†å¸ƒå¼äº‹åŠ¡ï¼‰æ¥è‡ª Spring Cloud Alibaba\n\n# Nacos\n\n# æ³¨å†Œä¸­å¿ƒ\n# æœåŠ¡æ³¨å†Œ\né¦–å…ˆè¿›è¡Œä¾èµ–å¯¼å…¥\n&lt;!--    nacos é…ç½®ä¸­å¿ƒã€æ³¨å†Œä¸­å¿ƒ    -->&lt;dependency>    &lt;groupId>com.alibaba.cloud&lt;/groupId>    &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId>&lt;/dependency>ä½¿ç”¨ docker æˆ–è€…ç›´æ¥è¿è¡Œçš„æ–¹å¼å¯åŠ¨ Nacos\nåœ¨ Windows å¹³å°ç›´æ¥è¿è¡Œä¸‹ä½¿ç”¨å‘½ä»¤ï¼šstartup.cmd -m standaloneï¼ˆstandalone ä¸ºä½¿ç”¨å•æœºæ¨¡å¼ï¼‰\nåœ¨ä¸åŒçš„æœåŠ¡ä¸‹ç¼–å†™é…ç½®ï¼Œå¦‚è®¢å•æœåŠ¡å’Œäº§å“æœåŠ¡ï¼š\nspring:  cloud:    nacos:      server-addr: 127.0.0.1:8848  application:    name: service-orderserver:  port: 8080spring:  cloud:    nacos:      server-addr: 127.0.0.1:8848  application:    name: service-productserver:  port: 9000å…¶ä¸­ nacos.server-addr ä¸º nacos æœåŠ¡çš„åœ°å€ä¸º 127.0.0.1:8848ï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰\nè®¿é—® http://localhost:8848/nacosï¼Œåœ¨æœåŠ¡ç®¡ç† - æœåŠ¡åˆ—è¡¨å¯ä»¥çœ‹åˆ°ç°åœ¨å·²ç»æ³¨å†Œä¸Šçš„æœåŠ¡\n\n\n\næœåŠ¡å\nåˆ†ç»„åç§°\né›†ç¾¤æ•°ç›®\nå®ä¾‹æ•°\nå¥åº·å®ä¾‹æ•°\nè§¦å‘ä¿æŠ¤é˜ˆå€¼\næ“ä½œ\n\n\n\n\nservice-order\nDEFAULT_GROUP\n1\n2\n2\nfalse\nè¯¦æƒ… | ç¤ºä¾‹ä»£ç  | è®¢é˜…è€… | åˆ é™¤\n\n\nservice-product\nDEFAULT_GROUP\n1\n3\n3\nfalse\nè¯¦æƒ… | ç¤ºä¾‹ä»£ç  | è®¢é˜…è€… | åˆ é™¤\n\n\n\n# æœåŠ¡å‘ç°\nç”±äºä½¿ç”¨äº† Nacosï¼ŒæœåŠ¡å‘ç°æ–¹æ³•çš„è°ƒç”¨å­˜åœ¨ä¸¤å¥—æ ‡å‡†ï¼Œåˆ†åˆ«æ˜¯ Spring Cloud çš„ DiscoveryClient å’Œ Nacos çš„ NacosServiceDiscovery\n@ResourceDiscoveryClient discoveryClient;@ResourceNacosServiceDiscovery nacosServiceDiscovery;ä¸‹é¢ä¸ºæµ‹è¯•ä»£ç ï¼š\n/** * spring æ ‡å‡† discovery ä½¿ç”¨ DiscoveryClient */@Testpublic void testDiscoveryClient() &#123;    for (String service : discoveryClient.getServices()) &#123;        /*            å¾ªç¯è¾“å‡ºæœåŠ¡åˆ—è¡¨ï¼ˆæœåŠ¡åï¼‰                service-order                service-product        */        System.out.println(service);        // è·å–æ‰€æœ‰å®ä¾‹ã€è¾“å‡º IP ä¸ç«¯å£å·        List&lt;ServiceInstance> instances = discoveryClient.getInstances(service);        for (ServiceInstance instance : instances) &#123;            System.out.println(instance.getHost() + \":\" + instance.getPort());        &#125;    &#125;&#125;/** * nacos æ ‡å‡† discovery ä½¿ç”¨ NacosServiceDiscovery */@Testpublic void testNacosServiceDiscovery() throws NacosException &#123;    for (String service : nacosServiceDiscovery.getServices()) &#123;        // è¾“å‡ºæœåŠ¡åˆ—è¡¨        System.out.println(service);        // è·å–æ‰€æœ‰å®ä¾‹ã€è¾“å‡º IP ä¸ç«¯å£å·        List&lt;ServiceInstance> instances = nacosServiceDiscovery.getInstances(service);        for (ServiceInstance instance : instances) &#123;            System.out.println(instance.getHost() + \":\" + instance.getPort());        &#125;    &#125;&#125;è¾“å‡ºï¼š\nservice-order192.168.25.1:8080192.168.25.1:8001service-product192.168.25.1:9000192.168.25.1:9002192.168.25.1:9001å¦‚æœå¹¶æ²¡æœ‰å¦‚æ­¤å¤šçš„è¾“å‡ºå¯èƒ½æ˜¯åªå¯åŠ¨äº†ä¸¤ä¸ªåç«¯æœåŠ¡ï¼Œè¿˜éœ€è¦å¤šå¯åŠ¨å‡ ä¸ªæ¥æ¨¡æ‹Ÿåˆ†å¸ƒå¼ã€‚\nå…¶æ¬¡ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™ä¸ªä¸€èˆ¬ä¼šè¢«è¿›ä¸€æ­¥å°è£…ï¼Œå…¶å‘ç°çš„è¿‡ç¨‹æ˜¯è‡ªåŠ¨è¿›è¡Œçš„ã€‚\n# åˆè§ï¼Œè¿œç¨‹è°ƒç”¨\nç°åœ¨æœ‰ä¸€ä¸ªå®ä¾‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸‹å•åŠŸèƒ½ï¼Œå½“ç”¨æˆ·ä¸‹å•åå¯¹å…¶å•†å“è¿›è¡Œç»“ç®—è¿™é‡Œæˆ‘ä»¬å¯¹ä¸€äº›æ•°æ®åšå‡ºæ¨¡æ‹Ÿã€‚\nè®¢å•å®ä½“ï¼š\n@Datapublic class Order &#123;    private Long id;    private BigDecimal totalAmount;    private Long userId;    private String nickName;    private String address;    private List&lt;Object> product;&#125;å•†å“å®ä½“ï¼š\n@Data\npublic class Product &#123;\n    private Long id;\n    private BigDecimal price;\n    private String productName;\n    private int num;\n&#125;\n\nå…¶æ¬¡å°±æ˜¯ç›¸åº”å’Œ Controller ä¸ Service ä»£ç ï¼Œå…¶è¾ƒä¸ºç®€å•ä¸åœ¨æ­¤å¤„è¯¦ç»†å±•å¼€ï¼Œä¸è¿‡æˆ‘æƒ³è¯´ä¸€ä¸‹è®¢å•éƒ¨åˆ†çš„ Serviceï¼š\n@Servicepublic class OrderServiceImpl implements OrderService &#123;    @Override    public Order createOrder(Long productId, Long userId) &#123;        Order order = new Order();        order.setId(1L);        // TODO éœ€è¦è®¡ç®—        order.setTotalAmount(new BigDecimal(\"0\"));        order.setUserId(userId);        order.setNickName(\"Karry.Liu\");        order.setAddress(\"åŒ—æ\");        // TODO éœ€è¦è¿œç¨‹æŸ¥è¯¢        order.setProduct(null);        return order;    &#125;&#125;ç”±äº Order ä¸ Product åˆ†åˆ«ä½äºä¸¤ä¸ªæœåŠ¡ä¹‹ä¸­ï¼Œå…¶è¯¦ç»†çš„é‡‘é¢ Amount ä¸äº§å“è¯¦æƒ…åˆ—è¡¨ Product List æˆ‘ä»¬ç›®å‰ä¼¼ä¹æ— æ³•è·å–ï¼Œé‚£æˆ‘ä»¬åº”è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿè¿™ä¸ªæˆ‘ä»¬æš‚æ—¶æŒ‰ä¸‹ä¸è¡¨ï¼Œæˆ‘ä»¬ç°åœ¨éœ€è¦è§£å†³ä¸€ä¸ªæ›´åŠ æ£˜æ‰‹çš„é—®é¢˜ã€‚\nç°åœ¨æˆ‘ä»¬æœ‰å¦‚ä¸‹é¡¹ç›®ç»“æ„ï¼ˆç®€ç•¥ç‰ˆï¼‰\n- cloud-demo(åŸºåº§é¡¹ç›®)|| - services(æœåŠ¡å±‚)| | | |  - service-order(è®¢å•æœåŠ¡)(åŒ…å«è®¢å•å®ä½“beanã€æœåŠ¡serviceå’Œæ§åˆ¶controller)| | | |  - service-product(å•†å“æœåŠ¡)(åŒ…å«å•†å“å®ä½“beanã€æœåŠ¡serviceå’Œæ§åˆ¶controller)è®¢å•æœåŠ¡æ— æ³•ä½¿ç”¨å•†å“beanï¼Œåä¹‹å•†å“æœåŠ¡æ— æ³•ä½¿ç”¨è®¢å•beanï¼Œå› ä¸ºå…¶æ¯ä¸ªæœåŠ¡å‡ä¸ºç‹¬ç«‹çš„é¡¹ç›®ã€‚å½“ Order æœåŠ¡éœ€è¦ Product æœåŠ¡æ—¶ï¼Œå…¶åœ¨ Order çš„ä»£ç å†…ä¸€å®šä¼šå­˜åœ¨ä¸ Product ç›¸å…³çš„å…³é”®å­—ï¼Œç‰¹åˆ«åœ°ï¼Œç”±äºä¸¤ä¸ªæœåŠ¡ä¹‹é—´é¡¹é“¾ç´§å¯†ï¼Œåœ¨ Product çš„ä»£ç å†…ä¹Ÿè®¸ä¹Ÿä¼šå‡ºç° Order ç›¸å…³çš„å…³é”®å­—ã€‚å¯æ˜¯ä¸¤å¥—æœåŠ¡åˆ†åˆ«ç»´æŠ¤ç€è‡ªå·±çš„ beanï¼ˆå®ä½“å¯¹è±¡ / å®ä½“ç±»ï¼‰ï¼Œåœ¨ä¸åŒçš„æœåŠ¡ä¹‹é—´ç”šè‡³æ²¡æœ‰åŠæ³•ä½¿ç”¨å¯¹æ–¹çš„å®ä½“ç±»ã€‚\nè§£å†³æ–¹æ¡ˆä¹Ÿå¾ˆç®€å•ï¼Œå°†å•†å“ä¸è®¢å•çš„ Bean å‰¥ç¦»å‡ºæ¥ï¼Œå½¢æˆä¸€ä¸ªç‹¬ç«‹çš„é¡¹ç›®ï¼Œä¸ services ç­‰ä»·åœ°ä½ï¼Œå¹¶åœ¨ services æ·»åŠ  model ä¾èµ–ã€‚\n&lt;!--    æ¨¡å‹ä¾èµ–    -->&lt;dependency>    &lt;groupId>com.KarryCode&lt;/groupId>    &lt;artifactId>model&lt;/artifactId>    &lt;version>0.0.1-SNAPSHOT&lt;/version>&lt;/dependency>ç°åœ¨çš„ç»“æ„ä¸ºï¼š\n- cloud-demo(åŸºåº§é¡¹ç›®)|| - model(æ¨¡å‹å±‚)(åŒ…å«è®¢å•å®ä½“beanä¸å•†å“å®ä½“bean)|| - services(æœåŠ¡å±‚)| | | |  - service-order(è®¢å•æœåŠ¡)(åŒ…å«æœåŠ¡serviceå’Œæ§åˆ¶controller)| | | |  - service-product(å•†å“æœåŠ¡)(åŒ…å«æœåŠ¡serviceå’Œæ§åˆ¶controller)è‡³æ­¤ï¼ŒæœåŠ¡ä¹‹é—´çš„å®ä½“ä½¿ç”¨å·²ç»è¢«æ‰“é€šã€‚\nå…¶æ¬¡ç¼–å†™è¿œç¨‹è®¿é—®è¯·æ±‚æ¨¡æ¿ç±» RestTemplateï¼Œç”±äº RestTemplate æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·å†™ï¼š\n@Configurationpublic class ProductServiceConfig &#123;    @Bean    public RestTemplate restTemplate() &#123;        return new RestTemplate();    &#125;&#125;// ä¸Šæ‹‰ä½¿ä»–æˆä¸ºä¸€ä¸ª Beanå…¶æ¬¡ç¼–å†™è¿œç¨‹è®¿é—®æ–¹æ³•ï¼š\nprivate Product getProductFromRemote(Long productId) &#123;    // è·å–å•†å“æœåŠ¡æ‰€åœ¨çš„æ‰€æœ‰æœºå™¨ IP + ç«¯å£    List&lt;ServiceInstance> instances = discoveryClient.getInstances(\"service-product\");    // è·å–ç¬¬ä¸€ä¸ªæœºå™¨ï¼ˆç®€å•ç‰ˆï¼‰    ServiceInstance serviceInstance = instances.get(0);    // æ‹¼æ¥è¯·æ±‚åœ°å€ http://192.168.25.1:9000/product/100    String url = \"http://\" + serviceInstance.getHost() + \":\" + serviceInstance.getPort() + \"/product/\" + productId;    log.info(\"è¿œç¨‹è¯·æ±‚: &#123;&#125;\", url);    // å‘é€è¯·æ±‚ï¼ˆè¿œç¨‹ï¼‰    return restTemplate.getForObject(url, Product.class);&#125;è¡¥å…… createOrder æ–¹æ³•\npublic Order createOrder(Long productId, Long userId) &#123;    // æ­¤å¤„æå‰è¿œç¨‹æŸ¥è¯¢    Product productFromRemote = getProductFromRemote(productId);    Order order = new Order();    order.setId(1L);    // è®¡ç®—    order.setTotalAmount(productFromRemote.getPrice().multiply(new BigDecimal(productFromRemote.getNum())));    order.setUserId(userId);    order.setNickName(\"Karry.Liu\");    order.setAddress(\"åŒ—æ\");    // è¿œç¨‹æŸ¥è¯¢çš„ç»“æœ    order.setProduct(List.of(productFromRemote));    return order;&#125;æ­¤æ—¶åŒç«¯æœåŠ¡å·²ç»æ‰“é€šäº†ï¼Œæ³¨æ„åˆ°æ—¥å¿—ï¼š2025-06-24T22:21:11.646+08:00  INFO 3496 â€” [service-order] [nio-8080-exec-1] c.K.service.impl.OrderServiceImpl        : è¿œç¨‹è¯·æ±‚: http://192.168.25.1:9000/product/100\n&#123;  \"id\": 1,  \"totalAmount\": 198,  \"userId\": 2,  \"nickName\": \"Karry.Liu\",  \"address\": \"åŒ—æ\",  \"product\": [    &#123;      \"id\": 100,      \"price\": 99,      \"productName\": \"IPhone-100\",      \"num\": 2    &#125;  ]&#125;æ­¤æ—¶æˆ‘ä»¬è¿˜æœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œä¸€æ˜¯æˆ‘ä»¬æ¯æ¬¡åªå–äº†ç¬¬ä¸€ä¸ªæœåŠ¡å™¨ï¼ŒäºŒæ˜¯è¿™æ ·å†™å¤ªå¤æ‚ï¼Œæ²¡æœ‰å®ç°è´Ÿè½½å‡è¡¡ã€‚\né’ˆå¯¹æ­¤ç¬¬ä¸€ä¸ªé—®é¢˜å°†åœ¨ä¸‹ä¸€å°èŠ‚ä¸­è§£å†³ï¼Œç¬¬äºŒä¸ªé—®é¢˜å°†åœ¨ä¸‹ä¸€ä¸ªç»„ä»¶ä¸­è§£å†³ã€‚\n# å®ç°è´Ÿè½½å‡è¡¡ APIs\né¦–å…ˆæ˜¯ä½¿ç”¨å¤æ‚ä¸€ç‚¹çš„æ–¹å¼ï¼Œåé¢å°†ä¼šä»‹ç»ä½¿ç”¨æ³¨è§£çš„å½¢å¼ã€‚\nå…ˆå¼•å…¥è´Ÿè½½å‡è¡¡ç¯å¢ƒä¾èµ–ã€‚\n&lt;!--    è´Ÿè½½å‡è¡¡    -->&lt;dependency>    &lt;groupId>org.springframework.cloud&lt;/groupId>    &lt;artifactId>spring-cloud-starter-loadbalancer&lt;/artifactId>&lt;/dependency># åŸºäºæ–¹æ³•çš„è´Ÿè½½å‡è¡¡\nå°† getProductFromRemote æ–¹æ³•æ”¹é€ ä¸º getProductFromRemoteLoadBalancingï¼š\nprivate Product getProductFromRemoteLoadBalancing(Long productId) &#123;    // è·å–å•†å“æœåŠ¡æ‰€åœ¨æœºå™¨ (è´Ÿè½½å‡è¡¡)    ServiceInstance chooseLoadBalancing = loadBalancerClient.choose(\"service-product\");    // æ‹¼æ¥è¯·æ±‚åœ°å€ http://192.168.25.1:9000/product/100    log.info(\"æœåŠ¡åœ°å€ï¼ˆuriï¼‰: &#123;&#125;\", chooseLoadBalancing.getUri());//http://192.168.25.1:9000    String url = \"http://\" + chooseLoadBalancing.getHost() + \":\" + chooseLoadBalancing.getPort() + \"/product/\" + productId;    log.info(\"è¿œç¨‹è¯·æ±‚: &#123;&#125;\", url);    // å‘é€è¯·æ±‚ï¼ˆè¿œç¨‹ï¼‰    return restTemplate.getForObject(url, Product.class);&#125;å¤šæ¬¡è¯·æ±‚ http://localhost:8080/create åè§‚å¯Ÿæ—¥å¿—ï¼š\næœåŠ¡åœ°å€ï¼ˆuriï¼‰: http://192.168.25.1:9001è¿œç¨‹è¯·æ±‚: http://192.168.25.1:9001/product/100æœåŠ¡åœ°å€ï¼ˆuriï¼‰: http://192.168.25.1:9002è¿œç¨‹è¯·æ±‚: http://192.168.25.1:9002/product/100æœåŠ¡åœ°å€ï¼ˆuriï¼‰: http://192.168.25.1:9000è¿œç¨‹è¯·æ±‚: http://192.168.25.1:9000/product/100å¯ä»¥è§‚å¯Ÿåˆ°å…¶è´Ÿè½½å‡è¡¡çš„ä½¿ç”¨äº†ä¸åŒçš„ç«¯å£ï¼Œä¸‹é¢å°†ä»‹ç»æ³¨è§£çš„å½¢å¼ã€‚\n# åŸºäºæ³¨è§£çš„è´Ÿè½½å‡è¡¡\nè¿˜è®°å¾—æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„ RestTemplate å˜›ï¼Ÿ\n@Resourceprivate RestTemplate restTemplate;æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œæ— è®ºå“ªç§æ–¹æ³•ï¼Œæœ€ç»ˆéƒ½ä¼šæ˜¯å»ä½¿ç”¨ restTemplate.getForObject (â€¦) è¿™ä¸ªæ–¹æ³•ï¼Œå¦‚æœè¿™ä¸ªæ–¹æ³•è‡ªå·±å°±å¯ä»¥è¿›è¡Œè´Ÿè½½å‡è¡¡å‘¢ï¼Ÿæˆ‘ä»¬æ˜¯ä¸æ˜¯å¯ä»¥å°‘äº›ä¸€ç‚¹ä»£ç ï¼Ÿ\næ”¹é€  ProductServiceConfig é…ç½®ç±»ï¼š\n@Configurationpublic class ProductServiceConfig &#123;    @LoadBalanced// ä½¿ç”¨è´Ÿè½½å‡è¡¡    @Bean    public RestTemplate restTemplate() &#123;        return new RestTemplate();    &#125;&#125;å°† getProductFromRemoteLoadBalancing æ–¹æ³•æ”¹é€ ä¸º getProductFromRemoteLoadBalancingWithAnnotationï¼š\nprivate Product getProductFromRemoteLoadBalancingWithAnnotation(Long productId) &#123;    String url = \"http://service-product/product/\" + productId;    // å‘é€è¯·æ±‚ï¼ˆè¿œç¨‹ï¼‰    return restTemplate.getForObject(url, Product.class);&#125;æ³¨æ„åˆ°æˆ‘ä»¬çš„ url ä¸­å‡ºç°äº† service-productï¼Œåœ¨ç”±äº restTemplate è¢«è¿½åŠ äº† @LoadBalanced æ³¨è§£ï¼Œä½¿å¾—æ•´ä¸ª restTemplate è‡ªå¸¦æœ‰è´Ÿè½½å‡è¡¡çš„èƒ½åŠ›ï¼Œurl ä¼ è¿‡å»çš„æ—¶å€™ service-product ä¼šè¢«è‡ªåŠ¨æ›¿æ¢ä¸º IP+HOST çš„å½¢å¼ï¼Œæ›¿æ¢çš„ç»“æœç¬¦åˆè´Ÿè½½å‡è¡¡ã€‚\n# é…ç½®ä¸­å¿ƒ\n# åŸºæœ¬ç”¨æ³•\nå¼•å…¥ä¾èµ–\n&lt;!--    é…ç½®ä¸­å¿ƒ    -->&lt;dependency>    &lt;groupId>com.alibaba.cloud&lt;/groupId>    &lt;artifactId>spring-cloud-starter-alibaba-nacos-config&lt;/artifactId>&lt;/dependency>ä¹¦å†™å¯¼å…¥é…ç½®ï¼šnacos:service-order.yml\nspring:  config:    import: nacos:service-order.yml  cloud:    nacos:      server-addr: 127.0.0.1:8848  application:    name: service-orderserver:  port: 8080åœ¨ nacos ä¸­è®¾ç½®åä¸º service-order.yml\norder:  timeout: 120s  autoConfirm: 7dåœ¨ controller åŠ å…¥ @RefreshScope è‡ªåŠ¨åˆ·æ–°æ³¨è§£\n@Value(\"$&#123;order.timeout&#125;\")private String orderTimeout;@Value(\"$&#123;order.auto-confirm&#125;\")private String orderAutoConfirm;// è·å–é…ç½®ä¿¡æ¯@GetMapping(\"/getConfig\")public String getConfig() &#123;    return \"order.timeout:\" + orderTimeout + \" order.autoConfirm:\" + orderAutoConfirm;&#125;è®¿é—®åå¾—åˆ°å›åº”ï¼šorder.timeout:120s order.autoConfirm:7d\nä½†æ˜¯é…ç½®ä¸­å¿ƒçš„ä¾èµ–å¯¼å…¥æ–¹æ³•å…·æœ‰å¹¿æ’­æ€§ï¼Œæœ‰å¯èƒ½å‡ºç°å…¶ä»–æœåŠ¡çš„æ— æ³•å¯åŠ¨é—®é¢˜ï¼Œå› æ­¤å¯ä»¥åœ¨ yml ä¸­åŠ å…¥ï¼š\nspring:  cloud:    nacos:      config:        import-check:          enabled: falseæ¥ç¦ç”¨æ£€æŸ¥ã€‚\n# æ— æ„ŸåŠ¨æ€åˆ·æ–°\næ‰‹åŠ¨é…ç½®å¾ˆéº»çƒ¦ï¼Œé€šå¸¸ä½¿ç”¨ç»Ÿä¸€å¯¼å…¥çš„æ–¹æ³•æ¥å®ç°ï¼Œåˆ›å»º OrderPropertiesï¼š\n@Data@Component// æ‰¹é‡è·å–é…ç½®ï¼Œæ— éœ€ä½¿ç”¨ @RefreshScope å³å¯è‡ªåŠ¨åˆ·æ–°@ConfigurationProperties(prefix = \"order\")public class OrderProperties &#123;    String timeout;    String autoConfirm;&#125;@ConfigurationProperties (prefix = â€œorderâ€) ä¸­ prefix = &quot;order&quot; è·å–å‰ç¼€ä¸º order çš„é…ç½®ï¼Œæœ‰äº† ConfigurationProperties æ— éœ€ä½¿ç”¨ @RefreshScope å³å¯è‡ªåŠ¨åˆ·æ–°ã€‚\næ”¹é€  OrderControllerï¼š\n@Autowiredprivate OrderProperties orderProperties;// è·å–é…ç½®ä¿¡æ¯@GetMapping(\"/getConfig\")public String getConfig() &#123;    return \"order.timeout:\" + orderProperties.getTimeout() + \" order.autoConfirm:\" + orderProperties.getAutoConfirm();&#125;# æœ¬åœ°é…ç½®ä¸ Nacos é…ç½®å†²çªæ—¶\nå½“æœ¬åœ°é…ç½®ä¸ Nacos é…ç½®å†²çªæ—¶ï¼Œä¼˜å…ˆä»¥ Nacos ä¸­çš„é…ç½®ä¸­å¿ƒä¸ºå‡†ã€‚\nå³å…ˆå¯¼å…¥ä¼˜å…ˆï¼Œå¤–éƒ¨ä¼˜å…ˆã€‚\nå½“ï¼šimport: nacos:service-order.yml,nacos:common.yml å‡ºç°æ—¶ï¼Œä»ç„¶æ˜¯ä¼˜å…ˆä»¥ç¬¬ä¸€æ¬¡å‡ºç°çš„ nacos:service-order.yml ä¸ºå‡†ã€‚\n# æ•°æ®éš”ç¦»\nå½“å‡ºç°ä¸åŒç¯å¢ƒéœ€è¦ä¸åŒé…ç½®æ—¶ï¼Œæ¯”å¦‚ dev ç¯å¢ƒã€test ç¯å¢ƒå’Œ prod ç¯å¢ƒï¼Œåˆ†åˆ«éœ€è¦ä¸åŒçš„é…ç½®ï¼Œæˆ‘ä»¬è¯¥å¦‚ä½•ç»„ç»‡ï¼Ÿ\né¦–å…ˆ Nacos æä¾›äº†ï¼šå‘½åç©ºé—´ - ç»„ç»‡ - é…ç½®å•å…ƒçš„æ¨¡å¼ï¼Œå‘½åç©ºé—´å¯ä»¥å¯¹åº”åˆ° dev ç¯å¢ƒã€test ç¯å¢ƒå’Œ prod ç¯å¢ƒç­‰ï¼Œç»„å¼€æºå¯¹åº”åˆ°ä¸åŒçš„å¾®æœåŠ¡æ¯”å¦‚å•†å“å¾®æœåŠ¡ã€ç”¨æˆ·å¾®æœåŠ¡ç­‰ï¼Œé…ç½®å•å…ƒå³ä¸ºå…·ä½“çš„è¯¦ç»†é…ç½®ã€‚\né¦–å…ˆåœ¨ Nacos å‘½åç©ºé—´ã€ç»„ç»‡ä¸é…ç½®ã€‚\n\nè¿™é‡Œå·²ç»åˆ›å»ºäº† dev ç¯å¢ƒã€test ç¯å¢ƒå’Œ prod ç¯å¢ƒï¼Œä¸‹é¢åˆ›å»ºè¯¦ç»†çš„ç»„ä¸é…ç½®\n\nç„¶åæ”¹é€  yml é…ç½®æ–‡ä»¶\nspring:  profiles:    active: dev  cloud:    nacos:      server-addr: 127.0.0.1:8848      config:        namespace: $&#123;spring.profiles.active:dev&#125;  application:    name: service-orderserver:  port: 8080---spring:  config:    activate:      on-profile: dev    import:      - nacos:common.yml?group=order      - nacos:database.yml?group=order---spring:  config:    activate:      on-profile: test    import:      - nacos:common.yml?group=order      - nacos:database.yml?group=order---spring:  config:    activate:      on-profile: prod    import:      - nacos:common.yml?group=order      - nacos:database.yml?group=order\nå…·ä½“åœ°ï¼š\nnamespace: $&#123;spring.profiles.active:dev&#125;è¿™é‡Œä¸»è¦è´Ÿè´£çš„æ—¶ä»é¡¹ç›®åˆ° Nacos æ—¶æˆ‘ä»¬åº”è¯¥é€‰æ‹©å“ªå¥—å‘½åç©ºé—´ï¼Œæ˜¯ Nacos çš„å‘½åç©ºé—´\nè€Œå¯¹äºï¼š\nprofiles:  active: devä¸»è¦è´Ÿè´£çš„æ˜¯è¦æ¿€æ´»å“ªå¥—åˆ†ç‰‡é…ç½®ï¼Œæ˜¯ on-profile: dev è¿˜æ˜¯ on-profile: testï¼Œè¿˜æ˜¯ on-profile: prodï¼Œè¿™é‡ŒæŒ‡çš„æ˜¯é¡¹ç›®çš„é…ç½®åˆ†ç‰‡\næ­¤æ—¶åªéœ€è¦åˆ‡æ¢ä¸åŒçš„ active: devï¼Œå³å¯å®Œæˆä¸åŒç¯å¢ƒçš„é…ç½®åˆ‡æ¢\n# Nacos æ€»ç»“\n\næ¥è‡ªå°šç¡…è°·è¯¾å ‚ï¼šhttps://www.bilibili.com/video/BV1UJc2ezEFU\n# OpenFeign\nOpenFeign æ˜¯ Spring Cloud ç”Ÿæ€ç³»ç»Ÿä¸­çš„ä¸€ä¸ªé‡è¦ç»„ä»¶ã€‚Spring Cloud æ˜¯ä¸€ä¸ªåŸºäº Spring Boot å®ç°çš„åˆ†å¸ƒå¼ç³»ç»Ÿå¼€å‘å·¥å…·ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—çš„å·¥å…·æ¥ç®€åŒ–åˆ†å¸ƒå¼ç³»ç»Ÿå¼€å‘ï¼ŒåŒ…æ‹¬æœåŠ¡æ³¨å†Œä¸å‘ç°ã€é…ç½®ä¸­å¿ƒã€æ–­è·¯å™¨ç­‰åŠŸèƒ½ï¼ŒOpenFeign é»˜è®¤é›†æˆäº† Ribbon è´Ÿè½½å‡è¡¡å™¨ã€‚\n# è¿œç¨‹è°ƒç”¨\n# å¯¼å…¥æ³¨è§£\n&lt;!--    openfeign è¿œç¨‹è°ƒç”¨    -->&lt;dependency>    &lt;groupId>org.springframework.cloud&lt;/groupId>    &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId>&lt;/dependency># åˆ›å»º feign åŒ…ä¸ XXXClient æ¥å£\n@FeignClient(value = \"service-product\")public interface ProductFeignClient &#123;    //mvc æ³¨è§£ä½¿ç”¨çš„ä¸¤å¥—é€»è¾‘ï¼Œæ”¾åœ¨ Controller ä¸Šæ˜¯æ¥æ”¶è¯·æ±‚ï¼Œæ”¾åœ¨ FeignClient ä¸Šæ˜¯å‘é€è¯·æ±‚    @GetMapping(\"/product/&#123;productId&#125;\")    Product getProductById(@PathVariable String productId);&#125;è¿™é‡Œçš„ value = &quot;service-product&quot; æŒ‡çš„æ˜¯ç»™é‚£ä¸ªå¾®æœåŠ¡å‘é€è¯·æ±‚ï¼Œè¿™é‡Œè¿˜æ ‡æ³¨äº† GetMappingï¼ŒæŒ‡çš„æ˜¯ç»™é‚£ä¸ªå¾®æœåŠ¡å‘é€è¯·æ±‚çš„è·¯å¾„æ˜¯ä»€ä¹ˆï¼Œå…¶æ˜ç¡®äº†æ¥å£ã€‚\n# æ”¹é€ è®¢å•åˆ›å»ºæ–¹æ³•\n@Override    public Order createOrder(Long productId, Long userId) &#123;//        Product productFromRemote = getProductFromRemoteLoadBalancingWithAnnotation(productId);        Product productFromRemote = productFeignClient.getProductById(productId);        Order order = new Order();        order.setId(1L);        // TODO éœ€è¦è®¡ç®—        order.setTotalAmount(productFromRemote.getPrice().multiply(new BigDecimal(productFromRemote.getNum())));        order.setUserId(userId);        order.setNickName(\"Karry.Liu\");        order.setAddress(\"åŒ—æ\");        // TODO éœ€è¦è¿œç¨‹æŸ¥è¯¢        order.setProduct(List.of(productFromRemote));        return order;    &#125;# ä¹Ÿå¯ä»¥å‘å¤–éƒ¨ï¼ˆç¬¬ä¸‰æ–¹ï¼‰åšå‡ºè¯·æ±‚\næ¯”å¦‚ä¸‹é¢æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤©æ°”æ•°æ®æ¥å£çš„ä»£ç å®ç°\n@FeignClient(value = \"weather-client\", url = \"http://apis.juhe.cn\")public interface WeatherFeignClient &#123;    @GetMapping(\"/simpleWeather/query\")    String getWeatherByCityId(@RequestParam(\"city\") String city,                              @RequestParam(\"key\") String key);    default String getEncodedCity(String city) throws Exception &#123;        return URLEncoder.encode(city, StandardCharsets.UTF_8);    &#125;&#125;# å°æŠ€å·§ï¼ˆæ‡’ç‹—æ¨¡å¼ï¼‰\nå¦‚æœæ˜¯è¦è®¿é—®è‡ªå·±çš„è®¾è®¡çš„æ¥å£ï¼Œç€é€šå¸¸æ˜¯ä¸šåŠ¡æ¥å£ï¼Œæ¯”å¦‚ä¸€ä¸ªè®¢å•æœåŠ¡è¦è®¿é—®å•†å“æœåŠ¡ï¼Œæœ€ç®€å•çš„æ–¹å¼å°±æ˜¯å°†ï¼Œå•†å“çš„ Controller ä¸‹çš„æ¥å£æ‰¾åˆ°ï¼Œç„¶åç›´æ¥å¤åˆ¶æ–¹æ³•åï¼ˆä»¥æ¥å£çš„æ–¹å¼è¿›è¡Œå¤åˆ¶å°±å¯ä»¥ï¼‰ï¼Œç„¶åæŠŠä»–æ”¾åœ¨åœ°ç‚¹æœåŠ¡çš„ OpenFegin æ¥å£ä¸‹å°±å¯ä»¥äº†ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒOpenFegin å·²ç»å¸®æˆ‘ä»¬åšå¥½äº†è´Ÿè½½å‡è¡¡ï¼Œç›¸æ¯”ä¸Šè¿° Nacos ä¸­é‚£ç§è¯·æ±‚æ¨¡æ¿æ–¹ä¾¿å¤šäº†ã€‚\nå…·ä½“åœ°å¦‚ä¸‹é¢çš„æ“ä½œæ‰€ç¤ºï¼š\n\n\næ‰¾åˆ°å•†å“æœåŠ¡æ¥å£çš„ä»£ç \n@Slf4j@RestControllerpublic class ProductController &#123;    @Autowired    private ProductService productService;    @GetMapping(\"/product/&#123;productId&#125;\")    public Product getProduct(@PathVariable Long productId) &#123;        log.info(\"æŸ¥è¯¢å•†å“ä¿¡æ¯: &#123;&#125;\", productId);        return productService.getProductById(productId);    &#125;&#125;\n\nå°±åƒæ¥å£çš„æ–¹å¼å»å¤åˆ¶ä»£ç \n@GetMapping(\"/product/&#123;productId&#125;\")public Product getProduct(@PathVariable Long productId)\n\nç²˜è´´åˆ°è®¢å•æœåŠ¡ä¹‹ä¸­\n@FeignClient(value = \"service-product\")public interface ProductFeignClient &#123;    //mvc æ³¨è§£ä½¿ç”¨çš„ä¸¤å¥—é€»è¾‘ï¼Œæ”¾åœ¨ Controller ä¸Šæ˜¯æ¥æ”¶è¯·æ±‚ï¼Œæ”¾åœ¨ FeignClient ä¸Šæ˜¯å‘é€è¯·æ±‚    @GetMapping(\"/product/&#123;productId&#125;\")    Product getProductById(@PathVariable Long productId);        @GetMapping(\"/product/&#123;productId&#125;\")    public Product getProduct(@PathVariable Long productId);&#125;å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œç²˜è´´åˆ° ProductFeignClient ä¸­çš„ä»£ç ä¸æˆ‘ä»¬ä¹‹å‰è‡ªå·±å®šä¹‰çš„ä»£ç ç‰‡æ®µåŸºæœ¬æ˜¯å®Œå…¨ä¸€è‡´ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½ç”¨çš„å°æŠ€å·§ã€‚\n\n\n# é¢è¯•é¢˜\né—®ï¼šå®¢æˆ·ç«¯çš„è´Ÿè½½å‡è¡¡å’ŒæœåŠ¡ç«¯è´Ÿè½½å‡è¡¡æœ‰ä¸ç”¨ï¼Ÿ\nç­”ï¼šé¦–å…ˆå¯¹äºå®¢æˆ·ç«¯çš„è´Ÿè½½å‡è¡¡æ¥è¯´ï¼Œå®¢æˆ·ç«¯æœåŠ¡ä¼šå…ˆå»è®¿é—®æ³¨å†Œä¸­å¿ƒï¼Œé¦–å…ˆè·å–åˆ°ä¸€äº›åœ°å€ï¼Œç„¶åé€‰æ‹©ä¸€ä¸ªåœ°å€ï¼Œæœ€åå‘èµ·è°ƒç”¨ï¼Œè¿™ä¸ªè¿‡ç¨‹å®Œå…¨æ˜¯å‘ç”Ÿåœ¨å®¢æˆ·ç«¯æ–¹é¢çš„ï¼Œä½†æ˜¯å¯¹äºæœåŠ¡ç«¯çš„è´Ÿè½½å‡è¡¡æ¥è¯´ï¼Œè¿™ä¸ªæœåŠ¡ç«¯åªå¯¹å¤–éƒ¨æš´éœ²ä¸€ä¸ªæœåŠ¡æ¥å£ï¼Œé‚£ä¹ˆæ‰€æœ‰çš„è¯·æ±‚éƒ½éœ€è¦é€šè¿‡è¿™ä¸ªå”¯ä¸€çš„æ¥å£æ¥è®¿é—®ã€‚ç„¶è€Œï¼Œåœ¨è¿™ä¸ªæ¥å£èƒŒåæœ‰ç€ä¸€å¥—è´Ÿè½½å‡è¡¡çš„é€»è¾‘ï¼Œæ¥å£èƒŒåè¿è¡Œç€è®¸å¤šçš„æœåŠ¡ï¼Œè€Œå…·ä½“ä½¿ç”¨å“ªä¸ªï¼Œç”±ä¸åŒçš„è´Ÿè½½å‡è¡¡ç®—æ³•å†³å®šï¼Œè¿™ä¸€è¿‡ç¨‹æ”¾ç”Ÿåœ¨æœåŠ¡ç«¯ã€‚\n# æ—¥å¿—\nå¯ä»¥åœ¨ Configuration ç±»ä¸‹åŠ å…¥ä»¥ä¸‹ä»£ç ï¼š\n@BeanLogger.Level feignLoggerLevel() &#123;    return Logger.Level.FULL;&#125;åœ¨ yaml ä¸‹åŠ å…¥è¿œç¨‹è°ƒç”¨åŒ…çš„æ—¥å¿—é…ç½®ï¼š\nlogging:  level:    com.KarryCode.feign: debugå†æ¬¡è¯·æ±‚å³å¯è§‚å¯Ÿåˆ°æ—¥å¿—è¾“å‡ºï¼Œå¯ä»¥çœ‹åˆ°æ˜¯æ€ä¹ˆè¯·æ±‚çš„ã€‚\n# è¶…æ—¶æ§åˆ¶\nåˆ†åˆ«æœ‰è¿æ¥è¶…æ—¶å’Œè¯»å–è¶…æ—¶ï¼Œé€šè¿‡å…¶æºç å®ç°å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œè¿æ¥è¶…æ—¶æ˜¯ 10 ç§’ï¼Œè€Œè¯»å–è¶…æ—¶æ˜¯ 60 ç§’ã€‚æˆ‘ä»¬ä»ç„¶å¯ä»¥é€šè¿‡é…ç½®æ¥ä¿®æ”¹ï¼Œè¿™ä¸ªå…·ä½“çš„æ—¶é—´ã€‚\n\nè¿™é‡Œè¯´ä¸€ä¸ªé¢˜å¤–è¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¤šä¸ªé…ç½®æ–‡ä»¶æ¥è®©å…¶ç”Ÿæ•ˆï¼Œæ¯”å¦‚æˆ‘è¿™é‡Œæœ‰ä¸€ä¸ª application-feign.ymlï¼Œæˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªä¸»æ–‡ä»¶ application.ymlï¼Œå¦‚æœæˆ‘ä»¬æƒ³è®© application-feign.yml ç”Ÿæ•ˆçš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸»é…ç½®æ–‡ä»¶åŠ ä¸Šè¿™æ ·çš„ä¸€å¥è¯ï¼šinclude: feign\nspring:  profiles:    active: dev    include: feign\nå…¶é…ç½®æ–¹å¼å¦‚ä¸‹æ‰€ç¤ºï¼š\nspring:  cloud:    openfeign:      client:        config:          default:            connectTimeout: 3000            readTimeout: 5000            logger-level: full# é‡è¯•æœºåˆ¶\né»˜è®¤æƒ…å†µä¸‹ï¼ŒOpenFeign çš„é‡è¯•ç­–ç•¥æ˜¯ä»ä¸é‡è¯•ï¼ˆæ˜¯çš„æ²¡é”™ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨å¯åŠ¨è¿™ä¸ªé‡è¯•ç­–ç•¥ï¼Œå…¶å…·ä½“çš„æœ‰ï¼šæˆ‘ä»¬å¯ä»¥è®¾è®¡é—´éš” 100 æ¯«ç§’ï¼Œæœ€å¤§é—´éš” 1 ç§’ã€‚æœ€å¤§å°è¯• 5 æ¬¡ã€‚ç±»ä¼¼è®¡ç½‘é‡Œé¢çš„é€€é¿ç®—æ³•\nåŒæ ·åœ¨ç›¸åº”çš„é…ç½®ä¸‹é¢åŠ å…¥è¿™æ ·çš„ä»£ç ï¼š\n@BeanRetryer feignRetryer() &#123;    return new Retryer.Default();&#125;è¿™æ˜¯ä¸€ä¸ªé»˜è®¤çš„é‡è¯•å™¨ï¼Œå…¶é‡è¯•è§„åˆ™æ­£å¦‚æˆ‘ä¸Šé¢æ‰€è¯´é‚£æ ·ï¼šæˆ‘ä»¬å¯ä»¥è®¾è®¡é—´éš” 100 æ¯«ç§’ï¼Œæœ€å¤§é—´éš” 1 ç§’ã€‚æœ€å¤§å°è¯• 5 æ¬¡ã€‚\n# æ‹¦æˆªå™¨\næˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªè¯·æ±‚æ‹¦æˆªå™¨ï¼š\n@Componentpublic class XTokenRequestInterceptor implements RequestInterceptor &#123;    @Override    public void apply(RequestTemplate requestTemplate) &#123;        System.out.println(\"æ‹¦æˆªå™¨å¯åŠ¨\");        requestTemplate.header(\"X-Token\", UUID.randomUUID().toString());    &#125;&#125;ç„¶åå†æ¥æ”¶è¯·æ±‚æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è§£æä¸€ä¸‹ï¼š\n@GetMapping(\"/product/&#123;productId&#125;\")public Product getProduct(@PathVariable Long productId, HttpServletRequest request) &#123;    System.out.println(\"token:\" + request.getHeader(\"X-Token\"));    log.info(\"æŸ¥è¯¢å•†å“ä¿¡æ¯: &#123;&#125;\", productId);    return productService.getProductById(productId);&#125;å¯ä»¥çœ‹åˆ° Token çš„è¾“å‡ºï¼štoken:ebf2c253-7e63-483a-92bc-fc9d1819a418ã€‚\n# Fallback å…œåº•è¿”å›\nå…œåº•è¿”å›æœºåˆ¶éœ€è¦é…åˆæˆ‘ä»¬è¿˜æ²¡æœ‰å­¦åˆ°çš„ sentinel æ¡†æ¶ï¼Œé¦–å…ˆå¼•å…¥ä¾èµ–ï¼š\n&lt;!--    sentinel    -->&lt;dependency>    &lt;groupId>com.alibaba.cloud&lt;/groupId>    &lt;artifactId>spring-cloud-starter-alibaba-sentinel&lt;/artifactId>&lt;/dependency>åŠ å…¥é…ç½®ï¼š\nfeign:  sentinel:    enabled: trueåœ¨æœåŠ¡å‘èµ·ç«¯åŠ å…¥å…œåº•ç­–ç•¥ï¼š\n@Componentpublic class ProductFeignClientFallback implements ProductFeignClient &#123;    @Override    public Product getProductById(Long productId) &#123;        Product product = new Product();        product.setId(productId);        product.setPrice(new BigDecimal(\"0\"));        product.setProductName(\"ä¸åˆ°å•Š-\" + productId);        product.setNum(2);        return product;    &#125;&#125;å…³é—­ Product æœåŠ¡ï¼Œåªä¿ç•™ Order æœåŠ¡ï¼Œå¯ä»¥çœ‹åˆ°è¿”å›äº†å…œåº•æ•°æ®ï¼š\n&#123;  \"id\": 1,  \"totalAmount\": 0,  \"userId\": 777,  \"nickName\": \"Karry.Liu\",  \"address\": \"åŒ—æ\",  \"product\": [    &#123;      \"id\": 888,      \"price\": 0,      \"productName\": \"ä¸åˆ°å•Š-888\",      \"num\": 2    &#125;  ]&#125;# Sentinel\n\n\n# åŸºç¡€åœºæ™¯\n@SentinelResource(value = \"createOrder\")æ·»åŠ ä¸Šæ­¤æ³¨è§£ï¼Œæµé‡å³è¢«ç›‘æ§ã€‚\n\næ·»åŠ æµæ§è§„åˆ™ï¼š\n\næ¯ç§’åªæ”¾è¡Œä¸€æ¬¡è¯·æ±‚ï¼Œå¦‚æœä½ è¯·æ±‚å¤šäº†å°±ä¼šè¢«æ‰“å›ã€‚\nFail to send:http://localhost:8081/create?productId=777&amp;userId=1Blocked by Sentinel (flow limiting)è¿™æ˜¯ä¸€ä¸ªé»˜è®¤é”™è¯¯é¡µé¢ï¼Œæˆ‘ä»¬èƒ½ä¸èƒ½è¿”å›ä¸€ä¸ªé«˜åº¦è‡ªå®šä¹‰çš„æ•°æ®å‘¢ï¼Ÿ\nä½†æ˜¯å¯ä»¥çš„ï¼è¿™æ¶‰åŠåˆ° Sentinal çš„å¼‚å¸¸å¤„ç†æœºåˆ¶ã€‚\n# å¼‚å¸¸å¤„ç†\n\n\nFlow Exceptionï¼šæµæ§å¼‚å¸¸\nParam Flow Exceptionï¼šçƒ­ç‚¹å‚æ•°å¼‚å¸¸\nDegrade Exceptionï¼šç†”æ–­é™çº§å¼‚å¸¸\nAuthority Exceptionï¼šæƒé™æ§åˆ¶ç±»å¼‚å¸¸\nSystem Block Exceptionï¼šç³»ç»Ÿé˜»å¡å¼‚å¸¸\n\nä¸Šè¿°è¯´çš„é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªå¼‚å¸¸ã€‚\n@Componentpublic class MyBlockException implements BlockExceptionHandler &#123;    private ObjectMapper objectMapper = new ObjectMapper();    @Override    public void handle(HttpServletRequest httpServletRequest,                       HttpServletResponse httpServletResponse,                       String resourceName, BlockException e) throws Exception &#123;        R error = R.error(500, resourceName + \"è¢«é™æµäº†\", e.getMessage());        httpServletResponse.setContentType(\"application/json;charset=utf-8\");        PrintWriter writer = httpServletResponse.getWriter();        String json = objectMapper.writeValueAsString(error);        writer.write(json);    &#125;&#125;\nè¿™ä¸ªæ—¶å€™ï¼Œå¦‚æœä½ ç»™ createOrder æ–¹æ³•æ·»åŠ æµæ§è§„åˆ™çš„è¯ï¼Œä½ ä¼šå‘ç°è¿™ä¸ªæˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„ json ä¸ç”Ÿæ•ˆäº†ã€‚\nFail to send:http://localhost:8081/create?productId=777&amp;userId=1&lt;html>&lt;body>&lt;h1>Whitelabel Error Page&lt;/h1>&lt;p>This application has no explicit mapping for /error, so you are seeing this as a fallback.&lt;/p>&lt;div id='created'>Wed Nov 05 16:15:00 CST 2025&lt;/div>&lt;div>There was an unexpected error (type=Internal Server Error, status=500).&lt;/div>&lt;/body>&lt;/html>è¿™æ˜¯å› ä¸ºå®ƒçš„å¼‚å¸¸ç±»å‹ä¸åŒï¼Œæ‰å¯¼è‡´çš„è¿™æ ·çš„ç»“æœã€‚\n# æµæ§è§„åˆ™\né˜ˆå€¼ç±»å‹ï¼š\n\nQPSï¼šæ¯ç§’è¯·æ±‚æ•°\nå¹¶å‘çº¿ç¨‹æ•°\n\næˆ‘ä»¬ä¼˜å…ˆæ¨èä½¿ç”¨ QPSã€‚\næ˜¯å¦é›†ç¾¤ï¼š\n\nå•æœºå‡æ‘Š\næ€»ä½“é˜ˆå€¼\n\næµæ§æ¨¡å¼ï¼š\n\nç›´æ¥æ¨¡å¼\nå…³è”æ¨¡å¼\né“¾è·¯æ¨¡å¼\n\næµæ§æ•ˆæœ\n\nå¿«é€Ÿå¤±è´¥\nWarm Up\næ’é˜Ÿç­‰å¾…\n\n\n\n# ç†”æ–­é™çº§\n\n# Gateway\n# å‚è€ƒæ–‡çŒ®\n\nã€å°šç¡…è°· SpringCloud é€Ÿæˆã€‘https://www.bilibili.com/video/BV1UJc2ezEFU\n\n","categories":["SpringCloud"],"tags":["java","å¾®æœåŠ¡"]},{"title":"åˆè§Linux","url":"/Linux/Linux01/","content":"# åˆè§ Linux\né¦–å…ˆå®‰è£…ä»€ä¹ˆçš„å°±ä¸è®²äº†ï¼Œè¿™é‡Œå…ˆè®²ä¸€ä¸‹åŸºç¡€å‘½ä»¤\n# ç®€å•å‘½ä»¤\n# who å‘½ä»¤\n[karry@localhost ~]$ who am i\n[karry@localhost ~]$ who am i\nkarry    pts/0        2023-09-01 10:26 (laptop-karry1107)\n\n# echo å‘½ä»¤\nè¿™ä¸ªå‘½ä»¤æ˜¯å°†å†…å®¹è¾“å‡ºåˆ°å±å¹•ä¸Š\n[karry@localhost ~]$ echo Hello Karry.Liu\n[karry@localhost ~]$ echo Hello Karry.Liu\nHello Karry.Liu\n\n# date å‘½ä»¤\n[karry@localhost ~]$ date\n[karry@localhost ~]$ date\n2023 å¹´ 09 æœˆ 01 æ—¥ æ˜ŸæœŸäº” 10:32:23 PDT\n\n# cal å‘½ä»¤\n[karry@localhost ~]$ cal 9 2023\n[karry@localhost ~]$ cal 9 2023\n ä¹æœˆ 2023\n æ—¥ ä¸€ äºŒ ä¸‰ å›› äº” å…­\n 1  2\n3  4  5  6  7  8  9\n10 11 12 13 14 15 16\n17 18 19 20 21 22 23\n24 25 26 27 28 29 30\n\n# åŸºç¡€å‘½ä»¤\n# åŸºç¡€æ–‡ä»¶æ“ä½œå‘½ä»¤\n# å±•ç¤ºæ–‡ä»¶å¤¹ä¸­çš„å†…å®¹\n[karry@localhost ~]$ ls\n[karry@localhost ~]$ ls\nDesktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos\n\n# è¿›å…¥ / é€€å‡ºæ–‡ä»¶å¤¹\n[karry@localhost ~]$ cd Desktop\n[karry@localhost ~]$ cd Desktop\n[karry@localhost Desktop]$\n\n# åˆ›å»ºæ–‡ä»¶å¤¹\n[karry@localhost Desktop]$ mkdir LinuxHello\n[karry@localhost Desktop]$ ls\nfirefox.desktop  myFile  test\n[karry@localhost Desktop]$ mkdir LinuxHello\n[karry@localhost Desktop]$ ls\nfirefox.desktop  LiunxHello  myFile  test\n\n# åˆ›å»ºä¸€ä¸ªæ–‡ä»¶\n[karry@localhost LinuxHello]$ touch fistText.txt\n[karry@localhost Desktop]$ ls\nfirefox.desktop  LinuxHello  myFile  test\n[karry@localhost Desktop]$ cd LinuxHello\n[karry@localhost LinuxHello]$ touch fistText.txt\n[karry@localhost LinuxHello]$ ls\nfistText.txt\n\n# ç¼–è¾‘æ–‡ä»¶\n[karry@localhost LinuxHello]$ touch fistText.txt\n~\n~\n~\nâ€œfistText.txtâ€ 0L, 0C\n\næŒ‰   i        è¿›å…¥æ’å…¥æ¨¡å¼\n\n~\n~\n~\nâ€“ æ’å…¥ â€“\n\nç°åœ¨å¯ä»¥ç¼–è¾‘æ–‡ä»¶äº†ï¼\n\nhi hiï¼Œè¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡å­¦ä¹  Linuxï¼ï¼ï¼\næˆ‘çš„åå­—æ˜¯è¯—å²¸æ¢¦è¡ŒèˆŸ\næˆ–è€…æ˜¯ Karry.Liu\n è®©æˆ‘ä»¬å…±åŒåŠªåŠ›å§ï¼ï¼\n~\n~                                                                                                                                                                                                                                                                                                                                                                       â€“ æ’å…¥ â€“\n\næŒ‰   Esc        é€€å‡ºæ’å…¥æ¨¡å¼\næŒ‰   :+  w       ä¿å­˜åˆšæ‰æ‰€ç¼–è¾‘çš„æ–‡ä»¶\n\nhi hiï¼Œè¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡å­¦ä¹  Linuxï¼ï¼ï¼\næˆ‘çš„åå­—æ˜¯è¯—å²¸æ¢¦è¡ŒèˆŸ\næˆ–è€…æ˜¯ Karry.Liu\n è®©æˆ‘ä»¬å…±åŒåŠªåŠ›å§ï¼ï¼\n~\nâ€œfistText.txtâ€ 4L, 128C å·²å†™å…¥\n\næœ€åæŒ‰ :+ q   é€€å‡º vi ç¼–è¾‘å™¨\n\n~\n~\n:q\n\n# è¯»æ–‡ä»¶å†…å®¹\n[karry@localhost LinuxHello]$ cat fistText.txt\n[karry@localhost LinuxHello]$ cat fistText.txt\nhi hiï¼Œè¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡å­¦ä¹  Linuxï¼ï¼ï¼\næˆ‘çš„åå­—æ˜¯è¯—å²¸æ¢¦è¡ŒèˆŸ\næˆ–è€…æ˜¯ Karry.Liu\n è®©æˆ‘ä»¬å…±åŒåŠªåŠ›å§ï¼ï¼\n[karry@localhost LinuxHello]$\n\n# ä½¿ç”¨ g++ ç¼–è¯‘ç¨‹åº\n\n\nå¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£… g++ ç¼–è¯‘å™¨ï¼Œè¯·å…ˆå®‰è£…\nsudo yum install gcc-c++ makeå®‰è£…éœ€è¦ä¸€å®šæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\n\n\nè¿›å…¥æŒ‡å®šç›®å½•ï¼Œåˆ›å»º cpp æ–‡ä»¶ã€‚\n[karry@localhost C++]$ touch firstApp.cpp\n\nä½¿ç”¨ vi æŒ‡ä»¤ç¼–è¾‘æ–‡ä»¶\n[karry@localhost C++]$ vi firstApp.cpp\n\næŒ‰ i è¿›å…¥æ’å…¥æ¨¡å¼ï¼Œç¼–è¾‘ç¨‹åº\n#include&lt;iostream>using namespace std;int main()&#123;        int a=1;        int b=2;        int c=a+b;        cout&lt;&lt;\"è®¡ç®—ç»“æœä¸ºï¼š\"&lt;&lt;a&lt;&lt;\"+\"&lt;&lt;b&lt;&lt;\"=\"&lt;&lt;c&lt;&lt;endl;        return 0;&#125;\n\næŒ‰   Esc        é€€å‡ºæ’å…¥æ¨¡å¼ï¼ŒæŒ‰   :+  w       ä¿å­˜åˆšæ‰æ‰€ç¼–è¾‘çš„æ–‡ä»¶ï¼Œæœ€åæŒ‰ :+ q   é€€å‡º vi ç¼–è¾‘å™¨\n\n\næ‰§è¡Œå‘½ä»¤ç¼–è¯‘ç¨‹åº\n[karry@localhost C++]$ g++ -o firstAppCompile firstApp.cpp\n\nè¿è¡Œè¾“å‡ºç»“æœ\n[karry@localhost C++]$ ./firstAppCompile\n[karry@localhost C++]$ ./firstAppCompile\n è®¡ç®—ç»“æœä¸ºï¼š1+2=3\n[karry@localhost C++]$\n\n\n\n","categories":["Linux"],"tags":["Linux"]},{"title":"Javaé«˜çº§ç‰¹æ€§1","url":"/Java/javaAd01/","content":"# List ä¸ Set\næœ¬ç¯‡å†…å®¹æ„åœ¨æ€»ç»“è¯¾ä¸Šæ‰€å­¦çš„çŸ¥è¯†å¹¶åŠ ä»¥å·©å›ºï¼Œå¦‚æœ‰é”™è¯¯è¯·ç«‹å³è”ç³»æˆ‘ï¼Œè°¢è°¢ï¼\n\n\nå…³äº Collection\næŒæ¡ List éƒ¨åˆ†å†…å®¹\næŒæ¡ Set éƒ¨åˆ†å†…å®¹\nè¿­ä»£å™¨\nWeChatï¼ša735690757\ngmailï¼š735690757carry@gmail.com\n\n\n# 1ï¼Œæ¦‚è¿°\nåœ¨ Java ä¸­ï¼ŒList å’Œ Set æ¥å£éƒ½æ˜¯ç»§æ‰¿è‡ª Collection æ¥å£ã€‚Collection æ¥å£å®šä¹‰äº†ä¸€ç»„é€šç”¨çš„é›†åˆæ“ä½œæ–¹æ³•ï¼Œè€Œ List å’Œ Set åˆ™åˆ†åˆ«æ‰©å±•äº† Collection æ¥å£ï¼Œä»¥æä¾›ç‰¹å®šçš„é›†åˆè¡Œä¸ºã€‚\n# 2ï¼ŒCollection\nåœ¨ Java ä¸­ï¼ŒCollection æ¥å£æ˜¯ä¸€ä¸ªé›†åˆæ¡†æ¶çš„æ ¹æ¥å£ï¼Œå®ƒå®šä¹‰äº†ä¸€ç»„é€šç”¨çš„é›†åˆæ“ä½œæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºå¤„ç†å„ç§ç±»å‹çš„é›†åˆã€‚Collection æ¥å£æä¾›äº†ä¸€äº›å¸¸ç”¨çš„æ–¹æ³•ï¼Œå¦‚æ·»åŠ å…ƒç´ ã€åˆ é™¤å…ƒç´ ã€æ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨ã€è¿­ä»£é›†åˆä¸­çš„å…ƒç´ ç­‰ã€‚å®ƒæ˜¯ Java é›†åˆæ¡†æ¶ä¸­æœ€åŸºæœ¬çš„æ¥å£ï¼Œæ‰€æœ‰å…¶ä»–çš„é›†åˆæ¥å£éƒ½æ˜¯æ‰©å±•è‡ª Collection æ¥å£ã€‚\nCollection æ¥å£å®šä¹‰äº†å¦‚ä¸‹æ–¹æ³•ï¼ˆå¸¸ç”¨ã€ä¸å®Œå…¨ï¼‰ï¼š\n\n\nboolean add (E e): å°†å…ƒç´ æ·»åŠ åˆ°é›†åˆä¸­ï¼Œå¹¶è¿”å›æ˜¯å¦æ·»åŠ æˆåŠŸã€‚\nboolean addAll (Collection&lt;? extends E&gt; c): å°†æŒ‡å®šé›†åˆä¸­çš„æ‰€æœ‰å…ƒç´ æ·»åŠ åˆ°è¯¥é›†åˆä¸­ï¼Œå¹¶è¿”å›æ˜¯å¦æ·»åŠ æˆåŠŸã€‚\nboolean remove (Object o): ä»é›†åˆä¸­åˆ é™¤æŒ‡å®šå…ƒç´ ï¼Œå¹¶è¿”å›æ˜¯å¦åˆ é™¤æˆåŠŸã€‚\nvoid clear (): æ¸…ç©ºé›†åˆä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚\nboolean isEmpty (): æ£€æŸ¥é›†åˆæ˜¯å¦ä¸ºç©ºã€‚\nint size (): è¿”å›é›†åˆä¸­å…ƒç´ çš„æ•°é‡ã€‚\n\n\n# 3ï¼ŒList\nJava ä¸­çš„ List æ˜¯ä¸€ç§å¸¸è§çš„é›†åˆç±»ï¼Œç”¨äºå­˜å‚¨ä¸€ç»„å…ƒç´ ã€‚List æ˜¯ä¸€ä¸ªæ¥å£ï¼Œå®ƒæœ‰å¤šä¸ªå®ç°ç±»ï¼Œå¦‚ ArrayListã€LinkedList ç­‰ã€‚\nï¼é‡è¦ï¼\n\n\nå…è®¸å­˜å‚¨é‡å¤çš„å…ƒç´ ã€‚\n\n\nå…ƒç´ æŒ‰ç…§æ’å…¥é¡ºåºæœ‰åºå­˜å‚¨ã€‚\n\n\nå¯ä»¥é€šè¿‡ç´¢å¼•è®¿é—® List ä¸­çš„å…ƒç´ ï¼Œç´¢å¼•ä» 0 å¼€å§‹ã€‚\n\n\nList å¯ä»¥åŠ¨æ€è°ƒæ•´å¤§å°ï¼Œå³æ·»åŠ æˆ–åˆ é™¤å…ƒç´ ã€‚\næœ‰åºï¼Œå¯é‡å¤\n\n\n# 3.1 ArrayList\nList çš„å¸¸ç”¨æ–¹æ³•ï¼ˆå¯èƒ½ä¸å®Œå…¨ï¼‰ï¼šï¼ˆç±»ä¼¼æ•°ç»„ï¼‰\n\nadd (element)ï¼šå‘ List æœ«å°¾æ·»åŠ å…ƒç´ ã€‚\nadd (index, element)ï¼šåœ¨æŒ‡å®šç´¢å¼•ä½ç½®æ’å…¥å…ƒç´ ã€‚\nremove (index)ï¼šåˆ é™¤æŒ‡å®šç´¢å¼•ä½ç½®çš„å…ƒç´ ã€‚\nget (index)ï¼šè¿”å›æŒ‡å®šç´¢å¼•ä½ç½®çš„å…ƒç´ ã€‚\nset (index, element)ï¼šæ›¿æ¢æŒ‡å®šç´¢å¼•ä½ç½®çš„å…ƒç´ ã€‚\nsize ()ï¼šè¿”å› List çš„å¤§å°ã€‚\ncontains (element)ï¼šåˆ¤æ–­ List æ˜¯å¦åŒ…å«æŒ‡å®šå…ƒç´ ã€‚\nindexOf (element)ï¼šè¿”å›æŒ‡å®šå…ƒç´ åœ¨ List ä¸­ç¬¬ä¸€æ¬¡å‡ºç°çš„ç´¢å¼•ä½ç½®ã€‚\nclear ()ï¼šæ¸…ç©º List ä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚\n\nimport java.util.ArrayList;import java.util.List;public class ListExample &#123;    public static void main(String[] args) &#123;        List&lt;String> list = new ArrayList&lt;>();        list.add(\"apple\");        list.add(\"banana\");        list.add(\"orange\");        System.out.println(list); // è¾“å‡ºï¼š[apple, banana, orange]        list.remove(1);        System.out.println(list); // è¾“å‡ºï¼š[apple, orange]        String fruit = list.get(1);        System.out.println(fruit); // è¾“å‡ºï¼šorange        list.set(1, \"grape\");        System.out.println(list); // è¾“å‡ºï¼š[apple, grape]    &#125;&#125;ä»¥ä¸Šä»£ç ç”± [ChatGPT Mar 14 Version] ç”Ÿæˆã€‚\npackage edu.beihua.KarryCode.listEX001.test;import edu.beihua.KarryCode.listEX001.entity.news;import java.util.ArrayList;public class test_for_ArrayList &#123;    public static void main(String[] args) &#123;        /*        * add ()     ---- å¢åŠ å¯¹è±¡        * get ()     ---- è·å–å¯¹è±¡        * éæ³›å‹è¿”å› Object        * isEmpty () ---- åˆ¤ç©º        * clear ()   ---- æ¸…é™¤        * iterator ()---- è¿­ä»£å™¨        * toArray () ---- è½¬ä¸ºæ•°ç»„        * */        news newslkr = new news(1,\"timu1\",\"lkr\");        news newsffl = new news(2,\"timu2\",\"ffl\");        news newslqr = new news(3,\"timu3\",\"lqr\");        news imnews = new news(4,\"hexin\",\"!!!!!\");        ArrayList&lt;news> arrayList = new ArrayList&lt;news>();        arrayList.add(newslkr);                                     // æ™®é€šè¿½åŠ         arrayList.add(newsffl);        arrayList.add(newslqr);         arrayList.add(0,imnews);                              // æ ‡è®°è¿½åŠ         System.out.println(\"______________æ ‡é¢˜æ•°ç›®è¾“å‡º______________\");        System.out.println(\"æ–°é—»æœ‰\"+arrayList.size()+\"æ¡\");        System.out.println(\"______________æ ‡é¢˜è¾“å‡º______________\");        for (int i=0;i&lt;arrayList.size();i++)&#123;            System.out.println(arrayList.get(i).getTitle());          // ä¸é€‚ç”¨éæ³›å‹ï¼Œå¯ä»¥ä½¿ç”¨ï¼ˆObjectï¼‰å¼ºåˆ¶è½¬æ¢ï¼Œï¼ˆnewsï¼‰è¿›è¡ŒåŒ¹é…        &#125;        System.out.println(\"______________æ ‡é¢˜è¾“å‡º____________\");        for(Object obj:arrayList)&#123;                                  //** å¢å¼ºå½¢æ€çš„ For**            news newst = (news) obj;            System.out.println(newst.getTitle());        &#125;        System.out.println(\"______________æ ‡é¢˜è¾“å‡º____________\");        for(news news:arrayList)&#123;                                  //** å¢å¼ºå½¢æ€çš„ For**|| æœ€ç»ˆç‰ˆï¼šé¢å‘å¯¹è±¡            System.out.println(news.getTitle());        &#125;        System.out.println(\"________________æ ‡é¢˜åˆ¤æ–­__________\");        System.out.println(arrayList.contains(newslqr));        arrayList.remove(3);        System.out.println(\"______________æ ‡é¢˜è¾“å‡º____________\");        for(news news:arrayList)&#123;                                  //** å¢å¼ºå½¢æ€çš„ For**|| æœ€ç»ˆç‰ˆï¼šé¢å‘å¯¹è±¡            System.out.println(news.getTitle());        &#125;        System.out.println(\"______________æ ‡é¢˜åˆ¤æ–­__________\");        System.out.println(arrayList.contains(newslqr));        System.out.println(\"________________æ¸…ç©º_______________\");        arrayList.clear();        System.out.println(arrayList.isEmpty());    &#125;&#125;ä»¥ä¸Šä»£ç ä¸ºä¸Šè¯¾æ‰€å†™ï¼ˆä¸‘ä¸‘çš„ wwwï¼‰ã€‚\n# 3.2 LinkedList\nLinkedList å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n\néšæœºè®¿é—®å…ƒç´ æ•ˆç‡è¾ƒä½ï¼Œå› ä¸ºéœ€è¦éå†é“¾è¡¨ã€‚\nåœ¨é“¾è¡¨çš„å¼€å¤´æˆ–ç»“å°¾æ’å…¥ã€åˆ é™¤å…ƒç´ çš„æ•ˆç‡è¾ƒé«˜ã€‚\nå ç”¨çš„å†…å­˜ç©ºé—´ç›¸å¯¹è¾ƒå°ã€‚\n\næœ‰è¶£çš„æ–¹æ³•ï¼š\n\n\ngetFirst ()ï¼šè¿”å›é“¾è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ ã€‚\ngetLast ()ï¼šè¿”å›é“¾è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ ã€‚\nremoveFirst ()ï¼šåˆ é™¤é“¾è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ ã€‚\nremoveLast ()ï¼šåˆ é™¤é“¾è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ ã€‚\n\n\nimport java.util.LinkedList;import java.util.List;public class LinkedListExample &#123;    public static void main(String[] args) &#123;        List&lt;String> list = new LinkedList&lt;>();        list.add(\"apple\");        list.add(\"banana\");        list.add(\"orange\");        System.out.println(list); // è¾“å‡ºï¼š[apple, banana, orange]        list.remove(1);        System.out.println(list); // è¾“å‡ºï¼š[apple, orange]        String fruit = list.get(1);        System.out.println(fruit); // è¾“å‡ºï¼šorange        list.set(1, \"grape\");        System.out.println(list); // è¾“å‡ºï¼š[apple, grape]    &#125;&#125;ä»¥ä¸Šä»£ç ç”± [ChatGPT Mar 14 Version] ç”Ÿæˆã€‚\npackage edu.beihua.KarryCode.listEX001.test;import edu.beihua.KarryCode.listEX001.entity.news;import java.util.Iterator;import java.util.LinkedList;public class test_for_LinkList &#123;    public static void main(String[] args) &#123;        news newslkr = new news(1,\"timu1\",\"lkr\");        news newsffl = new news(2,\"timu2\",\"ffl\");        news newslqr = new news(3,\"timu3\",\"lqr\");        news imnews = new news(4,\"hexin\",\"!!!!!\");        LinkedList list = new LinkedList();         // çˆ¶çˆ¶ new å­è¿™ç§åªèƒ½ä½¿ç”¨çˆ¶å­å…¬ç”¨çš„æ–¹æ³•        list.add(newslkr);                                     // æ™®é€šè¿½åŠ         list.add(newsffl);        list.add(newslqr);        list.remove(0);        list.add(0,imnews);        System.out.println(\"______________å†…å®¹è¾“å‡º____________\");        for(Object obj:list)&#123;            news s = (news) obj;            System.out.println(s.getTitle());        &#125;        news tyu = (news)list.getFirst();        System.out.println(tyu.getNo());        news imnews666 = new news(10,\"hexin66666\",\"!!66666!!!\");        list.addFirst(imnews666);        System.out.println(\"______________å†…å®¹è¾“å‡º____________\");        for(Object obj:list)&#123;            news s = (news) obj;            System.out.println(s.getTitle());        &#125;        news re = (news)list.removeLast();        System.out.println(re.getData());        System.out.println(list.size());        Iterator iterator = list.iterator();        System.out.println(\"_________________________\");        while (iterator.hasNext())&#123;            news news = (news) iterator.next();            System.out.println(news.getTitle());        &#125;    &#125;&#125;# 4ï¼ŒSet\nåœ¨ Java ä¸­ï¼ŒSet æ˜¯ä¸€ç§é›†åˆï¼ˆCollectionï¼‰ç±»å‹ï¼Œå®ƒæ˜¯ä¸€ç»„ä¸å…è®¸åŒ…å«é‡å¤å…ƒç´ çš„å¯¹è±¡ã€‚Set æ˜¯é€šè¿‡å“ˆå¸Œè¡¨ï¼ˆhash tableï¼‰å®ç°çš„ï¼Œå› æ­¤å®ƒæ²¡æœ‰é¡ºåºï¼Œä¹Ÿä¸èƒ½é€šè¿‡ç´¢å¼•è®¿é—®å…¶ä¸­çš„å…ƒç´ ã€‚Set æ¥å£ç»§æ‰¿è‡ª Collection æ¥å£ï¼Œå¹¶æ·»åŠ äº†ä¸€äº›ç‹¬æœ‰çš„æ–¹æ³•ã€‚\næ— åºï¼Œå”¯ä¸€\nJava ä¸­å¸¸ç”¨çš„ Set ç±»æœ‰ä»¥ä¸‹å‡ ç§ï¼š\n\nHashSetï¼šåŸºäºå“ˆå¸Œè¡¨å®ç°ï¼Œå…·æœ‰è‰¯å¥½çš„æ’å…¥å’ŒæŸ¥è¯¢æ€§èƒ½ï¼Œä½†ä¸ä¿è¯å…ƒç´ çš„é¡ºåºã€‚\nTreeSetï¼šåŸºäºçº¢é»‘æ ‘å®ç°ï¼Œå…ƒç´ æŒ‰ç…§è‡ªç„¶é¡ºåºæ’åºæˆ–æŒ‡å®šçš„ Comparator é¡ºåºæ’åºã€‚\nLinkedHashSetï¼šåŸºäºå“ˆå¸Œè¡¨å’Œé“¾è¡¨å®ç°ï¼Œä¿è¯å…ƒç´ æŒ‰ç…§æ’å…¥é¡ºåºæ’åˆ—ã€‚\n\nSet çš„å¸¸ç”¨æ–¹æ³•åŒ…æ‹¬ï¼š\n\nadd (element)ï¼šå‘é›†åˆä¸­æ·»åŠ å…ƒç´ ã€‚\nremove (element)ï¼šä»é›†åˆä¸­åˆ é™¤æŒ‡å®šå…ƒç´ ã€‚\ncontains (element)ï¼šåˆ¤æ–­é›†åˆä¸­æ˜¯å¦åŒ…å«æŒ‡å®šå…ƒç´ ã€‚\nsize ()ï¼šè¿”å›é›†åˆä¸­å…ƒç´ çš„æ•°é‡ã€‚\nisEmpty ()ï¼šåˆ¤æ–­é›†åˆæ˜¯å¦ä¸ºç©ºã€‚\nclear ()ï¼šæ¸…ç©ºé›†åˆä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚\n\nä¾‹å¦‚ï¼Œä»¥ä¸‹æ˜¯ä½¿ç”¨ HashSet å’Œ TreeSet å®ç°çš„ Set çš„ç¤ºä¾‹ï¼š\nimport java.util.HashSet;\nimport java.util.Set;\nimport java.util.TreeSet;\n\npublic class SetExample &#123;\n    public static void main(String[] args) &#123;\n        Set&lt;String&gt; hashSet = new HashSet&lt;&gt;();\n        hashSet.add(&quot;apple&quot;);\n        hashSet.add(&quot;banana&quot;);\n        hashSet.add(&quot;orange&quot;);\n\n        System.out.println(hashSet); // è¾“å‡ºï¼š[orange, banana, apple]\n\n        hashSet.remove(&quot;banana&quot;);\n        System.out.println(hashSet); // è¾“å‡ºï¼š[orange, apple]\n\n        System.out.println(hashSet.contains(&quot;orange&quot;)); // è¾“å‡ºï¼štrue\n\n        Set&lt;String&gt; treeSet = new TreeSet&lt;&gt;();\n        treeSet.add(&quot;apple&quot;);\n        treeSet.add(&quot;banana&quot;);\n        treeSet.add(&quot;orange&quot;);\n\n        System.out.println(treeSet); // è¾“å‡ºï¼š[apple, banana, orange]\n\n        treeSet.remove(&quot;banana&quot;);\n        System.out.println(treeSet); // è¾“å‡ºï¼š[apple, orange]\n\n        System.out.println(treeSet.contains(&quot;orange&quot;)); // è¾“å‡ºï¼štrue\n    &#125;\n&#125;\n\n\nä»¥ä¸Šä»£ç ç”± [ChatGPT Mar 14 Version] ç”Ÿæˆã€‚\n# 4.1 HashSet\nåœ¨ Java ä¸­ï¼ŒHashSet æ˜¯ä¸€ç§åŸºäºå“ˆå¸Œè¡¨å®ç°çš„ Set é›†åˆï¼Œå®ƒä¸ä¿è¯å…ƒç´ çš„é¡ºåºï¼Œä½†æ˜¯å¯ä»¥å¿«é€Ÿåœ°æ’å…¥å’ŒæŸ¥æ‰¾å…ƒç´ ã€‚HashSet ä½¿ç”¨å“ˆå¸Œå‡½æ•°å°†å…ƒç´ æ˜ å°„åˆ°å“ˆå¸Œè¡¨ä¸­çš„æ¡¶ï¼ˆbucketï¼‰ä¸­ï¼Œæ¡¶æ˜¯ä¸€ä¸ªé“¾è¡¨æˆ–æ ‘ç»“æ„ï¼Œç”¨äºè§£å†³å“ˆå¸Œå†²çªï¼ˆå³ä¸åŒå…ƒç´ æ˜ å°„åˆ°åŒä¸€ä¸ªæ¡¶ä¸­çš„æƒ…å†µï¼‰ã€‚\nHashSet çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š\n\nä¸ä¿è¯å…ƒç´ çš„é¡ºåºã€‚\nä¸å…è®¸é›†åˆä¸­å­˜åœ¨é‡å¤å…ƒç´ ã€‚\nå…è®¸ null å…ƒç´ ã€‚\n\npackage edu.beihua.KarryCode.listEX001.test;import edu.beihua.KarryCode.listEX001.entity.news;import java.util.HashSet;import java.util.Iterator;import java.util.Objects;import java.util.Set;public class test_foe_HashSet &#123;    public static void main(String[] args) &#123;        /*        * æ— è®ºä»€ä¹ˆ List è¿˜æ˜¯ Set å‡ä¸º Cll... çš„ç»§æ‰¿ç±»ï¼Œå…¶å‡å…·æœ‰çˆ¶ç±»çš„æ–¹æ³•        * Set ä¸­å­˜æ”¾çš„æ˜¯å¯¹è±¡çš„å¼•ç”¨ï¼Œç›¸åŒçš„å¼•ç”¨æ˜¯äº’æ–¥çš„åªèƒ½æ·»åŠ ä¸€æ¬¡        * equals () æ–¹æ³•å¯ä»¥è¢«é‡å†™        * Set æ˜¯æ— åºçš„ï¼Œä¸å­˜åœ¨ Functionï¼ˆindexï¼ŒXXXï¼‰ç±»ä¼¼å¦‚æ­¤çš„æœ‰åºå·çš„çš„æ–¹æ³•ï¼Œä¸”åªèƒ½ä½¿ç”¨å¢å¼ºå‹çš„ for è¿›è¡Œå¾ªç¯è¾“å‡º */        Set set = new HashSet();        news newslkr = new news(1,\"timu1\",\"lkr\");        news newsffl = new news(2,\"timu2\",\"ffl\");        news newslqr = new news(3,\"timu3\",\"lqr\");        set.add(newslkr);                                     // æ™®é€šè¿½åŠ         set.add(newsffl);        set.add(newslqr);        for(Object obj:set)&#123;            news test = (news) obj;            System.out.println(test.getData());        &#125;        Iterator iterator = set.iterator();        while (iterator.hasNext())&#123;            news test = (news) iterator.next();            System.out.println(test.getData());        &#125;    &#125;&#125;# 5ï¼ŒIterator è¿­ä»£å™¨\nåœ¨ Java ä¸­ï¼ŒIterator æ˜¯ä¸€ä¸ªç”¨äºéå†é›†åˆï¼ˆCollectionï¼‰å…ƒç´ çš„æ¥å£ï¼Œå®ƒæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„è®¿é—®é›†åˆä¸­å…ƒç´ çš„æ–¹å¼ã€‚é€šè¿‡ Iteratorï¼Œæˆ‘ä»¬å¯ä»¥éå†é›†åˆä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œè€Œä¸éœ€è¦çŸ¥é“é›†åˆçš„å…·ä½“å®ç°æ–¹å¼ã€‚\nIterator æ¥å£åŒ…å«äº†ä»¥ä¸‹æ–¹æ³•ï¼š\n\nhasNext ()ï¼šåˆ¤æ–­é›†åˆä¸­æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€ä¸ªå…ƒç´ ã€‚\nnext ()ï¼šè¿”å›é›†åˆä¸­çš„ä¸‹ä¸€ä¸ªå…ƒç´ ã€‚\nremove ()ï¼šä»é›†åˆä¸­ç§»é™¤é€šè¿‡ next () æ–¹æ³•è¿”å›çš„æœ€åä¸€ä¸ªå…ƒç´ ã€‚\n\nIterator çš„å·¥ä½œåŸç†æ˜¯ï¼Œé¦–å…ˆé€šè¿‡é›†åˆçš„ iterator () æ–¹æ³•è·å¾—ä¸€ä¸ª Iterator å¯¹è±¡ï¼Œç„¶åä½¿ç”¨ hasNext () å’Œ next () æ–¹æ³•éå†é›†åˆä¸­çš„å…ƒç´ ï¼Œæœ€åä½¿ç”¨ remove () æ–¹æ³•ä»é›†åˆä¸­ç§»é™¤å…ƒç´ ã€‚\nåœ¨ 4.1HashSet ä¸­ç”¨åˆ°äº†æœ¬è¿­ä»£å™¨ï¼Œä»¥ä¸‹ä¸ºå…³é”®è¯­å¥ï¼š\nIterator iterator = set.iterator();        while (iterator.hasNext())&#123;            news test = (news) iterator.next();            System.out.println(test.getData());        &#125;","categories":["javaé«˜çº§ç‰¹æ€§"],"tags":["java"]},{"title":"MongoDBåˆæ­¥ä½¿ç”¨","url":"/MongoDB/MongoDB02/","content":"# MongoDB å‘½ä»¤\n# åˆ›å»ºç”¨æˆ·ï¼ˆå¯è¯»å¯å†™ï¼‰\n# åˆ›å»º\ndb.createUser(&#123;user:\"lkr40\",pwd:\"123456\",roles:[\"readWrite\"]&#125;)# æ£€éªŒ\ndb.auth(\"lkr40\",\"123456\")\ndb.createUser({user:â€œlkr40â€,pwd:â€œ123456â€,roles:[â€œreadWriteâ€]})\nSuccessfully added user: { â€œuserâ€ : â€œlkr40â€, â€œrolesâ€ : [ â€œreadWriteâ€ ] }\ndb.auth(â€œlkr40â€,â€œ123456â€)\n1\n\n# ç™»å½•\nmongo 127.0.0.1:27017/mymongo -u lkr40 -p 123456# å»ºç«‹ / ä½¿ç”¨æ•°æ®åº“\nuse mymongo\nuse mymongo\nswitched to db mymongo\n\n# æŸ¥è¯¢å½“å‰æ•°æ®åº“\ndb\ndb\nmymongo\n\n# åˆ é™¤æ•°æ®åº“\ndb.dropDatabase()# æŸ¥è¯¢æ—¶é—´\nDate()\nDate()\nWed Sep 06 2023 10:21:36 GMT+0800\n\n# åˆ›å»ºé›†åˆ\né›†åˆä¸­å¯ä»¥åŒ…å«å­é›†åˆ\n# æ˜¾å¼åˆ›å»ºï¼ˆtï¼‰\ndb.createCollection(\"t\")\ndb.createCollection(â€œtâ€)\n\n# éšå¼åˆ›å»ºï¼ˆt1ï¼‰\ndb.t1.insert(&#123;&quot;age&quot;:18&#125;)\n\n\ndb.t1.insert({â€œageâ€:18})\nWriteResult({ â€œnInsertedâ€ : 1 })\nshow collections\nt\nt1\n\n# å±•ç¤ºé›†åˆ\nshow collections\nshow collections\nt\nt1\n\n# åˆ é™¤é›†åˆ\ndb.t.drop()\ndb.t.drop()\ntrue\n\n# æŸ¥è¯¢æ–‡æ¡£\ndb.t1.find()\ndb.t1.find()\n\n# æ¡ä»¶æŸ¥è¯¢\n# ç­‰äº\ndb.t.find(&#123;&quot;x&quot;:1&#125;)\n\n\ndb.t.find({â€œxâ€:1})\n\n# å°äº\ndb.t.find(&#123;\"x\":&#123;$lte : 5&#125;&#125;)# å¤§äº\ndb.t.find(&#123;\"x\":&#123;$lte : 5&#125;&#125;)# åœ¨ä¹‹ä¸­ï¼ˆåŒ…å«ï¼‰\ndb.t.find(&#123;\"x\":&#123;$in : [1,3,5]&#125;&#125;)# ä¸åœ¨å…¶ä¸­ï¼ˆä¸åŒ…å«ï¼‰\ndb.t.find(&#123;\"x\":&#123;$nin : [1,3,5]&#125;&#125;)# æ’å…¥æ–‡æ¡£\n# å•ä¸€æ’å…¥\ndb.t1.insert(&#123;\"_id\":\"1\",\"age\":23&#125;)\ndb.t1.insert({&quot;_id&quot;:â€œ1â€,â€œageâ€:23})\nWriteResult({ â€œnInsertedâ€ : 1 })\ndb.t1.find()\n\n\n# æ‰¹é‡æ’å…¥ï¼ˆå•è¯­å¥ï¼‰\ndb.t1.insertMany([&#123;\"_id\":2,\"age\":65&#125;,&#123;\"_id\":3,\"age\":45&#125;])\ndb.t1.insertMany([{&quot;_id&quot;:2,â€œageâ€:65},{&quot;_id&quot;:3,â€œageâ€:45}])\n{ â€œacknowledgedâ€ : true, â€œinsertedIdsâ€ : [ 2, 3 ] }\ndb.t1.find()\n{ â€œ_idâ€ : ObjectId(â€œ64f7ec7bff2142d2a2445360â€), â€œageâ€ : 18 }\n{ â€œ_idâ€ : â€œ1â€, â€œageâ€ : 33 }\n\n\n# å¾ªç¯æ’å…¥ï¼ˆforï¼‰\nfor(i=1;i&lt;9;i++) db.t.insert(&#123;\"x\":i&#125;)\nfor(i=1;i&lt;9;i++) db.t.insert({â€œxâ€:i})\nWriteResult({ â€œnInsertedâ€ : 1 })\ndb.t.find()\n{ â€œ_idâ€ : ObjectId(â€œ64f7f05bff2142d2a2445361â€), â€œxâ€ : 1 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f05cff2142d2a2445362â€), â€œxâ€ : 2 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f05cff2142d2a2445363â€), â€œxâ€ : 3 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f05cff2142d2a2445364â€), â€œxâ€ : 4 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f05cff2142d2a2445365â€), â€œxâ€ : 5 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f05cff2142d2a2445366â€), â€œxâ€ : 6 }\n\n\n# åŒ id æ’å…¥å¼‚å¸¸\n\ndb.t1.insert({&quot;_id&quot;:â€œ1â€,â€œageâ€:23})\nWriteResult({\nâ€œnInsertedâ€ : 0,\nâ€œwriteErrorâ€ : {\nâ€œcodeâ€ : 11000,\nâ€œerrmsgâ€ : â€œE11000 duplicate key error collection: mymongo.t1 index: id dup key: { _id: â€œ1â€ }â€\n}\n})\n\n# ä¿®æ”¹ï¼ˆè¾“å…¥å…¨éƒ¨å±æ€§ / æ›¿æ¢ï¼‰\ndb.t1.save(&#123;\"_id\":\"1\",\"age\":33&#125;)\ndb.t1.save({&quot;_id&quot;:â€œ1â€,â€œageâ€:33})\nWriteResult({ â€œnMatchedâ€ : 1, â€œnUpsertedâ€ : 0, â€œnModifiedâ€ : 1 })\ndb.t1.find()\n\n\n# æ›´æ–°\ndb.t1.update(&#123;\"age\":65&#125;,&#123;$set:&#123;\"age\":100&#125;&#125;)\ndb.t1.update({â€œageâ€:65},{$set:{â€œageâ€:100}})\nWriteResult({ â€œnMatchedâ€ : 1, â€œnUpsertedâ€ : 0, â€œnModifiedâ€ : 1 })\ndb.t1.find()\n{ â€œ_idâ€ : ObjectId(â€œ64f7ec7bff2142d2a2445360â€), â€œageâ€ : 18 }\n{ â€œ_idâ€ : â€œ1â€, â€œageâ€ : 33 }\n\n\n# åˆ é™¤\n# æ‰¹é‡åˆ é™¤\ndb.t1.remove(&#123;\"age\":33&#125;)\ndb.t1.remove({â€œageâ€:33})\nWriteResult({ â€œnRemovedâ€ : 1 })\ndb.t1.find()\n{ â€œ_idâ€ : ObjectId(â€œ64f7ec7bff2142d2a2445360â€), â€œageâ€ : 18 }\n\n\n# å•ä¸€åˆ é™¤\ndb.t1.remove(&#123;\"age\":45&#125;,&#123;justOne:1&#125;)\ndb.t1.remove({â€œageâ€:45},{justOne:1})\nWriteResult({ â€œnRemovedâ€ : 1 })\ndb.t1.find()\n{ â€œ_idâ€ : ObjectId(â€œ64f7ec7bff2142d2a2445360â€), â€œageâ€ : 18 }\n{ â€œ_idâ€ : 2, â€œageâ€ : 100 }\n\n\n# Capped é™åˆ¶\n# åˆ›å»ºé™åˆ¶\ndb.createCollection(\"t2\",&#123;capped:true,size:3,max:8&#125;)db.t2.isCapped()# æ£€éªŒ\nfor(i=1;i&lt;9;i++) db.t2.insert(&#123;\"x\":i&#125;)\ndb.t2.find();\n{ â€œ_idâ€ : ObjectId(â€œ64f7f23fff2142d2a244536aâ€), â€œxâ€ : 2 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f23fff2142d2a244536bâ€), â€œxâ€ : 3 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f23fff2142d2a244536câ€), â€œxâ€ : 4 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f23fff2142d2a244536dâ€), â€œxâ€ : 5 }\n{ â€œ_idâ€ : ObjectId(â€œ64f7f23fff2142d2a244536eâ€), â€œxâ€ : 6 }\n\n\n# ç»“è®º\nå‰é¢çš„æ•°æ®è¢«é¡¶æ‰äº†\n# pretty ç¾åŒ–è¾“å‡º\ndb.t3.insert(&#123;\"_id\":1,\"phone\":&#123;\"hemophone\":\"8617118\",\"mobilephone\":\"18643079329\"&#125;&#125;)\ndb.t3.find().pretty();\n{\nâ€œ_idâ€ : 1,\nâ€œphoneâ€ : {\nâ€œhemophoneâ€ : â€œ8617118â€,\nâ€œmobilephoneâ€ : â€œ18643079329â€\n}\n}\n\n# ç®¡é“æœºåˆ¶\n\n","categories":["MongoDB"],"tags":["MongoDB"]},{"title":"MongoDBåˆæ­¥ä½¿ç”¨","url":"/MongoDB/MongoDB03/","content":"# MongoDB çº¦æŸå‘½ä»¤\n# è¾“å‡ºè¡Œæ•°é™åˆ¶\ndb.t4.aggregate(&#123;$limit:4&#125;)# xx å‡åº / é™åº\ndb.t4.aggregate([&#123;$sort:&#123;price:-1&#125;&#125;])1ï¼šå‡åº\n2ï¼šé™åº\n# MapReduce\nMapReduce æ˜¯ä¸€ç§ç”¨äºåˆ†å¸ƒå¼è®¡ç®—çš„ç¼–ç¨‹æ¨¡å‹å’Œå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†çš„æ–¹æ³•ã€‚\nMapReduce æ¨¡å‹çš„åŸºæœ¬æ€æƒ³æ˜¯å°†å¤§è§„æ¨¡æ•°æ®é›†åˆ†æˆå°å—ï¼Œç„¶åå¹¶è¡Œå¤„ç†è¿™äº›å°å—æ•°æ®ä»¥ç”Ÿæˆä¸­é—´ç»“æœã€‚\n\nMap é˜¶æ®µï¼ˆæ˜ å°„é˜¶æ®µï¼‰ï¼šåœ¨è¿™ä¸ªé˜¶æ®µï¼ŒåŸå§‹æ•°æ®è¢«æ˜ å°„æˆé”® - å€¼å¯¹çš„å½¢å¼ã€‚æ¯ä¸ªæ˜ å°„æ“ä½œéƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œå¯ä»¥åœ¨ä¸åŒçš„è®¡ç®—èŠ‚ç‚¹ä¸Šå¹¶è¡Œæ‰§è¡Œã€‚Map æ“ä½œé€šå¸¸ç”¨äºç­›é€‰ã€è¿‡æ»¤ã€æ’åºå’Œè½¬æ¢æ•°æ®ã€‚\nReduce é˜¶æ®µï¼ˆå½’çº¦é˜¶æ®µï¼‰ï¼šåœ¨ Map é˜¶æ®µä¹‹åï¼Œæ‰€æœ‰çš„ä¸­é—´ç»“æœæŒ‰é”®åˆ†ç»„ï¼Œå¹¶å°†æ¯ä¸ªç»„çš„æ•°æ®ä¼ é€’ç»™ Reduce å‡½æ•°è¿›è¡Œèšåˆå’Œå¤„ç†ã€‚Reduce æ“ä½œé€šå¸¸ç”¨äºå¯¹æ•°æ®è¿›è¡Œæ±‡æ€»ã€è®¡æ•°ã€è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ç­‰æ“ä½œã€‚\n\n//MapReduce//mapæ˜ å°„var map = function()&#123;    emit(this.type,this.name);&#125;//reduceå‡å°‘å¹¶ä»¥â€œï¼Œâ€åˆ†å‰²var reduce = function(key,values)&#123;    return values.join(',');&#125;//é€‰é¡¹è®¾ç½®è¾“å‡ºvar opt=&#123;out:\"name_list\"&#125;db.t4.mapReduce(map,reduce,opt)\n[\n{\nâ€œ_idâ€: â€œç”µå­è®¾å¤‡â€,\nâ€œvalueâ€: â€œlogiâ€\n},\n{\nâ€œ_idâ€: â€œæœè£…â€,\nâ€œvalueâ€: â€œå®‰è¸ï¼Œliningâ€\n},\n{\nâ€œ_idâ€: â€œç”µå­é€šä¿¡â€,\nâ€œvalueâ€: â€œoppo,vivo,huawei,iphone8â€\n},\n{\nâ€œ_idâ€: â€œé¥®å“â€,\nâ€œvalueâ€: â€œåº·å¸ˆå‚…â€\n}\n]\n\n","categories":["MongoDB"],"tags":["MongoDB"]},{"title":"æ“ä½œç³»ç»ŸçŸ¥è¯†ç‚¹é˜¶æ®µæ€»ç»“","url":"/Operate-system/01OS/","content":"# å¼•è®º\n# æ“ä½œç³»ç»Ÿæ˜¯ä»€ä¹ˆï¼Ÿ\næ“ä½œç³»ç»Ÿæ˜¯è®¡ç®—æœºç³»ç»Ÿä¸­çš„æ ¸å¿ƒè½¯ä»¶ä¹‹ä¸€ï¼Œå®ƒæ˜¯ä½äºç¡¬ä»¶å’Œåº”ç”¨ç¨‹åºä¹‹é—´çš„ä¸€å±‚è½¯ä»¶ï¼Œè´Ÿè´£ç®¡ç†å’Œæ§åˆ¶è®¡ç®—æœºçš„ç¡¬ä»¶èµ„æºï¼Œå¹¶ä¸ºåº”ç”¨ç¨‹åºæä¾›ä¸€ä¸ªè¿è¡Œç¯å¢ƒã€‚æ“ä½œç³»ç»Ÿå……å½“è®¡ç®—æœºç³»ç»Ÿçš„ç®¡ç†è€…ï¼Œåè°ƒå„ç§ç¡¬ä»¶å’Œè½¯ä»¶èµ„æºçš„åˆ†é…å’Œè°ƒåº¦ï¼Œä»¥ä½¿è®¡ç®—æœºèƒ½å¤Ÿé«˜æ•ˆã€å¯é åœ°è¿è¡Œã€‚\n# ä¸ºä»€ä¹ˆè¦æ“ä½œç³»ç»Ÿï¼Ÿ\næ“ä½œç³»ç»Ÿçš„å­˜åœ¨æ˜¯ä¸ºäº†è§£å†³è®¡ç®—æœºèµ„æºç®¡ç†å’Œç”¨æˆ·ç¨‹åºæ‰§è¡Œçš„å¤æ‚æ€§ã€‚å®ƒæä¾›äº†ä¸€ç§æŠ½è±¡å±‚ï¼Œä½¿åº”ç”¨ç¨‹åºå¼€å‘äººå‘˜ä¸å¿…ç›´æ¥ä¸åº•å±‚ç¡¬ä»¶è¿›è¡Œäº¤äº’ï¼Œä»è€Œç®€åŒ–äº†åº”ç”¨ç¨‹åºçš„å¼€å‘å’Œç»´æŠ¤ã€‚æ­¤å¤–ï¼Œæ“ä½œç³»ç»Ÿè¿˜è´Ÿè´£å¤„ç†å¤šä»»åŠ¡ç®¡ç†ã€å†…å­˜ç®¡ç†ã€æ–‡ä»¶ç³»ç»Ÿç®¡ç†ã€ç”¨æˆ·æ¥å£ç­‰ï¼Œä¸ºç”¨æˆ·å’Œåº”ç”¨ç¨‹åºæä¾›äº†ä¸€ä¸ªå‹å¥½ä¸”é«˜æ•ˆçš„è®¡ç®—ç¯å¢ƒã€‚\n# æ“ä½œç³»ç»Ÿçš„ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿ\næ“ä½œç³»ç»Ÿå…·æœ‰ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç‰¹å¾ï¼š\n\n\nå¹¶å‘ï¼ˆConcurrencyï¼‰ï¼š èƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡æˆ–ç¨‹åºï¼Œä½¿å¤šä¸ªç¨‹åºå¯ä»¥åœ¨åŒä¸€å°è®¡ç®—æœºä¸Šäº¤æ›¿æ‰§è¡Œã€‚\nï¼ˆå¹¶å‘ï¼šåŒä¸€æ—¶é—´æ®µ å¹¶è¡Œï¼šåŒä¸€æ—¶åˆ»ï¼‰\n\n\nå…±äº«ï¼ˆSharingï¼‰ï¼š å¤šä¸ªç”¨æˆ·å’Œåº”ç”¨ç¨‹åºå¯ä»¥åŒæ—¶è®¿é—®è®¡ç®—æœºçš„èµ„æºï¼Œå¦‚å†…å­˜ã€å¤„ç†å™¨ã€æ–‡ä»¶ç­‰ã€‚\næ“ä½œç³»ç»Ÿçš„æœ€åŸºæœ¬ç‰¹å¾ï¼šå¹¶å‘ä¸å…±äº«\n\n\nè™šæ‹Ÿï¼ˆVirtualizationï¼‰ï¼š æ“ä½œç³»ç»Ÿå¯ä»¥ä¸ºæ¯ä¸ªåº”ç”¨ç¨‹åºæä¾›ä¸€ç§è™šæ‹Ÿçš„ç¯å¢ƒï¼Œä½¿å…¶æ„Ÿè§‰è‡ªå·±ç‹¬å äº†è®¡ç®—æœºèµ„æºã€‚\n\n\nå¼‚æ­¥ï¼ˆasynchronousï¼‰ï¼š å¼‚æ­¥ç‰¹æ€§æŒ‡çš„æ˜¯æ“ä½œç³»ç»Ÿå…è®¸æŸäº›ä»»åŠ¡åœ¨è¿›è¡Œçš„è¿‡ç¨‹ä¸­ï¼Œä¸å¿…ç­‰å¾…å‰ä¸€ä¸ªä»»åŠ¡çš„å®Œæˆï¼Œè€Œå¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡ã€‚ï¼ˆå­˜åœ¨ä¸ç¡®å®šæ€§ï¼‰\nâœ”ï¸æ“ä½œç³»ç»Ÿçš„åŸºæœ¬ç‰¹å¾ï¼šå¹¶å‘ã€å…±äº«ã€è™šæ‹Ÿã€å¼‚æ­¥\n\n\næŠ½è±¡ï¼ˆAbstractionï¼‰ï¼š æ“ä½œç³»ç»Ÿé€šè¿‡æŠ½è±¡åŒ–ç¡¬ä»¶å’Œè½¯ä»¶èµ„æºï¼Œä¸ºåº”ç”¨ç¨‹åºæä¾›ä¸€ä¸ªæ›´ç®€å•ã€ä¸€è‡´çš„ç¼–ç¨‹æ¥å£ã€‚\n\n\næŒä¹…æ€§ï¼ˆPersistenceï¼‰ï¼š æ•°æ®å’Œç¨‹åºå¯ä»¥è¢«å­˜å‚¨åœ¨æŒä¹…æ€§å­˜å‚¨è®¾å¤‡ä¸­ï¼Œå¹¶åœ¨è®¡ç®—æœºå…³é—­åä¿ç•™ä¸‹æ¥ã€‚\n\n\nå¤„ç†å™¨ç®¡ç†ï¼ˆProcessor Managementï¼‰ï¼š åˆ†é…å’Œç®¡ç†å¤„ç†å™¨çš„æ—¶é—´ç‰‡ï¼Œä»¥ä¾¿å¤šä¸ªä»»åŠ¡å¯ä»¥è½®æµæ‰§è¡Œã€‚\n\n\nå†…å­˜ç®¡ç†ï¼ˆMemory Managementï¼‰ï¼š ç®¡ç†è®¡ç®—æœºçš„å†…å­˜èµ„æºï¼ŒåŒ…æ‹¬åˆ†é…ã€é‡Šæ”¾ã€è™šæ‹Ÿå†…å­˜ç­‰ã€‚\n\n\næ–‡ä»¶ç³»ç»Ÿç®¡ç†ï¼ˆFile System Managementï¼‰ï¼š ç®¡ç†æ–‡ä»¶çš„å­˜å‚¨ã€ç»„ç»‡ã€æ£€ç´¢å’Œä¿æŠ¤ã€‚\n\n\nè®¾å¤‡ç®¡ç†ï¼ˆDevice Managementï¼‰ï¼š ç®¡ç†è¾“å…¥è¾“å‡ºè®¾å¤‡ï¼Œä½¿åº”ç”¨ç¨‹åºèƒ½å¤Ÿä¸è®¾å¤‡è¿›è¡Œäº¤äº’ã€‚\n\n\n# å®æ—¶æ“ä½œç³»ç»Ÿå’Œåˆ†æ—¶æ“ä½œç³»ç»Ÿï¼Ÿ\nå®æ—¶æ“ä½œç³»ç»Ÿï¼ˆReal-time Operating Systemï¼ŒRTOSï¼‰å’Œåˆ†æ—¶æ“ä½œç³»ç»Ÿï¼ˆTime-sharing Operating Systemï¼‰æ˜¯ä¸¤ç§ä¸åŒç±»å‹çš„æ“ä½œç³»ç»Ÿï¼Œç”¨äºæ»¡è¶³ä¸åŒåº”ç”¨åœºæ™¯ä¸‹çš„éœ€æ±‚ã€‚\n# å®æ—¶æ“ä½œç³»ç»Ÿï¼ˆRTOSï¼‰ï¼š\nå®æ—¶æ“ä½œç³»ç»Ÿæ˜¯ä¸“é—¨è®¾è®¡ç”¨äºå¤„ç†å®æ—¶ä»»åŠ¡çš„æ“ä½œç³»ç»Ÿã€‚å®æ—¶ä»»åŠ¡æ˜¯å…·æœ‰ä¸¥æ ¼æ—¶é—´è¦æ±‚çš„ä»»åŠ¡ï¼Œå¯ä»¥åˆ†ä¸ºç¡¬å®æ—¶å’Œè½¯å®æ—¶ä»»åŠ¡ã€‚ç¡¬å®æ—¶ä»»åŠ¡è¦æ±‚ä»»åŠ¡å¿…é¡»åœ¨ä¸¥æ ¼çš„æ—¶é—´é™åˆ¶å†…å®Œæˆï¼Œå¦åˆ™ä¼šå¯¼è‡´ç³»ç»Ÿé”™è¯¯ã€‚è½¯å®æ—¶ä»»åŠ¡ä¹Ÿæœ‰æ—¶é—´è¦æ±‚ï¼Œä½†å¯¹äºè¿™ç±»ä»»åŠ¡ï¼Œå¦‚æœé”™è¿‡äº†æˆªæ­¢æ—¥æœŸï¼Œç³»ç»Ÿä¸ä¼šå´©æºƒï¼Œä½†ä¼šå½±å“ä»»åŠ¡çš„ç»“æœçš„å®ç”¨æ€§ã€‚\nRTOS è‡´åŠ›äºç¡®ä¿ä»»åŠ¡èƒ½å¤ŸæŒ‰ç…§ç‰¹å®šçš„æ—¶é—´è¦æ±‚å¾—åˆ°æ‰§è¡Œã€‚å®ƒé€šå¸¸é‡‡ç”¨ä¼˜å…ˆçº§è°ƒåº¦ç­–ç•¥ï¼Œç¡®ä¿é«˜ä¼˜å…ˆçº§çš„å®æ—¶ä»»åŠ¡èƒ½å¤Ÿåœ¨é¢„å®šçš„æ—¶é—´å†…å¾—åˆ°æ‰§è¡Œã€‚\n# åˆ†æ—¶æ“ä½œç³»ç»Ÿï¼ˆTime-sharing Operating Systemï¼‰ï¼š\nåˆ†æ—¶æ“ä½œç³»ç»Ÿæ—¨åœ¨æ”¯æŒå¤šç”¨æˆ·çš„å…±äº«è®¡ç®—æœºç³»ç»Ÿã€‚å®ƒå…è®¸å¤šä¸ªç”¨æˆ·é€šè¿‡ç»ˆç«¯æˆ–å…¶ä»–ç”¨æˆ·ç•Œé¢åŒæ—¶è®¿é—®ç³»ç»Ÿï¼Œæ¯ä¸ªç”¨æˆ·ä¼¼ä¹éƒ½åœ¨ç‹¬å åœ°ä½¿ç”¨è®¡ç®—æœºèµ„æºã€‚åˆ†æ—¶æ“ä½œç³»ç»Ÿé€šè¿‡åˆ†é…æ—¶é—´ç‰‡ï¼ˆæ—¶é—´ç‰‡è½®è½¬ï¼‰æ¥åœ¨å¤šä¸ªä»»åŠ¡ä¹‹é—´åˆ‡æ¢ï¼Œæ¯ä¸ªä»»åŠ¡åœ¨æ—¶é—´ç‰‡ç»“æŸå‰éƒ½èƒ½å¾—åˆ°ä¸€æ®µæ—¶é—´çš„æ‰§è¡Œã€‚\nåˆ†æ—¶æ“ä½œç³»ç»Ÿçš„ç›®æ ‡æ˜¯å®ç°å¤šä»»åŠ¡çš„å¹¶å‘æ‰§è¡Œï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨å‡ ä¹åŒæ—¶ä½¿ç”¨è®¡ç®—æœºèµ„æºï¼Œè¿™æ ·å¯ä»¥æé«˜èµ„æºåˆ©ç”¨ç‡å’Œç”¨æˆ·ä½“éªŒã€‚\nåˆ†æ—¶æ“ä½œç³»ç»Ÿç‰¹å¾ï¼šå¤šè·¯æ€§ã€ç‹¬ç«‹æ€§ã€åŠæ—¶æ€§ã€äº¤äº’æ€§ã€‚è¯¦ç»†è§£é‡Šï¼šP10\n# å•é“æ‰¹å¤„ç†ç³»ç»Ÿå’Œå¤šé“æ‰¹å¤„ç†ç³»ç»Ÿï¼Ÿ\nå•é“æ‰¹å¤„ç†ç³»ç»Ÿï¼ˆSingle Batch Processing Systemï¼‰å’Œå¤šé“æ‰¹å¤„ç†ç³»ç»Ÿï¼ˆMulti-Batch Processing Systemï¼‰æ˜¯ä¸¤ç§ä¸åŒçš„æ“ä½œç³»ç»Ÿå·¥ä½œæ–¹å¼ï¼Œç”¨äºç®¡ç†å’Œæ‰§è¡Œè®¡ç®—æœºä¸­çš„å¤šä¸ªä»»åŠ¡ã€‚\n# å•é“æ‰¹å¤„ç†ç³»ç»Ÿï¼š\nå•é“æ‰¹å¤„ç†ç³»ç»Ÿæ˜¯æ—©æœŸè®¡ç®—æœºæ“ä½œç³»ç»Ÿçš„ä¸€ç§ã€‚åœ¨è¿™ç§ç³»ç»Ÿä¸­ï¼Œè®¡ç®—æœºåªèƒ½å¤„ç†ä¸€é“ç¨‹åºï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªä»»åŠ¡ï¼Œæ¯æ¬¡åªæœ‰ä¸€ä¸ªä»»åŠ¡åœ¨è¿è¡Œã€‚å½“ä¸€ä¸ªä»»åŠ¡æ‰§è¡Œå®Œæˆåï¼Œæ‰èƒ½åŠ è½½å¹¶æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚è¿™ç§ç³»ç»Ÿå¯¹äºç”¨æˆ·å’Œç¨‹åºå‘˜æ¥è¯´ï¼Œæ“ä½œä¸å¤Ÿçµæ´»ï¼Œå› ä¸ºä»–ä»¬å¿…é¡»ç­‰å¾…å½“å‰ä»»åŠ¡æ‰§è¡Œå®Œæˆæ‰èƒ½ç»§ç»­å·¥ä½œã€‚\nğŸ’”å•é“æ‰¹å¤„ç†ç³»ç»Ÿçš„ç¼ºç‚¹ï¼šç³»ç»Ÿä¸­çš„çš„èµ„æºå¾—ä¸åˆ°å……åˆ†åˆ©ç”¨ï¼\nâœï¸æ³¨æ„æ³¨æ„ï¼ï¼ï¼å•é“æ‰¹å¤„ç†ç³»ç»Ÿæ— å¹¶å‘ï¼Œä¸èƒ½ç§°ä¹‹ä¸º OSï¼ï¼ï¼\n# å¤šé“æ‰¹å¤„ç†ç³»ç»Ÿï¼š\nå¤šé“æ‰¹å¤„ç†ç³»ç»Ÿæ˜¯åœ¨å•é“æ‰¹å¤„ç†ç³»ç»Ÿçš„åŸºç¡€ä¸Šå‘å±•è€Œæ¥çš„ã€‚è¿™ç§ç³»ç»Ÿå…è®¸è®¡ç®—æœºåœ¨å†…å­˜ä¸­åŒæ—¶åŠ è½½å’Œç®¡ç†å¤šä¸ªä»»åŠ¡ï¼Œè€Œä¸éœ€è¦ç­‰å¾…å‰ä¸€ä¸ªä»»åŠ¡çš„å®Œæˆã€‚å¤šé“æ‰¹å¤„ç†ç³»ç»Ÿå°†å†…å­˜åˆ†å‰²æˆå¤šä¸ªåŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸå¯ä»¥åŠ è½½ä¸€ä¸ªä»»åŠ¡çš„ä»£ç å’Œæ•°æ®ã€‚æ“ä½œç³»ç»Ÿä¼šåœ¨ä»»åŠ¡ä¹‹é—´è¿›è¡Œåˆ‡æ¢ï¼Œä»¥å®ç°å¤šä¸ªä»»åŠ¡çš„å¹¶å‘æ‰§è¡Œã€‚è¿™ç§æ–¹å¼æé«˜äº†è®¡ç®—æœºçš„èµ„æºåˆ©ç”¨ç‡å’Œæ•ˆç‡ã€‚\n# OS çš„ç±»å‹ï¼Ÿ\n\nå¤šé“æ‰¹å¤„ç†ç³»ç»Ÿï¼ˆMulti-programming Batch Systemï¼‰ï¼š å¤šé“æ‰¹å¤„ç†ç³»ç»Ÿæ˜¯ä¸€ç§æ“ä½œç³»ç»Ÿï¼Œå…è®¸å¤šä¸ªä»»åŠ¡ï¼ˆä½œä¸šï¼‰åœ¨å†…å­˜ä¸­åŒæ—¶å­˜åœ¨ï¼Œä½†æ¯ä¸ªä»»åŠ¡çš„æ‰§è¡Œæ˜¯æŒ‰ç…§ä¸€å®šçš„è°ƒåº¦ç­–ç•¥è½®æµè¿›è¡Œçš„ã€‚å®ƒæ—¨åœ¨æé«˜è®¡ç®—æœºçš„èµ„æºåˆ©ç”¨ç‡ï¼Œé€šè¿‡åœ¨ä»»åŠ¡ä¹‹é—´åˆ‡æ¢ä»¥é¿å… CPU ç©ºé—²ã€‚æ¯ä¸ªä»»åŠ¡é€šå¸¸ç‹¬ç«‹è¿è¡Œï¼Œä¸éœ€è¦ç”¨æˆ·å¹²é¢„ã€‚è¿™ç§ç³»ç»Ÿé€‚ç”¨äºå¤§é‡ä»»åŠ¡éœ€è¦æ‰¹é‡å¤„ç†ï¼Œä¾‹å¦‚æ‰¹é‡æ•°æ®å¤„ç†ä»»åŠ¡ã€‚\nåˆ†æ—¶ç³»ç»Ÿï¼ˆTime-sharing Systemï¼‰ï¼š åˆ†æ—¶ç³»ç»Ÿå…è®¸å¤šä¸ªç”¨æˆ·é€šè¿‡ç»ˆç«¯æˆ–ç”¨æˆ·ç•Œé¢åŒæ—¶è®¿é—®è®¡ç®—æœºï¼Œæ¯ä¸ªç”¨æˆ·ä¼¼ä¹éƒ½åœ¨ç‹¬å åœ°ä½¿ç”¨è®¡ç®—æœºèµ„æºã€‚ç³»ç»Ÿé€šè¿‡å¿«é€Ÿçš„ä»»åŠ¡åˆ‡æ¢ï¼ˆæ—¶é—´ç‰‡è½®è½¬ï¼‰å®ç°ç”¨æˆ·ä¹‹é—´çš„å¹¶å‘æ‰§è¡Œï¼Œæ¯ä¸ªç”¨æˆ·èƒ½å¤Ÿè¿…é€Ÿäº¤äº’å¹¶ä½¿ç”¨è®¡ç®—æœºã€‚åˆ†æ—¶ç³»ç»Ÿé€‚ç”¨äºå¤šç”¨æˆ·ã€äº¤äº’å¼çš„ç¯å¢ƒï¼Œå¦‚å›¾å½¢ç”¨æˆ·ç•Œé¢å’Œç»ˆç«¯ã€‚\nå®æ—¶ç³»ç»Ÿï¼ˆReal-time Systemï¼‰ï¼š å®æ—¶ç³»ç»Ÿæ˜¯ä¸“é—¨è®¾è®¡ç”¨äºå¤„ç†å®æ—¶ä»»åŠ¡çš„æ“ä½œç³»ç»Ÿã€‚å®æ—¶ä»»åŠ¡å…·æœ‰ä¸¥æ ¼çš„æ—¶é—´è¦æ±‚ï¼Œå¯ä»¥åˆ†ä¸ºç¡¬å®æ—¶å’Œè½¯å®æ—¶ã€‚ç¡¬å®æ—¶ä»»åŠ¡è¦æ±‚ä»»åŠ¡å¿…é¡»åœ¨ä¸¥æ ¼çš„æ—¶é—´é™åˆ¶å†…å®Œæˆï¼Œå¦åˆ™ä¼šå¯¼è‡´ç³»ç»Ÿé”™è¯¯ã€‚è½¯å®æ—¶ä»»åŠ¡ä¹Ÿæœ‰æ—¶é—´è¦æ±‚ï¼Œä½†é”™è¿‡æˆªæ­¢æ—¥æœŸä¸ä¼šå¯¼è‡´ç³»ç»Ÿé”™è¯¯ã€‚å®æ—¶ç³»ç»Ÿæ—¨åœ¨ç¡®ä¿ä»»åŠ¡èƒ½å¤ŸæŒ‰ç…§ç‰¹å®šçš„æ—¶é—´è¦æ±‚å¾—åˆ°æ‰§è¡Œï¼Œé€‚ç”¨äºéœ€è¦åœ¨ä¸¥æ ¼æ—¶é—´çº¦æŸä¸‹è¿è¡Œçš„åº”ç”¨ï¼Œå¦‚é£è¡Œæ§åˆ¶ç³»ç»Ÿå’ŒåŒ»ç–—è®¾å¤‡ã€‚\n\n# æ“ä½œç³»ç»Ÿèƒ½å¹²ä»€ä¹ˆï¼Ÿ\næ“ä½œç³»ç»Ÿçš„ä¸»è¦ä»»åŠ¡åŒ…æ‹¬ï¼š\n\nç®¡ç†è®¡ç®—æœºçš„ç¡¬ä»¶èµ„æºï¼Œå¦‚å¤„ç†å™¨ã€å†…å­˜ã€ç¡¬ç›˜ã€ç½‘ç»œæ¥å£ç­‰ã€‚\næä¾›å¤šä»»åŠ¡ç®¡ç†ï¼Œä½¿å¤šä¸ªåº”ç”¨ç¨‹åºå¯ä»¥åŒæ—¶è¿è¡Œã€‚\næä¾›è™šæ‹ŸåŒ–ï¼Œå°†ç‰©ç†èµ„æºæŠ½è±¡ä¸ºå¤šä¸ªè™šæ‹Ÿèµ„æºï¼Œæä¾›æ›´å¥½çš„èµ„æºåˆ©ç”¨ç‡ã€‚\nç®¡ç†æ–‡ä»¶ç³»ç»Ÿï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿåˆ›å»ºã€å­˜å‚¨ã€ç»„ç»‡å’Œæ£€ç´¢æ–‡ä»¶ã€‚\nå¤„ç†è¾“å…¥è¾“å‡ºï¼Œä½¿ç”¨æˆ·å’Œåº”ç”¨ç¨‹åºèƒ½å¤Ÿä¸å¤–éƒ¨è®¾å¤‡è¿›è¡Œäº¤äº’ã€‚\næä¾›ç”¨æˆ·ç•Œé¢ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿä¸è®¡ç®—æœºè¿›è¡Œäº¤äº’ï¼Œå¦‚å‘½ä»¤è¡Œç•Œé¢æˆ–å›¾å½¢ç”¨æˆ·ç•Œé¢ã€‚\n\n# æ“ä½œç³»ç»Ÿæœ‰å“ªäº›ï¼Ÿ\nå¸¸è§çš„æ“ä½œç³»ç»ŸåŒ…æ‹¬ï¼š\n\nWindowsï¼šå¾®è½¯å¼€å‘çš„æ“ä½œç³»ç»Ÿç³»åˆ—ï¼Œå¦‚ Windows 10ã€Windows 11 ç­‰ã€‚\nmacOSï¼šè‹¹æœå…¬å¸å¼€å‘çš„æ“ä½œç³»ç»Ÿï¼Œç”¨äº Mac ç”µè„‘ã€‚\nLinuxï¼šä¸€ç§å¼€æºçš„ Unix-like æ“ä½œç³»ç»Ÿï¼Œæœ‰è®¸å¤šä¸åŒçš„å‘è¡Œç‰ˆï¼Œå¦‚ Ubuntuã€Fedoraã€Debian ç­‰ã€‚\nUnixï¼šä¸€ç§ç»å…¸çš„å¤šç”¨æˆ·å¤šä»»åŠ¡æ“ä½œç³»ç»Ÿï¼Œå½±å“äº†è®¸å¤šå…¶ä»–æ“ä½œç³»ç»Ÿçš„è®¾è®¡ã€‚\nAndroidï¼šåŸºäº Linux å†…æ ¸çš„ç§»åŠ¨è®¾å¤‡æ“ä½œç³»ç»Ÿï¼Œç”±è°·æ­Œå¼€å‘ã€‚\niOSï¼šè‹¹æœå…¬å¸ç”¨äº iPhone å’Œ iPad ç­‰ç§»åŠ¨è®¾å¤‡çš„æ“ä½œç³»ç»Ÿã€‚\nOpenHarmonyï¼šåˆ†å¸ƒå¼æ“ä½œç³»ç»Ÿï¼Œç”±åä¸ºå…¬å¸å¼€å‘ã€‚\n\n# æ“ä½œç³»ç»Ÿçš„æ–°å‘å±•ï¼Ÿ\næ“ä½œç³»ç»Ÿé¢†åŸŸä¸€ç›´åœ¨ä¸æ–­å‘å±•æ¼”è¿›ã€‚ä¸€äº›æ–°çš„è¶‹åŠ¿å’Œå‘å±•åŒ…æ‹¬ï¼š\n\näº‘æ“ä½œç³»ç»Ÿï¼š é’ˆå¯¹äº‘è®¡ç®—ç¯å¢ƒçš„æ“ä½œç³»ç»Ÿï¼Œå¦‚ Google çš„ Chrome OS å’Œå¾®è½¯çš„ Azure Sphereã€‚\nåµŒå…¥å¼æ“ä½œç³»ç»Ÿï¼š ç”¨äºåµŒå…¥å¼ç³»ç»Ÿï¼Œå¦‚ç‰©è”ç½‘è®¾å¤‡å’ŒåµŒå…¥å¼æ§åˆ¶å™¨çš„æ“ä½œç³»ç»Ÿï¼Œå¦‚ FreeRTOS å’Œ Zephyrã€‚\nå®¹å™¨åŒ–å’Œå¾®æœåŠ¡ï¼š ä½¿ç”¨å®¹å™¨æŠ€æœ¯ï¼ˆå¦‚ Dockerï¼‰å’Œå¾®æœåŠ¡æ¶æ„çš„æ“ä½œç³»ç»Ÿï¼Œä»¥æ”¯æŒæ›´é«˜æ•ˆçš„åº”ç”¨ç¨‹åºéƒ¨ç½²å’Œç®¡ç†ã€‚\nå®æ—¶æ“ä½œç³»ç»Ÿï¼ˆRTOSï¼‰ï¼š é’ˆå¯¹å®æ—¶åº”ç”¨ç¨‹åºçš„æ“ä½œç³»ç»Ÿï¼Œè¦æ±‚ä»»åŠ¡èƒ½å¤Ÿåœ¨ä¸¥æ ¼çš„æ—¶é—´é™åˆ¶å†…å¾—åˆ°æ‰§è¡Œã€‚\né‡å­æ“ä½œç³»ç»Ÿï¼š éšç€é‡å­è®¡ç®—çš„å‘å±•ï¼Œæ¶‰åŠç®¡ç†é‡å­èµ„æºå’Œè¿è¡Œé‡å­ç®—æ³•çš„æ“ä½œç³»ç»Ÿæ­£åœ¨æ¢ç´¢ä¸­ã€‚\n\nè¿™äº›éƒ½åªæ˜¯æ“ä½œç³»ç»Ÿé¢†åŸŸçš„ä¸€éƒ¨åˆ†å‘å±•è¶‹åŠ¿ï¼Œæ“ä½œç³»ç»Ÿå°†ç»§ç»­é€‚åº”æ–°çš„ç¡¬ä»¶å’Œåº”ç”¨åœºæ™¯ï¼Œä»¥æ»¡è¶³ä¸æ–­å˜åŒ–çš„éœ€æ±‚ã€‚\n# ç®€å•æ€»ç»“ï¼\næ“ä½œç³»ç»Ÿçš„å®šä¹‰å¯å½’çº³ä¸ºï¼šæ“ä½œç³»ç»Ÿæ˜¯æ§åˆ¶å’Œç®¡ç†è®¡ç®—æœºç³»ç»Ÿå†…å„ç§ç¡¬ä»¶å’Œè½¯ä»¶èµ„æºã€åˆç†ç»„ç»‡è®¡ç®—æœºå·¥ä½œæµç¨‹çš„ç³»ç»Ÿè½¯ä»¶ (æˆ–ç¨‹åºé›†åˆ)ï¼Œæ˜¯ç”¨æˆ·ä¸è®¡ç®—æœºä¹‹é—´çš„æ¥å£ã€‚\næ“ä½œç³»ç»Ÿæ˜¯ä»€ä¹ˆï¼Ÿæ˜¯æ ¸å¿ƒç³»ç»Ÿè½¯ä»¶\næ“ä½œç³»ç»Ÿç®¡ä»€ä¹ˆï¼Ÿæ§åˆ¶å’Œç®¡ç†ç³»ç»Ÿå†…å„èµ„æº\næ“ä½œç³»ç»Ÿæœ‰ä½•ç”¨ï¼Ÿæ‰©å……ç¡¬ä»¶åŠŸèƒ½ï¼Œæ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨\n# ç»ƒä¹ \n\n\nä¸€ä¸ªä½œä¸šç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶ç”¨äº† 5 åˆ†é’Ÿï¼Œè€Œç¬¬äºŒæ¬¡æ‰§è¡Œæ—¶ç”¨äº† 6 åˆ†é’Ÿï¼Œè¿™è¯´æ˜äº†æ“ä½œç³»ç»Ÿçš„  ç‰¹ç‚¹ã€‚\n\nå¹¶å‘\nå…±äº«\nè™šæ‹Ÿ\nå¼‚æ­¥\n\nè§£é‡Š\n\nå¼‚æ­¥å­˜åœ¨æ—¶é—´ä¸ç¡®å®šæ€§\n\n\n\n\næ“ä½œç³»ç»Ÿçš„æœ€åŸºæœ¬çš„ä¸¤ä¸ªç‰¹å¾æ˜¯èµ„æºå…±äº«å’Œ  ã€‚\n\nå¤šé“ç¨‹åºè®¾è®¡\nç¨‹åºçš„å¹¶å‘æ‰§è¡Œ\nä¸­æ–­\nç¨‹åºé¡ºåºæ‰§è¡Œ\n\n\n\nå•é“æ‰¹å¤„ç†ç³»ç»Ÿçš„ä¸»è¦ç¼ºç‚¹æ˜¯  ã€‚\n\nCPU åˆ©ç”¨ç‡ä¸é«˜\nå¤±å»äº†äº¤äº’æ€§\nä¸å…·å¤‡å¹¶è¡Œæ€§\nä»¥ä¸Šéƒ½ä¸æ˜¯\n\n\n\nè§£é‡Š\n\nå®é™…ä¸Š ABC éƒ½æ˜¯ä»–çš„ç¼ºç‚¹ï¼Œä½†æ˜¯ CPU / èµ„æºåˆ©ç”¨ç‡ä¸é«˜æ˜¯ä»–çš„ä¸»è¦ç¼ºç‚¹\n\n\n\n\né‡‡ç”¨å¤šé“ç¨‹åºè®¾è®¡çš„ç³»ç»Ÿä¸­ï¼Œç³»ç»Ÿä¸­çš„ç¨‹åºé“æ•°è¶Šå¤šï¼Œç³»ç»Ÿçš„æ•ˆç‡è¶Šé«˜ã€‚\n\n\né€šå¸¸å°† CPU æ¨¡å¼åˆ†ä¸ºå†…æ ¸æ€ (æ ¸å¿ƒæ€) å’Œç”¨æˆ·æ€ï¼Œè¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†æé«˜è¿è¡Œé€Ÿåº¦ã€‚\n\n\næ“ä½œç³»ç»Ÿå†…æ ¸èƒ½ä½¿ç”¨ç‰¹æƒæŒ‡ä»¤ã€‚\n\n\nè§£æ\n\nç¨‹åºé“æ•°å¤šå¤šä¼šå¯¼è‡´æ¯ä¸ªç¨‹åºåˆ†å¾—çš„å†…å­˜ä¸å¤Ÿï¼Œå¾ˆå¤šç¨‹åºæ‰€éœ€çš„æ•°æ®å’Œä»£ç è¦ä¸´æ—¶ä»ç£ç›˜è°ƒå…¥å†…å­˜ç³»ç»Ÿä¼šé¢‘ç¹çš„è¿›è¡Œ I/Oï¼Œä½¿å¾—ç³»ç»Ÿæ•ˆç‡ä¸‹é™ï¼\næ˜¯ä¸ºäº†æé«˜å®‰å…¨æ€§ ==ï¼ˆåŒé‡å·¥ä½œæ¨¡å¼ P20ï¼‰==\nç¡®å®å¯¹\n\n\n# è¿›ç¨‹\n# è¿›ç¨‹çš„å‡ ä¸ªåŸºæœ¬çŠ¶æ€\n\nå°±ç»ªçŠ¶æ€ï¼ˆReadyï¼‰ï¼š è¿›ç¨‹å·²è·å¾—é™¤å¤„ç†å™¨å¤–çš„æ‰€éœ€èµ„æºï¼Œç­‰å¾…åˆ†é…å¤„ç†å™¨èµ„æºï¼›åªè¦åˆ†é…äº†å¤„ç†å™¨è¿›ç¨‹å°±å¯æ‰§è¡Œã€‚å°±ç»ªè¿›ç¨‹å¯ä»¥æŒ‰å¤šä¸ªä¼˜å…ˆçº§æ¥åˆ’åˆ†é˜Ÿåˆ—ã€‚ä¾‹å¦‚ï¼Œå½“ä¸€ä¸ªè¿›ç¨‹ç”±äºæ—¶é—´ç‰‡ç”¨å®Œè€Œè¿›å…¥å°±ç»ªçŠ¶æ€æ—¶ï¼Œæ’å…¥ä½ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼›å½“è¿›ç¨‹ç”± I/O æ“ä½œå®Œæˆè€Œè¿›å…¥å°±ç»ªçŠ¶æ€æ—¶ï¼Œæ’å…¥é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—.\nè¿è¡ŒçŠ¶æ€ (Running)ï¼š è¿›ç¨‹å ç”¨å¤„ç†å™¨èµ„æºï¼›å¤„äºæ­¤çŠ¶æ€çš„è¿›ç¨‹çš„æ•°ç›®å°äºç­‰äºå¤„ç†å™¨çš„æ•°ç›®ã€‚åœ¨æ²¡æœ‰å…¶ä»–è¿›ç¨‹å¯ä»¥æ‰§è¡Œæ—¶ (å¦‚æ‰€æœ‰è¿›ç¨‹éƒ½åœ¨é˜»å¡çŠ¶æ€), é€šå¸¸ä¼šè‡ªåŠ¨æ‰§è¡Œç³»ç»Ÿçš„ç©ºé—²è¿›ç¨‹.\né˜»å¡çŠ¶æ€ (Blocked)ï¼š ç”±äºè¿›ç¨‹ç­‰å¾…æŸç§æ¡ä»¶ï¼ˆå¦‚ I/O æ“ä½œæˆ–è¿›ç¨‹åŒæ­¥ï¼‰, åœ¨æ¡ä»¶æ»¡è¶³ä¹‹å‰æ— æ³•ç»§ç»­æ‰§è¡Œã€‚è¯¥äº‹ä»¶å‘ç”Ÿå‰å³ä½¿æŠŠå¤„ç†æœºåˆ†é…ç»™è¯¥è¿›ç¨‹ï¼Œä¹Ÿæ— æ³•è¿è¡Œ.\n\n\n# åè¯è§£é‡Š\næŒ‚èµ·ï¼š ä»å†…å­˜æŒ‚è‡³å¤–å­˜\næ—¶é—´ç‰‡ï¼š ç¨‹åºæ‰§è¡Œçš„ä¸€æ®µæ—¶é—´\né˜»å¡ï¼š å‘ç”Ÿ I/O æˆ–è€…å…¶ä»–äº‹ä»¶è¿›å…¥é˜»å¡çŠ¶æ€\n# æ‰©å±•çŠ¶æ€ï¼ˆè€ƒç ”ï¼‰\n\n# ç»ƒä¹ \n\n\nå½“  æ—¶ï¼Œè¿›ç¨‹ä»æ‰§è¡ŒçŠ¶æ€è½¬å˜ä¸ºå°±ç»ªçŠ¶æ€ã€‚\n\nè¿›ç¨‹è¢«è°ƒåº¦ç¨‹åºé€‰ä¸­\næ—¶é—´ç‰‡åˆ°\nç­‰å¾…æŸä¸€äº‹ä»¶\nç­‰å¾…çš„äº‹ä»¶å‘ç”Ÿ\n\n\n\nåœ¨è¿›ç¨‹çŠ¶æ€è½¬æ¢æ—¶ï¼Œä¸‹åˆ—  è½¬æ¢æ˜¯ä¸å¯èƒ½å‘ç”Ÿçš„ã€‚\n\nå°±ç»ªæ€ ä¸€ &gt; è¿è¡Œæ€\nè¿è¡Œæ€ ä¸€ &gt; å°±ç»ªæ€\nè¿è¡Œæ€ ä¸€ &gt; é˜»å¡æ€\né˜»å¡æ€ ä¸€ &gt; è¿è¡Œæ€\n\n\n\nè¿›ç¨‹å’Œç¨‹åºçš„æœ¬è´¨åŒºåˆ«æ˜¯ \n\nå‰è€…æ˜¯åŠ¨æ€çš„ï¼Œåè€…æ˜¯é™æ€çš„\nå‰è€…å­˜å‚¨åœ¨å†…å­˜ï¼Œåè€…å­˜å‚¨åœ¨å¤–å­˜\nå‰è€…åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œåè€…åœ¨å¤šä¸ªæ–‡ä»¶ä¸­\nå‰è€…åˆ†æ—¶ä½¿ç”¨ CPUï¼Œåè€…ç‹¬å  CPU\n\n\n\nç¨‹åºè¿è¡Œæ—¶ç‹¬å ç³»ç»Ÿèµ„æºï¼Œåªæœ‰ç¨‹åºæœ¬èº«èƒ½æ”¹å˜ç³»ç»Ÿèµ„æºçŠ¶æ€ï¼Œè¿™æ˜¯æŒ‡ \n\nç¨‹åºé¡ºåºæ‰§è¡Œçš„å†ç°æ€§\nå¹¶å‘ç¨‹åºå¤±å»å†ç°æ€§\nå¹¶å‘ç¨‹åºå¤±å¤«å°é—­æ€§\nç¨‹åºé¡ºåºæ‰§è¡Œæ—¶çš„å°é—­æ€§\n\n\n\nä¸åŒçš„è¿›ç¨‹å¿…ç„¶å¯¹åº”ä¸åŒçš„ç¨‹åºã€‚\n\n\nè¿›ç¨‹çŠ¶æ€çš„è½¬æ¢æ˜¯ç”±æ“ä½œç³»ç»Ÿå®Œæˆçš„ï¼Œå¯¹ç”¨æˆ·æ˜¯é€æ˜çš„ã€‚\n\n\n# è¿›ç¨‹æ§åˆ¶å—ï¼ˆProcess Control Blockï¼ŒPCBï¼‰\næ¯ä¸ªæ­£åœ¨è¿è¡Œæˆ–ç­‰å¾…è¿è¡Œçš„è¿›ç¨‹éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„ PCBï¼Œå®ƒåŒ…å«äº†è¿›ç¨‹çš„å„ç§å±æ€§ã€çŠ¶æ€ä»¥åŠä¸å…¶ç›¸å…³çš„æ§åˆ¶ä¿¡æ¯ã€‚PCB æ˜¯æ“ä½œç³»ç»Ÿå†…éƒ¨ç”¨äºå®ç°è¿›ç¨‹ç®¡ç†çš„é‡è¦æ•°æ®ç»“æ„ä¹‹ä¸€ã€‚\n\nè¿›ç¨‹çŠ¶æ€ï¼ˆProcess Stateï¼‰ï¼šè¡¨ç¤ºè¿›ç¨‹çš„å½“å‰çŠ¶æ€ï¼Œå¦‚è¿è¡Œã€å°±ç»ªã€é˜»å¡ç­‰ã€‚æ“ä½œç³»ç»Ÿæ ¹æ®è¿›ç¨‹çŠ¶æ€æ¥è¿›è¡Œè°ƒåº¦å’Œç®¡ç†ã€‚\nç¨‹åºè®¡æ•°å™¨ï¼ˆProgram Counterï¼‰ï¼šæŒ‡å‘è¿›ç¨‹å½“å‰æ‰§è¡Œçš„æŒ‡ä»¤çš„åœ°å€ï¼Œç”¨äºæ¢å¤è¿›ç¨‹çš„æ‰§è¡ŒçŠ¶æ€ã€‚\nå¯„å­˜å™¨ï¼ˆRegistersï¼‰ï¼šä¿å­˜è¿›ç¨‹çš„å¯„å­˜å™¨å€¼ï¼ŒåŒ…æ‹¬é€šç”¨å¯„å­˜å™¨ã€ç¨‹åºçŠ¶æ€å¯„å­˜å™¨ç­‰ã€‚\nè¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆProcess Priorityï¼‰ï¼šç”¨äºè°ƒåº¦å™¨å†³å®šå“ªä¸ªè¿›ç¨‹å°†è·å¾— CPU æ‰§è¡Œæ—¶é—´ã€‚\nè¿›ç¨‹æ ‡è¯†ç¬¦ï¼ˆProcess IDï¼‰ï¼šå”¯ä¸€æ ‡è¯†ä¸€ä¸ªè¿›ç¨‹çš„æ•°å­—æˆ–å­—ç¬¦ä¸²ã€‚\nè¿›ç¨‹æ‰€æ‹¥æœ‰çš„èµ„æºä¿¡æ¯ï¼šå¦‚æ‰“å¼€çš„æ–‡ä»¶åˆ—è¡¨ã€åˆ†é…çš„å†…å­˜ç©ºé—´ç­‰ã€‚\nè¿›ç¨‹çš„çˆ¶å­å…³ç³»ï¼šè®°å½•è¿›ç¨‹ä¹‹é—´çš„å±‚æ¬¡ç»“æ„ï¼Œç”¨äºå®ç°è¿›ç¨‹é—´çš„é€šä¿¡å’Œåä½œã€‚\nè¿›ç¨‹çš„å„ç§ç»Ÿè®¡ä¿¡æ¯ï¼šå¦‚è¿è¡Œæ—¶é—´ã€ç­‰å¾…æ—¶é—´ç­‰ï¼Œç”¨äºæ€§èƒ½åˆ†æå’Œè°ƒä¼˜ã€‚\n\nPCB çš„å­˜åœ¨ä½¿å¾—æ“ä½œç³»ç»Ÿå¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œè¿›ç¨‹çš„åˆ‡æ¢ã€è°ƒåº¦ã€æŒ‚èµ·ã€æ¢å¤ç­‰æ“ä½œã€‚å½“æ“ä½œç³»ç»Ÿéœ€è¦åˆ‡æ¢åˆ°å¦ä¸€ä¸ªè¿›ç¨‹æ—¶ï¼Œå®ƒå¯ä»¥ä¿å­˜å½“å‰è¿›ç¨‹çš„çŠ¶æ€ä¿¡æ¯åˆ°å…¶å¯¹åº”çš„ PCBï¼Œç„¶ååŠ è½½æ–°è¿›ç¨‹çš„çŠ¶æ€ä¿¡æ¯ï¼Œä»è€Œå®ç°è¿›ç¨‹åˆ‡æ¢ã€‚è¿™ç§åˆ‡æ¢æ˜¯æ“ä½œç³»ç»Ÿå¤šä»»åŠ¡å¤„ç†çš„åŸºç¡€ï¼Œä½¿å¾—å¤šä¸ªè¿›ç¨‹å¯ä»¥åœ¨å•ä¸ª CPU ä¸Šå…±äº«æ—¶é—´ï¼Œå¹¶ä¸”å®ç°äº†å¯¹ç³»ç»Ÿèµ„æºçš„åˆç†åˆ†é…å’Œåˆ©ç”¨ã€‚\n# PCB ç»„ç»‡æ–¹å¼\n\n\n\n# ç»ƒä¹ \n\n\nåœ¨ PCB ä¸­å¯ä»¥ç›´æ¥æˆ–é—´æ¥æ‰¾åˆ°æœ‰å…³è¯¥è¿›ç¨‹çš„æ‰€æœ‰ä¿¡æ¯ã€‚\n\n\nè¿›ç¨‹ç”± PCB å’Œå…¶æ‰§è¡Œçš„ç¨‹åºã€æ•°æ®æ‰€ç»„æˆ\n\n\n","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"MongoDBçš„å®‰è£…ä¸åˆæ­¥ä½¿ç”¨ï¼ˆWindowså¹³å°ï¼‰","url":"/MongoDB/MongoDB01/","content":"# åˆè§ MongoDB\n# ä»€ä¹ˆæ˜¯ MongoDBï¼Ÿ\nMongoDB æ˜¯ä¸€ä¸ªå¼€æºçš„ã€é¢å‘æ–‡æ¡£çš„ NoSQL æ•°æ®åº“ç®¡ç†ç³»ç»Ÿã€‚å®ƒä¸ä¼ ç»Ÿçš„å…³ç³»å‹æ•°æ®åº“ï¼ˆå¦‚ MySQLã€PostgreSQLï¼‰ä¸åŒï¼Œå› ä¸ºå®ƒä¸ä½¿ç”¨è¡¨æ ¼æ¥å­˜å‚¨æ•°æ®ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€ç§ç§°ä¸º &quot;æ–‡æ¡£&quot; çš„æ•°æ®ç»“æ„æ¥ç»„ç»‡å’Œå­˜å‚¨æ•°æ®ã€‚æ¯ä¸ªæ–‡æ¡£æ˜¯ä¸€ä¸ªåŒ…å«é”®å€¼å¯¹çš„æ•°æ®ç»“æ„ï¼Œç±»ä¼¼äº JSON æ ¼å¼ï¼Œè¿™ä½¿å¾— MongoDB éå¸¸é€‚åˆå­˜å‚¨å…·æœ‰ä¸åŒç»“æ„çš„æ•°æ®ã€‚\n\n# MongoDB çš„å®‰è£…ä¸æœåŠ¡å¯åŠ¨\n# ä¸‹è½½ MongoDB å®‰è£…åŒ…\nè®¿é—® https://www.mongodb.com/download-center#community\n æˆ–è€…ç‚¹å‡»ä¸‹æ–¹è¿æ¥\n\n          \n          MogoDB\n          å®˜æ–¹ä¸‹è½½åœ°å€\n          \nä¸‹è½½è½½æœ€æ–°ç‰ˆæœ¬çš„ MongoDB æ•°æ®åº“ã€‚\n# MongoDB å®‰è£…\n\nåŒå‡»åˆšåˆšä¸‹è½½çš„å®‰è£…æ–‡ä»¶ (mongodb-XXXX-XXXX-signed.msi) å¯åŠ¨å®‰è£…ç¨‹åºã€‚\nå•å‡»ã€Nextã€‘æŒ‰é’®ï¼Œè¿›å…¥ â€œEnd-User License Agreementâ€ ç•Œé¢\nå‹¾é€‰ â€œI accept the terms in the License Agreementâ€ é€‰é¡¹ï¼Œå•å‡»ã€Nextã€‘æŒ‰é’®è¿›å…¥ â€œChoose Setup Typeâ€ ç•Œé¢ï¼Œè¯¥ç•Œé¢ä¸­å¯é€‰æ‹©å®‰è£…ç±»å‹\n\nCompleteã€‚æ­¤ç±»å‹å°†å®‰è£…æ‰€æœ‰ç¨‹åºåŠŸèƒ½ï¼Œéœ€å ç”¨è¾ƒå¤šçš„ç£ç›˜ç©ºé—´ï¼Œå»ºè®®å¤§å¤šæ•°ç”¨æˆ·ä½¿ç”¨ã€‚\nCustomã€‚æ­¤ç±»å‹å…è®¸ç”¨æˆ·è‡ªè¡Œé€‰æ‹©è¦å®‰è£…çš„ç¨‹åºåŠŸèƒ½åŠå®‰è£…ä½ç½®ï¼Œå»ºè®®é«˜çº§ç”¨æˆ·ä½¿ç”¨ã€‚\n\nMongoDB Compass æ˜¯ MongoDB æ•°æ®åº“çš„ GUI ç®¡ç†ç³»ç»Ÿï¼Œé»˜è®¤ä¼šé€‰æ‹©å®‰è£…ï¼Œä½†æ˜¯å®‰è£…é€Ÿåº¦éå¸¸æ…¢ã€‚\n\nå€¼å¾—ä¸€æçš„æ˜¯ï¼ŒMongoDB é»˜è®¤ä¼šå°†åˆ›å»ºçš„æ•°æ®åº“æ–‡ä»¶å­˜å‚¨åœ¨ db ç›®å½•ä¸‹ï¼Œä½†æ˜¯è¿™ä¸ªç›®å½•ä¸ä¼šè¢«ä¸»åŠ¨åˆ›å»ºï¼Œç”¨æˆ·éœ€è¦åœ¨ MongoDB å®‰è£…å®Œæˆåæ‰‹åŠ¨åˆ›å»º db ç›®å½•ã€‚åœ¨ â€œC:\\Program Files\\MongoDB\\Server\\4.0\\data\\â€ ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ db\n# é…ç½®\nåŒæ ·çš„æˆ‘ä»¬ä¹Ÿå¯ä»¥å°† bin ç›®å½•é…ç½®åˆ°ç¯å¢ƒå˜é‡çš„ Path ä¸­\n# å¯åŠ¨ MongoDB æœåŠ¡ï¼ˆå¯åŠ¨ä¸åœæ­¢ï¼‰\nè¿›å…¥å¦‚å›¾æ‰€ç¤ºçš„ç›®å½•è¾“å…¥ net start MongoDB å¯åŠ¨æœåŠ¡ï¼Œç›¸åº”çš„è¾“å…¥ net stop MongoDB åˆ™ä¸ºåœæ­¢æœåŠ¡\n\n# MongoDB åŸºæœ¬å‘½ä»¤\nåœ¨ cmd ä¸­è¾“å…¥ Mongo è¿›å…¥ Mongo çš„äº¤äº’ç•Œé¢\nåˆ›å»ºæ•°æ®åº“:\nåˆ›å»ºæ•°æ®åº“use mydbå±•ç¤ºæ•°æ®åº“:\nå±•ç¤ºæ®åº“show dbsåˆ é™¤æ•°æ®åº“:\nåˆ é™¤æ•°æ®åº“db.dropDatabase()åˆ›å»ºé›†åˆï¼š\nåˆ›å»ºé›†åˆdb.createCollection(\"myCollection\")æ’å…¥æ•°æ®ï¼š\næ’å…¥db.myCollection.insert(&#123;\"_id\":1,\"name\":\"è¯—å²¸æ¢¦è¡ŒèˆŸ\"&#125;)åˆ é™¤ï¼š\nåˆ é™¤db.myCollection.remove(&#123;\"_id\":1&#125;)æ›´æ–°ï¼š\næ›´æ–°db.myCollection.update(&#123;\"_id\":1&#125;,&#123;$set&#123;\"name\":\"Karry.Liu\"&#125;&#125;)æŸ¥è¯¢æ‰€æœ‰ï¼š\nåˆ é™¤db.myCollection.find()æŒ‡å®šæŸ¥è¯¢ï¼š\nåˆ é™¤db.myCollection.find(&#123;\"_id\":1&#125;)","categories":["MongoDB"],"tags":["MongoDB"]},{"title":"è¿›ç¨‹ä¸çº¿ç¨‹","url":"/Operate-system/02OS/","content":"# ä»€ä¹ˆæ˜¯è¿›ç¨‹ä¸çº¿ç¨‹\nè¿›ç¨‹ï¼ˆProcessï¼‰å’Œçº¿ç¨‹ï¼ˆThreadï¼‰æ˜¯æ“ä½œç³»ç»Ÿä¸­çš„ä¸¤ä¸ªé‡è¦æ¦‚å¿µï¼Œç”¨äºç®¡ç†å’Œæ‰§è¡Œç¨‹åºçš„æ‰§è¡Œå•å…ƒã€‚å®ƒä»¬åœ¨å¤šä»»åŠ¡å¤„ç†å’Œå¹¶å‘æ‰§è¡Œä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚\n# è¿›ç¨‹\nè¿›ç¨‹æ˜¯è®¡ç®—æœºç³»ç»Ÿä¸­è¿è¡Œçš„ç¨‹åºçš„å®ä¾‹ã€‚æ¯ä¸ªè¿›ç¨‹éƒ½æœ‰è‡ªå·±çš„å†…å­˜ç©ºé—´ã€ä»£ç å’Œæ•°æ®ï¼Œä»¥åŠä¸å…¶ä»–è¿›ç¨‹éš”ç¦»çš„èµ„æºã€‚è¿›ç¨‹å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æ‰§è¡Œç¯å¢ƒï¼Œå¯ä»¥æ‰§è¡Œè‡ªå·±çš„ä»»åŠ¡ã€‚æ¯ä¸ªè¿›ç¨‹éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„è¿›ç¨‹æ ‡è¯†ç¬¦ï¼ˆPIDï¼‰ï¼Œç”¨äºåŒºåˆ†å’Œç®¡ç†ä¸åŒçš„è¿›ç¨‹ã€‚\nä¸€ä¸ªè¿›ç¨‹å¯ä»¥åŒ…å«å¤šä¸ªçº¿ç¨‹ï¼Œè¿™äº›çº¿ç¨‹å…±äº«åŒä¸€ä¸ªè¿›ç¨‹çš„èµ„æºï¼Œå¦‚å†…å­˜ç©ºé—´ã€æ–‡ä»¶å¥æŸ„ç­‰ã€‚ä¸åŒè¿›ç¨‹ä¹‹é—´çš„é€šä¿¡ç›¸å¯¹å¤æ‚ï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨è¿›ç¨‹é—´é€šä¿¡ï¼ˆIPCï¼‰æœºåˆ¶ï¼Œå¦‚ç®¡é“ã€æ¶ˆæ¯é˜Ÿåˆ—ã€å…±äº«å†…å­˜ç­‰ã€‚\n# çº¿ç¨‹\nçº¿ç¨‹æ˜¯è¿›ç¨‹å†…çš„æ‰§è¡Œå•å…ƒï¼Œä¸€ä¸ªè¿›ç¨‹å¯ä»¥åŒ…å«å¤šä¸ªçº¿ç¨‹ã€‚çº¿ç¨‹å…±äº«åŒä¸€ä¸ªè¿›ç¨‹çš„ä»£ç å’Œæ•°æ®ï¼Œä½†æ¯ä¸ªçº¿ç¨‹æ‹¥æœ‰è‡ªå·±çš„æ ˆç©ºé—´å’Œç¨‹åºè®¡æ•°å™¨ã€‚å› ä¸ºçº¿ç¨‹å…±äº«ç›¸åŒçš„å†…å­˜ç©ºé—´ï¼Œå®ƒä»¬ä¹‹é—´çš„é€šä¿¡å’Œæ•°æ®å…±äº«æ›´åŠ æ–¹ä¾¿ï¼Œä½†ä¹Ÿéœ€è¦é€‚å½“çš„åŒæ­¥æ§åˆ¶æ¥é¿å…ç«æ€æ¡ä»¶å’Œæ•°æ®ä¸ä¸€è‡´é—®é¢˜ã€‚\nå¤šçº¿ç¨‹çš„ä½¿ç”¨å¯ä»¥å®ç°å¹¶å‘æ‰§è¡Œï¼Œæé«˜ç¨‹åºçš„å“åº”é€Ÿåº¦å’Œèµ„æºåˆ©ç”¨ç‡ã€‚å¸¸è§çš„çº¿ç¨‹ä½¿ç”¨åœºæ™¯åŒ…æ‹¬å›¾å½¢ç•Œé¢åº”ç”¨ç¨‹åºä¸­çš„å“åº”æ€§ã€å¤šåª’ä½“å¤„ç†ã€ç½‘ç»œæœåŠ¡å™¨ç­‰ã€‚\n# ç¨‹åºå¹¶å‘æ‰§è¡Œçš„ç‰¹å¾\n\né—´æ–­æ€§ï¼šå¹¶å‘ç¨‹åºä¹‹é—´ç›¸äº’åˆ¶çº¦\nå¤±å»å°é—­æ€§ï¼šå¤šä¸ªç¨‹åºå…±äº«å…¨æœºèµ„æºï¼Œæ‰§è¡ŒçŠ¶æ€æ”¶å¤–ç•Œå› ç´ å½±å“\nä¸å¯åœ¨ç°æ€§ï¼šç¨‹åºç»è¿‡å¤šæ¬¡æ‰§è¡Œåï¼Œè™½ç„¶å…¶æ‰§è¡Œæ—¶çš„ç¯å¢ƒå’Œåˆå§‹æ¡ä»¶éƒ½ç›¸åŒï¼Œä½†å¾—åˆ°çš„ç»“æœå´å„ä¸ç›¸åŒ\n\n# è¿›ç¨‹çš„ç‰¹æ€§\n\nåŠ¨æ€æ€§ï¼ˆæœ€åŸºæœ¬çš„ç‰¹å¾ï¼‰\nå¹¶å‘æ€§\nç‹¬ç«‹æ€§\nå¼‚æ­¥æ€§ï¼šä¸å¯é¢„çŸ¥çš„é€Ÿåº¦\n\n# è¿›ç¨‹æ§åˆ¶\nä¸€èˆ¬åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n\nè¿›ç¨‹åˆ›å»º\nè¿›ç¨‹ç»ˆæ­¢\nè¿›ç¨‹é˜»å¡ä¸å”¤é†’\nè¿›ç¨‹æŒ‚èµ·ä¸æ¿€æ´»\n\n# è¿›ç¨‹åˆ›å»º\nUNIX ä¸‹çš„è¿›ç¨‹åˆ›å»º â€”â€”fork ()\n# æ¶ˆæ¯æœºåˆ¶\nç›´æ¥é€šä¿¡æ–¹å¼ä¸€ä¸€æ¶ˆæ¯ç¼“å†²é˜Ÿåˆ—\nè¿™æ˜¯æŒ‡å‘é€è¿›ç¨‹åˆ©ç”¨ OS æ‰€æä¾›çš„å‘é€å‘½ä»¤ï¼Œç›´æ¥æŠŠæ¶ˆæ¯å‘é€ç»™ç›®æ ‡è¿›ç¨‹ã€‚æ­¤æ—¶ï¼Œè¦æ±‚å‘é€è¿›ç¨‹å’Œæ¥æ”¶è¿›ç¨‹éƒ½ä»¥æ˜¾å¼æ–¹å¼æä¾›å¯¹æ–¹çš„æ ‡è¯†ç¬¦ã€‚é€šå¸¸ï¼Œç³»ç»Ÿæä¾›ä¸‹è¿°ä¸¤æ¡é€šä¿¡å‘½ä»¤ (åŸè¯­):\nSend (Receiver, message): å‘é€ä¸€ä¸ªæ¶ˆæ¯ç»™ Receiver\nReceive (Sender,message): æ¥æ”¶ Sender å‘æ¥çš„æ¶ˆæ¯\nä¾‹å¦‚ï¼ŒåŸè¯­ Send (Pï¼Œm) è¡¨ç¤ºå°†æ¶ˆæ¯ m, å‘é€ç»™æ¥æ”¶è¿›ç¨‹ P; è€ŒåŸè¯­ Receive (Pï¼Œm) åˆ™è¡¨ç¤ºæ¥æ”¶ç”± P å‘æ¥çš„æ¶ˆæ¯ mã€‚\n# è¿›ç¨‹é€šä¿¡\nè¿›ç¨‹é€šä¿¡å®ä¾‹ ------ ç®¡é“é€šä¿¡æ–¹å¼ Pipe\n\nwrite (fd [1],buf,size); å°† buf ä¸­é•¿ä¸º size å­—ç¬¦çš„æ¶ˆæ¯é€å…¥ fd [1] å£\n\n\nread (fd [0], bufâ€™,size); ä» fd [O] å£è¯»å‡º size ä¸ªå­—ç¬¦ç½®äº buf ä¸­\n\n# è¿›ç¨‹ä¸çº¿ç¨‹çš„æ¯”è¾ƒ\n# å…³äºè°ƒåº¦çš„åŸºæœ¬å•ä½\nåœ¨ä¼ ç»Ÿ OS ä¸­ï¼Œæ‹¥æœ‰èµ„æºã€ç‹¬ç«‹è°ƒåº¦å’Œåˆ†é…çš„åŸºæœ¬å•ä½éƒ½æ˜¯è¿›ç¨‹ã€‚\nåœ¨å¼•å…¥çº¿ç¨‹çš„ OS ä¸­ï¼Œçº¿ç¨‹ä½œä¸ºè°ƒåº¦å’Œåˆ†æ´¾çš„åŸºæœ¬å•ä½ï¼Œè¿›ç¨‹ä½œä¸ºæ‹¥æœ‰èµ„æºçš„åŸºæœ¬å•ä½ã€‚\nåœ¨åŒä¸€è¿›ç¨‹ä¸­ï¼Œçº¿ç¨‹çš„åˆ‡æ¢ä¸ä¼šå¼•èµ·è¿›ç¨‹åˆ‡æ¢ï¼Œåœ¨ç”±ä¸€ä¸ªè¿›ç¨‹ä¸­çš„çº¿ç¨‹åˆ‡æ¢åˆ°å¦ä¸€ä¸ªè¿›ç¨‹ä¸­çš„çº¿ç¨‹æ—¶ï¼Œå°†ä¼šå¼•èµ·è¿›ç¨‹åˆ‡æ¢ã€‚\n# å¹¶å‘æ€§\nåœ¨å¼•å…¥çº¿ç¨‹çš„æ“ä½œç³»ç»Ÿä¸­ï¼Œä¸ä»…è¿›ç¨‹ä¹‹é—´å¯ä»¥å¹¶å‘æ‰§è¡Œï¼Œè€Œä¸”åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­çš„å¤šä¸ªçº¿ç¨‹ä¹‹é—´ï¼Œä¹Ÿå¯å¹¶å‘æ‰§è¡Œ\n# æ‹¥æœ‰èµ„æº\nè¿›ç¨‹æ˜¯ç³»ç»Ÿä¸­æ‹¥æœ‰èµ„æºçš„ä¸€ä¸ªåŸºæœ¬å•ä½ï¼Œå®ƒå¯ä»¥æ‹¥æœ‰èµ„æº\nçº¿ç¨‹æœ¬èº«ä¸æ‹¥æœ‰ç³»ç»Ÿèµ„æºï¼Œä»…æœ‰ä¸€ç‚¹ä¿è¯ç‹¬ç«‹è¿è¡Œçš„èµ„æº\nå…è®¸å¤šä¸ªçº¿ç¨‹å…±äº«å…¶éš¶å±è¿›ç¨‹æ‰€æ‹¥æœ‰çš„èµ„æº\n# ç‹¬ç«‹æ€§\nåŒä¸€è¿›ç¨‹ä¸­çš„ä¸åŒçº¿ç¨‹ä¹‹é—´çš„ç‹¬ç«‹æ€§è¦æ¯”ä¸åŒè¿›ç¨‹ä¹‹é—´çš„ç‹¬ç«‹æ€§ä½å¾—å¤š\n# å¼€é”€\nåœ¨åˆ›å»ºæˆ–æ’¤æ¶ˆè¿›ç¨‹æ—¶ï¼ŒOS æ‰€ä»˜å‡ºçš„å¼€é”€å°†æ˜¾è‘—å¤§äºåˆ›å»ºæˆ–æ’¤æ¶ˆçº¿ç¨‹æ—¶çš„å¼€é”€\nçº¿ç¨‹åˆ‡æ¢çš„ä»£ä»·è¿œä½äºè¿›ç¨‹åˆ‡æ¢çš„ä»£ä»·ã€‚\nåŒä¸€è¿›ç¨‹ä¸­çš„å¤šä¸ªçº¿ç¨‹ä¹‹é—´çš„åŒæ­¥å’Œé€šä¿¡ä¹Ÿæ¯”è¿›ç¨‹çš„ç®€å•\n# æ”¯æŒå¤šå¤„ç†æœºç³»ç»Ÿ\n","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"è¿›ç¨‹åŒæ­¥é—®é¢˜","url":"/Operate-system/03OS/","content":"# ç”Ÿäº§è€… - æ¶ˆè´¹è€…é—®é¢˜\nåœ¨è¿›ç¨‹åŒæ­¥ä¸­ç¬¬ä¸€ä¸ªé—®é¢˜å°±æ˜¯ç”Ÿäº§è€… - æ¶ˆè´¹è€…é—®é¢˜ï¼Œé¦–å…ˆæˆ‘ä»¬åˆ©ç”¨è®°å½•å‹ä¿¡å·æ¥åˆ†æè¿™ä¸ªé—®é¢˜ã€‚\nå¥½å¥½å¥½ï¼Œæˆ‘ä»¬ç›´æ¥ä¼ªä»£ç è§£æï¼\nè§£é‡Šåœ¨è¡Œä»£ç çš„ä¸Šæ–¹\nè¯¦ç»†ä¼ªä»£ç //in ä»£è¡¨ä¸‹ä¸€ä¸ªè¦å†™å…¥çš„ä½ç½®ï¼Œout ä»£è¡¨è¦è¯»å–çš„ä½ç½®int in = 0,out = 0;// ç”¨äºå­˜å‚¨ç”Ÿäº§è€…ç”Ÿäº§çš„å®¹å™¨ï¼Œå¯ä»¥ç†è§£ä¸ºç¼“å†²åŒºitem buffer[n];// å‰ä¸¤è¡Œä¸æ˜¯é‡ç‚¹ï¼Œä¸‹é¢æ‰æ˜¯æ ¸å¿ƒï¼ï¼//mutex ç”¨äºäº’æ–¥è®¿é—®å…±äº«èµ„æºï¼Œåˆå€¼å¿…é¡»ä¸º 1ï¼ˆå¯ä»¥ç†è§£ä¸ºé”ï¼‰//empty ä»£è¡¨ä¸­è½¬çš„å®¹é‡ï¼Œåˆå€¼ä¸ºæœ€å¤§æ‰¿è½½å®¹é‡ï¼Œé¢˜é‡Œä¼šç»™ï¼ˆå¯ä»¥æ˜¯å„ç§å®¹å™¨ï¼‰//full æ˜¯ç”Ÿäº§å‡ºçš„ä¸€ç§é€»è¾‘ / å®ä½“çš„ç‰©è´¨// æ€»ä¹‹ä¸ç®¡æ˜¯ä»€ä¹ˆä»–æ˜¯ç”Ÿäº§è€…ç”Ÿäº§å‡ºæ¥çš„ï¼Œä¸€å¼€å§‹è¿˜æ²¡ç”Ÿäº§ï¼Œfull åˆå€¼ä¸º 0semaphore mutex = 1,empty = n,full = 0;// ç”Ÿäº§è€…é€»è¾‘void producer()&#123;    //do-while æ­»å¾ªç¯ï¼Œä¸æ–­ç”Ÿäº§ï¼Œé…åˆæ¶ˆè´¹è€…æ¨¡æ‹Ÿç¨‹åºå¹¶å‘    do&#123;        // ç”Ÿäº§ä¸€ä¸ªäº§å“        produce an item nextp;        ...        //wait ä»€ä¹ˆä»€ä¹ˆå°±æ˜¯ä»€ä¹ˆä»€ä¹ˆ â€œ--â€ï¼Œæ¯”å¦‚è¿™é‡Œ wait (empty) å°±æ˜¯ empty--        // ç›¸å½“äºç©ºä½ç½®å‡ä¸€ï¼Œç”³è¯·ä¸€ä¸ªç¼“å†²åŒº        wait(empty);        // ç›¸å½“äºåŠ é”ï¼Œç”³è¯·ç¼“å†²åŒºçš„ä½¿ç”¨æƒ        wait(mutex);        // å°†äº§å“æ”¾å…¥ç¼“å†²åŒºä¹‹ä¸­        buffer[in] = nextp;        // ä¸‹ä¸€ä¸ªç¼“å†²åŒºçš„åœ°å€        in = (in + 1) % n;        //signal ä»€ä¹ˆä»€ä¹ˆå°±æ˜¯ä»€ä¹ˆä»€ä¹ˆ â€œ++â€ï¼Œæ¯”å¦‚è¿™é‡Œ signal (mutex) å°±æ˜¯ empty++        // è§£é”ï¼Œç›¸å½“äºé‡Šæ”¾æƒé™        signal(mutex);        // ç”Ÿäº§çš„ä¸œè¥¿æ•°é‡åŠ  1ï¼Œä¹Ÿå°±æ˜¯é‡Šæ”¾ç¼“å†²åŒº        signal(full);    &#125;while(true);&#125;// æ¶ˆè´¹è€…é€»è¾‘void consumer()&#123;    //do-while æ­»å¾ªç¯ï¼Œä¸æ–­ç”Ÿæ¶ˆè´¹ï¼Œé…åˆç”Ÿäº§è€…æ¨¡æ‹Ÿç¨‹åºå¹¶å‘    do&#123;        // æ¶ˆè´¹è€…è¦æ¶ˆè´¹ä¸€ä¸ªç‰©è´¨ï¼Œå°†ç”Ÿäº§è€…çš„ç”Ÿäº§çš„ full--        wait(full);        // åŠ é”ï¼Œmutex--        wait(mutex);        // å…¶å®è¿™é‡Œä¸ç”¨å¤ªæ·±ç©¶ï¼Œè¿™é‡Œå°±æ˜¯æ¶ˆè´¹è€…ä»ç¼“å†²åŒºæ‹¿èµ°äº†ä¸€ä¸ªç”Ÿäº§è€…çš„ç”Ÿäº§çš„ç‰©è´¨        // ä»ç¼“å†²åŒºä¸­å–å‡ºäº§å“        nextc = buffer[out];        // å¯¼å‘ä¸‹ä¸€ä¸ªç¼“å†²åŒºçš„åœ°å€        out = (out + 1) % n;        // è§£é”ï¼Œmutex++        signal(mutex);        // æ¶ˆè´¹è€…å·²ç»å–èµ°äº†ï¼Œç©ºä½ç½® empty++        signal(empty);        // æ¶ˆè´¹è€…æ¶ˆè´¹ç‰©è´¨        consume the item nextc;        ...    &#125;while(true)&#125;void main()&#123;    cobegin    producer();consumer()    coend&#125;ç®€å•çš„å†™æ³•ï¼š\nç®€å•ä¼ªä»£ç Producer():  Repeat    ç”Ÿäº§ä¸€ä¸ªå•†å“    wait(empty);    wait(mutex);    å°†å•†å“é€è‡³ç¼“å†²åŒº;    signal(mutex);    signal(full);  Until falseComsumer():  Repeat    wait(full);    wait(mutex);    ä»ç¼“å†²åŒºå–èµ°ä¸€ä¸ªç‰©å“    singal(mutex);    signal(empty);  Until falseProgram main()  empty,full,mutex;    begin      empty = n;      full = 0;      mutex = 1;      cobegin        producer();consumer();      coend    end# ç»ƒä¹ ä¸€ä¸‹ï¼\næ¡Œä¸Šæœ‰ä¸ªèƒ½ç››å¾—ä¸‹äº”ä¸ªæ°´æœçš„ç©ºå­ã€‚çˆ¸çˆ¸ä¸åœåœ°å‘ç›˜ä¸­æ”¾è‹¹æœæˆ–æ©˜å­ï¼Œå„¿å­ä¸åœåœ°ä»ç›˜ä¸­å–å‡ºæ¡”å­äº«ç”¨ï¼Œå¥³å„¿ä¸åœåœ°ä»ç›˜ä¸­å–å‡ºè‹¹æœäº«ç”¨ã€‚è§„å®šä¸‰äººä¸èƒ½åŒæ—¶ä»ç›˜å­ä¸­å–æ”¾æ°´æœã€‚ä½¿ç”¨ä¿¡å·é‡å®ç°çˆ¸çˆ¸ã€å„¿å­å’Œå¥³å„¿è¿™ä¸‰ä¸ªå¾ªç¯è¿›ç¨‹ä¹‹é—´çš„åŒæ­¥ã€‚\nempty = 5,orange = 0,apple = 0,mutex = 1;Dad()&#123;    while(1)&#123;        wait(empty);        wait(mutex);        å°†æ°´æœæ”¾å…¥ç›˜ä¸­;        signal(mutex);        if(æ”¾äº†æ©˜å­) signal(orange);        else signal(apple);    &#125;&#125;Son()&#123;    while(1)&#123;        wait(orange);        wait(mutex);        æ‹¿èµ°ä¸€ä¸ªæ¡”å­;        signal(mutex);        signal(empty);        åƒæ¡”å­;    &#125;&#125;Daughter()&#123;    while(1)&#123;        wait(apple);        wait(mutex);        æ‹¿ä¸€ä¸ªè‹¹æœ;        signal(mutex);        signal(empty);        åƒè‹¹æœ;    &#125;&#125;","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"æ“ä½œç³»ç»Ÿç»†ç¢çŸ¥è¯†ç‚¹åŠå…¬å¼é€Ÿè®°","url":"/Operate-system/KnowledgeSummary/","content":"# æ“ä½œç³»ç»Ÿç»†ç¢çŸ¥è¯†ç‚¹æ€»ç»“\n\nç°ä»£æ“ä½œç³»ç»Ÿä¸¤ä¸ªæœ€åŸºæœ¬ç‰¹å¾ï¼šå¹¶å‘  ä¸  å…±äº«\nOS ä¸»è¦ç‰¹å¾æ˜¯ï¼šå¹¶å‘ã€å…±äº«ã€è™šæ‹Ÿ ä»¥åŠ å¼‚æ­¥\næ“ä½œç³»ç»Ÿå‡ºç°çš„æ ‡å¿—ï¼šå¤šé“ç¨‹åºè®¾è®¡ ä»¥åŠ åˆ†æ—¶æ“ä½œç³»ç»Ÿ çš„å‡ºç°\né«˜çº§è°ƒåº¦ï¼šä½œä¸šè°ƒåº¦\nä¸­çº§è°ƒåº¦ï¼šå†…å­˜è°ƒåº¦\nä½çº§è°ƒåº¦ï¼šè¿›ç¨‹è°ƒåº¦\nå¤šçº§å­˜å‚¨åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šé«˜é€Ÿç¼“å­˜ã€å†…å­˜ / ä¸»å­˜ ä»¥åŠ å¤–å­˜\nè¿›ç¨‹çš„è°ƒåº¦æ—¶æœºï¼šæ—¶é—´ç‰‡å®Œã€æ­£å¸¸ç»“æŸã€P æ“ä½œã€IO è¯·æ±‚ ä»¥åŠ ä¼˜å…ˆçº§æŠ¢å \næ–‡ä»¶ç³»ç»Ÿçš„åŠŸèƒ½ï¼šæŒ‰åå­˜å–ã€å­˜å‚¨ç©ºé—´ç®¡ç†ã€æ–‡ä»¶å…±äº«ä¸ä¿æŠ¤ ä»¥åŠ æ–‡ä»¶æ“ä½œ\nSPOOLING ç³»ç»Ÿçš„ç»„æˆï¼šè¾“å…¥è¿›ç¨‹ã€è¾“å…¥ç¼“å†²åŒºã€è¾“å…¥äº•ã€è¾“å‡ºè¿›ç¨‹ã€è¾“å‡ºç¼“å†²åŒº ä»¥åŠ è¾“å‡ºäº•\nè¿›ç¨‹çš„ç»“æ„ç‰¹å¾ï¼ˆæœ‰äº‰è®® / ä¸ä¸¥è°¨ï¼‰ï¼šç‹¬ç«‹æ€§ã€åŠ¨æ€æ€§ã€å¼‚æ­¥æ€§ ä»¥åŠ å¹¶å‘æ€§\nè™šæ‹Ÿå­˜å‚¨å™¨çš„ä¸»è¦ç‰¹å¾ï¼šå¤šæ¬¡æ€§ã€å¯¹æ¢æ€§ ä»¥åŠ è™šæ‹Ÿæ€§\næ‰€å­¦çš„è¿›ç¨‹è°ƒåº¦ç®—æ³•ä¸­ï¼Œæœ€ä¸­åº¸ã€æœ€èƒ½è®©é•¿ä½œä¸šå’ŒçŸ­ä½œä¸šéƒ½æ»¡æ„çš„è°ƒåº¦ç®—æ³•æ˜¯ï¼šå¤šçº§åé¦ˆé˜Ÿåˆ—è°ƒåº¦ç®—æ³•\nè¿›ç¨‹æ˜¯èµ„æºåˆ†é…çš„åŸºæœ¬å•ä½ï¼Œçº¿ç¨‹æ˜¯è°ƒåº¦çš„åŸºæœ¬å•ä½\nç¨‹åºçš„å‡ ç§è£…å…¥æ–¹å¼ï¼šé™æ€è£…å…¥ã€å¯é‡å®šä½è£…å…¥ ä»¥åŠ åŠ¨æ€è¿è¡Œæ—¶è£…å…¥\nç¨‹åºçš„å‡ ç§é“¾æ¥æ–¹å¼ï¼šé™æ€é“¾æ¥ã€è£…å…¥æ—¶åŠ¨æ€é“¾æ¥ ä»¥åŠ è¿è¡Œæ—¶åŠ¨æ€é“¾æ¥\nç¨‹åºçš„é¡ºåºæ‰§è¡Œçš„ç‰¹å¾ï¼šé¡ºåºæ€§ã€å°é—­æ€§ ä»¥åŠ ç»“æœå¯å†ç°æ€§\nè¯·æ±‚åˆ†é¡µå¼è™šæ‹Ÿå­˜å‚¨ç³»ç»Ÿå¿…é¡»è‡³å°‘å…·æœ‰ä¸‰ç§ç¡¬ä»¶æ”¯æŒï¼Œå³é¡µè¡¨æœºåˆ¶ã€ç¼ºé¡µä¸­æ–­æœºæ„ ä»¥åŠ åœ°å€å˜æ¢æœºæ„\nç¨‹åºå¹¶å‘æ‰§è¡Œçš„ç‰¹æ€§æœ‰ï¼šé—´æ–­æ€§ã€å¤±å»å°é—­æ€§ã€å¤±å»ç»“æœå¯å†ç°æ€§\nè¿›ç¨‹æ§åˆ¶å—çš„ä¿¡æ¯æœ‰ï¼šè¿›ç¨‹æ ‡è¯†ç¬¦ã€å¤„ç†æœºçŠ¶æ€ã€è¿›ç¨‹æ§åˆ¶ä¿¡æ¯ã€è¿›ç¨‹è°ƒåº¦ä¿¡æ¯\næ‰‡åŒºæ˜¯ç£ç›˜ç©ºé—´ç®¡ç†çš„æœ€åŸºæœ¬å•ä½ï¼Œå…¶ç‰©ç†åœ°å€æ˜¯ç”±ï¼šæŸ±é¢å·ã€æ‰‡åŒºå·ã€ç£å¤´å·ä¸‰éƒ¨åˆ†ç»„æˆçš„\nç«è½¦ç«™å”®ç¥¨ç³»ç»Ÿå±äºå®æ—¶ç³»ç»Ÿ\nI/O ç®¡åˆ¶ç¨‹åºçš„ä¸»è¦åŠŸèƒ½æ˜¯ç®¡ç†è®¾å¤‡ã€æ§åˆ¶å™¨å’Œé€šé“çš„çŠ¶æ€ä¿¡æ¯\nä¾æ®ä¿¡å·é‡çš„å‘å±•è¿‡ç¨‹ï¼Œå¯å°†ä¿¡å·é‡åˆ†ä¸ºå››ç§ï¼šand å‹ä¿¡å·é‡ã€ä¿¡å·é‡é›†ã€äº’æ–¥ä¿¡å·é‡ ä»¥åŠ æ•´å‹ä¿¡å·é‡\nè¿›ç¨‹é€šä¿¡ç±»å‹æœ‰ï¼šå…±äº«å­˜å‚¨å™¨ç³»ç»Ÿã€æ¶ˆæ¯ä¼ é€’ç³»ç»Ÿã€ç®¡é“é€šä¿¡ ä»¥åŠ å¼‚æ­¥é˜»å¡é€šä¿¡\nåˆ†æ®µå­˜å‚¨ç®¡ç†çš„ä¼˜ç‚¹æœ‰ï¼šæ–¹ä¾¿ç¼–ç¨‹ã€ä¿¡æ¯å…±äº«ã€åŠ¨æ€å¢é•¿ã€åŠ¨æ€é“¾æ¥ä»¥åŠ ä¿¡æ¯ä¿æŠ¤\næˆæ‰¹æ€§æ˜¯æ‰¹å¤„ç†æ“ä½œç³»ç»Ÿçš„ä¸»è¦ç‰¹å¾ï¼Œä¸æ˜¯åˆ†æ—¶ç³»ç»Ÿçš„ç‰¹æ€§\næ¨åŠ¨æ“ä½œç³»ç»Ÿå‘å±•çš„ä¸»è¦åŠ¨åŠ›æœ‰ï¼šä¸æ–­æé«˜è®¡ç®—æœºèµ„æºåˆ©ç”¨ç‡ã€æ–¹ä¾¿ç”¨æˆ·ã€å™¨ä»¶çš„ä¸æ–­æ›´æ–°æ¢ä»£ ä»¥åŠ è®¡ç®—æœºä½“ç³»ç»“æ„çš„ä¸æ–­å‘å±•\nåŒæ­¥æœºåˆ¶åº”å½“éµå¾ªçš„è§„åˆ™æœ‰ï¼šç©ºé—²è®©è¿›ã€è®©æƒç­‰å¾…ã€å¿™åˆ™ç­‰å¾… ä»¥åŠ æœ‰é™ç­‰å¾…\nç³»ç»Ÿä¸­å„ä¸ªè¿›ç¨‹ç›¸äº’åˆ¶çº¦çš„å…³ç³»ç§°ä¸ºåŒæ­¥\nå¯¹äºæ­»é”ï¼Œä¸€èˆ¬åº”è€ƒè™‘æ­»é”çš„é¢„é˜²ã€æ£€æµ‹ã€é¿å… ä»¥åŠ è§£é™¤\nå…¸å‹çš„é“¶è¡Œå®¶ç®—æ³•æ˜¯å±äºæ­»é”é¿å…ï¼Œç ´åç¯è·¯ç­‰å¾…æ¡ä»¶æ˜¯å±äºæ­»é”é¢„é˜²ï¼Œå‰¥å¤ºèµ„æºæ˜¯å±äºæ­»é”è§£é™¤\næ“ä½œç³»ç»Ÿå‘ç”¨æˆ·æä¾›äº†ä¸¤ç§æ¥å£åˆ†åˆ«æ˜¯ç”¨æˆ·æ¥å£å’Œç³»ç»Ÿæ¥å£\nè®¾åˆ«åˆ†åˆ«é…åº”ä¿è¯è®¾å¤‡æœ‰é«˜åˆ©ç”¨ç‡å’Œé¿å…æ­»é”\nå¯¹äºæ“ä½œç³»ç»Ÿè€Œè¨€ï¼Œæ‰“å¼€æ–‡ä»¶å¹¿ä¹‰æŒ‡ä»¤çš„ä¸»è¦ä½œç”¨æ˜¯è£…å…¥æ–‡ä»¶ç›®å½•é¡¹\nä¸ºäº†å®ç°å¤šé“ç¨‹åºè®¾è®¡ï¼Œè®¡ç®—æœºåœ¨ç¡¬ä»¶æ–¹é¢å¿…é¡»æä¾›ä¸¤ç§æ”¯æŒï¼Œä»–ä»¬åˆ†åˆ«æ˜¯ä¸­æ–­å’Œé€šé“\nå¤šé“ç¨‹åºè®¾è®¡ç»™å­˜å‚¨ç®¡ç†æå‡ºäº†æ–°è¯¾é¢˜ï¼Œåº”è€ƒè™‘çš„ä¸‰ä¸ªé—®é¢˜æ˜¯å­˜å‚¨åˆ†é…ã€è™šå­˜ç®¡ç†ã€å­˜å‚¨ä¿æŠ¤\næ“ä½œç³»ç»Ÿçš„å†…æ ¸åº”æä¾›ç»ˆç«¯ç®¡ç†ã€çŸ­ç¨‹ç®¡ç†ã€åŸè¯­ç®¡ç†ä¸‰æ–¹é¢çš„åŠŸèƒ½\næ­»é”äº§ç”Ÿçš„ä¸»è¦åŸå› ä¸ºèµ„æºç«äº‰å’Œè¿›ç¨‹éæ³•æ¨è¿›\nè®¾å¤‡åˆ†é…å¤–éƒ¨è®¾å¤‡æ—¶ã€‚å…ˆåˆ†é…è®¾å¤‡ï¼Œå†åˆ†é…æ§åˆ¶å™¨ï¼Œå†åˆ†é…é€šé“\nå¯ç”¨äºæ–‡ä»¶ç³»ç»Ÿç®¡ç†ç©ºé—²ç£ç›˜å—çš„æ•°æ®ç»“æ„æ˜¯ä½ç¤ºå›¾ã€ç©ºé—²ç›˜å—é“¾ã€æ–‡ä»¶åˆ†é…è¡¨ FAT\nç´¢å¼•æ–‡ä»¶æ—¢åˆ©äºæ–‡ä»¶çš„åŠ¨æ€å¢é•¿ï¼Œä¹Ÿé€‚åˆéšæœºè®¿é—®ã€‚\nPeterson ç®—æ³•å®ç°äº’æ–¥è®¿é—®ï¼Œswap æŒ‡ä»¤ä¸ TestAndSet æŒ‡ä»¤å®ç°å¿™åˆ™ç­‰å¾…ï¼Œä¿¡å·é‡ç®—æ³•å®ç°è®©æƒç­‰å¾…ï¼Œè‡ªæ—‹é”å®ç°ç©ºé—²è®©è¿›\né“¶è¡Œå®¶ç®—æ³•ç ´åäº†æ­»é”å››ä¸ªå¿…è¦æ¡ä»¶çš„å¾ªç¯ç­‰å¾…æ¡ä»¶\næ­»é”çš„å››ä¸ªæ¡ä»¶ä¸ºï¼šäº’æ–¥æ¡ä»¶ã€è¯·æ±‚ä¸ä¿æŒæ¡ä»¶ã€ä¸å¯å‰¥å¤ºæ¡ä»¶ ä»¥åŠ å¾ªç¯ç­‰å¾…æ¡ä»¶\n\n\n# å¸¸ç”¨å…¬å¼é€Ÿè®°\n# è¿›ç¨‹è°ƒåº¦æœ‰å…³å…¬å¼\nTå‘¨è½¬æ—¶é—´=Tç»“æŸæ—¶é—´âˆ’Tæäº¤æ—¶é—´\n\\begin {array}{c}\nT_{\\text{å‘¨è½¬æ—¶é—´}}=T_{\\text{ç»“æŸæ—¶é—´}}-T_{\\text{æäº¤æ—¶é—´}}\n\\end {array}\nTå‘¨è½¬æ—¶é—´â€‹=Tç»“æŸæ—¶é—´â€‹âˆ’Tæäº¤æ—¶é—´â€‹â€‹\nTå¸¦æƒå‘¨è½¬æ—¶é—´=Tå‘¨è½¬æ—¶é—´Tè¿è¡Œæ—¶é—´\n\\begin {array}{c}\nT_{\\text{å¸¦æƒå‘¨è½¬æ—¶é—´}}=\\frac{T_{\\text{å‘¨è½¬æ—¶é—´}}}{T_{\\text{è¿è¡Œæ—¶é—´}}}\n\\end {array}\nTå¸¦æƒå‘¨è½¬æ—¶é—´â€‹=Tè¿è¡Œæ—¶é—´â€‹Tå‘¨è½¬æ—¶é—´â€‹â€‹â€‹\nTå¹³å‡å‘¨è½¬æ—¶é—´=âˆ‘i=1nTiå‘¨è½¬æ—¶é—´n\n\\begin {array}{c}\nT_{\\text{å¹³å‡å‘¨è½¬æ—¶é—´}}=\\frac{\\sum_{i=1}^{n}  {T_{i\\text{å‘¨è½¬æ—¶é—´}}}}{n}\n\\end {array}\nTå¹³å‡å‘¨è½¬æ—¶é—´â€‹=nâˆ‘i=1nâ€‹Tiå‘¨è½¬æ—¶é—´â€‹â€‹â€‹\nTå¹³å‡å¸¦æƒå‘¨è½¬æ—¶é—´=âˆ‘i=1nTiå¸¦æƒå‘¨è½¬æ—¶é—´n\n\\begin {array}{c}\nT_{\\text{å¹³å‡å¸¦æƒå‘¨è½¬æ—¶é—´}}=\\frac{\\sum_{i=1}^{n}  {T_{i\\text{å¸¦æƒå‘¨è½¬æ—¶é—´}}}}{n}\n\\end {array}\nTå¹³å‡å¸¦æƒå‘¨è½¬æ—¶é—´â€‹=nâˆ‘i=1nâ€‹Tiå¸¦æƒå‘¨è½¬æ—¶é—´â€‹â€‹â€‹\nRå“åº”æ¯”=Tå½“å‰å‘¨è½¬æ—¶é—´Tè¿è¡Œæ—¶é—´=Tå½“å‰ç­‰å¾…æ—¶é—´Tè¿è¡Œæ—¶é—´+1\n\\begin {array}{c}\nR_{\\text{å“åº”æ¯”}}=\\frac{T_{\\text{å½“å‰å‘¨è½¬æ—¶é—´}}}{T_{\\text{è¿è¡Œæ—¶é—´}}}=\\frac{T_{\\text{å½“å‰ç­‰å¾…æ—¶é—´}}}{T_{\\text{è¿è¡Œæ—¶é—´}}}+1\n\\end {array}\nRå“åº”æ¯”â€‹=Tè¿è¡Œæ—¶é—´â€‹Tå½“å‰å‘¨è½¬æ—¶é—´â€‹â€‹=Tè¿è¡Œæ—¶é—´â€‹Tå½“å‰ç­‰å¾…æ—¶é—´â€‹â€‹+1â€‹\n# å…¸å‹ä¾‹é¢˜\n# é€»è¾‘åœ°å€è½¬ç‰©ç†åœ°å€\nå·²çŸ¥æŸåˆ†é¡µç³»ç»Ÿï¼Œå†…å­˜å®¹é‡ä¸º 64KBï¼Œé¡µé¢å¤§å°ä¸º 1KBï¼Œå¯¹ä¸€ä¸ª 4 é¡µå¤§çš„ä½œä¸šï¼Œå…¶ 0ã€1ã€2ã€3 é¡µåˆ†åˆ«è¢«åˆ†é…åˆ°å†…å­˜çš„ 2ã€4ã€6ã€7 å—ä¸­ã€‚\nå°†åè¿›åˆ¶çš„é€»è¾‘åœ°å€ 1023 å˜æ¢ä¸ºç‰©ç†åœ°å€ã€‚\nå†…å­˜å®¹é‡64KBâ€”â€”216\n\\begin {array}{c}\nå†…å­˜å®¹é‡64KB â€”â€”2^{16}\n\\end {array}\nå†…å­˜å®¹é‡64KBâ€”â€”216â€‹\né¡µé¢å¤§å°ä¸º1KBâ€”â€”210\n\\begin {array}{c}\né¡µé¢å¤§å°ä¸º1KBâ€”â€”2^{10}\n\\end {array}\né¡µé¢å¤§å°ä¸º1KBâ€”â€”210â€‹\nå…±æœ‰216210=26é¡µ\n\\begin {array}{c}\nå…±æœ‰\\frac{2^{16}}{2^{10}} =2^{6}é¡µ\n\\end {array}\nå…±æœ‰210216â€‹=26é¡µâ€‹\n\n\n\né¡µ\nå—\n\n\n\n\n0\n2\n\n\n1\n4\n\n\n2\n6\n\n\n3\n7\n\n\n\n1023(10)=001111111111(2)\n\\begin {array}{c}\n1023_{(10)} =0011 1111 1111_{(2)}\n\\end {array}\n1023(10)â€‹=001111111111(2)â€‹â€‹\nè½¬æ¢å101111111111(2)=3,071(10)\n\\begin {array}{c}\nè½¬æ¢å 1011 1111 1111_{(2)}=3,071_{(10)}\n\\end {array}\nè½¬æ¢å101111111111(2)â€‹=3,071(10)â€‹â€‹\n","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"æ“ä½œç³»ç»ŸPVä»£ç é¢˜é€Ÿè®°","url":"/Operate-system/OSPVCode/","content":"# æ“ä½œç³»ç»Ÿ PV ä»£ç é¢˜é€Ÿè®°\nè¿›ç¨‹ P å‘ m ä¸ªè¿›ç¨‹ Q1ã€Q2ã€Q3â€¦Qm å‘é€æ¶ˆæ¯ï¼Œè¿›ç¨‹ P å‘æ¶ˆæ¯åˆ°ç¼“å†²åŒºï¼Œåªæœ‰æ‰€æœ‰çš„ Q è¿›ç¨‹éƒ½æ¥æ”¶åˆ°æ¶ˆæ¯åï¼Œè¿›ç¨‹ P æ‰èƒ½ç»§ç»­å‘ç¼“å†²åŒºæ”¾æ¶ˆæ¯ï¼Œè¯·å†™å‡º PV æ“ä½œé€»è¾‘ã€‚\nsemaphore mutex=1, T[i]=0, notHave=1;//mutex æ˜¯ç¼“å†²åŒºäº’æ–¥é”ï¼ŒT [i] æ˜¯ Qi è¿›ç¨‹å®Œæˆæ•°ç»„ï¼Œæ˜¯ä¸€ä¸ªè‡ªé˜»å¡æ•°ç»„//notHave æ˜¯ç¼“å†²åŒºæ˜¯å¦ä¸ºç©ºï¼Œ1 å°±æ˜¯ç©ºï¼Œåˆå§‹æ²¡æœ‰ä¿¡æ¯int R=0;//R æ˜¯ä¸€ä¸ªè®¡æ•°å™¨Process_P()&#123;    while(1)&#123;        P(notHave);        P(mutex);        æ”¾å…¥ç¼“å†²åŒº;        for(int i=1;i&lt;=m;i++)&#123;            P(T[i]);        &#125;        R=0;        V(mutex);    &#125;&#125;Process_Qi()&#123;    while(1)&#123;        P(T[i]);        P(mutex);        å–æ¶ˆæ¯;        R=R+1;        if(R==m)&#123;            V(notHave);        &#125;        V(mutex);    &#125;&#125;# å•ç”Ÿäº§è€… - å•æ¶ˆè´¹è€…\nä¸€ç»„ç”Ÿäº§è€…è¿›ç¨‹å’Œä¸€ç»„æ¶ˆè´¹è€…è¿›ç¨‹å…±äº«ä¸€ä¸ªåˆå§‹ä¸ºç©ºã€å¤§å°ä¸º n çš„ç¼“å†²åŒºï¼šåªæœ‰ç¼“å†²åŒºæ²¡æ»¡æ—¶ï¼Œç”Ÿäº§è€…æ‰èƒ½æŠŠæ¶ˆæ¯æ”¾å…¥ç¼“å†²åŒºï¼Œå¦åˆ™å¿…é¡»ç­‰å¾…ï¼šåªæœ‰ç¼“å†²åŒºä¸ç©ºæ—¶ï¼Œæ¶ˆè´¹è€…æ‰èƒ½ä»ä¸­å–å‡ºæ¶ˆæ¯ï¼Œå¦åˆ™å¿…é¡»ç­‰å¾…ã€‚ç”±äºç¼“å†²åŒºæ˜¯ä¸´ç•Œèµ„æºï¼Œå®ƒåªå…è®¸ä¸€ä¸ªç”Ÿäº§è€…æ”¾å…¥æ¶ˆæ¯ï¼Œæˆ–ä¸€ä¸ªæ¶ˆè´¹è€…ä»ä¸­å–å‡ºæ¶ˆæ¯ã€‚\nsemaphore full = 0;\t// å·²ç”Ÿäº§semaphore empty = n;// æ€»å¯ç”¨ç©ºé—´semaphore mutex = 1;// äº’æ–¥é”procuder()&#123;    while(1)&#123;        ç”Ÿäº§å•†å“;        P(empty);\t// å‡å–ç©ºé—´        P(mutex);\t// åŠ é”        æ”¾å…¥ç¼“å†²åŒº;\t        V(mutex);\t// è§£é”        V(full);\t// å‘ŠçŸ¥ä»¥ç”Ÿäº§    &#125;&#125;consumer()&#123;    while(1)&#123;        P(full);        P(mutex);        ä»ç¼“å†²åŒºå–;        V(mutex);        V(empty);        æ¶ˆè´¹å•†å“;    &#125;&#125;# å¤šç”Ÿäº§è€… - å¤šæ¶ˆè´¹è€…\næ¡Œå­ä¸Šæœ‰ä¸€ä¸ªç›˜å­ï¼Œæ¯æ¬¡åªèƒ½å‘å…¶ä¸­æ”¾å…¥ä¸€ä¸ªæ°´æœï¼›çˆ¸çˆ¸ä¸“å‘ç›˜å­ä¸­æ”¾é©æœï¼Œå¦ˆå¦ˆä¸“å‘ç›˜å­ä¸­æ”¾æ©˜å­ï¼›å„¿å­ä¸“ç­‰åƒç›˜å­ä¸­çš„æ©˜å­ï¼Œå¥³å„¿ä¸“ç­‰åƒç›˜å­ä¸­çš„é©æœï¼Œåªæœ‰ç›˜å­ä¸ºç©ºæ—¶ï¼Œçˆ¸çˆ¸æˆ–å¦ˆå¦ˆæ‰å¯å‘ç›˜å­ä¸­æ”¾ä¸€ä¸ªæ°´æœï¼Œä»…å½“ç›˜å­ä¸­æœ‰è‡ªå·±éœ€è¦çš„æ°´æœæ—¶ï¼Œå„¿å­æˆ–å¥³å„¿å¯ä»¥ä»ç›˜å­ä¸­å–å‡ºã€‚\nsemaphore mutex = 1;\t// ç›˜å­é”semaphore apple = 0;semaphore orange = 0;dad()&#123;    while(1)&#123;        å‡†å¤‡è‹¹æœ;        P(mutex);        æ”¾è‹¹æœ;        V(apple);    &#125;&#125;mom()&#123;    while(1)&#123;        å‡†å¤‡æ©˜å­;        P(mutex);        æ”¾æ©˜å­;        V(orange);    &#125;&#125;son()&#123;    while(1)&#123;        P(orange);        æ‹¿è‹¹æœ;        V(mutex);        åƒè‹¹æœ;    &#125;&#125;daughter()&#123;    while(1)&#123;        P(apple);        æ‹¿è‹¹æœ;        V(mutex);        åƒè‹¹æœ;    &#125;&#125;# è¯»è€…å†™è€…é—®é¢˜ï¼ˆè¯»ä¼˜å…ˆï¼‰\næœ‰è¯»è€…å’Œå†™è€…ä¸¤ç»„å¹¶å‘è¿›ç¨‹ï¼Œå…±äº«ä¸€ä¸ªæ–‡ä»¶ï¼Œå½“ä¸¤ä¸ªæˆ–ä»¥ä¸Šçš„è¯»è¿›ç¨‹åŒæ—¶è®¿é—®å…±äº«æ•°æ®æ—¶ä¸ä¼šäº§ç”Ÿå‰¯ä½œç”¨ã€‚ä½†è‹¥æŸä¸ªå†™è¿›ç¨‹å’Œå…¶ä»–è¿›ç¨‹ï¼ˆè¯»è¿›ç¨‹æˆ–å†™è¿›ç¨‹ï¼‰åŒæ—¶è®¿é—®å…±äº«æ•°æ®æ—¶åˆ™å¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´çš„é”™è¯¯ã€‚\nå› æ­¤è¦æ±‚:\n\nå…è®¸å¤šä¸ªè¯»è€…å¯ä»¥åŒæ—¶å¯¹æ–‡ä»¶æ‰§è¡Œè¯»æ“ä½œã€‚\nåªä¸­è®¸ä¸€ä¸ªå†™è€…å¾€æ–‡ä»¶ä¸­å†™ä¿¡æ¯ã€‚\nä»»ä¸€å†™è€…åœ¨å®Œæˆå†™æ“ä½œä¹‹å‰ä¸å…è®¸å…¶ä»–è¯»è€…æˆ–å†™è€…å·¥ä½œã€‚\nå†™è€…æ‰§è¡Œå†™æ“ä½œå‰ï¼Œåº”è®©å·²æœ‰çš„è¯»è€…å’Œå†™è€…å…¨éƒ¨é€€å‡ºã€‚\n\nsemaphore rw = 1;\t//r-w è¯»è€…åœ¨è¯»æ—¶ï¼Œä¸å®¹è®¸å…¶ä»–å†™è€…åŠ å…¥ã€‚å†™è€…åœ¨å†™æ—¶ï¼Œä¸å®¹è®¸å…¶ä»–è¯»è€…å†™è€…åŠ å…¥ã€‚int count = 0;\t\t// è®°å½•å·²åŠ å…¥çš„è¯»è€…çš„æ•°é‡ï¼Œå¦‚æœä¸ä¸º 0ï¼Œé‚£ä¹ˆå…¶ä¸­å¿…æœ‰è¯»è€…ï¼Œé‚£ä¹ˆå…¶ä»–è¯»è€…éšä¾¿åŠ å…¥ã€‚semaphore count_mutex = 1;writer()&#123;    while(1)&#123;        P(rw);        å†™æ–‡ä»¶;        V(rw);    &#125;&#125;reader()&#123;    while(1)&#123;        P(count_mutex);        if(count == 0)&#123;\t// å¦‚æœä¸ä¸º 0ï¼Œé‚£ä¹ˆå…¶ä¸­å¿…æœ‰è¯»è€…ï¼Œé‚£ä¹ˆå…¶ä»–è¯»è€…éšä¾¿åŠ å…¥ã€‚            P(rw);\t// è¯»è€…ä¸ºæ’é™¤å…¶ä»–å†™è€…        &#125;        count++;\t// åœ¨çº¿åŠ  1        V(count_mutex);        è¯»æ–‡ä»¶;        P(count_mutex);        count--;\t// åœ¨çº¿å‡ 1        if(count == 0)&#123;            V(rw);        &#125;        V(count_mutex);            &#125;&#125;æœ‰å¯èƒ½é€ æˆå†™é¥¥é¥¿\n# è¯»è€…å†™è€…é—®é¢˜ï¼ˆå†™ä¼˜å…ˆï¼‰\nsemaphore rw = 1;int count = 0;semaphore w = 1;\t// å†™è¿›ç¨‹éœ¸å semaphore count_mutex = 1;writer()&#123;    while(1)&#123;        P(w);\t// å†™è¿›ç¨‹å¯ç”¨éœ¸å         P(rw);        å†™æ–‡ä»¶;        V(rw);        V(w);    &#125;&#125;reader()&#123;    while(1)&#123;        P(w);\t// å†™è¿›ç¨‹é˜»ç¢è¯»è¿›ç¨‹è¿›å…¥        P(count_mutex);        if(count == 0)&#123;            P(rw);        &#125;        count++;        V(count_mutex);        V(w);        è¯»æ–‡ä»¶;        P(count_mutex);        count--;        if(count == 0)&#123;            V(rw);        &#125;        V(count_mutex);            &#125;&#125;# å¸çƒŸè€…é—®é¢˜\nå‡è®¾ä¸€ä¸ªç³»ç»Ÿæœ‰ä¸‰ä¸ªæŠ½çƒŸè€…è¿›ç¨‹å’Œä¸€ä¸ªä¾›åº”è€…è¿›ç¨‹ã€‚æ¯ä¸ªæŠ½çƒŸè€…ä¸åœåœ°å·çƒŸå¹¶æŠ½æ‰å®ƒï¼Œä½†è¦å·èµ·å¹¶æŠ½æ‰ä¸€æ”¯çƒŸï¼ŒæŠ½çƒŸè€…éœ€è¦æœ‰ä¸‰ç§ææ–™ï¼šçƒŸè‰ã€çº¸å’Œèƒ¶æ°´ã€‚ä¸‰ä¸ªæŠ½çƒŸè€…ä¸­ï¼Œç¬¬ä¸€ä¸ªæ‹¥æœ‰çƒŸè‰ï¼Œç¬¬äºŒä¸ªæ‹¥æœ‰çº¸ï¼Œç¬¬ä¸‰ä¸ªæ‹¥æœ‰èƒ¶æ°´ã€‚ä¾›åº”è€…è¿›ç¨‹æ— é™åœ°æä¾›ä¸‰ç§ææ–™ï¼Œä¾›åº”è€…æ¯æ¬¡å°†ä¸¤ç§ææ–™æ”¾åˆ°æ¡Œå­ä¸Šï¼Œæ‹¥æœ‰å‰©ä¸‹é‚£ç§ææ–™çš„æŠ½çƒŸè€…å·ä¸€æ ¹çƒŸå¹¶æŠ½æ‰å®ƒï¼Œå¹¶ç»™ä¾›åº”è€…ä¸€ä¸ªä¿¡å·å‘Šè¯‰å·²å®Œæˆï¼Œæ­¤æ—¶ä¾›åº”è€…å°±ä¼šå°†å¦å¤–ä¸¤ç§ææ–™æ”¾åˆ°æ¡Œä¸Šï¼Œå¦‚æ­¤é‡å¤ (è®©ä¸‰ä¸ªæŠ½çƒŸè€…è½®æµåœ°æŠ½çƒŸ)ã€‚\nsemaphore offer1 = 0;semaphore offer2 = 0;semaphore offer3 = 0;semaphore isFinish = 1;int i = 0;provider()&#123;    while(1)&#123;        P(isFinish);    \tif(i%3 == 0)&#123;        \tV(offer1);    \t&#125;else if(i%3 == 1)&#123;        \tV(offer2);    \t&#125;else&#123;        \tV(offer3);    \t&#125;    &#125;    &#125;somker1()&#123;    while(1)&#123;        P(offer1);    \tåˆ¶ä½œé¦™çƒŸ;    \tå¸çƒŸ;        V(isFinish);    &#125; &#125;somker2()&#123;    while(1)&#123;        P(offer2);    \tåˆ¶ä½œé¦™çƒŸ;    \tå¸çƒŸ;        V(isFinish);    &#125; &#125;somker3()&#123;    while(1)&#123;        P(offer3);    \tåˆ¶ä½œé¦™çƒŸ;    \tå¸çƒŸ;        V(isFinish);    &#125; &#125;# PV å®¡é¢˜æµç¨‹\n\nçœ‹æœ‰å‡ ä¸ªè¿›ç¨‹\nè¿›ç¨‹å†…éƒ¨çš„æ­¥éª¤\næ˜¯å¦éœ€è¦ whileï¼ˆ1ï¼‰\nå“ªé‡Œæœ‰ Pï¼Ÿæœ‰ P å¿…æœ‰ V\nè¿ç»­ P æ˜¯å¦ä¼šæ­»é”\nå®šä¹‰ä¿¡å·é‡ï¼Œå†™æ³¨é‡Š\n\n# é¢˜ç›®å®æ“\n# 2020 ç»Ÿè€ƒçœŸé¢˜\nã€2020 ç»Ÿè€ƒçœŸé¢˜ã€‘ç°æœ‰ 5 ä¸ªæ“ä½œ Aã€Bã€Cã€D å’Œ Eï¼Œæ“ä½œ C å¿…é¡»åœ¨ A å’Œ B å®Œæˆåæ‰§è¡Œæ“ä½œ E å¿…é¡»åœ¨ C å’Œ D å®Œæˆåæ‰§è¡Œï¼Œè¯·ä½¿ç”¨ä¿¡å·é‡çš„ waitï¼ˆï¼‰ã€signalï¼ˆï¼‰æ“ä½œï¼ˆPã€V æ“ä½œï¼‰æè¿°ä¸Šè¿°æ“ä½œä¹‹é—´çš„åŒæ­¥å…³ç³»ï¼Œå¹¶è¯´æ˜æ‰€ç”¨ä¿¡å·é‡åŠå…¶åˆå€¼ã€‚\nsemaphore ac = 0;semaphore bc = 0;semaphore ce = 0;semaphore ce = 0;A()&#123;    æ‰§è¡Œä»»åŠ¡;    V(ac);&#125;B()&#123;    æ‰§è¡Œä»»åŠ¡;    V(bc);&#125;C()&#123;    P(ac);    P(bc);    æ‰§è¡Œä»»åŠ¡;    V(ce);&#125;D()&#123;    æ‰§è¡Œä»»åŠ¡;    V(de);&#125;C()&#123;    P(ce);    P(de);    æ‰§è¡Œä»»åŠ¡;&#125;ã€2009 ç»Ÿè€ƒçœŸé¢˜ã€‘ä¸‰ä¸ªè¿›ç¨‹ P1,P2,P3, äº’æ–¥ä½¿ç”¨ä¸€ä¸ªåŒ…å« N (N&gt;0) ä¸ªå•å…ƒçš„ç¼“å†²åŒºã€‚\n\nP1 æ¯æ¬¡ç”¨ produce () ç”Ÿæˆä¸€ä¸ªæ­£æ•´æ•°å¹¶ç”¨ put () é€å…¥ç¼“å†²åŒºæŸä¸€ç©ºå•å…ƒï¼›\nP2 æ¯æ¬¡ç”¨ getodd () ä»è¯¥ç¼“å†²åŒºä¸­å–å‡ºä¸€ä¸ªå¥‡æ•°å¹¶ç”¨ countodd () ç»Ÿè®¡å¥‡æ•°ä¸ªæ•°ï¼›\nP3 æ¯æ¬¡ç”¨ geteven () ä»è¯¥ç¼“å†²åŒºä¸­å–å‡ºä¸€ä¸ªå¶æ•°å¹¶ç”¨ counteven () ç»Ÿè®¡å¶æ•°ä¸ªæ•°ã€‚\n\nè¯·ç”¨ä¿¡å·é‡æœºåˆ¶å®ç°è¿™ä¸‰ä¸ªè¿›ç¨‹çš„åŒæ­¥ä¸äº’æ–¥æ´»åŠ¨ï¼Œå¹¶è¯´æ˜æ‰€å®šä¹‰çš„ä¿¡å·é‡çš„å«ä¹‰ (è¦æ±‚ç”¨ä¼ªä»£ç æè¿°)ã€‚\nsemaphore mutex = 1;semaphore odd = 0;semaphore even = 0;P1()&#123;    while(1)&#123;        int num = produce();        if(num%2 == 0)&#123;            P(mutex);            put();            V(mutex);            V(even);        &#125;else&#123;            P(mutex);            put();            V(mutex);            V(odd);        &#125;    &#125;&#125;P2()&#123;    while(1)&#123;        P(odd);        P(mutex);        getodd();        V(mutex);        countodd()    &#125;&#125;P2()&#123;    while(1)&#123;        P(even);        P(mutex);        geteven();        V(mutex);        counteven()    &#125;&#125;# 2011 ç»Ÿè€ƒçœŸé¢˜\nã€2011 ç»Ÿè€ƒçœŸé¢˜ã€‘æŸé“¶è¡Œæä¾› 1 ä¸ªæœåŠ¡çª—å£å’Œ 10 ä¸ªä¾›é¡¾å®¢ç­‰å¾…çš„åº§ä½ã€‚é¡¾å®¢åˆ°è¾¾é“¶è¡Œæ—¶è‹¥æœ‰ç©ºåº§ä½ï¼Œåˆ™åˆ°å–å·æœºä¸Šé¢†å–ä¸€ä¸ªå·ï¼Œç­‰å¾…å«å·ã€‚å–å·æœºæ¯æ¬¡ä»…å…è®¸ä¸€ä½é¡¾å®¢ä½¿ç”¨ã€‚å½“è¥ä¸šå‘˜ç©ºé—²æ—¶ï¼Œé€šè¿‡å«å·é€‰å–ä¸€ä½é¡¾å®¢ï¼Œå¹¶ä¸ºå…¶æœåŠ¡ã€‚\nsemaphore count = 10;semaphore mutex = 1;semaphore server = 1;semaphore full = 0;customer()&#123;    while(1)&#123;        P(count);        P(mutex);    \tä»å–å·æœºå–å·;    \tV(mutex);    \tV(full);    \tç­‰å¾…å«å·;    \tP(server);    \tè·å–æœåŠ¡;    &#125;    &#125;clerk()&#123;    while(1)&#123;        P(full);        å«å·;        V(server);        æœåŠ¡;        V(count);    &#125;    &#125;# 809-24 å¹´ çœŸé¢˜\nå´‚å±±æœ‰ä¸€æ™¯ç‚¹ç§°ä½œä¸Šæ¸…å®«ï¼Œæ¸¸å®¢åœ¨ä¸Šæ¸…å®«æ¸¸ç©åå¯ä»¥åœ¨å®«é—¨å£å…è´¹æ­ä¹˜è½¿è½¦æ¸¸è§ˆå…¶ä»–æ™¯åŒºï¼Œæ¸¸è§ˆåå†è¿”å›å®«é—¨å£ã€‚å·²çŸ¥é£æ™¯åŒºæ¸¸è§ˆè½¿è½¦æ€»é‡æœ‰ M é‡ï¼Œæ¸¸å®¢æ€»æ•°ä¸º Nï¼Œçº¦å®š:\n\næ¯è¾†è½¿è½¦é™ä¹˜ä¸€ä½æ¸¸å®¢ï¼›\nå¦‚æœæœ‰ç©ºé—²çš„è½¿è½¦ï¼Œåº”å½“å…è®¸æƒ³æ¸¸è§ˆçš„æ¸¸å®¢ä¹˜åï¼›\næ— ç©ºé—²è½¿è½¦æ—¶ï¼Œæ¸¸å®¢åªèƒ½æ’é˜Ÿç­‰å¾…ï¼›\nè‹¥æ²¡æœ‰æƒ³æ¸¸è§ˆçš„æ¸¸å®¢ï¼Œç©ºé—²çš„è½¿è½¦ä¹Ÿè¦ç­‰å¾…ã€‚\n\nè¯•åˆ©ç”¨ Pã€V æ“ä½œå®ç°åœ¨ä¸Šæ¸…å®«é—¨å£ä¹˜è½¦ç‚¹ï¼šN ä¸ªæ¸¸å®¢è¿›ç¨‹å’Œ M è¾†è½¿è½¦è¿›ç¨‹çš„åŒæ­¥æ“ä½œè¿‡ç¨‹ã€‚\nsemaphore mutex = 1;semaphore car = 0; \t\t// ç©ºé—²è½¦è¾†æ•°é‡semaphore customer = 0; // ç­‰å¾…ä¹˜è½¦çš„æ¸¸å®¢æ•°é‡//M ä¸ªè½¦è¾†è¿›ç¨‹car()&#123;    while(1)&#123;        ç­‰å¾…æ¸¸å®¢;        P(customer);\t// ç­‰å¾…æœ‰æ¸¸å®¢è¯·æ±‚ä¹˜è½¦        P(mutex);\t\t// è¿›å…¥ä¸´ç•ŒåŒº        V(car);\t\t\t// æä¾›ä¸€è¾†ç©ºé—²è½¿è½¦        V(mutex);\t\t// ç¦»å¼€ä¸´ç•ŒåŒº        æ¥å¾…æ¸¸è§ˆ;        é‡Šæ”¾æ¸¸å®¢;    &#125;&#125;//N ä¸ªæ¸¸å®¢è¿›ç¨‹customer()&#123;    while(1)&#123;        ç­‰å¾…è½¦è¾†;        P(car);\t\t\t// ç­‰å¾…ç©ºé—²è½¿è½¦       \tP(mutex);\t\t// è¿›å…¥ä¸´ç•ŒåŒº        V(customer)\t\t// é€šçŸ¥æœ‰æ¸¸å®¢è¯·æ±‚ä¹˜è½¦        V(mutex);\t\t// ç¦»å¼€ä¸´ç•ŒåŒº        ä¸Šè½¦æ¸¸è§ˆ;        ç¦»å¼€;    &#125;&#125;# å…¸ä¾‹ å’Œå°šæ‰“æ°´\næŸå¯ºåº™æœ‰å°å’Œå°šã€è€å’Œå°šè‹¥å¹²ï¼Œæœ‰ä¸€æ°´ç¼¸ï¼Œç”±å°å’Œå°šææ°´å…¥ç¼¸ä¾›è€å’Œå°šé¥®ç”¨ã€‚æ°´ç¼¸å¯å®¹ 10 æ¡¶æ°´ï¼Œæ°´å–è‡ªåŒä¸€äº•ä¸­ã€‚æ°´äº•å¾„çª„ï¼Œæ¯æ¬¡åªèƒ½å®¹ä¸€ä¸ªæ¡¶å–æ°´ã€‚æ°´æ¡¶æ€»æ•°ä¸º 3 ä¸ªã€‚æ¯æ¬¡å…¥ç¼¸å–æ°´ä»…ä¸º 1 æ¡¶æ°´ï¼Œä¸”ä¸å¯åŒæ—¶è¿›è¡Œï¼Œè¯•ç»™å‡ºæœ‰å…³ä»ç¼¸å–æ°´ã€å…¥æ°´çš„ç®—æ³•æè¿°ã€‚\nsemaphore total_empty = 10;semaphore total_full = 0;semaphore mutex_jing = 1;semaphore mutex_gang = 1;demaphore bucket = 3;Old ()&#123;    P(total_full);    P(bucket);    P(mutex_gang);    ä»ç¼¸é‡Œå–æ°´;    V(total_empty);    V(mutex_gang);\tå–æ°´;    V(bucket);&#125;Young()&#123;    P(total_empty);    P(bucket)    P(mutex_jing);    ä»æ°´äº•å–æ°´;    V(mutex_jing);    P(mutex_gang);\tå€’è¿›ç¼¸é‡Œ;    V(total_full);    V(mutex_gang);    V(bucket);    &#125;# å…¸ä¾‹ å…¬äº¤è½¦å”®ç¥¨\nè®¾å…¬å…±æ±½è½¦ä¸Šï¼Œå¸æœºå’Œå”®ç¥¨å‘˜çš„æ´»åŠ¨åˆ†åˆ«æ˜¯ï¼š\n\nå¸æœºçš„æ´»åŠ¨ï¼šå¯åŠ¨è½¦è¾†ï¼›æ­£å¸¸è¡Œè½¦ï¼›åˆ°ç«™åœè½¦ï¼›\nå”®ç¥¨å‘˜çš„æ´»åŠ¨ï¼šå…³è½¦é—¨ï¼›å”®ç¥¨ï¼›å¼€è½¦é—¨ï¼›\n\nè¯·ç”¨è®°å½•å‹ä¿¡å·é‡æœºåˆ¶å®ç°ä¸Šè¿°é—®é¢˜çš„åŒæ­¥ã€‚\nsemaphore door_mutex = 1;semaphore start_mutex = 0;driver()&#123;    while(1)&#123;        P(start_mutex);        å¯åŠ¨è½¦è¾†;        æ­£å¸¸è¡Œè½¦;        åˆ°ç«™åœè½¦;        V(door_mutex);    &#125;&#125;busman()&#123;    while(1)&#123;        P(door_mutex);        å¼€è½¦é—¨;        å”®ç¥¨;        å…³è½¦é—¨;        V(start_mutex);    &#125;&#125;# å…¸ä¾‹ ç‹¬æœ¨æ¡¥é—®é¢˜\nè¯·ç”¨ä¿¡å·é‡è§£å†³ä»¥ä¸‹çš„ â€œè¿‡ç‹¬æœ¨æ¡¥â€ é—®é¢˜ï¼šåŒä¸€æ–¹å‘çš„è¡Œäººå¯è¿ç»­è¿‡æ¡¥ï¼Œå½“æŸä¸€æ–¹å‘æœ‰äººè¿‡æ¡¥æ—¶ï¼Œå¦ä¸€æ–¹å‘çš„è¡Œäººå¿…é¡»ç­‰å¾…ï¼›å½“æŸä¸€æ–¹å‘æ— äººè¿‡æ¡¥æ—¶ï¼Œå¦ä¸€æ–¹å‘çš„è¡Œäººå¯ä»¥è¿‡æ¡¥ã€‚\nsemaphore isOK = 1;int toACount = 0;int toBCount = 0;semaphore toACount_mutex = 1;semaphore toBCount_mutex = 1;toA()&#123;    P(toACount_mutex);    if(toACount == 0)&#123;        P(isOK);    &#125;    toACount++;    V(toACount_mutex);    ä¸Šæ¡¥èµ°å‘A;    P(toACount_mutex);    toACount--;    if(toACount == 0)&#123;        V(isOK);    &#125;    V(toACount_mutex);&#125;toB()&#123;    P(toBCount_mutex);    if(toBCount == 0)&#123;        P(isOK);    &#125;    toBCount++;\tV(toBCount_mutex);    ä¸Šæ¡¥èµ°å‘B;    P(toBCount_mutex);    toBCount--;    if(toBCount == 0)&#123;        V(isOK);    &#125;\tV(toBCount_mutex);&#125;# å…¸ä¾‹ é˜…è§ˆå®¤é—®é¢˜\næœ‰ä¸€é˜…è§ˆå®¤ï¼Œå…±æœ‰ 100 ä¸ªåº§ä½ã€‚ä¸ºäº†å¾ˆå¥½åˆ©ç”¨å®ƒï¼Œè¯»è€…è¿›å…¥æ—¶å¿…é¡»å…ˆåœ¨ç™»è®°è¡¨ä¸Šè¿›è¡Œç™»è®°ã€‚è¯¥è¡¨è¡¨ç›®è®¾æœ‰åº§ä½å·å’Œè¯»è€…å§“åï¼›ç¦»å¼€æ—¶å†å°†å…¶ç™»è®°é¡¹æ‘ˆé™¤ã€‚è¯•é—®ï¼š\n\nä¸ºæè¿°è¯»è€…çš„åŠ¨ä½œï¼Œåº”è®¾å“ªå‡ ä¸ªè¿›ç¨‹ï¼Ÿå®ƒä»¬ä¹‹é—´çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ\nè¯•ç”¨ Pã€V æ“ä½œæè¿°è¿›ç¨‹ä¹‹é—´çš„åŒæ­¥æˆ–ç®—æ³•ã€‚\n\nç­”ï¼šè¦è®¾è¯»è€…è¿›å…¥è¿›ç¨‹å’Œç¦»å¼€è¿›ç¨‹ï¼Œæ€»è®¡ä¸¤ä¸ªè¿›ç¨‹ã€‚ä»–ä»¬æ˜¯äº’æ–¥å…³ç³»ã€‚\nsemaphore seats = 100;semaphore readers = 0;semaphore table_mutex = 1;getIn()&#123;    while(1)&#123;        P(seats);        P(table_mutex);        ç™»è®°;        V(table_mutex);        V(readers);    &#125;&#125;getOut()&#123;    while(1)&#123;        P(readers);        P(table_mutex);        ç§»é™¤ç™»è®°;        V(table_mutex);        V(seats);    &#125;&#125;# å…¸ä¾‹ è€ƒè¯•é—®é¢˜\nã€Šæ“ä½œç³»ç»Ÿã€‹è¯¾ç¨‹çš„æœŸæœ«è€ƒè¯•å³å°†ä¸¾è¡Œï¼Œå‡è®¾æŠŠå­¦ç”Ÿå’Œç›‘è€ƒè€å¸ˆéƒ½çœ‹ä½œè¿›ç¨‹ï¼Œå­¦ç”Ÿæœ‰ N äººï¼Œæ•™å¸ˆ 1 äººã€‚è€ƒåœºé—¨å£æ¯æ¬¡åªèƒ½è¿›å‡ºä¸€ä¸ªäººï¼Œè¿›è€ƒåœºçš„åŸåˆ™æ˜¯å…ˆæ¥å…ˆè¿›ã€‚å½“ N ä¸ªå­¦ç”Ÿéƒ½è¿›å…¥äº†è€ƒåœºåï¼Œæ•™å¸ˆæ‰èƒ½å‘å·å­ã€‚å­¦ç”Ÿäº¤å·åå³å¯ç¦»å¼€è€ƒåœºï¼Œè€Œæ•™å¸ˆè¦ç­‰æ”¶ä¸Šæ¥å…¨éƒ¨å·å­å¹¶å°è£…å·å­åæ‰èƒ½ç¦»å¼€è€ƒåœºã€‚\n(1) é—®å…±éœ€è®¾ç½®å‡ ä¸ªè¿›ç¨‹ï¼Ÿ\n(2) è¯·ç”¨ Pã€V æ“ä½œè§£å†³ä¸Šè¿°é—®é¢˜ä¸­çš„åŒæ­¥å’Œäº’æ–¥å…³ç³»ã€‚\nç­”ï¼šå…±è®¾ç½® N+1 ä¸ªè¿›ç¨‹ï¼Œä¸€ä¸ªæ•™å¸ˆè¿›ç¨‹ï¼ŒN ä¸ªå­¦ç”Ÿè¿›ç¨‹\nint studentCount = 0;int onPageCount = 0;semaphore door_mutex = 1;semaphore startTest = 0;semaphore endTest = 0;semaphore readyToTest = 0;semaphore onPageCount_mutex = 1;semaphore allStudentsOK = 0;teacher()&#123;    P(door_mutex);    è¿›é—¨;    V(door_mutex);    P(readyToTest);    å‘å·å­;    V(startTest);    ç›‘è€ƒ;    P(allStudentsOK);    æ•´ç†è¯•å·;    P(door_mutex);    å‡ºé—¨;    V(door_mutex);&#125;students()&#123;    P(door_mutex);    è¿›é—¨;    studentCount++;    if(studentCont == N)&#123;        V(readyToTest);    &#125;    V(door_mutex);    P(startTest);    å¼€å§‹ç­”é¢˜;    P(onPageCount_mutex);    äº¤å·;    onPageCount++;    if(onPageCount == N)&#123;        V(allStudentsOK);    &#125;    V(onPageCount_mutex);    P(door_mutex);    å‡ºé—¨;    studentCount--;    V(door_mutex);&#125;\n          \n          hunter_wyh CSDN åšå®¢\n          éƒ¨åˆ†é¢˜ç›®å‡ºè‡ªæ­¤åšå®¢\n          ","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"CPUä¸å­˜å‚¨å™¨çš„è¿æ¥","url":"/Principles-of-computer-composition/Connection_between_CPU_and_memory/","content":"# å‰è¨€\né’ˆå¯¹è¿™ä¸€éƒ¨åˆ†å†…å®¹æˆ‘è¿˜æ˜¯æ¨èå¤§å®¶å»çœ‹çœ‹ä¹¦æœ¬ä¸Šå’Œå…¶ä»–æ•™å­¦è§†é¢‘é‡Œçš„å†…å®¹ï¼Œæœ¬ç¯‡æ–‡ç« åªé’ˆå¯¹è®¡ç®—æœºç»„æˆåŸç†ï¼ˆç¬¬ 3 ç‰ˆï¼‰P91 é¡µä¹‹åçš„å†…å®¹è¿›è¡Œç®€å•æ•´ç†æ±‡æ€»ã€‚\næ¥ä¸‹æ¥æˆ‘å°†ä¼šæŒ‰ç…§ä¹¦ä¸Šçš„é¡ºåºè¿›è¡Œå™è¿°ã€‚\n# CPU ä¸å­˜å‚¨å™¨çš„è¿æ¥\n# å­˜å‚¨å™¨å®¹é‡æ‰©å±•\n# å­—æ‰©å±•\nåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå­—æ‰©å±•å¯ä»¥è¢«è§†ä¸ºä¸€ç§æ‰©å®¹æ“ä½œã€‚å­—æ‰©å±•é€šå¸¸æŒ‡çš„æ˜¯å°†ä¸€ä¸ªå­—ç¬¦æˆ–å­—ç¬¦ä¸²è½¬æ¢ä¸ºå…·æœ‰æ›´å¤šä½æ•°æˆ–æ›´é«˜ç²¾åº¦çš„æ•°æ®ç±»å‹ï¼Œä»¥ä¾¿è¿›è¡Œæ›´å¤æ‚çš„è®¡ç®—æˆ–å­˜å‚¨æ›´å¤§çš„å€¼ã€‚è¿™ä¸ªè¿‡ç¨‹å¯èƒ½æ¶‰åŠåˆ°å†…å­˜åˆ†é…å’Œé‡æ–°åˆ†é…ï¼Œå› æ­¤å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§æ‰©å®¹æ“ä½œã€‚ä½†æ˜¯ï¼Œåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œå­—æ‰©å±•å¯èƒ½åªæ˜¯ç®€å•åœ°å°†ä¸€ä¸ªå­—ç¬¦æˆ–å­—ç¬¦ä¸²è¿›è¡Œæ ¼å¼åŒ–æˆ–è§£ç ï¼Œè€Œä¸æ¶‰åŠä»»ä½•å†…å­˜æ“ä½œã€‚å› æ­¤ï¼Œæ˜¯å¦å°†å­—æ‰©å±•è§†ä¸ºæ‰©å®¹å–å†³äºå…·ä½“çš„ä¸Šä¸‹æ–‡å’Œå®ç°æ–¹å¼ã€‚\nä½†æ˜¯æˆ‘ä»¬å¯ä»¥ç®€å•åœ°æŠŠå­—æ‰©å±•ç†è§£ä¸ºæ‰©å®¹ã€‚\næ¯”å¦‚ï¼Œä¸¤ç‰‡ 1K*8 ä½é€šè¿‡å­—æ‰©å±•æ‰©å®¹ä½é€»è¾‘ä¸Šçš„ä¸€ç‰‡ 2K*8 ä½\n# ä½æ‰©å±•\nä½æ‰©å±•æ˜¯ä¸€ç§å°†ä¸€ä¸ªäºŒè¿›åˆ¶æ•°å€¼çš„ä½æ•°å¢åŠ çš„æ“ä½œã€‚åœ¨ä½æ‰©å±•ä¸­ï¼Œå¦‚æœåŸå§‹äºŒè¿›åˆ¶æ•°å€¼çš„æœ€é«˜ä½ä¸º 0ï¼Œåˆ™åœ¨å…¶å·¦ä¾§æ·»åŠ  0 ä»¥å¢åŠ ä½æ•°ï¼›å¦‚æœæœ€é«˜ä½ä¸º 1ï¼Œåˆ™åœ¨å…¶å·¦ä¾§æ·»åŠ  1 ä»¥ä¿æŒç¬¦å·ä¸å˜ã€‚ä¾‹å¦‚ï¼Œå°† 8 ä½äºŒè¿›åˆ¶æ•°å€¼ &quot;00110110&quot; è¿›è¡Œä½æ‰©å±•ä¸º 16 ä½ï¼Œåˆ™ç»“æœä¸º &quot;00000000 00110110&quot;ã€‚ä½æ‰©å±•é€šå¸¸ç”¨äºå°†ä½ç²¾åº¦æ•°æ®ç±»å‹è½¬æ¢ä¸ºé«˜ç²¾åº¦æ•°æ®ç±»å‹ï¼Œæˆ–è€…åœ¨è¿›è¡Œç®—æœ¯è¿ç®—æ—¶å¯¹æ“ä½œæ•°è¿›è¡Œå¯¹é½ã€‚\nå’³å’³å’³ï¼Œç®€å•ç†è§£å°±æ˜¯äºŒè¿›åˆ¶åŠ é•¿\n# å­—ä½æ‰©å±•\nå­—ä½æ‰©å±•æ˜¯ä¸€ç§å°†ä¸€ä¸ªæ•°æ®ç±»å‹çš„ä½æ•°å¢åŠ çš„æ“ä½œï¼Œå…¶ä¸­ â€œå­—â€ æŒ‡çš„æ˜¯è®¡ç®—æœºä¸­çš„ä¸€ä¸ªå›ºå®šå¤§å°çš„æ•°æ®å•å…ƒã€‚åœ¨å­—ä½æ‰©å±•ä¸­ï¼Œå¦‚æœåŸå§‹æ•°æ®ç±»å‹çš„æœ€é«˜ä½ä¸º 0ï¼Œåˆ™åœ¨å…¶å·¦ä¾§æ·»åŠ  0 ä»¥å¢åŠ ä½æ•°ï¼›å¦‚æœæœ€é«˜ä½ä¸º 1ï¼Œåˆ™åœ¨å…¶å·¦ä¾§æ·»åŠ  1 ä»¥ä¿æŒç¬¦å·ä¸å˜ã€‚ä¾‹å¦‚ï¼Œå°† 16 ä½æœ‰ç¬¦å·æ•´æ•°è¿›è¡Œå­—ä½æ‰©å±•ä¸º 32 ä½ï¼Œåˆ™ç»“æœä¸ºåœ¨æœ€é«˜ä½ä¹‹å‰æ·»åŠ  16 ä¸ªç›¸åŒçš„ç¬¦å·ä½ã€‚å­—ä½æ‰©å±•é€šå¸¸ç”¨äºå°†ä½ç²¾åº¦æ•°æ®ç±»å‹è½¬æ¢ä¸ºé«˜ç²¾åº¦æ•°æ®ç±»å‹ï¼Œæˆ–è€…åœ¨è¿›è¡Œç®—æœ¯è¿ç®—æ—¶å¯¹æ“ä½œæ•°è¿›è¡Œå¯¹é½ã€‚\nç®€å•ç†è§£å°±æ˜¯â€¦ ç»“åˆç‰ˆ\n# ä¾‹é¢˜\næ€ä¹ˆå‡ºé¢˜å‘¢ï¼Ÿä¸€èˆ¬éƒ½åƒè¿™æ ·ï¼š\nCPU æœ‰ 16 æ ¹åœ°å€çº¿ã€8 æ ¹æ•°æ®çº¿ï¼Œå¹¶ç”¨ MREQ éä½œä¸ºè®¿å­˜æ§åˆ¶ä¿¡å·ï¼ˆä½ç”µé¢‘æœ‰æ•ˆï¼‰ï¼Œç”¨ WR ä½œä¸ºè¯» / å†™æ§åˆ¶ä¿¡å·ã€‚ç°åœ¨æœ‰å¦‚ä¸‹å­˜å‚¨èŠ¯ç‰‡ï¼š1K X 4 ä½ RAMã€4K X 8 ä½ RAMã€8K X 8 ä½ RAMã€2K X 8 ä½ ROMã€4K X 8 ä½ ROMã€8K X 8 ä½ ROM åŠ 74138 è¯‘ç å™¨å’Œå„ç§é—¨ç”µè·¯ã€‚ç°è¦æ±‚å¦‚ä¸‹ï¼š\n\nä¸»å­˜åœ°å€ç©ºé—´åˆ†é…ï¼š\n\n6000H ~ 67FFH ä¸ºç³»ç»Ÿç¨‹åºåŒº\n6800H ~ 6BFFH ä¸ºç”¨æˆ·ç¨‹åºåŒº\n\n\nåˆç†é€‰ç”¨ä¸Šè¿°å­˜å‚¨èŠ¯ç‰‡ï¼Œè¯´æ˜å„é€‰å‡ ç‰‡\nè¯¦ç»†ç”»å‡ºèŠ¯ç‰‡ç‰‡é€‰é€»è¾‘å›¾\n\n# è§£ï¼ï¼\nç¬¬ä¸€æ­¥ï¼šå†™å‡ºåœ°å€ç©ºé—´åˆ†é…èŒƒå›´äºŒè¿›åˆ¶ç \n6000H ~ 67FFH ä¸ºç³»ç»Ÿç¨‹åºåŒº\n6800H ~ 6BFFH ä¸ºç”¨æˆ·ç¨‹åºåŒº\n6000Hã€67FFHã€6800Hã€6BFFH åŒ–ä¸ºäºŒè¿›åˆ¶ï¼š\n\n\n\nA15\nA14\nA13\nA12\nA11\nA10\nA9\nA8\nA7\nA6\nA5\nA4\nA3\nA2\nA1\nA0\n\n\n\n\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\né¦–å…ˆï¼Œå…ˆç¡®å®šèŠ¯ç‰‡ï¼Œå…¨é›¶åˆ°å…¨ä¸€å°±æ˜¯ä¸€ä¸ªèŠ¯ç‰‡\nå…ˆçœ‹ ROMï¼Œä¹Ÿå°±æ˜¯ç³»ç»ŸåŒºï¼š\n\n\n\nA15\nA14\nA13\nA12\nA11\nA10\nA9\nA8\nA7\nA6\nA5\nA4\nA3\nA2\nA1\nA0\n\n\n\n\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\nA0 ~ A10 ä¸ºä¸€ä¸ª ROMï¼Œä¸€å…± 11 ä½ï¼Œç†æƒ³æ˜¯è¦ä¸€ä¸ªè§„æ ¼ä¸º 2K X 8 ä½ ROM\nå†æ¥çœ‹ RAM ï¼Œä¹Ÿå°±æ˜¯ç”¨æˆ·åŒºï¼š\n\n\n\nA15\nA14\nA13\nA12\nA11\nA10\nA9\nA8\nA7\nA6\nA5\nA4\nA3\nA2\nA1\nA0\n\n\n\n\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\nA0 ~ A9 ä¸ºä¸€ä¸ª RAMï¼Œä¸€å…± 10 ä½ï¼Œç†æƒ³æ˜¯è¦ä¸€ä¸ªè§„æ ¼ä¸º 1K X 8 ä½ RAM\nç„¶åå‘¢ï¼Œæˆ‘ä»¬éœ€è¦å¯¹ ROM å’Œ RAM è¿›è¡Œè¯»å†™ï¼Œè¿™å°±æ¶‰åŠåˆ°åˆ‡æ¢ ROM å’Œ RAM èŠ¯ç‰‡çš„é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å¼„ä¸€ä¸ªç‰‡é€‰ä¿¡å·ï¼š\n\n\n\nA15\nA14\nA13\nA12\nA11\nA10\nA9\nA8\nA7\nA6\nA5\nA4\nA3\nA2\nA1\nA0\n\n\n\n\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\nä¸Šä¸¤è¡Œæ˜¯ ROMï¼Œä¸‹ä¸¤è¡Œæ˜¯ RAMï¼Œå¯ä»¥çœ‹åˆ° A11 åŠå…¶å…³é”®çš„å†³å®šäº†åˆ°åº•é€‰æ‹©å“ªä¸€ä¸ªèŠ¯ç‰‡ï¼Œæ˜¯ ROM è¿˜æ˜¯ RAMã€‚å½“ A11 ä¸º 0 æ—¶ ROM è¢«é€‰ä¸­ï¼Œå½“ A11 ä¸º 1 æ—¶ RAM è¢«é€‰ä¸­ã€‚\nç„¶è€Œ 74138 è¯‘ç å™¨éœ€è¦ä¸‰ä¸ªæ•°æ®è¾“å…¥ç«¯ï¼Œè¿™æ—¶å€™æˆ‘ä»¬å°±éœ€è¦å†æ‹‰æ¥ä¸¤ä¸ªå«èƒŒçš„ A12 ä¸ A13ã€‚\n\n\n\nA15\nA14\nA13\nA12\nA11\nA10\nA9\nA8\nA7\nA6\nA5\nA4\nA3\nA2\nA1\nA0\n\n\n\n\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\nA11 A12 A13 ä¸€æ¬¡æ’åˆ—è¿æ¥è‡³ 74138 çš„æ•°æ®è¾“å…¥ç«¯ A B Cï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼ï¼ä½ä½æ˜¯èµ·å§‹ç‚¹ Aï¼Œé«˜ä½æ—¶ç»ˆç‚¹ Cã€‚\næ•°æ®ä¸º 100 æ—¶ ROM è¢«é€‰ä¸­ï¼Œ74138Y4 éç«¯è¢«ç‚¹äº®ï¼Œå› ä¸º 100 æ­£æ˜¯æ•°å­— 4ã€‚\næ•°æ®ä¸º 101 æ—¶ RAM è¢«é€‰ä¸­ï¼Œ74138Y4 éç«¯è¢«ç‚¹äº®ï¼Œå› ä¸º 101 æ­£æ˜¯æ•°å­— 5ã€‚\næ¥ä¸‹æ¥å†è®¨è®ºè®¨è®ºèŠ¯ç‰‡çš„é€‰æ‹©ï¼š\nA0 ~ A10 ä¸ºä¸€ä¸ª ROMï¼Œä¸€å…± 11 ä½ï¼Œç†æƒ³æ˜¯è¦ä¸€ä¸ªè§„æ ¼ä¸º 2K X 8 ä½ ROM\nA0 ~ A9 ä¸ºä¸€ä¸ª RAMï¼Œä¸€å…± 10 ä½ï¼Œç†æƒ³æ˜¯è¦ä¸€ä¸ªè§„æ ¼ä¸º 1K X 8 ä½ RAM\nå¯¹äº ROMï¼Œé¢˜ä¸­åˆšå¥½æœ‰ä¸€ä¸ªè§„æ ¼ä¸º 2K X 8 ä½çš„ ROM èŠ¯ç‰‡ï¼Œæ‹¿æ¥ä¾¿æ˜¯ï¼\nå¯¹äº RAMï¼Œé¢˜ä¸­æ²¡æœ‰é‚£ä¸ªè§„æ ¼çš„æˆ‘ä»¬è¿™é‡Œå°±éœ€è¦è¿›è¡Œæ‰©å±•ï¼Œè¿™é‡Œæˆ‘ä»¬é€‰æ‹©ä¸¤ç‰‡ 1K X 4 ä½çš„ ROM èŠ¯ç‰‡å¯¹ä»–è¿›è¡Œä½æ‰©å±•å°±å¥½äº†ã€‚ä½æ‰©å±• ä½æ‰©å±• ä½æ‰©å±•ï¼Œè¯´æ˜å®ƒä½æ•°ä¸å¤Ÿï¼Œæ•°æ®ä¸€æ¬¡æ— æ³•å†™è¿›ä¸€ä¸ªèŠ¯ç‰‡ï¼Œä½†æ˜¯ä¸€æ¬¡å¯ä»¥å†™è¿›ä¸¤ä¸ªèŠ¯ç‰‡ã€‚è¿™æ ·å°±è§£å†³äº†ï¼\n# æ€»ç»“\nCPU ä¸å­˜å‚¨å™¨çš„è¿æ¥æ˜¯è®¡ç®—æœºè®¡ç®—æœºç»„æˆåŸç†ä¸­çš„é‡è¦è€ƒé¢˜ï¼Œæ›´æ˜¯æœŸæœ«è€ƒè¯•ä¸­çš„é‡ç‚¹ï¼Œçœ‹ç€å¾ˆå¤æ‚çš„è¿æ¥å›¾ï¼Œä½†å…¶å®å†…åœ¨çš„åŸç†è¿˜æ˜¯å¾ˆç®€å•çš„ï¼Œæ— éå°±æ˜¯ï¼šå†™äºŒè¿›åˆ¶ã€é€‰èŠ¯ç‰‡ã€æ‰©å±•å¤–å¸¦ç”»å›¾è¿æ¥ï¼Œæœ¬è´¨è¿˜æ˜¯æ¯”è¾ƒå®¹æ˜“ä½œçš„\n","categories":["è®¡ç®—æœºç»„æˆåŸç†"],"tags":["è®¡ç®—æœºç»„æˆåŸç†"]},{"title":"æ“ä½œç³»ç»Ÿè¯¾ç¨‹è®¾è®¡","url":"/Operate-system/kcsj/","content":"# è™šæ‹Ÿå­˜å‚¨å™¨ç®¡ç†\n \n# ä»€ä¹ˆæ˜¯è™šæ‹Ÿå­˜å‚¨å™¨ï¼Ÿ\nâ€‹ è™šæ‹Ÿå­˜å‚¨å™¨æ˜¯ä¸€ç§è®¡ç®—æœºå†…å­˜ç®¡ç†æŠ€æœ¯ï¼Œå®ƒé€šè¿‡å°†è®¡ç®—æœºçš„ç¡¬ç›˜ç©ºé—´ä½œä¸ºè¾…åŠ©å­˜å‚¨å™¨ï¼Œå…è®¸ç¨‹åºä½¿ç”¨æ¯”ç‰©ç†å†…å­˜æ›´å¤§çš„åœ°å€ç©ºé—´ã€‚è™šæ‹Ÿå­˜å‚¨å™¨çš„ç›®æ ‡æ˜¯æä¾›æ›´å¤§çš„å¯ç”¨å†…å­˜ç©ºé—´ï¼Œä»¥ä¾¿åŒæ—¶è¿è¡Œæ›´å¤šçš„ç¨‹åºï¼Œè€Œä¸å—ç‰©ç†å†…å­˜çš„é™åˆ¶ã€‚\nâ€‹ è™šæ‹Ÿå­˜å‚¨çš„å®ç°æ˜¯åŸºäºå±€éƒ¨å­˜å‚¨åŸç†çš„ï¼Œè¦ç†è§£è™šæ‹Ÿå­˜å‚¨æˆ‘ä»¬å°±è¦å»ç†è§£å±€éƒ¨å­˜å‚¨çš„æ˜¯å®ç°ï¼Œå³ï¼šåˆ†é¡µå­˜å‚¨ã€åˆ†æ®µå­˜å‚¨ã€æ®µé¡µå¼å­˜å‚¨ã€‚\nï¼ˆè¿™é‡Œæˆ‘ä»¬é‡ç‚¹æŒæ¡å…·æœ‰å—è¡¨çš„åˆ†é¡µå­˜å‚¨ï¼‰\n# è¯¾ç¨‹è®¾è®¡æ ¸å¿ƒç›®çš„ï¼Ÿ\nå°†é€»è¾‘åœ°å€è½¬ä¸ºç‰©ç†åœ°å€\n# é¡µè¡¨ï¼Ÿ\n\n\n\né¡µå·\nå—å·\n\n\n\n\n0\n0\n\n\n1\n2\n\n\n2\n4\n\n\n3\n6\n\n\n\né’ˆå¯¹è¿™ä¸ªè¯¾ç¨‹è®¾è®¡ï¼Œæˆ‘ä»¬ç®€å•çš„ç†è§£ä¸ºåº”ç”¨é¡µè¡¨å°±æ˜¯é€šè¿‡é¡µå·ï¼Œæ¥å»æ‰¾åˆ°å—å·\n\nç”±è™šæ‹Ÿåœ°å€ï¼ˆé€»è¾‘åœ°å€ï¼‰è½¬æ¢ä¸ºç‰©ç†åœ°å€ï¼Œè¿™å°±æ˜¯é¡µè¡¨æœ€æ ¸å¿ƒçš„ä½œç”¨ï¼\n# ä¸ºä»€ä¹ˆè¦ç”¨è™šæ‹Ÿå†…å­˜\nä½†æ˜¯ï¼Œæˆ‘ä»¬çš„å†…å­˜å¾ˆå°ï¼Œè¿˜æƒ³è¿è¡Œå¤šä¸ªåº”ç”¨ç¨‹åºï¼Œè¿™å¿…ç„¶æ— æ³•æ»¡è¶³æ‰€æœ‰çš„æœ‰çš„åº”ç”¨ç¨‹åºä¸€æ¬¡æ€§å…¨éƒ¨åŠ è½½åˆ°å†…å­˜ä¹‹ä¸­ã€‚æ ¹æ®å±€éƒ¨æ€§ç†è®ºåŸºç¡€ï¼Œæˆ‘ä»¬åˆå¼•ç”³å‡ºé¡µé¢çš„å¯¹æ¢ç®—æ³•ï¼ˆé¡µé¢ç½®æ¢ç®—æ³•ï¼‰ã€‚\næœ¬æ¬¡è¯¾ç¨‹è®¾è®¡é‡‡ç”¨çš„æ˜¯ Clock ç®—æ³•\nå°†é¡µè¡¨æ‰©å……ï¼Œå¼•å…¥è®¿é—®ä½ã€ä¿®æ”¹ä½ã€æœ‰æ•ˆä½ï¼ˆæœ¬æ¬¡ä»…ç”¨äºç®—æ³•å®ç°ï¼Œå®ƒå…¶å®ç”¨å…¶ä»–\næ›´æœ‰ç”¨çš„åŠŸèƒ½ï¼Œåœ¨æ­¤ä¸åšä»‹ç»ï¼‰\n\n\n\nä¿®æ”¹ä½\nè®¿é—®ä½\né‡è¦æ’å\n\n\n\n\n0\n0\n4\n\n\n0\n1\n3\n\n\n1\n0\n2\n\n\n1\n1\n1\n\n\n\nåœ¨ç½®æ¢æ—¶ï¼Œä¼˜å…ˆè€ƒè™‘ä¸é‚£ä¹ˆé‡è¦çš„ï¼ˆæ’åè¶Šä½è¶Šä¸é‡è¦ï¼‰ï¼Œå¯¹äºä¸é‡è¦çš„é¡µä¼˜å…ˆæ¢å‡º\n# çŠ¶æ€è½¬æ¢ï¼Ÿ\nè¿™é‡Œç¨ååŒæ­¥ï¼Œå¤§å®¶å¯ä»¥å…ˆçœ‹è§†é¢‘é‡Œçš„æœ‰å…³çŠ¶æ€è½¬æ¢çš„å›¾ã€‚\n# ä»£ç å®ç°\n/** * @Author KarryLiu * @Creed may all the beauty be blessed * @Date 2023/12/4 ä¸Šåˆ 10:04 * @Description TODO è¯—å²¸æ¢¦è¡ŒèˆŸ * @Version 1.0 */#include &lt;limits>#include \"iostream\"#include \"windows.h\"#include \"unistd.h\"// é¢œè‰²æšä¸¾ï¼Œä¸ºäº†å¥½çœ‹enum ConsoleColor &#123;    Black = 0,    Blue = 1,    Green = 2,    Cyan = 3,    Red = 4,    Magenta = 5,    Yellow = 6,    White = 7,    Gray = 8&#125;;// è®¾ç½®æ–‡æœ¬é¢œè‰²å‡½æ•°void setConsoleColor(ConsoleColor text, ConsoleColor background) &#123;    int color = text + background * 16;    SetConsoleTextAttribute(GetStdHandle(STD_OUTPUT_HANDLE), color);&#125;// å—å¤§å°#define blockSize 4// é¡µå¤§å°#define pageSize 2// å¿«è¡¨å°ºå¯¸#define fastTableDimensions 4// é¡µè¡¨å°ºå¯¸#define pageTableDimensions 6// ç¨‹åºæœ€å¤§é€»è¾‘åœ°å€const int logicalMaxAddress = 100;// é€»è¾‘åœ°å€æ•°æ®ç»“æ„ -> é¡µstruct logicalAddressDataStruct &#123;    int pageNumber;    int inPageAddress;&#125;;// é¡µé€»è¾‘åœ°å€å®ç°æœºæ„logicalAddressDataStruct logicalAddress;// æ¨¡æ‹Ÿå¤–å­˜ä¸­å•æ¡æ•°æ®çš„æ•°æ®ç»“æ„struct externalMemoryDataStruct &#123;    int externalPageNumber;    int externalBlockNumber;    // è®¿é—®ä½    bool accessBit;    // ä¿®æ”¹ä½    bool modifyBit;    // æœ‰æ•ˆä½    bool validBit;&#125;;// å¤–å­˜æ‰€æœ‰å­˜å‚¨ç»“æ„ï¼Œä¹Ÿå°±æ˜¯æœ€å¤§é€»è¾‘åœ°å€ 100 çš„ä¸€åŠï¼Œ50 é¡µexternalMemoryDataStruct externalMemory[logicalMaxAddress / pageSize];// æ¨¡æ‹Ÿå†…å­˜ä¸­å•æ¡æ•°æ®çš„æ•°æ®ç»“æ„ (é¡µè¡¨)struct internalStorageDataStruct &#123;    int internalPageNumber;    int internalBlockNumber;    // è®¿é—®ä½    bool accessBit;    // ä¿®æ”¹ä½    bool modifyBit;    // æœ‰æ•ˆä½    bool validBit;&#125;;// é¡µè¡¨å®ä½“internalStorageDataStruct pageTable[pageTableDimensions];// å¿«è¡¨æ•°æ®ç»“æ„struct fastTableDataStruct &#123;    int fastTablePageNumber;    int fastTableBlockNumber;    // è®¿é—®ä½    bool accessBit;    // ä¿®æ”¹ä½    bool modifyBit;    // æœ‰æ•ˆä½    bool validBit;&#125;;// å¿«è¡¨å®ä½“fastTableDataStruct fastTable[fastTableDimensions];// å¿«è¡¨ç½®æ¢æ’è¡Œæ¦œæ•°æ®ç»“æ„struct rankForFastTableDataStruct &#123;    int pageNumber;    int fastTableIndex;&#125;;// é¡µè¡¨ç½®æ¢æ’è¡Œæ¦œæ•°æ®ç»“æ„struct rankForPageTableDataStruct &#123;    int pageNumber;    int pageTableIndex;&#125;;// ç‰©ç†åœ°å€æ•°æ®ç»“æ„struct physicalAddressDataStruct &#123;    int blockNumber;    int internalBlockAddress;&#125;;// è½¬æ¢åçš„ç‰©ç†åœ°å€å®ä½“physicalAddressDataStruct physicalAddress;using namespace std;/** * @Describe åˆå§‹åŒ–å¤–å­˜æ•°æ® */void InitializeExternalData() &#123;    for (int i = 0; i &lt; logicalMaxAddress / pageSize; i++) &#123;        // è®¡ç®—é¡µå·ä¸å—å·        externalMemory[i].externalPageNumber = i;        externalMemory[i].externalBlockNumber = i / blockSize;    &#125;//    for (int i = 0; i &lt; logicalMaxAddress / pageSize; ++i) &#123;//        cout&lt;&lt;externalMemory[i].externalPageNumber&lt;&lt;\"   \"&lt;&lt;externalMemory[i].externalBlockNumber&lt;&lt;endl;//    &#125;&#125;/** * @Describe ä»å¤–å­˜ä¸­å¯»æ‰¾æ‰€ç¼ºå¤±çš„é¡µ * @return externalMemoryDataStruct è¿”å›æ‰¾åˆ°çš„å¤–å­˜æ•°æ®é¡µ */externalMemoryDataStruct LookMissingPageFromExternalMemory(int logicalAddressPageNumber) &#123;    for (int i = 0; i &lt; logicalMaxAddress / pageSize; i++) &#123;        // è®¡ç®—é¡µå·ä¸å—å·        if (externalMemory[i].externalPageNumber == logicalAddressPageNumber) &#123;            return externalMemory[i];        &#125;    &#125;&#125;void PageTableVisualization() &#123;    setConsoleColor(Magenta, Black);    cout &lt;&lt; \"-------------------é¡µè¡¨ï¼ˆå†…å­˜ï¼‰-------------------+\" &lt;&lt; endl;    for (int i = 0; i &lt; pageTableDimensions; i++) &#123;        cout &lt;&lt; \"é¡µå·ï¼š\" &lt;&lt; pageTable[i].internalPageNumber &lt;&lt; \"  å—å·ï¼š\" &lt;&lt; pageTable[i].internalBlockNumber &lt;&lt; \"  è®¿é—®ä½ï¼š\"             &lt;&lt; pageTable[i].accessBit &lt;&lt; \"  ä¿®æ”¹ä½ï¼š\" &lt;&lt; pageTable[i].modifyBit &lt;&lt; \"  æœ‰æ•ˆä½ï¼š\" &lt;&lt; pageTable[i].validBit             &lt;&lt; endl;    &#125;    cout &lt;&lt; \"--------------------------------------------------+\" &lt;&lt; endl;&#125;void FastTableVisualization() &#123;    setConsoleColor(Cyan, Black);//    sleep(1);    cout &lt;&lt; \"----------------------å¿«è¡¨-----------------------+\" &lt;&lt; endl;    for (int i = 0; i &lt; fastTableDimensions; i++) &#123;        cout &lt;&lt; \"é¡µå·ï¼š\" &lt;&lt; fastTable[i].fastTablePageNumber &lt;&lt; \"  å—å·ï¼š\" &lt;&lt; fastTable[i].fastTableBlockNumber             &lt;&lt; \"  è®¿é—®ä½ï¼š\" &lt;&lt; fastTable[i].accessBit &lt;&lt; \"  ä¿®æ”¹ä½ï¼š\" &lt;&lt; fastTable[i].modifyBit &lt;&lt; \"  æœ‰æ•ˆä½ï¼š\"             &lt;&lt; fastTable[i].validBit &lt;&lt; endl;    &#125;    cout &lt;&lt; \"-------------------------------------------------+\" &lt;&lt; endl;&#125;/** * @Describe åˆå§‹åŒ–é¡µè¡¨ */void InitializePageTable() &#123;&#125;int main() &#123;    setConsoleColor(Cyan, Black);    cout&lt;&lt;\"è¯—å²¸æ¢¦è¡ŒèˆŸ\"&lt;&lt;endl;    cout&lt;&lt;\"æ“ä½œç³»ç»Ÿè¯¾ç¨‹è®¾è®¡ï¼šè™šæ‹Ÿå­˜å‚¨å™¨ç®¡ç†\"&lt;&lt;endl;    sleep(2);    // ç³»ç»Ÿè¯·æ±‚çš„é€»è¾‘åœ°å€    int requestLogicalAddressByOS = 0;    // åˆå§‹åŒ–å¤–å­˜æ•°æ®ç»“æ„    InitializeExternalData();    // å¿«è¡¨å‘ç°ä½ï¼ŒçœŸå°±æ˜¯å‘ç°äº†ï¼Œå‡å°±æ˜¯æ²¡å‘ç°    bool fastTableFind = false;    // åœ¨å¿«è¡¨çš„å“ªä¸€ä½å‘ç°çš„ï¼Ÿ    int fastTableFindPoint;    // é¡µè¡¨å‘ç°ä½ï¼ŒçœŸå°±æ˜¯å‘ç°äº†ï¼Œå‡å°±æ˜¯æ²¡å‘ç°    bool pageTableFind = false;    // åœ¨é¡µè¡¨çš„å“ªä¸€ä½å‘ç°çš„ï¼Ÿ    int pageTableFindPoint;    // å½“å‰å†…å­˜å®¹é‡ï¼ˆé¡µè¡¨å‰©ä½™å®¹é‡ï¼‰    int remainingCapacityOfPageTable = 6;    // å½“å‰å¿«è¡¨å®¹é‡ï¼ˆå¿«è¡¨å‰©ä½™å®¹é‡ï¼‰    int remainingCapacityOfFastTable = 4;    while (true) &#123;        // åˆå§‹åŒ–ç‰©ç†åœ°å€æ•°æ®æš‚å­˜        physicalAddress.blockNumber = -1;        physicalAddress.internalBlockAddress = -1;        setConsoleColor(Blue, Black);//        sleep(2);        cout &lt;&lt; \"ç³»ç»ŸåŸºæœ¬ä¿¡æ¯ï¼š\" &lt;&lt; endl;        cout &lt;&lt; \" +------------------------+\" &lt;&lt;\"----------------------+\"&lt;&lt; endl;        cout &lt;&lt; \" |  å—å¤§å°ï¼š\" &lt;&lt; blockSize &lt;&lt; \"             |\" &lt;&lt;\"       xxå¤§å­¦       |\"&lt;&lt; endl;        cout &lt;&lt; \" |  é¡µå¤§å°ï¼š\" &lt;&lt; pageSize &lt;&lt; \"             |\" &lt;&lt;\"     ä¸“ä¸š     |\"&lt;&lt; endl;        cout &lt;&lt; \" |  æœ€å¤§é€»è¾‘åœ°å€ï¼š\" &lt;&lt; logicalMaxAddress &lt;&lt; \"     |\" &lt;&lt;\"     OS  è¯¾ç¨‹è®¾è®¡     |\"&lt;&lt; endl;        cout &lt;&lt; \" |  å¿«è¡¨å°ºå¯¸ï¼š\" &lt;&lt; fastTableDimensions &lt;&lt; \"           |\" &lt;&lt;\"   è¯—å²¸æ¢¦è¡ŒèˆŸ  |\"&lt;&lt; endl;        cout &lt;&lt; \" |  é¡µè¡¨å°ºå¯¸ï¼š\" &lt;&lt; pageTableDimensions &lt;&lt; \"           |\" &lt;&lt;\" è™š æ‹Ÿ å­˜ å‚¨ å™¨ ç®¡ ç† |\"&lt;&lt; endl;        cout &lt;&lt; \" +------------------------+\" &lt;&lt;\"----------------------+\"&lt;&lt; endl;        FastTableVisualization();        PageTableVisualization();        setConsoleColor(White, Black);        cout &lt;&lt; \"è¯·è¾“å…¥åº”ç”¨ç¨‹åºè¯·æ±‚çš„é€»è¾‘åœ°å€ï¼š\" &lt;&lt; endl;        cin >> requestLogicalAddressByOS;        // ç»“æŸç¨‹åº        if (requestLogicalAddressByOS &lt; 0) &#123; break; &#125;        // é€»è¾‘åœ°å€è¶Šç•Œ        if (requestLogicalAddressByOS > logicalMaxAddress) &#123;            setConsoleColor(Red, Black);            cout &lt;&lt; \"æ‚¨è¯·æ±‚çš„åœ°å€è¶…å‡ºæœ€å¤§é€»è¾‘åœ°å€ï¼äº§ç”Ÿè¶Šç•Œä¸­æ–­ï¼\" &lt;&lt; endl;            setConsoleColor(White, Black);            sleep(2);            continue;        &#125;        setConsoleColor(Cyan, Black);        cout &lt;&lt; \"æ‚¨è¯·æ±‚çš„åè¿›åˆ¶åœ°å€ï¼š\" &lt;&lt; requestLogicalAddressByOS &lt;&lt; endl;        setConsoleColor(White, Black);        /**         * è®¡ç®—é€»è¾‘åœ°å€æ•°æ®         * P = [A / L]         * d = A % L         */        logicalAddress.pageNumber = requestLogicalAddressByOS / pageSize;        logicalAddress.inPageAddress = requestLogicalAddressByOS % pageSize;        cout &lt;&lt; \"è®¡ç®—åå½¢æˆé€»è¾‘åœ°å€ï¼š\" &lt;&lt; endl;        setConsoleColor(Magenta, Black);        cout &lt;&lt; \"+---é¡µå·---+---é¡µå†…åœ°å€----+\" &lt;&lt; endl;        cout &lt;&lt; \"|    \" &lt;&lt; logicalAddress.pageNumber &lt;&lt; \"    |       \" &lt;&lt; logicalAddress.inPageAddress &lt;&lt; \"       |\"             &lt;&lt; endl;        cout &lt;&lt; \"+----------+---------------+\" &lt;&lt; endl;//        cout&lt;&lt;\"æŒ‰å›è½¦ç»§ç»­æ‰§è¡Œ...\";//        cin.get();cin.get();        setConsoleColor(White, Black);        // CPU æ£€ç´¢å—è¡¨        cout &lt;&lt; \"æ“ä½œç³»ç»Ÿæ£€ç´¢å¿«è¡¨...\" &lt;&lt; endl;        for (int i = 0; i &lt; fastTableDimensions; i++) &#123;            if (fastTable[i].fastTablePageNumber == logicalAddress.pageNumber &amp;&amp; fastTable[i].validBit) &#123;                // åœ¨å¿«è¡¨ä¸­å‘ç°äº†ä¸ä¹‹å¯¹åº”çš„é¡µå·çš„æ•°æ®é¡µ                setConsoleColor(Green, Black);                cout &lt;&lt; \"æ“ä½œç³»ç»Ÿåœ¨å¿«è¡¨ä¸­å‘ç°äº†ç›¸åº”çš„æ•°æ®é¡µ!\" &lt;&lt; endl;                fastTableFindPoint = i;                // å°†å‘ç°æ£€æŸ¥ä½ç½®çœŸ                fastTableFind = true;                setConsoleColor(White, Black);                break;            &#125;        &#125;        if (!fastTableFind) &#123;            // å¿«è¡¨ä¸­æ²¡æœ‰ï¼Œè®¿é—®é¡µè¡¨            setConsoleColor(Yellow, Black);            cout &lt;&lt; \"å¿«è¡¨ä¸­æ²¡æœ‰å‘ç°ç›¸åº”çš„æ•°æ®é¡µ!\" &lt;&lt; endl;            setConsoleColor(White, Black);            cout &lt;&lt; \"æ“ä½œç³»ç»Ÿæ£€ç´¢é¡µè¡¨...\" &lt;&lt; endl;            // ä»å†…å­˜ä¸­ï¼ˆé¡µè¡¨ï¼‰å¯»æ‰¾æ‰€ç¼ºå¤±çš„é¡µ            for (int i = 0; i &lt; pageTableDimensions; i++) &#123;                if (pageTable[i].internalPageNumber == logicalAddress.pageNumber &amp;&amp; pageTable[i].validBit) &#123;                    // åœ¨å†…å­˜ä¸­ï¼ˆé¡µè¡¨ï¼‰æ‰¾åˆ°äº†æ•°æ®é¡µ                    setConsoleColor(Green, Black);                    cout &lt;&lt; \"æ“ä½œç³»ç»Ÿåœ¨é¡µè¡¨ä¸­å‘ç°äº†ç›¸åº”çš„æ•°æ®é¡µ!\" &lt;&lt; endl;                    pageTableFind = true;                    pageTableFindPoint = i;                    setConsoleColor(White, Black);                    break;                &#125;            &#125;            if (!pageTableFind) &#123;                // é¡µè¡¨ï¼ˆå†…å­˜ï¼‰ä¸­æ²¡æœ‰                setConsoleColor(Yellow, Black);                cout &lt;&lt; \"é¡µä¸­æ²¡æœ‰å‘ç°ç›¸åº”çš„æ•°æ®é¡µ!\" &lt;&lt; endl;                setConsoleColor(White, Black);                cout &lt;&lt; \"æ“ä½œç³»ç»Ÿä¼šæ­£åœ¨ä»å¤–å­˜ä¸­æŠ½å–é¡µ...\" &lt;&lt; endl;                // ä»å¤–å­˜ä¸­æŠ½å–é¡µ                externalMemoryDataStruct externalMemoryFindPage = LookMissingPageFromExternalMemory(                        logicalAddress.pageNumber);                /*cout&lt;&lt;externalMemoryFindPage.externalPageNumber&lt;&lt;\"  \"&lt;&lt;externalMemoryFindPage.externalBlockNumber;*/                cout &lt;&lt; \"æˆåŠŸæŠ½å–åˆ°äº†ï¼Œç°åœ¨æ­£åœ¨æ£€æŸ¥å†…å­˜æ˜¯å¦å·²æ»¡...\" &lt;&lt; endl;                sleep(1);                if (!(remainingCapacityOfPageTable > 0)) &#123;                    // å†…å­˜ï¼ˆé¡µè¡¨ï¼‰å·²æ»¡                    // è¿™é‡Œå¾—é€‰æ‹©ä¸€ä¸ªæœ€æ²¡ç”¨çš„ä¸€é¡µå¯¹æ¢å‡ºå»                    setConsoleColor(Red, Black);                    cout &lt;&lt; \"å†…å­˜å·²æ»¡ï¼Œæ“ä½œç³»ç»Ÿéœ€è¦è¿›è¡Œé¡µé¢ç½®æ¢ï¼Œæ­£åœ¨é€‰æ‹©ä¸€ä¸ªæœ€æ²¡ç”¨çš„ä¸€é¡µè¿›è¡Œæ¢å‡º...\" &lt;&lt; endl;;                    setConsoleColor(White, Black);                    // å¼€å§‹é€‰æ‹©ä¸€ä¸ªæœ€æ²¡ç”¨çš„ä¸€é¡µ                    // é¡µè¡¨ç½®æ¢æ’è¡Œæ¦œ                    rankForPageTableDataStruct rankForPageTable[pageTableDimensions];                    // åˆå§‹åŒ–æ’è¡Œæ¦œ                    for (int i = 0; i &lt; pageTableDimensions; i++) &#123;                        rankForPageTable[i].pageNumber - 1;                        rankForPageTable[i].pageTableIndex = -1;                    &#125;                    // æ¨¡æ‹Ÿæ€æ¡¶æ’åº                    for (int i = 0; i &lt; pageTableDimensions; i++) &#123;                        if (pageTable[i].validBit                            &amp;&amp; !pageTable[i].accessBit                            &amp;&amp; !pageTable[i].modifyBit) &#123;                            rankForPageTable[0].pageTableIndex = i;                            rankForPageTable[0].pageNumber = pageTable[i].internalPageNumber;                        &#125; else if (pageTable[i].validBit                                   &amp;&amp; pageTable[i].accessBit                                   &amp;&amp; !pageTable[i].modifyBit) &#123;                            rankForPageTable[1].pageTableIndex = i;                            rankForPageTable[1].pageNumber = pageTable[i].internalPageNumber;                        &#125; else if (pageTable[i].validBit                                   &amp;&amp; !pageTable[i].accessBit                                   &amp;&amp; pageTable[i].modifyBit) &#123;                            rankForPageTable[2].pageTableIndex = i;                            rankForPageTable[2].pageNumber = pageTable[i].internalPageNumber;                        &#125; else &#123;                            rankForPageTable[3].pageTableIndex = i;                            rankForPageTable[3].pageNumber = pageTable[i].internalPageNumber;                        &#125;                    &#125;                    for (int i = 0; i &lt; pageTableDimensions; i++) &#123;                        if (rankForPageTable[i].pageNumber != -1) &#123;                            // æ‰¾åˆ°ä¸€ä¸ªæ²¡ç”¨çš„é¡µ                            setConsoleColor(Green, Black);                            cout &lt;&lt; \"æ“ä½œç³»ç»Ÿé¡µè¡¨è¡¨é€‰æ‹©äº†ä¸€ä¸ªé¡µå·ä¸º\"                                 &lt;&lt; pageTable[rankForPageTable[i].pageTableIndex].internalPageNumber                                 &lt;&lt; \"çš„é¡µè¿›è¡Œæ¢å‡º...\"                                 &lt;&lt; endl;;                            setConsoleColor(White, Black);                            sleep(1);                            // æŠŠé¡µè¡¨ä¸­å¯¹åº”çš„é¡µå·ç½®ä¸ºæ— æ•ˆ                            pageTable[rankForPageTable[i].pageTableIndex].validBit = false;                            // é¡µè¡¨é¡µé¢ç½®æ¢                            pageTable[rankForPageTable[i].pageTableIndex].internalPageNumber = externalMemoryFindPage.externalPageNumber;                            pageTable[rankForPageTable[i].pageTableIndex].internalBlockNumber = externalMemoryFindPage.externalBlockNumber;                            pageTable[rankForPageTable[i].pageTableIndex].accessBit = false;                            pageTable[rankForPageTable[i].pageTableIndex].modifyBit = false;                            pageTable[rankForPageTable[i].pageTableIndex].validBit = true;                            break;                        &#125;                    &#125;                &#125; else &#123;                    // å†…å­˜ï¼ˆé¡µè¡¨ï¼‰ä»æœ‰ç©ºé—´                    // æœ‰ç©ºé—´å°±å¯ä»¥å¡è¿›å»                    setConsoleColor(Blue, Black);                    cout &lt;&lt; \"å†…å­˜è¿˜æœ‰ç©ºé—´ï¼Œæ“ä½œç³»ç»Ÿæ­£åœ¨è¯»å–ç¼ºé¡µå¹¶å›å†™å†…å­˜ä¸­...\" &lt;&lt; endl;;                    setConsoleColor(White, Black);                    for (int i = 0; i &lt; pageTableDimensions; i++) &#123;                        if (pageTable[i].validBit == false) &#123;                            pageTable[i].validBit = true;                            pageTable[i].internalPageNumber = externalMemoryFindPage.externalPageNumber;                            pageTable[i].internalBlockNumber = externalMemoryFindPage.externalBlockNumber;                            break;                        &#125;                    &#125;                    setConsoleColor(Green, Black);                    cout &lt;&lt; \"é¡µè¡¨å›å†™æˆåŠŸï¼\" &lt;&lt; endl;;                    setConsoleColor(White, Black);                    // å¡å®Œå°±å‡å‡                    remainingCapacityOfPageTable--;                &#125;                if (!(remainingCapacityOfFastTable > 0)) &#123;                    // å¿«è¡¨æ²¡æœ‰ç©ºé—´äº†                    setConsoleColor(Red, Black);                    cout &lt;&lt; \"å¿«è¡¨å·²æ»¡ï¼Œæ“ä½œç³»ç»Ÿéœ€è¦è¿›è¡Œé¡µé¢ç½®æ¢ï¼Œæ­£åœ¨é€‰æ‹©ä¸€ä¸ªæœ€æ²¡ç”¨çš„ä¸€é¡µè¿›è¡Œæ¢å‡º...\" &lt;&lt; endl;;                    setConsoleColor(White, Black);                    // é€‰æ‹©ä¸€ä¸ªæœ€æ²¡ç”¨çš„ä¸€é¡µè¿›è¡Œæ¢å‡ºï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼                    bool fastTableFindCheckIsTrue = false;                    int fastTableFindCheckIndex;                    // å¿«è¡¨ç½®æ¢æ’è¡Œæ¦œ                    rankForFastTableDataStruct rankForFastTable[fastTableDimensions];                    // åˆå§‹åŒ–æ’è¡Œæ¦œ                    for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                        rankForFastTable[i].pageNumber = -1;                        rankForFastTable[i].fastTableIndex = -1;                    &#125;                    // æ¨¡æ‹Ÿæ€æ¡¶æ’åº                    for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                        if (fastTable[i].validBit                            &amp;&amp; !fastTable[i].accessBit                            &amp;&amp; !fastTable[i].modifyBit) &#123;                            rankForFastTable[0].fastTableIndex = i;                            rankForFastTable[0].pageNumber = fastTable[i].fastTablePageNumber;                        &#125; else if (fastTable[i].validBit                                   &amp;&amp; fastTable[i].accessBit                                   &amp;&amp; !fastTable[i].modifyBit) &#123;                            rankForFastTable[1].fastTableIndex = i;                            rankForFastTable[1].pageNumber = fastTable[i].fastTablePageNumber;                        &#125; else if (fastTable[i].validBit                                   &amp;&amp; !fastTable[i].accessBit                                   &amp;&amp; fastTable[i].modifyBit) &#123;                            rankForFastTable[2].fastTableIndex = i;                            rankForFastTable[2].pageNumber = fastTable[i].fastTablePageNumber;                        &#125; else &#123;                            rankForFastTable[3].fastTableIndex = i;                            rankForFastTable[3].pageNumber = fastTable[i].fastTablePageNumber;                        &#125;                    &#125;                    for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                        if (rankForFastTable[i].pageNumber != -1) &#123;                            // æ‰¾åˆ°ä¸€ä¸ªæ²¡ç”¨çš„é¡µ                            setConsoleColor(Green, Black);                            cout &lt;&lt; \"æ“ä½œç³»ç»Ÿåœ¨å¿«è¡¨é€‰æ‹©äº†ä¸€ä¸ªé¡µå·ä¸º\"                                 &lt;&lt; fastTable[rankForFastTable[i].fastTableIndex].fastTablePageNumber                                 &lt;&lt; \"çš„é¡µè¿›è¡Œæ¢å‡º...\"                                 &lt;&lt; endl;                            setConsoleColor(White, Black);                            sleep(1);                            // æŠŠå¿«è¡¨ä¸­å¯¹åº”çš„é¡µå·ç½®ä¸ºæ— æ•ˆ                            fastTable[rankForFastTable[i].fastTableIndex].validBit = false;                            // å¿«è¡¨é¡µé¢ç½®æ¢                            fastTable[rankForFastTable[i].fastTableIndex].fastTablePageNumber = externalMemoryFindPage.externalPageNumber;                            fastTable[rankForFastTable[i].fastTableIndex].fastTableBlockNumber = externalMemoryFindPage.externalBlockNumber;                            fastTable[rankForFastTable[i].fastTableIndex].accessBit = false;                            fastTable[rankForFastTable[i].fastTableIndex].modifyBit = false;                            fastTable[rankForFastTable[i].fastTableIndex].validBit = true;                            // æŠŠé¡µè¡¨ä¸­å¯¹åº”çš„é¡µå·ç½®ä¸ºæ— æ•ˆï¼Ÿ                            fastTableFindCheckIsTrue = true;                            break;                        &#125;                    &#125;                    if (fastTableFindCheckIsTrue) &#123;                    &#125; else &#123;                        setConsoleColor(Red, Black);                        cout &lt;&lt; \"ä¸€èˆ¬ä¸å­˜åœ¨è¿™ç§æƒ…å†µï¼Œä»¥é˜²ä¸‡ä¸€ç•™ç€DeBugç”¨\" &lt;&lt; endl;                        setConsoleColor(White, Black);                    &#125;                &#125; else &#123;                    // å¿«è¡¨ä»ç„¶æœ‰ç©ºé—´                    // æœ‰ç©ºé—´å°±å¡                    setConsoleColor(Blue, Black);                    cout &lt;&lt; \"å¿«è¡¨è¿˜æœ‰ç©ºé—´ï¼Œæ“ä½œç³»ç»Ÿæ­£åœ¨è¯»å–ç¼ºé¡µå¹¶å›å†™å†…å­˜ä¸­...\" &lt;&lt; endl;;                    setConsoleColor(White, Black);                    for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                        if (fastTable[i].validBit == false) &#123;                            fastTable[i].validBit = true;                            fastTable[i].fastTablePageNumber = externalMemoryFindPage.externalPageNumber;                            fastTable[i].fastTableBlockNumber = externalMemoryFindPage.externalBlockNumber;                            break;                        &#125;                    &#125;                    setConsoleColor(Green, Black);                    cout &lt;&lt; \"å¿«è¡¨å›å†™æˆåŠŸï¼\" &lt;&lt; endl;;                    setConsoleColor(White, Black);                    // å¡å®Œå°±å‡å‡                    remainingCapacityOfFastTable--;                &#125;                //!!!!!!!!!!!!!!                physicalAddress.blockNumber = externalMemoryFindPage.externalBlockNumber;                physicalAddress.internalBlockAddress = logicalAddress.inPageAddress;                cout &lt;&lt; \"è®¡ç®—åå¾—åˆ°ç‰©ç†åœ°å€ï¼š\" &lt;&lt; endl;                setConsoleColor(Magenta, Black);                cout &lt;&lt; \"+---å—å·---+---å—å†…åœ°å€----+\" &lt;&lt; endl;                cout &lt;&lt; \"|    \" &lt;&lt; physicalAddress.blockNumber &lt;&lt; \"    |       \" &lt;&lt; physicalAddress.internalBlockAddress                     &lt;&lt; \"       |\"                     &lt;&lt; endl;                cout &lt;&lt; \"+----------+---------------+\" &lt;&lt; endl;                sleep(2);            &#125; else &#123;                // é¡µè¡¨ä¸­æœ‰                // é¡µè¡¨ä¸­çš„è¯ï¼Œä¿®æ”¹é¡µè¡¨åè¿˜éœ€è¦è¿›è¡Œå¿«è¡¨ç½®æ¢                /**                 * å¦‚æœé¡µè¡¨é‡Œé¢æœ‰ï¼Œé‚£å°±æ›´æ”¹ä»–çš„è®¿é—®ä½å’Œä¿®æ”¹ä½ï¼Œ                 * ä¸ºäº†ç¼–å†™ç®€å•ï¼Œåœ¨è¿™é‡Œæˆ‘åšå‡ºä¸€ä¸ªè§„å®šï¼š                 * å½“åº”ç”¨ç¨‹åºç¬¬ä¸€æ¬¡è®¿é—®æ—¶å°†è®¿é—®ä½ç½®çœŸï¼Œ                 * å½“åº”ç”¨ç¨‹åºç¬¬äºŒæ¬¡è®¿é—®æ—¶å°†ä¿®æ”¹ä¸ºç½®çœŸã€‚                 * è¿™ä¹ˆåšä¹Ÿæ˜¯ç›¸å¯¹åˆç†çš„ï¼ŒåŸå› å¦‚ä¸‹ï¼š                 * è®¿é—®ä½ä¸ä¿®æ”¹ä½è”åˆç½®æ¢é€»è¾‘ï¼ˆä¿®æ”¹ï¼Œè®¿é—®ï¼‰å³å¯¹æ¢ä¼˜å…ˆçº§ï¼š                 * * * 1.ï¼ˆ0ï¼Œ0ï¼‰                 * * * 2.ï¼ˆ0ï¼Œ1ï¼‰                 * * * 3.ï¼ˆ1ï¼Œ0ï¼‰                 * * * 4.ï¼ˆ1ï¼Œ1ï¼‰                 * æ’åè¶Šé«˜ï¼Œç½®æ¢ä¼˜å…ˆçº§è¶Šé«˜ï¼Œ                 * ç›¸å¯¹æ¥è®²ï¼Œè®¿é—®ä½ä¸ä¿®æ”¹ä½ç½®çœŸåï¼Œè®¿é—®ä½ä¼˜å…ˆçº§é«˜äºä¿®æ”¹ä½                 * å…¶å®æˆ‘æ‡’äº† ä½†æˆ‘ä¸è¯´ï¼ˆqwqï¼‰                 */                // å¿«è¡¨ç½®æ¢ï¼ŒåŸºäºé¡µè¡¨                // å¿«è¡¨ç½®æ¢æ’è¡Œæ¦œ                rankForFastTableDataStruct rankForFastTable[fastTableDimensions];                // åˆå§‹åŒ–æ’è¡Œæ¦œ                for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                    rankForFastTable[i].pageNumber = -1;                    rankForFastTable[i].fastTableIndex = -1;                &#125;                // æ¨¡æ‹Ÿæ€æ¡¶æ’åº                for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                    if (fastTable[i].validBit                        &amp;&amp; !fastTable[i].accessBit                        &amp;&amp; !fastTable[i].modifyBit) &#123;                        rankForFastTable[0].fastTableIndex = i;                        rankForFastTable[0].pageNumber = fastTable[i].fastTablePageNumber;                    &#125; else if (fastTable[i].validBit                               &amp;&amp; fastTable[i].accessBit                               &amp;&amp; !fastTable[i].modifyBit) &#123;                        rankForFastTable[1].fastTableIndex = i;                        rankForFastTable[1].pageNumber = fastTable[i].fastTablePageNumber;                    &#125; else if (fastTable[i].validBit                               &amp;&amp; !fastTable[i].accessBit                               &amp;&amp; fastTable[i].modifyBit) &#123;                        rankForFastTable[2].fastTableIndex = i;                        rankForFastTable[2].pageNumber = fastTable[i].fastTablePageNumber;                    &#125; else &#123;                        rankForFastTable[3].fastTableIndex = i;                        rankForFastTable[3].pageNumber = fastTable[i].fastTablePageNumber;                    &#125;                &#125;                for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                    if (rankForFastTable[i].pageNumber != -1) &#123;                        // æ‰¾åˆ°ä¸€ä¸ªæ²¡ç”¨çš„é¡µ                        setConsoleColor(Green, Black);                        cout &lt;&lt; \"æ“ä½œç³»ç»Ÿåœ¨å¿«è¡¨é€‰æ‹©äº†ä¸€ä¸ªé¡µå·ä¸º\"                             &lt;&lt; fastTable[rankForFastTable[i].fastTableIndex].fastTablePageNumber                             &lt;&lt; \"çš„é¡µè¿›è¡Œæ¢å‡º...\"                             &lt;&lt; endl;;                        setConsoleColor(White, Black);                        sleep(1);                        // æŠŠå¿«è¡¨ä¸­å¯¹åº”çš„é¡µå·ç½®ä¸ºæ— æ•ˆ                        fastTable[rankForFastTable[i].fastTableIndex].validBit = false;                        // å¿«è¡¨é¡µé¢ç½®æ¢                        fastTable[rankForFastTable[i].fastTableIndex].fastTablePageNumber = pageTable[pageTableFindPoint].internalPageNumber;                        fastTable[rankForFastTable[i].fastTableIndex].fastTableBlockNumber = pageTable[pageTableFindPoint].internalBlockNumber;                        fastTable[rankForFastTable[i].fastTableIndex].accessBit = false;                        fastTable[rankForFastTable[i].fastTableIndex].modifyBit = false;                        fastTable[rankForFastTable[i].fastTableIndex].validBit = true;                        // ç‰©ç†åœ°å€å­˜å‚¨                        physicalAddress.blockNumber = pageTable[pageTableFindPoint].internalBlockNumber;                        physicalAddress.internalBlockAddress = logicalAddress.inPageAddress;                        break;                    &#125;                &#125;                cout &lt;&lt; \"è®¡ç®—åå¾—åˆ°ç‰©ç†åœ°å€ï¼š\" &lt;&lt; endl;                setConsoleColor(Magenta, Black);                cout &lt;&lt; \"+---å—å·---+---å—å†…åœ°å€----+\" &lt;&lt; endl;                cout &lt;&lt; \"|    \" &lt;&lt; physicalAddress.blockNumber &lt;&lt; \"    |       \" &lt;&lt; physicalAddress.internalBlockAddress                     &lt;&lt; \"       |\"                     &lt;&lt; endl;                cout &lt;&lt; \"+----------+---------------+\" &lt;&lt; endl;                // ä¿®æ”¹é¡µè¡¨                if (pageTable[pageTableFindPoint].validBit                    &amp;&amp; !pageTable[pageTableFindPoint].accessBit                    &amp;&amp; !pageTable[pageTableFindPoint].modifyBit) &#123;                    pageTable[pageTableFindPoint].accessBit = true;                &#125; else if (pageTable[pageTableFindPoint].validBit                           &amp;&amp; pageTable[pageTableFindPoint].accessBit                           &amp;&amp; !pageTable[pageTableFindPoint].modifyBit) &#123;                    pageTable[pageTableFindPoint].accessBit = false;                    pageTable[pageTableFindPoint].modifyBit = true;                &#125; else if (pageTable[pageTableFindPoint].validBit                           &amp;&amp; !pageTable[pageTableFindPoint].accessBit                           &amp;&amp; pageTable[pageTableFindPoint].modifyBit) &#123;                    pageTable[pageTableFindPoint].accessBit = true;                    pageTable[pageTableFindPoint].modifyBit = true;                &#125;                // åŒæ­¥å¿«è¡¨                for (int i = 0; i &lt; fastTableDimensions; i++) &#123;                    if (fastTable[i].fastTablePageNumber == pageTable[pageTableFindPoint].internalPageNumber) &#123;                        if (fastTable[i].validBit                            &amp;&amp; !fastTable[i].accessBit                            &amp;&amp; !fastTable[i].modifyBit) &#123;                            fastTable[i].accessBit = true;                        &#125; else if (fastTable[i].validBit                                   &amp;&amp; fastTable[i].accessBit                                   &amp;&amp; !fastTable[i].modifyBit) &#123;                            fastTable[i].accessBit = false;                            fastTable[i].modifyBit = true;                        &#125; else if (fastTable[i].validBit                                   &amp;&amp; !fastTable[i].accessBit                                   &amp;&amp; fastTable[i].modifyBit) &#123;                            fastTable[i].accessBit = true;                            fastTable[i].modifyBit = true;                        &#125;                        break;                    &#125;                &#125;            &#125;        &#125; else &#123;            // å¿«è¡¨ä¸­æœ‰            // ä¿®æ”¹å¿«è¡¨            fastTable[fastTableFindPoint];            if (fastTable[fastTableFindPoint].validBit                &amp;&amp; !fastTable[fastTableFindPoint].accessBit                &amp;&amp; !fastTable[fastTableFindPoint].modifyBit) &#123;                fastTable[fastTableFindPoint].accessBit = true;            &#125; else if (fastTable[fastTableFindPoint].validBit                       &amp;&amp; fastTable[fastTableFindPoint].accessBit                       &amp;&amp; !fastTable[fastTableFindPoint].modifyBit) &#123;                fastTable[fastTableFindPoint].accessBit = false;                fastTable[fastTableFindPoint].modifyBit = true;            &#125; else if (fastTable[fastTableFindPoint].validBit                       &amp;&amp; !fastTable[fastTableFindPoint].accessBit                       &amp;&amp; fastTable[fastTableFindPoint].modifyBit) &#123;                fastTable[fastTableFindPoint].accessBit = true;                fastTable[fastTableFindPoint].modifyBit = true;            &#125;            // åŒæ­¥é¡µè¡¨            for (int i = 0; i &lt; pageTableDimensions; i++) &#123;                if (pageTable[i].internalPageNumber == fastTable[fastTableFindPoint].fastTablePageNumber) &#123;                    if (pageTable[i].validBit                        &amp;&amp; !pageTable[i].accessBit                        &amp;&amp; !pageTable[i].modifyBit) &#123;                        pageTable[i].accessBit = true;                    &#125; else if (pageTable[i].validBit                               &amp;&amp; pageTable[i].accessBit                               &amp;&amp; !pageTable[i].modifyBit) &#123;                        pageTable[i].accessBit = false;                        pageTable[i].modifyBit = true;                    &#125; else if (pageTable[i].validBit                               &amp;&amp; !pageTable[i].accessBit                               &amp;&amp; pageTable[i].modifyBit) &#123;                        pageTable[i].accessBit = true;                        pageTable[i].modifyBit = true;                    &#125;                    break;                &#125;            &#125;            // ç›´æ¥ä»å¿«è¡¨ä¸­æå–            physicalAddress.blockNumber = fastTable[fastTableFindPoint].fastTableBlockNumber;            physicalAddress.internalBlockAddress = logicalAddress.inPageAddress;            cout &lt;&lt; \"è®¡ç®—åå¾—åˆ°ç‰©ç†åœ°å€ï¼š\" &lt;&lt; endl;            setConsoleColor(Magenta, Black);            cout &lt;&lt; \"+---å—å·---+---å—å†…åœ°å€----+\" &lt;&lt; endl;            cout &lt;&lt; \"|    \" &lt;&lt; physicalAddress.blockNumber &lt;&lt; \"    |       \" &lt;&lt; physicalAddress.internalBlockAddress                 &lt;&lt; \"       |\"                 &lt;&lt; endl;            cout &lt;&lt; \"+----------+---------------+\" &lt;&lt; endl;            sleep(2);        &#125;        // æ¢å¤åˆå§‹çŠ¶æ€        fastTableFind = false;        pageTableFind = false;        setConsoleColor(Green, Black);        sleep(1);        cout &lt;&lt; \"---------------åœ°å€å˜æ¢ç»“æŸ---------------\";        sleep(1);        cout &lt;&lt; endl;        setConsoleColor(White, Black);    &#125;    cout &lt;&lt; \"ä¸‹æ¬¡å†è§ï¼\";&#125;","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"è®¡ç®—æœºæ“ä½œç³»ç»Ÿå¤è¯•é€Ÿè§ˆ","url":"/Operate-system/os_retest/","content":"# è®¡ç®—æœºæ“ä½œç³»ç»Ÿå¤è¯•\n# æ“ä½œç³»ç»Ÿçš„ä½œç”¨\n\næ˜¯ç”¨æˆ·ä¸è®¡ç®—æœºç¡¬ä»¶ä¹‹é—´çš„æ¥å£\næ˜¯è®¡ç®—æœºç³»ç»Ÿèµ„æºçš„ç®¡ç†è€…\nå®ç°äº†å¯¹è®¡ç®—æœºèµ„æºçš„æŠ½è±¡\n\n# æ“ä½œç³»ç»ŸåŸºæœ¬ç‰¹å¾\n\nå¹¶å‘\nå…±äº«\nè™šæ‹Ÿ\nå¼‚æ­¥\n\n# æ“ä½œç³»ç»Ÿæœ€åŸºæœ¬è°ƒç‰¹å¾\n\nå¹¶å‘\nå…±äº«\n\n# å¤„ç†æœºçš„åŒé‡å·¥ä½œæ¨¡å¼\nç”¨æˆ·æ€ã€æ ¸å¿ƒæ€\nç‰¹æƒæŒ‡ä»¤åœ¨æ ¸å¿ƒæ€æ‰§è¡Œï¼Œéç‰¹æƒæŒ‡ä»¤åœ¨ç”¨æˆ·æ€ä¸‹æ‰§è¡Œ\n# æ“ä½œç³»ç»Ÿä¸»è¦åŠŸèƒ½\n\nå¤„ç†æœºè°ƒåº¦\n\nè¿›ç¨‹æ§åˆ¶\nè¿›ç¨‹åŒæ­¥\nè¿›ç¨‹é€šä¿¡\nè°ƒåº¦\n\nä½œä¸šè°ƒåº¦ï¼ˆé«˜çº§è°ƒåº¦ï¼‰\nè¿›ç¨‹è°ƒåº¦ï¼ˆä½çº§è°ƒåº¦ï¼‰\n\n\n\n\nå­˜å‚¨å™¨ç®¡ç†\n\nå†…å­˜çš„åˆ†é…ä¸å›æ”¶\nå†…å­˜ä¿æŠ¤\nåœ°å€æ˜ å°„\nå†…å­˜æ‰©å……\n\n\nè®¾å¤‡ç®¡ç†\n\nç¼“å†²ç®¡ç†\nè®¾å¤‡åˆ†é…\nè®¾å¤‡å¤„ç†\n\n\næ–‡ä»¶ç®¡ç†\n\næ–‡ä»¶å­˜å‚¨ç©ºé—´ç®¡ç†\nç›®å½•ç®¡ç†\næ–‡ä»¶çš„è¯»å†™ç®¡ç†å’Œä¿æŠ¤\n\n\næ¥å£ç®¡ç†\n\nç”¨æˆ·æ¥å£ï¼ˆè„±æœºç”¨æˆ·æ¥å£ã€è”æœºç”¨æˆ·æ¥å£ã€å›¾å½¢ç”¨æˆ·æ¥å£ï¼‰\nç¨‹åºæ¥å£\n\n\n\n# ç¨‹åºå¹¶å‘æ‰§è¡Œç‰¹æ€§\n\né—´æ–­æ€§\nå¤±å»å°é—­æ€§\nä¸å¯å†ç°æ€§\n\n# è¿›ç¨‹çš„ç‰¹å¾\nåŠ¨æ€æ€§ã€å¹¶å‘æ€§ã€ç‹¬ç«‹æ€§ã€å¼‚æ­¥æ€§\n# è¿›ç¨‹çš„ 3 çŠ¶æ€æ¨¡å‹ã€5 çŠ¶æ€æ¨¡å‹ã€7 çŠ¶æ€æ¨¡å‹\n# å• CPU ä¸­çš„çŠ¶æ€\n\n\n\nçŠ¶æ€\næœ€å¤š\næœ€å°‘\n\n\n\n\nè¿è¡Œ\n1\n0\n\n\nå°±ç»ª\nN-1\n0\n\n\né˜»å¡\nN\n0\n\n\n\n# PCB ä¸­çš„ä¿¡æ¯\n\nè¿›ç¨‹æ ‡è¯†ç¬¦\nå¤„ç†æœºçŠ¶æ€\nè¿›ç¨‹è°ƒåº¦ä¿¡æ¯\nè¿›ç¨‹æ§åˆ¶ä¿¡æ¯\n\n# æ‹¥æœ‰èµ„æºï¼Ÿè°ƒåº¦ï¼Ÿ\n\nè¿›ç¨‹æ˜¯æ‹¥æœ‰èµ„æºçš„\nçº¿ç¨‹æ˜¯ç‹¬ç«‹è°ƒåº¦çš„\n\n# é«˜çº§è°ƒåº¦ï¼ˆä½œä¸šè°ƒåº¦ï¼‰\nå†³å®šå“ªäº›ä½œä¸šä»å¤–å­˜è°ƒå…¥å†…å­˜å‡†å¤‡æ‰§è¡Œï¼Œæ§åˆ¶ç³»ç»Ÿçš„å¹¶å‘åº¦ã€‚\n# ä¸­çº§è°ƒåº¦ï¼ˆå†…å­˜è°ƒåº¦ï¼‰\nç®¡ç†å†…å­˜ä¸­çš„è¿›ç¨‹ï¼Œé€šè¿‡æŒ‚èµ·å’Œæ¿€æ´»æ¥è°ƒæ•´å†…å­˜ä½¿ç”¨ã€‚\n# ä½çº§è°ƒåº¦ï¼ˆè¿›ç¨‹è°ƒåº¦ï¼‰\nå†³å®šå“ªä¸ªå°±ç»ªè¿›ç¨‹è·å¾— CPU æ‰§è¡Œã€‚\n# å…ˆæ¥å…ˆæœåŠ¡ FCFS\næŒ‰ä½œä¸šæˆ–è¿›ç¨‹åˆ°è¾¾çš„é¡ºåºåˆ†é… CPUã€‚\n\nç®€å•æ˜“å®ç°ã€‚\néæŠ¢å å¼ï¼Œå¯èƒ½å¯¼è‡´ â€œæŠ¤èˆªæ•ˆåº”â€ï¼ˆçŸ­ä½œä¸šç­‰å¾…é•¿ä½œä¸šå®Œæˆï¼‰ã€‚\nå¹³å‡ç­‰å¾…æ—¶é—´è¾ƒé•¿ï¼Œé€‚åˆé•¿ä½œä¸šã€‚\n\n# çŸ­ä½œä¸šä¼˜å…ˆ SJF\nä¼˜å…ˆè°ƒåº¦è¿è¡Œæ—¶é—´æœ€çŸ­çš„ä½œä¸šã€‚\n\nå¯æŠ¢å æˆ–éæŠ¢å ã€‚\næœ€å°åŒ–å¹³å‡ç­‰å¾…æ—¶é—´ã€‚\nå¯èƒ½å¯¼è‡´é•¿ä½œä¸š â€œé¥¥é¥¿â€ã€‚\n\n# ä¼˜å…ˆçº§è°ƒåº¦ Priority Scheduling\næŒ‰ä¼˜å…ˆçº§åˆ†é… CPUï¼Œä¼˜å…ˆçº§é«˜çš„å…ˆæ‰§è¡Œã€‚\n\nå¯æŠ¢å æˆ–éæŠ¢å ã€‚\nå¯èƒ½å¯¼è‡´ä½ä¼˜å…ˆçº§è¿›ç¨‹ â€œé¥¥é¥¿â€ã€‚\nä¼˜å…ˆçº§å¯ä»¥æ˜¯é™æ€æˆ–åŠ¨æ€è°ƒæ•´ã€‚\n\n# æ—¶é—´ç‰‡è½®è½¬è°ƒåº¦ RR\næ¯ä¸ªè¿›ç¨‹åˆ†é…ä¸€ä¸ªå›ºå®šæ—¶é—´ç‰‡ï¼ˆTime Quantumï¼‰ï¼Œè½®æµæ‰§è¡Œã€‚\n\næŠ¢å å¼ï¼Œé€‚åˆåˆ†æ—¶ç³»ç»Ÿã€‚\næ—¶é—´ç‰‡å¤§å°å½±å“æ€§èƒ½ï¼šå¤ªå°å¢åŠ ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ï¼Œå¤ªå¤§é€€åŒ–ä¸º FCFSã€‚\nå…¬å¹³æ€§å¥½ï¼Œå“åº”æ—¶é—´çŸ­ã€‚\n\n# å¤šçº§é˜Ÿåˆ—è°ƒåº¦ Multilevel Queue Scheduling\nå°†è¿›ç¨‹åˆ†ä¸ºå¤šä¸ªé˜Ÿåˆ—ï¼Œæ¯ä¸ªé˜Ÿåˆ—é‡‡ç”¨ä¸åŒçš„è°ƒåº¦ç®—æ³•ã€‚\n\né˜Ÿåˆ—é—´å¯è®¾ç½®ä¼˜å…ˆçº§ã€‚\né€‚åˆæ··åˆå‹ä»»åŠ¡ï¼ˆå¦‚å‰å°äº¤äº’ä»»åŠ¡å’Œåå°æ‰¹å¤„ç†ä»»åŠ¡ï¼‰ã€‚\n\n# å¤šçº§åé¦ˆé˜Ÿåˆ—è°ƒåº¦ Multilevel Feedback Queue Scheduling\nè¿›ç¨‹å¯åœ¨å¤šä¸ªé˜Ÿåˆ—é—´ç§»åŠ¨ï¼Œæ ¹æ®è¡Œä¸ºåŠ¨æ€è°ƒæ•´ä¼˜å…ˆçº§ã€‚\n\nç»“åˆäº†ä¼˜å…ˆçº§è°ƒåº¦å’Œè½®è½¬è°ƒåº¦çš„ä¼˜ç‚¹ã€‚\nåŠ¨æ€é€‚åº”è¿›ç¨‹è¡Œä¸ºï¼Œé¿å… â€œé¥¥é¥¿â€ã€‚\nå®ç°å¤æ‚ã€‚\n\n# ç®—æ³•æ€»ç»“\n\n\n\nç®—æ³•\nç‰¹ç‚¹\né€‚ç”¨åœºæ™¯\n\n\n\n\nFCFS\nç®€å•ï¼ŒéæŠ¢å ï¼ŒæŠ¤èˆªæ•ˆåº”\næ‰¹å¤„ç†ç³»ç»Ÿ\n\n\nSJF\næœ€å°åŒ–ç­‰å¾…æ—¶é—´ï¼Œå¯èƒ½å¯¼è‡´é•¿ä½œä¸šé¥¥é¥¿\næ‰¹å¤„ç†ç³»ç»Ÿ\n\n\nä¼˜å…ˆçº§è°ƒåº¦\næŒ‰ä¼˜å…ˆçº§æ‰§è¡Œï¼Œå¯èƒ½å¯¼è‡´ä½ä¼˜å…ˆçº§é¥¥é¥¿\nå®æ—¶ç³»ç»Ÿ\n\n\nè½®è½¬è°ƒåº¦\nå…¬å¹³ï¼Œå“åº”æ—¶é—´çŸ­ï¼Œæ—¶é—´ç‰‡å¤§å°å½±å“æ€§èƒ½\näº¤äº’å¼ç³»ç»Ÿ\n\n\nå¤šçº§é˜Ÿåˆ—è°ƒåº¦\nå¤šé˜Ÿåˆ—ï¼Œä¸åŒç­–ç•¥\næ··åˆä»»åŠ¡ç³»ç»Ÿ\n\n\nå¤šçº§åé¦ˆé˜Ÿåˆ—è°ƒåº¦\nåŠ¨æ€è°ƒæ•´ä¼˜å…ˆçº§ï¼Œé¿å…é¥¥é¥¿\né€šç”¨æ“ä½œç³»ç»Ÿ\n\n\n\n# æ­»é”\næ­»é”æ˜¯æ“ä½œç³»ç»Ÿä¸­çš„ä¸€ç§èµ„æºç«äº‰ç°è±¡ï¼ŒæŒ‡å¤šä¸ªè¿›ç¨‹æˆ–çº¿ç¨‹å› äº‰å¤ºèµ„æºè€Œé™·å…¥æ— é™ç­‰å¾…çš„çŠ¶æ€ï¼Œå¯¼è‡´å®ƒä»¬éƒ½æ— æ³•ç»§ç»­æ‰§è¡Œã€‚æ­»é”çš„å‘ç”Ÿé€šå¸¸éœ€è¦æ»¡è¶³å››ä¸ªå¿…è¦æ¡ä»¶ï¼Œç§°ä¸ºæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶ã€‚\n# æ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶\n\näº’æ–¥æ¡ä»¶ï¼ˆMutual Exclusionï¼‰ï¼š\n\nèµ„æºä¸€æ¬¡åªèƒ½è¢«ä¸€ä¸ªè¿›ç¨‹å ç”¨ï¼Œå…¶ä»–è¿›ç¨‹å¿…é¡»ç­‰å¾…ã€‚\n\n\nè¯·æ±‚ä¸ä¿æŒæ¨èï¼ˆHold and Waitï¼‰ï¼š\n\nè¿›ç¨‹å·²ç»å æœ‰ä¸€äº›èµ„æºï¼ŒåŒæ—¶è¯·æ±‚å…¶ä»–è¢«å ç”¨çš„èµ„æºã€‚\n\n\nä¸å‰¥å¤ºæ¡ä»¶ï¼ˆNo Preemptionï¼‰ï¼š\n\nè¿›ç¨‹å·²è·å¾—çš„èµ„æºä¸èƒ½è¢«å¼ºåˆ¶å‰¥å¤ºï¼Œåªèƒ½ç”±è¿›ç¨‹è‡ªè¡Œé‡Šæ”¾ã€‚\n\n\nå¾ªç¯ç­‰å¾…æ¡ä»¶ï¼ˆCircular Waitï¼‰ï¼š\n\nå­˜åœ¨ä¸€ä¸ªè¿›ç¨‹ç­‰å¾…çš„å¾ªç¯é“¾ï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½åœ¨ç­‰å¾…ä¸‹ä¸€ä¸ªè¿›ç¨‹å ç”¨çš„èµ„æºã€‚\n\n\n\n# æ­»é”çš„å¤„ç†æ–¹æ³•\n\næ­»é”é¢„é˜²\næ­»é”é¿å…\næ­»é”æ£€æµ‹\næ­»é”è§£é™¤\n\n# é“¶è¡Œå®¶ç®—æ³•\n\n\næ£€æŸ¥èµ„æºåˆ†é…åç³»ç»Ÿæ˜¯å¦å¤„äºå®‰å…¨çŠ¶æ€ï¼ˆå³æ˜¯å¦å­˜åœ¨ä¸€ä¸ªæ‰§è¡Œåºåˆ—ä½¿æ‰€æœ‰è¿›ç¨‹å®Œæˆï¼‰ã€‚\n\n\nå¦‚æœä¸å®‰å…¨ï¼Œåˆ™æ‹’ç»åˆ†é…è¯·æ±‚ã€‚\n\n\n# ä¸¤ç§åˆ¶çº¦å…³ç³»\n\näº’æ–¥å…³ç³»\nåŒæ­¥å…³ç³»\n\n# è§£å†³ä¸´ç•ŒåŒºåŒæ­¥é—®é¢˜é¡»éµå¾ªä»¥ä¸‹å‡†åˆ™\n\nç©ºé—²è®©è¿›\nå¿™åˆ™ç­‰å¾…\næœ‰é™ç­‰å¾…\nè®©æƒç­‰å¾…\n\n# ç¨‹åºçš„è£…å…¥æ–¹å¼\n\nç»å¯¹è£…å…¥\n\nç¨‹åºä¸­çš„åœ°å€æ˜¯å›ºå®šçš„ï¼Œè£…å…¥æ—¶ä¸éœ€è¦è¿›è¡Œåœ°å€è½¬æ¢ã€‚\né€‚ç”¨äºå•é“ç¨‹åºç¯å¢ƒï¼Œæˆ–è€…å†…å­˜åœ°å€å›ºå®šçš„ç³»ç»Ÿã€‚\nçµæ´»æ€§å·®ï¼Œç¨‹åºå¿…é¡»åŠ è½½åˆ°æŒ‡å®šçš„å†…å­˜ä½ç½®ï¼Œæ— æ³•é€‚åº”å¤šé“ç¨‹åºç¯å¢ƒã€‚\n\n\nå¯é‡å®šä½è£…å…¥\n\nç¨‹åºå¯ä»¥åœ¨å†…å­˜çš„ä¸åŒä½ç½®åŠ è½½ï¼Œé€‚åº”å¤šé“ç¨‹åºè®¾è®¡ã€‚\nè£…å…¥æ—¶éœ€è¦è¿›è¡Œåœ°å€é‡å®šä½ï¼Œé€šå¸¸ç”±æ“ä½œç³»ç»Ÿæˆ–è£…å…¥ç¨‹åºå®Œæˆã€‚\né€‚ç”¨äºå¤šé“ç¨‹åºç¯å¢ƒï¼Œæ”¯æŒå†…å­˜çš„åŠ¨æ€åˆ†é…ã€‚\n\n\nåŠ¨æ€è¿è¡Œæ—¶è£…å…¥\n\nç¨‹åºå¯ä»¥éƒ¨åˆ†åŠ è½½ï¼Œåªæœ‰åœ¨éœ€è¦æ—¶æ‰å°†ç›¸å…³éƒ¨åˆ†åŠ è½½åˆ°å†…å­˜ã€‚\nåœ°å€è½¬æ¢ç”±ç¡¬ä»¶å’Œæ“ä½œç³»ç»Ÿå…±åŒå®Œæˆã€‚\næ”¯æŒè™šæ‹Ÿå†…å­˜æŠ€æœ¯ï¼Œå…è®¸ç¨‹åºçš„å¤§å°è¶…è¿‡ç‰©ç†å†…å­˜çš„å®¹é‡ã€‚\n\n\n\n\nç»å¯¹è£…å…¥ï¼šé€‚ç”¨äºå•é“ç¨‹åºç¯å¢ƒï¼Œåœ°å€å›ºå®šï¼Œè£…å…¥ç®€å•ä½†ç¼ºä¹çµæ´»æ€§ã€‚\nå¯é‡å®šä½è£…å…¥ï¼šé€‚ç”¨äºå¤šé“ç¨‹åºç¯å¢ƒï¼Œæ”¯æŒåœ°å€é‡å®šä½ï¼Œçµæ´»æ€§é«˜ã€‚\nåŠ¨æ€è¿è¡Œæ—¶è£…å…¥ï¼šæ”¯æŒè™šæ‹Ÿå†…å­˜ï¼Œç¨‹åºå¯ä»¥åŠ¨æ€åŠ è½½ï¼Œé€‚åˆç°ä»£æ“ä½œç³»ç»Ÿã€‚\n\n# è¿ç»­åˆ†é…å­˜å‚¨å™¨ç®¡ç†æ–¹å¼\n\nå•ä¸€è¿ç»­åˆ†é…\nå›ºå®šåˆ†åŒºåˆ†é…\nåŠ¨æ€åˆ†åŒºåˆ†é…\n\n# åŠ¨æ€åˆ†åŒºåˆ†é…çš„ç®—æ³•\n\né¦–æ¬¡é€‚åº”ç®—æ³•\nå¾ªç¯é¦–æ¬¡é€‚åº”ç®—æ³•\næœ€ä½³é€‚é…ç®—æ³•\næœ€åé€‚é…ç®—æ³•\n\n# åˆ†é¡µå­˜å‚¨\n# åˆ†æ®µå­˜å‚¨\n# é¡µé¢ç½®æ¢ç®—æ³•\n\nå…ˆè¿›å…ˆå‡ºç®—æ³•\næœ€ä½³é¡µé¢ç½®æ¢ç®—æ³•\næœ€è¿‘æœ€ä¹…æœªä½¿ç”¨ç®—æ³•\næœ€å°‘ä½¿ç”¨ç®—æ³•\nClock ç®—æ³•\næ”¹è¿›å‹ Clock ç®—æ³•\n\n# æŠ–åŠ¨\n** æŠ–åŠ¨ï¼ˆThrashingï¼‰** æ˜¯æ“ä½œç³»ç»Ÿä¸­ä¸è™šæ‹Ÿå†…å­˜ç®¡ç†ç›¸å…³çš„ä¸€ç§ç°è±¡ï¼Œé€šå¸¸å‘ç”Ÿåœ¨ç³»ç»Ÿå†…å­˜èµ„æºä¸è¶³æ—¶ã€‚å½“ç³»ç»Ÿé¢‘ç¹åœ°è¿›è¡Œé¡µé¢ç½®æ¢ï¼ˆå³é¢‘ç¹åœ°å°†å†…å­˜ä¸­çš„é¡µé¢æ¢å‡ºåˆ°å¤–å­˜ï¼Œå†ä»å¤–å­˜æ¢å…¥æ–°çš„é¡µé¢ï¼‰ï¼Œå¯¼è‡´å¤§éƒ¨åˆ†æ—¶é—´éƒ½èŠ±åœ¨é¡µé¢è°ƒåº¦ä¸Šï¼Œè€Œä¸æ˜¯æ‰§è¡Œå®é™…ä»»åŠ¡æ—¶ï¼Œå°±å‘ç”Ÿäº†æŠ–åŠ¨ã€‚\n# I/O è®¾åˆ«æ§åˆ¶æ–¹å¼\n\nä½¿ç”¨è½®è¯¢çš„å¯ç¼–ç¨‹ I/O æ–¹å¼ï¼ˆè½åï¼‰\nä½¿ç”¨ä¸­æ–­çš„å¯ç¼–ç¨‹ I/O æ–¹å¼ï¼ˆç”¨çš„æ¯”è¾ƒå¤šï¼‰\nä½¿ç”¨ DMAï¼ˆå‡å°‘äº† CPU å¯¹ I/O çš„å¹²é¢„ï¼‰\nä½¿ç”¨ I/O é€šé“\n\n# å‡è„±æœºæŠ€æœ¯ - SPOOLing\nå‡è„±æœºæŠ€æœ¯ï¼ˆSPOOLingï¼ŒSimultaneous Peripheral Operations On-Lineï¼‰ æ˜¯ä¸€ç§ç”¨äºç®¡ç†è¾“å…¥ / è¾“å‡ºï¼ˆI/Oï¼‰æ“ä½œçš„æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ä½é€Ÿå¤–è®¾ï¼ˆå¦‚æ‰“å°æœºï¼‰æ—¶ã€‚SPOOLing çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ç¼“å†²å’Œæ’é˜Ÿæœºåˆ¶ï¼Œå°†å¤–è®¾çš„æ“ä½œä¸ä¸»æœºçš„è®¡ç®—ä»»åŠ¡åˆ†ç¦»ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„æ•ˆç‡å’Œèµ„æºåˆ©ç”¨ç‡ã€‚\nSPOOLing çš„åŸºæœ¬åŸç†\n\nè¾“å…¥äº•å’Œè¾“å‡ºäº•ï¼š\n\nSPOOLing ç³»ç»Ÿåœ¨ç£ç›˜ä¸Šåˆ›å»ºä¸¤ä¸ªä¸“é—¨çš„å­˜å‚¨åŒºåŸŸï¼šè¾“å…¥äº•å’Œè¾“å‡ºäº•ã€‚\nè¾“å…¥äº•ç”¨äºæš‚å­˜ä»è¾“å…¥è®¾å¤‡ï¼ˆå¦‚è¯»å¡å™¨ï¼‰è¯»å–çš„æ•°æ®ã€‚\nè¾“å‡ºäº•ç”¨äºæš‚å­˜éœ€è¦å‘é€åˆ°è¾“å‡ºè®¾å¤‡ï¼ˆå¦‚æ‰“å°æœºï¼‰çš„æ•°æ®ã€‚\n\n\nç¼“å†²å’Œæ’é˜Ÿï¼š\n\nå½“ç”¨æˆ·æäº¤ä»»åŠ¡æ—¶ï¼Œæ•°æ®é¦–å…ˆè¢«å†™å…¥ç£ç›˜çš„è¾“å…¥äº•æˆ–è¾“å‡ºäº•ï¼Œè€Œä¸æ˜¯ç›´æ¥å‘é€åˆ°å¤–è®¾ã€‚\nå¤–è®¾ï¼ˆå¦‚æ‰“å°æœºï¼‰ä»è¾“å‡ºäº•ä¸­æŒ‰é¡ºåºè¯»å–æ•°æ®å¹¶æ‰§è¡Œæ“ä½œï¼Œè€Œä¸»æœºå¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡ã€‚\n\n\nå¹¶è¡Œæ“ä½œï¼š\n\nä¸»æœºå’Œå¤–è®¾å¯ä»¥å¹¶è¡Œå·¥ä½œã€‚ä¸»æœºä¸éœ€è¦ç­‰å¾…å¤–è®¾å®Œæˆæ“ä½œï¼Œè€Œæ˜¯å°†æ•°æ®äº¤ç»™ SPOOLing ç³»ç»Ÿåç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡ã€‚\n\n\n\nSPOOLing çš„åº”ç”¨åœºæ™¯\n\næ‰“å°ä»»åŠ¡ç®¡ç†ï¼š\n\næ‰“å°æœºæ˜¯å…¸å‹çš„ä½é€Ÿå¤–è®¾ï¼ŒSPOOLing æŠ€æœ¯å¯ä»¥æœ‰æ•ˆåœ°ç®¡ç†å¤šä¸ªæ‰“å°ä»»åŠ¡ï¼Œé¿å…ç”¨æˆ·ç­‰å¾…ã€‚\n\n\næ‰¹å¤„ç†ç³»ç»Ÿï¼š\n\nåœ¨æ‰¹å¤„ç†ç³»ç»Ÿä¸­ï¼ŒSPOOLing æŠ€æœ¯å¯ä»¥ç”¨äºç®¡ç†è¾“å…¥ä½œä¸šå’Œè¾“å‡ºç»“æœã€‚\n\n\nç½‘ç»œæ‰“å°ï¼š\n\nç°ä»£ç½‘ç»œæ‰“å°æœºé€šå¸¸ä½¿ç”¨ SPOOLing æŠ€æœ¯æ¥ç®¡ç†æ¥è‡ªå¤šä¸ªç”¨æˆ·çš„æ‰“å°ä»»åŠ¡ã€‚\n\n\n\nSPOOLing æŠ€æœ¯å°±æ˜¯å°†ç‹¬å è®¾å¤‡è½¬å˜ä¸ºé€»è¾‘ä¸Šçš„å…±äº«è®¾å¤‡ï¼Œæé«˜äº† I/O é€Ÿåº¦ï¼Œå®ç°äº†è™šæ‹Ÿè®¾å¤‡çš„åŠŸèƒ½ã€‚\n# æ–‡ä»¶åœ¨å¤–å­˜çš„ç»„ç»‡æ–¹å¼\n\nè¿ç»­ç»„ç»‡æ–¹å¼\né“¾æ¥ç»„ç»‡æ–¹å¼ï¼ˆæ˜¾ç¤ºè¿æ¥ FATã€éšå¼é“¾æ¥ï¼‰\nç´¢å¼•ç»„ç»‡æ–¹å¼ï¼ˆä¸€çº§ç´¢å¼•ã€äºŒçº§ç´¢å¼•â€¦ï¼‰\n\n# æ˜¾ç¤ºé“¾æ¥\næ˜¾ç¤ºé“¾æ¥é€šè¿‡ä¸€ä¸ªä¸“é—¨çš„é“¾æ¥è¡¨æ¥è®°å½•æ–‡ä»¶ä¸­å„ä¸ªå—çš„ç‰©ç†åœ°å€ã€‚è¿™ä¸ªè¡¨é€šå¸¸ç§°ä¸ºæ–‡ä»¶åˆ†é…è¡¨ï¼ˆFAT, File Allocation Tableï¼‰ã€‚\n# éšå¼é“¾æ¥\néšå¼é“¾æ¥å°†æ¯ä¸ªå—çš„æŒ‡é’ˆå­˜å‚¨åœ¨å—æœ¬èº«ä¸­ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ä¸€ä¸ªå…¨å±€çš„é“¾æ¥è¡¨ã€‚æ¯ä¸ªå—ä¸­é™¤äº†å­˜å‚¨æ•°æ®å¤–ï¼Œè¿˜åŒ…å«ä¸‹ä¸€ä¸ªå—çš„åœ°å€ã€‚\n# æ˜¾ç¤ºé“¾æ¥ vs éšå¼é“¾æ¥\n\n\n\nç‰¹æ€§\næ˜¾ç¤ºé“¾æ¥ï¼ˆFATï¼‰\néšå¼é“¾æ¥\n\n\n\n\nå­˜å‚¨ç»“æ„\nä½¿ç”¨å…¨å±€çš„ FAT è¡¨å­˜å‚¨é“¾æ¥ä¿¡æ¯\né“¾æ¥ä¿¡æ¯å­˜å‚¨åœ¨å—å†…éƒ¨\n\n\nè®¿é—®æ–¹å¼\næ”¯æŒéšæœºè®¿é—®\nä»…æ”¯æŒé¡ºåºè®¿é—®\n\n\nç©ºé—´å¼€é”€\nFAT è¡¨å ç”¨é¢å¤–ç©ºé—´\næ— é¢å¤–ç©ºé—´å¼€é”€\n\n\nå®ç°å¤æ‚åº¦\nè¾ƒå¤æ‚\nè¾ƒç®€å•\n\n\nå¯é æ€§\nFAT æŸåå¯èƒ½å¯¼è‡´æ–‡ä»¶ç³»ç»Ÿå¤±æ•ˆ\nå•ä¸ªå—æŸåå¯èƒ½å½±å“æ–‡ä»¶å®Œæ•´æ€§\n\n\né€‚ç”¨åœºæ™¯\néœ€è¦éšæœºè®¿é—®çš„åœºæ™¯\né¡ºåºè®¿é—®ä¸ºä¸»çš„åœºæ™¯\n\n\n\n# å°é—®é¢˜\n# è¿›ç¨‹å’Œç¨‹åºæœ‰ä»€ä¹ˆåŒºåˆ«\n\nç¨‹åº\n\nç¨‹åºæ˜¯å­˜å‚¨åœ¨ç£ç›˜æˆ–å…¶ä»–å­˜å‚¨ä»‹è´¨ä¸Šçš„é™æ€å®ä½“ï¼Œç”±ä¸€ç³»åˆ—æŒ‡ä»¤å’Œæ•°æ®ç»„æˆã€‚\nå®ƒæ˜¯ä¸€ä¸ªè¢«åŠ¨çš„å®ä½“ï¼Œåªæœ‰åœ¨è¢«åŠ è½½åˆ°å†…å­˜å¹¶æ‰§è¡Œæ—¶æ‰ä¼šå‘æŒ¥ä½œç”¨ã€‚\n\n\nè¿›ç¨‹\n\nè¿›ç¨‹æ˜¯ç¨‹åºåœ¨å†…å­˜ä¸­çš„åŠ¨æ€æ‰§è¡Œå®ä¾‹ã€‚\nå®ƒæ˜¯ä¸€ä¸ªä¸»åŠ¨çš„å®ä½“ï¼ŒåŒ…å«äº†ç¨‹åºçš„æ‰§è¡ŒçŠ¶æ€ï¼ˆå¦‚ç¨‹åºè®¡æ•°å™¨ã€å¯„å­˜å™¨ã€å †æ ˆç­‰ï¼‰ä»¥åŠç³»ç»Ÿåˆ†é…çš„èµ„æºï¼ˆå¦‚å†…å­˜ã€æ–‡ä»¶å¥æŸ„ç­‰ï¼‰ã€‚\n\n\n\n\n\n\nç‰¹æ€§\nç¨‹åºï¼ˆProgramï¼‰\nè¿›ç¨‹ï¼ˆProcessï¼‰\n\n\n\n\nå®šä¹‰\né™æ€çš„æŒ‡ä»¤å’Œæ•°æ®é›†åˆ\nç¨‹åºçš„åŠ¨æ€æ‰§è¡Œå®ä¾‹\n\n\nç”Ÿå‘½å‘¨æœŸ\næ°¸ä¹…å­˜åœ¨\nä¸´æ—¶å­˜åœ¨ï¼Œä»åˆ›å»ºåˆ°ç»ˆæ­¢\n\n\nçŠ¶æ€\næ— çŠ¶æ€\næœ‰çŠ¶æ€ï¼ˆè¿è¡Œã€å°±ç»ªã€é˜»å¡ç­‰ï¼‰\n\n\nèµ„æºå ç”¨\nä¸å ç”¨ç³»ç»Ÿèµ„æº\nå ç”¨ç³»ç»Ÿèµ„æºï¼ˆCPUã€å†…å­˜ç­‰ï¼‰\n\n\nå¹¶å‘æ€§\nä¸æ”¯æŒå¹¶å‘\næ”¯æŒå¹¶å‘\n\n\nç‹¬ç«‹æ€§\nç‹¬ç«‹å­˜åœ¨\nè¿›ç¨‹é—´ç‹¬ç«‹ï¼Œå¯é€šè¿‡ IPC äº¤äº’\n\n\nåˆ›å»ºæ–¹å¼\nå¼€å‘è€…ç¼–å†™ï¼Œç¼–è¯‘ç”Ÿæˆ\næ“ä½œç³»ç»Ÿåˆ›å»º\n\n\nç¤ºä¾‹\nå¯æ‰§è¡Œæ–‡ä»¶ï¼ˆå¦‚  a.exe ï¼‰\nè¿è¡Œä¸­çš„ç¨‹åºå®ä¾‹\n\n\n\n# æ­»é”æ˜¯ä»€ä¹ˆï¼Ÿæ­»é”æ˜¯æ€ä¹ˆäº§ç”Ÿçš„ï¼Ÿå¦‚ä½•å¤„ç†æ­»é”ï¼Ÿ\næ­»é”æ˜¯æ“ä½œç³»ç»Ÿä¸­çš„ä¸€ç§èµ„æºç«äº‰é—®é¢˜ï¼ŒæŒ‡çš„æ˜¯å¤šä¸ªè¿›ç¨‹æˆ–çº¿ç¨‹å› ä¸ºç«äº‰èµ„æºè€Œç›¸äº’ç­‰å¾…ï¼Œå¯¼è‡´å®ƒä»¬éƒ½æ— æ³•ç»§ç»­æ‰§è¡Œçš„çŠ¶æ€ã€‚æ­»é”æ˜¯ä¸€ç§ä¸¥é‡çš„ç³»ç»Ÿé—®é¢˜ï¼Œä¼šå¯¼è‡´ç³»ç»Ÿèµ„æºæµªè´¹å’Œç¨‹åºæ— æ³•æ­£å¸¸è¿è¡Œã€‚\n\næ­»é”çš„äº§ç”Ÿæ¡ä»¶\n\näº’æ–¥æ¡ä»¶\nä¸å‰¥å¤ºæ¡ä»¶\nè¯·æ±‚ä¸ä¿æŒæ¡ä»¶\nå¾ªç¯ç­‰å¾…æ¡ä»¶\n\n\næ­»é”çš„å¤„ç†æ–¹æ³•\n\næ­»é”çš„é¢„é˜²\næ­»é”çš„æ£€æµ‹\næ­»é”çš„é¿å…\næ­»é”çš„è§£é™¤\n\n\n\n# é¥¥é¥¿æ˜¯ä»€ä¹ˆï¼Ÿå’Œæ­»é”æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\né¥¥é¥¿æ˜¯æŒ‡æŸä¸ªè¿›ç¨‹æˆ–çº¿ç¨‹å› ä¸ºèµ„æºæ€»æ˜¯è¢«å…¶ä»–è¿›ç¨‹æŠ¢å ï¼Œå¯¼è‡´å®ƒé•¿æœŸå¾—ä¸åˆ°æ‰€éœ€çš„èµ„æºï¼Œä»è€Œæ— æ³•ç»§ç»­æ‰§è¡Œã€‚\näº§ç”ŸåŸå› \n\nèµ„æºåˆ†é…ç­–ç•¥ä¸å…¬å¹³ï¼š\n\næŸäº›è¿›ç¨‹æ€»æ˜¯ä¼˜å…ˆè·å¾—èµ„æºï¼Œè€Œå…¶ä»–è¿›ç¨‹è¢«å¿½ç•¥ã€‚\n\n\nä¼˜å…ˆçº§è°ƒåº¦é—®é¢˜ï¼š\n\né«˜ä¼˜å…ˆçº§è¿›ç¨‹ä¸æ–­æŠ¢å èµ„æºï¼Œä½ä¼˜å…ˆçº§è¿›ç¨‹å§‹ç»ˆå¾—ä¸åˆ°èµ„æºã€‚\n\n\nèµ„æºç«äº‰æ¿€çƒˆï¼š\n\nèµ„æºæ•°é‡æœ‰é™ï¼Œä¸”ç«äº‰èµ„æºçš„è¿›ç¨‹è¿‡å¤šã€‚\n\n\n\n\n\n\nç‰¹æ€§\né¥¥é¥¿ï¼ˆStarvationï¼‰\næ­»é”ï¼ˆDeadlockï¼‰\n\n\n\n\nå®šä¹‰\næŸä¸ªè¿›ç¨‹é•¿æœŸå¾—ä¸åˆ°èµ„æº\nå¤šä¸ªè¿›ç¨‹ç›¸äº’ç­‰å¾…ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œ\n\n\næˆå› \nèµ„æºåˆ†é…ä¸å…¬å¹³æˆ–ä¼˜å…ˆçº§è°ƒåº¦é—®é¢˜\nå››ä¸ªå¿…è¦æ¡ä»¶åŒæ—¶æ»¡è¶³\n\n\næ¶‰åŠè¿›ç¨‹æ•°é‡\nå¯èƒ½åªæœ‰ä¸€ä¸ªè¿›ç¨‹è¢« â€œé¥¿æ­»â€\nè‡³å°‘æœ‰ä¸¤ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹ç›¸äº’ç­‰å¾…\n\n\nèµ„æºçŠ¶æ€\nèµ„æºè¢«å…¶ä»–è¿›ç¨‹å ç”¨ï¼Œä½†æœªè¢«é˜»å¡\nèµ„æºè¢«å ç”¨ä¸”è¿›ç¨‹ç›¸äº’é˜»å¡\n\n\nè§£å†³æ–¹æ³•\nå…¬å¹³è°ƒåº¦ã€åŠ¨æ€ä¼˜å…ˆçº§è°ƒæ•´ã€èµ„æºé¢„ç•™\né¢„é˜²ã€é¿å…ã€æ£€æµ‹ä¸æ¢å¤ã€å¿½ç•¥\n\n\nå½±å“èŒƒå›´\nåªå½±å“è¢« â€œé¥¿æ­»â€ çš„è¿›ç¨‹\nå½±å“æ‰€æœ‰å‚ä¸æ­»é”çš„è¿›ç¨‹\n\n\næ˜¯å¦å¯æ¢å¤\nå¯ä»¥é€šè¿‡è°ƒæ•´èµ„æºåˆ†é…æ¢å¤\néœ€è¦å¤–éƒ¨å¹²é¢„ï¼ˆå¦‚ç»ˆæ­¢è¿›ç¨‹ï¼‰æ‰èƒ½æ¢å¤\n\n\n\n","categories":["æ“ä½œç³»ç»Ÿ"],"tags":["OS"]},{"title":"æ”¿æ²»çŸ¥è¯†ç‚¹é€Ÿè®°ï¼ˆæŒç»­æ›´æ–°ï¼‰","url":"/PoliticalKnowledge/politicalNote/","content":"# é¢†èˆª\n\néƒ¨åˆ†å£è¯€æ¥è‡ªæä¸½åŒè€å¸ˆ\nä¸»è¦å†…å®¹æ¥è‡ªã€Šè‚–ç§€è£ 1000 é¢˜ã€‹ã€ã€Šç²¾è®²ç²¾ç‚¼ã€‹ã€ã€Š30 å¤© 70 åˆ†ã€‹çš„ç­”æ¡ˆè§£æ\nä»¥åŠå…¶ä»–åŒå­¦ä»¬çš„ç¬”è®°\nç‰ˆæƒé—®é¢˜è¯·è”ç³»ä½œè€… QQï¼š735690757\n\n# å²çº²\n# é©¬åŸç†\n# ä¹ æ€æƒ³\n# çç¢\nåœ¨ä¹ è¿‘å¹³æ–°æ—¶ä»£ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ€æƒ³çš„æŒ‡å¯¼ä¸‹ï¼Œä¸­å›½å…±äº§å…šå›¢ç»“å¸¦é¢†ä¸­å›½äººæ°‘ï¼Œè‡ªä¿¡è‡ªå¼ºã€å®ˆæ­£åˆ›æ–°ï¼Œç»Ÿæ½ä¼Ÿå¤§æ–—äº‰ã€ä¼Ÿå¤§å·¥ç¨‹ã€ä¼Ÿå¤§äº‹ä¸šã€ä¼Ÿå¤§æ¢¦æƒ³ï¼Œåˆ›é€ äº†æ–°æ—¶ä»£ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰çš„ ä¼Ÿå¤§æˆå°±ï¼Œä¸ºå®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´æä¾›äº†æ›´ä¸ºå®Œå–„çš„åˆ¶åº¦ä¿è¯ã€æ›´ä¸ºåšå®çš„ç‰©è´¨åŸºç¡€ã€æ›´ä¸ºä¸»åŠ¨çš„ç²¾ç¥åŠ›é‡ã€‚\n# å…­ä¸ªåšæŒ\nâ€œå…­ä¸ªå¿…é¡»åšæŒâ€: å¿…é¡»åšæŒäººæ°‘è‡³ä¸Šã€å¿…é¡»åšæŒè‡ªä¿¡è‡ªç«‹ã€å¿…é¡»åšæŒå®ˆæ­£åˆ›æ–°ã€å¿…é¡»åšæŒé—®é¢˜å¯¼å‘ã€å¿…é¡»åšæŒç³»ç»Ÿè§‚å¿µã€å¿…é¡»åšæŒèƒ¸æ€€å¤©ä¸‹ã€‚\n\näººå¿ƒæ­£é“ç³»å¤©ä¸‹\n\n# å…šçš„æ ¹æœ¬å®—æ—¨\nå…šçš„æ ¹æœ¬å®—æ—¨æ˜¯å…¨å¿ƒå…¨æ„ä¸ºäººæ°‘æœåŠ¡\n# å®ç°é€”å¾„ã€è¡ŒåŠ¨æŒ‡å—ã€æ ¹æœ¬ä¿éšœã€ç²¾ç¥åŠ›é‡\næ”¹é©å¼€æ”¾ä»¥æ¥æˆ‘ä»¬å–å¾—ä¸€åˆ‡æˆç»©å’Œè¿›æ­¥çš„æ ¹æœ¬åŸå› ï¼Œå½’ç»“èµ·æ¥å°±æ˜¯ï¼›å¼€è¾Ÿäº†ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰é“è·¯ï¼Œå½¢æˆäº†ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç†è®ºä½“ç³»ï¼Œç¡®ç«‹äº†ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰åˆ¶åº¦ï¼Œå‘å±•äº†ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ–‡åŒ–ã€‚å…¶ä¸­ï¼Œé“è·¯æ˜¯å®ç°é€”å¾„ï¼Œç†è®ºä½“ç³»æ˜¯è¡ŒåŠ¨æŒ‡å—ï¼Œåˆ¶åº¦æ˜¯æ ¹æœ¬ä¿éšœï¼Œæ–‡åŒ–æ˜¯ç²¾ç¥åŠ›é‡ï¼Œå››è€…ç»Ÿä¸€äºä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ä¼Ÿå¤§å®è·µã€‚\n# å››ä¸ªè‡ªä¿¡ç†è®ºæ”¯æ’‘å’Œæ ¹æœ¬ä¾æ®\né©¬å…‹æ€ä¸»ä¹‰æ·±åˆ»æ­ç¤ºäº†ç¤¾ä¼šä¸»ä¹‰å¿…ç„¶ä»£æ›¿èµ„æœ¬ä¸»ä¹‰çš„å®¢è§‚è§„å¾‹ï¼Œè¿™æ˜¯æˆ‘ä»¬åšå®š â€œå››ä¸ªè‡ªä¿¡â€ çš„ç†è®ºæ”¯æ’‘å’Œæ ¹æœ¬ä¾æ®ã€‚\n# å››ä¸ªè‡ªä¿¡çš„æ¥æº\nä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰é“è·¯è‡ªä¿¡ã€ç†è®ºè‡ªä¿¡ã€åˆ¶åº¦è‡ªä¿¡ã€æ–‡åŒ–è‡ªä¿¡ï¼Œæ¥æºäºå®è·µã€æ¥æºäºäººæ°‘ã€æ¥æºäºçœŸç†ã€‚\n# å››ä¸ªå…¨é¢å¤„äºä¸»å¯¼åœ°ä½çš„æ˜¯\nâ€œå››ä¸ªå…¨é¢â€ æˆ˜ç•¥å¸ƒå±€æ—¢æœ‰æˆ˜ç•¥ç›®æ ‡åˆæœ‰æˆ˜ç•¥ä¸¾æªï¼Œæ¯ä¸ª â€œå…¨é¢â€ ä¹‹é—´å…·æœ‰ç´§å¯†çš„å†…åœ¨é€»è¾‘æ˜¯ä¸€ä¸ªæ•´ä½“æˆ˜ç•¥éƒ¨ç½²çš„æœ‰åºå±•å¼€ã€‚å…¨é¢å»ºè®¾ç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å›½å®¶æ˜¯æˆ˜ç•¥ç›®æ ‡ï¼Œåœ¨ â€œå››ä¸ªå…¨é¢â€ ä¸­å±…äºå¼•é¢†åœ°ä½ï¼›å…¨é¢æ·±åŒ–æ”¹é©ã€å…¨é¢ä¾æ³•æ²»å›½ã€å…¨é¢ä»ä¸¥æ²»å…šæ˜¯ä¸‰å¤§æˆ˜ç•¥ä¸¾æªï¼Œä¸ºå…¨é¢å»ºè®¾ç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å›½å®¶æä¾›é‡è¦ä¿éšœã€‚\n# å…šçš„åŸºæœ¬è·¯çº¿\nå…šçš„åŸºæœ¬è·¯çº¿æ˜¯å›½å®¶çš„ç”Ÿå‘½çº¿ã€äººæ°‘çš„å¹¸ç¦çº¿ã€‚\n# ç§‘å­¦ç¤¾ä¼šä¸»ä¹‰çš„ä¸»å¼ \nç§‘å­¦ç¤¾ä¼šä¸»ä¹‰çš„ä¸»å¼ å—åˆ°ä¸­å›½äººæ°‘çƒ­çƒˆæ¬¢è¿ï¼Œå¹¶æœ€ç»ˆæ‰æ ¹ä¸­å›½å¤§åœ°ã€å¼€èŠ±ç»“æœï¼Œæ˜¯å› ä¸ºï¼šç¬¬ä¸€ï¼Œå®ƒå›ç­”äº†è¿‘ä»£ä»¥æ¥ä¸­åæ°‘æ—é¢ä¸´çš„å†å²æ€§è¯¾é¢˜ (æ±‚å¾—æ°‘æ—ç‹¬ç«‹å’Œäººæ°‘è§£æ”¾ï¼›å®ç°å›½å®¶å¯Œå¼ºå’Œäººæ°‘å¹¸ç¦)ã€æŒ‡æ˜äº†å®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´çš„æ­£ç¡®é“è·¯ (ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ˜¯å®ç°ä¸­åæ°‘æ—å¤å…´çš„æ­£ç¡®é“è·¯); ç¬¬äºŒï¼Œå®ƒåŒæˆ‘å›½ä¼ æ‰¿äº†å‡ åƒå¹´çš„ä¼˜ç§€å†å²æ–‡åŒ–å’Œå¹¿å¤§äººæ°‘æ—¥ç”¨è€Œä¸è§‰çš„ä»·å€¼è§‚å¿µå…·æœ‰é«˜åº¦çš„å¥‘åˆæ€§\n# ç™¾å¹´å¥‹æ–—ç›®æ ‡ - ä¸æ˜¯é¡ºåºçš„è€Œæ˜¯äº¤é”™çš„ 100 å¹´\nç¬¬ä¸€ä¸ªä¸€ç™¾å¹´ï¼ˆå…±äº§å…šæˆç«‹ 100 å‘¨å¹´ï¼‰ï¼Œæ˜¯åˆ°ä¸­å›½å…±äº§å…šæˆç«‹ 100 å¹´æ—¶å…¨é¢å»ºæˆå°åº·ç¤¾ä¼šï¼ˆ1921-2021ï¼‰\nç¬¬äºŒä¸ªä¸€ç™¾å¹´ï¼ˆæ–°ä¸­å›½æˆç«‹ 100 å‘¨å¹´ï¼‰ï¼Œæ˜¯åˆ°æ–°ä¸­å›½æˆç«‹ 100 å¹´æ—¶å»ºæˆå¯Œå¼ºæ°‘ä¸»æ–‡æ˜å’Œè°ç¾ä¸½çš„ç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å¼ºå›½ï¼ˆ1949-2049ï¼‰\n# æ–°å½¢åŠ¿ä¸‹åšå¥½æ–°é—»èˆ†è®ºå·¥ä½œçš„å…³é”®\näº’è”ç½‘æ˜¯æ„è¯†å½¢æ€å·¥ä½œçš„ä¸»é˜µåœ°ã€ä¸»æˆ˜åœºã€æœ€å‰æ²¿ï¼Œç®¡å¥½ç”¨å¥½äº’è”ç½‘æ˜¯æ–°å½¢åŠ¿ä¸‹åšå¥½æ–°é—»èˆ†è®ºå·¥ä½œçš„å…³é”®ã€‚ä¹ è¿‘å¹³æŒ‡å‡ºï¼šâ€œè¿‡ä¸äº†äº’è”ç½‘è¿™ä¸€å…³ï¼Œå°±è¿‡ä¸äº†é•¿æœŸæ‰§æ”¿è¿™ä¸€å…³ã€‚\n# æ–‡åŒ–æ˜¯â€¦\né¢å»ºæˆç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å¼ºå›½å¿…ç„¶è¦æ±‚å»ºè®¾ç¤¾ä¼šä¸»ä¹‰æ–‡åŒ–å¼ºå›½ã€‚ç»Ÿç­¹æ¨è¿› â€œäº”ä½ä¸€ä½“â€ æ€»ä½“å¸ƒå±€ã€åè°ƒæ¨è¿› â€œå››ä¸ªå…¨é¢â€ æˆ˜ç•¥å¸ƒå±€ï¼Œæ–‡åŒ–æ˜¯é‡è¦å†…å®¹ï¼›æ¨åŠ¨é«˜è´¨é‡å‘å±•ï¼Œæ–‡åŒ–æ˜¯é‡è¦æ”¯ç‚¹ï¼›æ»¡è¶³äººæ°‘æ—¥ç›Šå¢é•¿çš„ç¾å¥½ç”Ÿæ´»éœ€è¦ï¼Œæ–‡åŒ–æ˜¯é‡è¦å› ç´ ï¼›æˆ˜èƒœå‰è¿›é“è·¯ä¸Šå„ç§é£é™©æŒ‘æˆ˜ï¼Œæ–‡åŒ–æ˜¯é‡è¦åŠ›é‡æºæ³‰ã€‚åªæœ‰æ¨åŠ¨æ–‡åŒ–ç¹è£å…´ç››ï¼Œæ‰èƒ½ä¸ºæ¨è¿›ä¸­å›½å¼ç°ä»£åŒ–å»ºè®¾ã€å®ç°ç¬¬äºŒä¸ªç™¾å¹´å¥‹æ–—ç›®æ ‡æä¾›æ€æƒ³ä¿è¯ã€èˆ†è®ºæ”¯æŒã€ç²¾ç¥åŠ¨åŠ›å’Œæ–‡åŒ–æ¡ä»¶ã€‚\n# ä¸­å›½å…±äº§å…šçš„ç²¾ç¥ä¹‹æº\nä¼Ÿå¤§å»ºå…šç²¾ç¥æ˜¯ä¸­å›½å…±äº§å…šçš„ç²¾ç¥ä¹‹æº\n# å…³ä¹æ——å¸œã€å…³ä¹é“è·¯ã€å…³ä¹å›½å®¶æ”¿æ²»å®‰å…¨ï¼Œå†³å®šæ–‡åŒ–å‰è¿›æ–¹å‘å’Œå‘å±•é“è·¯\næ„è¯†å½¢æ€å…³ä¹æ——å¸œã€å…³ä¹é“è·¯ã€å…³ä¹å›½å®¶æ”¿æ²»å®‰å…¨ï¼Œå†³å®šæ–‡åŒ–å‰è¿›æ–¹å‘å’Œå‘å±•é“è·¯ã€‚\n# åšæŒç™¾èŠ±é½æ”¾ã€ç™¾å®¶äº‰é¸£ (â€œåŒç™¾â€)\nåšæŒç™¾èŠ±é½æ”¾ã€ç™¾å®¶äº‰é¸£ (â€œåŒç™¾â€) æ˜¯ç¹è£å‘å±•ç¤¾ä¼šä¸»ä¹‰æ–‡åŒ–çš„é‡è¦æ–¹é’ˆã€‚\n# åšæŒä¸ºäººæ°‘æœåŠ¡ã€ä¸ºç¤¾ä¼šä¸»ä¹‰æœåŠ¡ (â€œäºŒä¸ºâ€)\nåšæŒä¸ºäººæ°‘æœåŠ¡ã€ä¸ºç¤¾ä¼šä¸»ä¹‰æœåŠ¡ (â€œäºŒä¸ºâ€) çš„æ ¹æœ¬æ–¹å‘ï¼Œæ˜¯å†³å®šç¤¾ä¼šä¸»ä¹‰æ–‡åŒ–äº‹ä¸šå‰é€”å‘½è¿çš„å…³é”®ã€‚\n# åŒºåˆ«äºå…¶ä»–å›½å®¶å’Œæ°‘æ—çš„æ ¹æœ¬ç‰¹å¾\nä¸­åæ°‘æ—åˆ›é€ çš„ä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–æ˜¯æ°‘æ—çš„æ ¹è„‰ï¼Œæ ¹æ¤åœ¨ä¸­å›½äººå†…å¿ƒï¼Œå½¢æˆäº†ä¸­å›½äººçœ‹å¾…ä¸–ç•Œã€çœ‹å¾…ç¤¾ä¼šã€çœ‹å¾…äººç”Ÿçš„ç‹¬ç‰¹ä»·å€¼ä½“ç³»ã€æ–‡åŒ–å†…æ¶µå’Œç²¾ç¥å“è´¨ï¼Œè¿™æ˜¯æˆ‘ä»¬åŒºåˆ«äºå…¶ä»–å›½å®¶å’Œæ°‘æ—çš„æ ¹æœ¬ç‰¹å¾ã€‚\n# æ–‡åŒ–çš„ç”Ÿå‘½æ‰€åœ¨ã€æœ¬è´¨ç‰¹å¾\nåˆ›æ–°åˆ›é€ æ˜¯æ–‡åŒ–çš„ç”Ÿå‘½æ‰€åœ¨ï¼Œæ˜¯æ–‡åŒ–çš„æœ¬è´¨ç‰¹å¾ã€‚å› æ­¤\n# å…±åŒå¯Œè£•çš„åŸºç¡€æ€§åˆ¶åº¦\nåˆ†é…åˆ¶åº¦\n# åˆæ¬¡åˆ†é…\nç¬¬ä¸€æ¬¡åˆ†é…çš„ä¸»ä½“æ˜¯å¸‚åœºå‚ä¸çš„å„è¦ç´ ä¸»ä½“ã€‚\n\nåˆæ¬¡åˆ†é…ï¼Œå³åˆæ¬¡æ”¶å…¥åˆ†é…ã€‚åœ¨ç¤¾ä¼šåˆ†é…ä¸­ï¼Œåˆæ¬¡åˆ†é…æ³¨é‡æ•ˆç‡ï¼Œæ˜¯æŒ‰è´¡çŒ®åˆ†é…ã€‚è¯¥è´¡çŒ®åŒ…æ‹¬å¯¹åˆ›é€ åˆ©æ¶¦æœ‰ç›Šçš„å„ç§å› ç´ ï¼Œå¦‚èµ„é‡‘ã€æŠ€æœ¯ã€ç®¡ç†ã€ç”Ÿäº§èµ„æ–™ã€åŠ³åŠ¨åŠ›ã€ä¿¡æ¯ã€å¸‚åœºã€è¥é”€ç­‰ã€‚è°èƒ½åˆ©ç”¨è¿™äº›è¦ç´ ä½œå‡ºè´¡çŒ®ï¼Œå°±èƒ½åˆ†åˆ°ä¸€æ¯ç¾¹ã€‚è¿™æ ·ç¾¤ç­–ç¾¤åŠ›ï¼Œæ•ˆç‡ä¾¿å¾—ä»¥æé«˜ã€‚\nå‚è€ƒ\n\n# å†åˆ†é…\nç¬¬äºŒæ¬¡åˆ†é…çš„ä¸»ä½“æ˜¯æ”¿åºœã€‚\n\nå†åˆ†é…ï¼ˆäºŒæ¬¡åˆ†é…ï¼‰æ˜¯æŒ‡æ”¿åºœæ ¹æ®æ³•å¾‹æ³•è§„ï¼Œåœ¨åˆæ¬¡åˆ†é…çš„åŸºç¡€ä¸Šé€šè¿‡å¾æ”¶ç¨æ”¶å’Œæ”¿åºœéç¨æ”¶å…¥ï¼Œåœ¨å„æ”¶å…¥ä¸»ä½“ä¹‹é—´ä»¥ç°é‡‘æˆ–å®ç‰©è¿›è¡Œçš„æ”¶å…¥å†æ¬¡åˆ†é…è¿‡ç¨‹ã€‚ä¸åˆæ¬¡åˆ†é…ä¸åŒï¼Œå†åˆ†é…ä¸­èµ·ä¸»å¯¼ä½œç”¨çš„æ˜¯æ”¿åºœï¼Œå¼ºè°ƒå…¬å¹³çš„åŸåˆ™ï¼Œå…·æœ‰é€šè¿‡å›½å®¶æƒåŠ›å¼ºåˆ¶è¿›è¡Œçš„ç‰¹å¾ã€‚é™¤äº†å…¬å¹³çš„ç›®æ ‡å¤–ï¼Œå†åˆ†é…ä¹Ÿé€šè¿‡æ•™è‚²ã€å¥åº·ç­‰åŸºæœ¬å…¬å…±æœåŠ¡çš„æä¾›ï¼Œåˆ›é€ æœºä¼šå¹³ç­‰çš„å…»æ•™ç¯å¢ƒï¼Œä»¥æå‡ç¤¾ä¼šç»æµå‘å±•çš„å¯æŒç»­æ€§ã€‚\nå‚è€ƒ\n\n# ä¸‰æ¬¡åˆ†é…\nè€Œç¬¬ä¸‰æ¬¡åˆ†é…çš„ä¸»ä½“æ˜¯æ°‘é—´ç¤¾ä¼šåŠ›é‡ï¼ŒåŒ…æ‹¬ä¼ä¸šã€ç¤¾ä¼šç»„ç»‡å’Œä¸ªäººç­‰ã€‚\n\nä¸‰æ¬¡åˆ†é…æœ‰åˆ«äºå‰ä¸¤è€…ï¼Œä¸»è¦æ˜¯ä¼ä¸šã€ç¤¾ä¼šç»„ç»‡ã€å®¶æ—ã€å®¶åº­å’Œä¸ªäººç­‰åŸºäºè‡ªæ„¿åŸåˆ™å’Œé“å¾·å‡†åˆ™ï¼Œä»¥å‹Ÿé›†ã€æèµ ã€èµ„åŠ©ã€ä¹‰å·¥ç­‰æ…ˆå–„ã€å…¬ç›Šæ–¹å¼å¯¹æ‰€å±èµ„æºå’Œè´¢å¯Œè¿›è¡Œåˆ†é…ã€‚ç¤¾ä¼šç»„ç»‡å’Œç¤¾ä¼šåŠ›é‡æ˜¯ä¸‰æ¬¡åˆ†é…çš„ä¸­åšåŠ›é‡ ã€‚\nå‚è€ƒ\n\n# ä¸‰æ¬¡åˆ†é…çš„å˜åŒ–\nå¸‚åœºğŸ‘‰æ”¿åºœğŸ‘‰ç¤¾ä¼š\n# å†›æ°‘èåˆå‘å±•\nä¹ è¿‘å¹³å¼ºå†›æ€æƒ³æ˜ç¡®å†›æ°‘èåˆå‘å±•æ˜¯å…´å›½ä¹‹ä¸¾ã€å¼ºå†›ä¹‹ç­–ï¼›æ˜ç¡®å…šå¯¹äººæ°‘å†›é˜Ÿçš„ç»å¯¹é¢†å¯¼æ˜¯äººæ°‘å†›é˜Ÿå»ºå†›ä¹‹æœ¬ã€å¼ºå†›ä¹‹é­‚ï¼›æ˜ç¡®ä¾æ³•æ²»å†›æ˜¯æˆ‘ä»¬å…šå»ºå†›æ²»å†›åŸºæœ¬æ–¹å¼ï¼›æ˜ç¡®ä½œé£ä¼˜è‰¯æ˜¯æˆ‘å†›é²œæ˜ç‰¹è‰²å’Œæ”¿æ²»ä¼˜åŠ¿ã€‚\n# æ”¿æ²»å»ºå†›\næ”¿æ²»å»ºå†›æ˜¯äººæ°‘å†›é˜Ÿçš„ç«‹å†›ä¹‹æœ¬ï¼ŒæŠ“å†›é˜Ÿå»ºè®¾é¦–å…ˆè¦ä»æ”¿æ²»ä¸Šçœ‹ã€‚\n# ä¾æ³•æ²»å†›\nä¾æ³•æ²»å†›æ˜¯æˆ‘ä»¬å…šå»ºå†›æ²»å†›åŸºæœ¬æ–¹å¼ã€‚\n# ä¸€æµå†›é˜Ÿè¦æ±‚ä¸€æµç§‘æŠ€\nä¸€æµå†›é˜Ÿè¦æ±‚ä¸€æµç§‘æŠ€ï¼Œå¿…é¡»å…¨é¢å®æ–½ç§‘æŠ€å¼ºå†›æˆ˜ç•¥ã€‚\nç§‘æŠ€æ˜¯æ ¸å¿ƒæˆ˜æ–—åŠ›ï¼Œæ˜¯å†›äº‹å‘å±•ä¸­æœ€æ´»è·ƒã€æœ€å…·é©å‘½æ€§çš„å› ç´ ã€‚\n# åšæŒå…šå¯¹äººæ°‘å†›é˜Ÿçš„ç»å¯¹é¢†å¯¼\nå†›å§”ä¸»å¸­è´Ÿè´£åˆ¶æ˜¯åšæŒå…šå¯¹äººæ°‘å†›é˜Ÿç»å¯¹é¢†å¯¼çš„æ ¹æœ¬åˆ¶åº¦å’Œæ ¹æœ¬å®ç°å½¢å¼ï¼Œåœ¨å…šé¢†å¯¼å†›é˜Ÿçš„ä¸€æ•´å¥—åˆ¶åº¦ä½“ç³»ä¸­å¤„äºæœ€é«˜å±‚æ¬¡ï¼Œå±…äºç»Ÿé¢†åœ°ä½ã€‚\n# å¬å…šæŒ‡æŒ¥ â€”â€” é¦–è¦ã€æ ¸å¿ƒ\nå¬å…šæŒ‡æŒ¥æ˜¯çµé­‚ï¼Œå†³å®šå†›é˜Ÿå»ºè®¾çš„æ”¿æ²»æ–¹å‘ï¼›èƒ½æ‰“èƒœä»—æ˜¯æ ¸å¿ƒï¼Œåæ˜ å†›é˜Ÿçš„æ ¹æœ¬èŒèƒ½å’Œå†›é˜Ÿå»ºè®¾çš„æ ¹æœ¬æŒ‡å‘ã€‚\n# ä½œé£ä¼˜è‰¯ â€”â€” ä¿è¯ã€æ€§è´¨ã€å®—æ—¨ã€æœ¬è´¨\nä½œé£ä¼˜è‰¯æ˜¯ä¿è¯ï¼Œå…³ç³»å†›é˜Ÿçš„æ€§è´¨ã€å®—æ—¨ã€æœ¬è‰²ï¼Œæ˜¯äººæ°‘å†›é˜Ÿçš„é²œæ˜ç‰¹è‰²å’Œæ”¿æ²»ä¼˜åŠ¿ï¼Œä¹Ÿæ˜¯äººæ°‘å†›é˜Ÿæˆ˜æ— ä¸èƒœã€æ”»æ— ä¸å…‹çš„é‡è¦ä¿è¯ã€‚\n# ä½œé£ä¼˜è‰¯ â€”â€” æ ¸å¿ƒ\n# å…³é”®ä¸€æ‹›\næ”¹é©æ˜¯å†³å®šäººæ°‘å†›é˜Ÿå‘å±•å£®å¤§ã€åˆ¶èƒœæœªæ¥çš„å…³é”®ä¸€æ‹›ã€‚\n# å››ä¸ªæˆ˜ç•¥æ”¯æ’‘\nâ€Œæˆ‘å†›æ–°æ—¶ä»£ä½¿å‘½ä»»åŠ¡çš„å››ä¸ªæˆ˜ç•¥æ”¯æ’‘æ˜¯â€Œï¼šâ€Œ\n\n\nä¸ºå·©å›ºâ€Œä¸­å›½å…±äº§å…šé¢†å¯¼å’Œç¤¾ä¼šä¸»ä¹‰åˆ¶åº¦æä¾›æˆ˜ç•¥æ”¯æ’‘â€Œï¼šç¡®ä¿å…šçš„é¢†å¯¼å’Œç¤¾ä¼šä¸»ä¹‰åˆ¶åº¦çš„å®‰å…¨å’Œç¨³å®šã€‚\n\n\nä¸ºæå«â€Œå›½å®¶ä¸»æƒã€ç»Ÿä¸€ã€â€Œé¢†åœŸå®Œæ•´æä¾›æˆ˜ç•¥æ”¯æ’‘â€Œï¼šç»´æŠ¤å›½å®¶çš„é¢†åœŸå®Œæ•´å’Œä¸»æƒä¸å—ä¾µçŠ¯ã€‚\n\n\nâ€Œä¸ºç»´æŠ¤å›½å®¶æµ·å¤–åˆ©ç›Šæä¾›æˆ˜ç•¥æ”¯æ’‘â€Œï¼šä¿æŠ¤å›½å®¶åœ¨æµ·å¤–çš„åˆ©ç›Šå’Œå…¬æ°‘çš„å®‰å…¨ã€‚\n\n\nä¸ºä¿ƒè¿›â€Œä¸–ç•Œå’Œå¹³ä¸å‘å±•æä¾›æˆ˜ç•¥æ”¯æ’‘â€Œï¼šç§¯æå‚ä¸å›½é™…äº‹åŠ¡ï¼Œæ¨åŠ¨ä¸–ç•Œå’Œå¹³ä¸å‘å±•ã€‚\n\n\n# ä¸€å›½ä¸¤åˆ¶\nâ€œä¸€å›½ä¸¤åˆ¶â€ çš„æ ¹æœ¬å®—æ—¨æ˜¯ç»´æŠ¤å›½å®¶ä¸»æƒã€å®‰å…¨ã€å‘å±•åˆ©ç›Šï¼Œä¿æŒé¦™æ¸¯ã€æ¾³é—¨é•¿æœŸç¹è£ç¨³å®š\nç»´æŠ¤å›½å®¶å®‰å…¨æ˜¯ â€œä¸€å›½ä¸¤åˆ¶â€ çš„æ ¸å¿ƒè¦ä¹‰\nç»´æŠ¤å›½å®¶ä¸»æƒã€å®‰å…¨ã€å‘å±•åˆ©ç›Šæ˜¯ â€œä¸€å›½ä¸¤åˆ¶â€ æ–¹é’ˆçš„æœ€é«˜åŸåˆ™ï¼Œåœ¨è¿™ä¸ªå‰æä¸‹ï¼Œé¦™æ¸¯ã€æ¾³é—¨ä¿æŒåŸæœ‰çš„èµ„æœ¬ä¸»ä¹‰åˆ¶åº¦é•¿æœŸä¸å˜ï¼Œäº«æœ‰é«˜åº¦è‡ªæ²»æƒã€‚\nåšæŒ â€œçˆ±å›½è€…æ²»æ¸¯â€â€œçˆ±å›½è€…æ²»æ¾³â€ åŸåˆ™æ˜¯äº‹å…³å›½å®¶ä¸»æƒã€å®‰å…¨ã€å‘å±•åˆ©ç›Šï¼Œäº‹å…³é¦™æ¸¯ã€æ¾³é—¨é•¿æœŸç¹è£ç¨³å®šçš„æ ¹æœ¬åŸåˆ™ï¼Œæ˜¯ä¿è¯é¦™æ¸¯ã€æ¾³é—¨é•¿æ²»ä¹…å®‰çš„å¿…ç„¶è¦æ±‚\n# å…¨é¢è´¯å½»æ–°æ—¶ä»£å…šè§£å†³å°æ¹¾é—®é¢˜çš„æ€»ä½“æ–¹ç•¥\n\næ ¹æœ¬ä¿è¯åšæŒå…šä¸­å¤®å¯¹å¯¹å°å·¥ä½œçš„é›†ä¸­ç»Ÿä¸€é¢†å¯¼\nå†å²æ–¹ä½åœ¨ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´è¿›ç¨‹ä¸­æ¨è¿›ç¥–å›½ç»Ÿä¸€\næˆ˜ç•¥æ€è·¯åœ¨ç¥–å›½å¤§é™†å‘å±•è¿›æ­¥åŸºç¡€ä¸Šè§£å†³å°æ¹¾é—®é¢˜\nå¤§æ”¿æ–¹é’ˆ â€œå’Œå¹³ç»Ÿä¸€ã€ä¸€å›½ä¸¤åˆ¶â€\næ”¿æ²»åŸºç¡€ä¸€ä¸ªä¸­å›½åŸåˆ™å’Œ â€œä¹äºŒå…±è¯†â€\nå®è·µé€”å¾„æ¨åŠ¨ä¸¤å²¸å…³ç³»å’Œå¹³å‘å±•ã€èåˆå‘å±•\næ ¹æœ¬åŠ¨åŠ›å›¢ç»“å°æ¹¾åŒèƒã€äº‰å–å°æ¹¾æ°‘å¿ƒ\nå¿…ç„¶è¦æ±‚ç²‰ç¢ â€œå°ç‹¬â€ åˆ†è£‚å›¾è°‹\nå¤–éƒ¨æ¡ä»¶åå¯¹å¤–éƒ¨åŠ¿åŠ›å¹²æ¶‰\næˆ˜ç•¥æ”¯æ’‘å†³ä¸æ‰¿è¯ºæ”¾å¼ƒä½¿ç”¨æ­¦åŠ›\n\n# å¤–äº¤å·¥ä½œä¸»çº¿\næœåŠ¡æ°‘æ—å¤å…´ï¼Œä¿ƒè¿›äººç±»è¿›æ­¥\n# ç»æµå»ºè®¾ä¸»çº¿\nä¾›ç»™ä¾§ç»“æ„æ€§æ”¹é©\n# å…¨é¢æ·±åŒ–æ”¹é©å¼€æ”¾ä¸»çº¿\nåˆ¶åº¦å»ºè®¾\n# ä¸€å¸¦ä¸€è·¯\näº’è”äº’é€š â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¸»çº¿\nå…±å•†å…±å»ºå…±äº« â€”â€”â€”â€”â€”â€”â€”â€” åŸåˆ™\nåšæŒå¼€æ”¾ã€ç»¿è‰²ã€å»‰æ´ â€”â€”â€”â€” ç†å¿µ\né«˜æ ‡å‡†ã€å¯æŒç»­ã€æƒ æ°‘ç”Ÿ â€”â€”â€” ç›®æ ‡\n# å…šå»º\nåŠ å¼ºå…šçš„é•¿æœŸæ‰§æ”¿èƒ½åŠ›å»ºè®¾ï¼Œå…ˆè¿›æ€§å’Œçº¯æ´æ€§å»ºè®¾\n# æ„å»ºæ–°å‹å›½é™…å…³ç³»è¦ç§‰æŒåŸåˆ™\n\nç›¸äº’å°Šé‡\nå…¬å¹³æ­£ä¹‰\nåˆä½œå…±èµ¢åŸåˆ™\n\næ²¡æœ‰å’Œå¹³å…±å¤„\n# åŒºåˆ†æ–°å‹å›½é™…å…³ç³»å’Œå¤§å›½å…³ç³»\nå›½é™…å…³ç³»ä¸ç”¨å’Œå¹³ï¼Œå¤§å›½å…³ç³»ä¸ç”¨å…±èµ¢ã€‚\n# æ–°å‹å›½é™…å…³ç³»\nå°Šé‡ â€” åˆä½œ â€” å…¬å¹³\n# æ–°å‹å›½é™…å…³ç³»åˆåˆ†ä¸ºä¸åŒçš„å…·ä½“è¦æ±‚\naã€ã€å¤§å›½å…³ç³»æ ¼å±€ã€‘â€”â€” å’Œå¹³å…±å¤„ã€æ€»ä½“ç¨³å®šã€å‡è¡¡å‘å±•\n bã€å‘¨è¾¹å¤–äº¤æ–¹é’ˆ\n cã€å‘¨è¾¹å¤–äº¤ç†å¿µï¼ˆå¤–äº¤å…¨å±€çš„é¦–è¦ä½ç½®ï¼‰\ndã€å‘å±•ä¸­å›½å®¶ â€”â€” çœŸå®äº²è¯š\n eã€æ–°å‹æ”¿å…šå…³ç³» â€”â€” æ±‚åŒå­˜å¼‚ã€ç›¸äº’å°Šé‡ã€äº’å­¦äº’é‰´\n# å…šçš„æ”¿æ²»å»ºè®¾é¦–è¦ä»»åŠ¡\nä¿è¯å…¨å…šæœä»å…šä¸­å¤®ï¼Œç»´æŠ¤å…šä¸­å¤®æƒå¨å’Œé›†ä¸­ç»Ÿä¸€é¢†å¯¼\n# æ¯›ä¸­ç‰¹\n# çç¢\nâ€œå·¥å†œæ­¦è£…å‰²æ®â€ å’Œå†œæ‘åŒ…å›´åŸå¸‚ã€æ­¦è£…å¤ºå–æ”¿æƒçš„æ€æƒ³æ˜¯æ¯›æ³½ä¸œåœ¨åœŸåœ°é©å‘½æˆ˜äº‰æ—¶æœŸæå‡ºçš„\nå®äº‹æ±‚æ˜¯ï¼Œå°±æ˜¯ä¸€åˆ‡ä»å®é™…å‡ºå‘ï¼Œç†è®ºè”ç³»å®é™…ï¼ŒåšæŒåœ¨å®è·µä¸­æ£€éªŒçœŸç†å’Œå‘å±•çœŸç†ï¼Œå®äº‹æ±‚æ˜¯æ˜¯ A. ä¸­å›½å…±äº§å…šçš„æ€æƒ³è·¯çº¿ï¼ŒB. ä¸­å›½å…±äº§å…šäººè®¤è¯†ä¸–ç•Œã€æ”¹é€ ä¸–ç•Œçš„æ ¹æœ¬è¦æ±‚ï¼ŒC. ä¸­å›½å…±äº§å…šçš„åŸºæœ¬æ€æƒ³æ–¹æ³•ã€å·¥ä½œæ–¹æ³•ã€é¢†å¯¼æ–¹æ³•ï¼ŒD. é©¬å…‹æ€ä¸»ä¹‰çš„æ ¹æœ¬è§‚ç‚¹\n\nç¾¤ä¼—è·¯çº¿æ˜¯å…šçš„ç”Ÿå‘½çº¿å’Œæ ¹æœ¬å·¥ä½œè·¯çº¿\n\n# å—æ–¹è°ˆè¯çš„å†…å®¹\n\nè®¡åˆ’å’Œå¸‚åœºéƒ½æ˜¯ç»æµæ‰‹æ®µï¼›\né˜æ˜äº†ç¤¾ä¼šä¸»ä¹‰æœ¬è´¨ï¼›\næå‡ºäº† â€œå‘å±•æ‰æ˜¯ç¡¬é“ç†â€ çš„é‡è¦è®ºæ–­\næå‡ºåˆ¤æ–­æ”¹é©å¼€æ”¾å’Œå„é¡¹å·¥ä½œæˆè´¥å¾—å¤±çš„ â€œä¸‰ä¸ªæœ‰åˆ©äºâ€ æ ‡å‡†ï¼›\nå¼ºè°ƒåŠ å¼ºå…šçš„å»ºè®¾ï¼›\nå…³äºç¤¾ä¼šä¸»ä¹‰åˆçº§é˜¶æ®µçš„é•¿æœŸæ€§å’Œå‰é€”\n\n# é€Ÿè®°å£è¯€ä¸€äºŒä¸‰å››\nä¸€å¤§ç«‹å…šï¼ŒäºŒå¤§ç«‹çº²ï¼Œä¸‰å¤§å¯¹å›½å…±åˆä½œçš„æ–¹é’ˆå’ŒåŠæ³•åšäº†æ­£å¼å†³å®šï¼Œå³ â€œå…šå†…åˆä½œâ€ï¼Œå››å¤§æå‡ºæ— äº§é˜¶çº§é¢†å¯¼æ ¡å’Œå·¥å†œåŒç›Ÿå†›æ€æƒ³ï¼Œäº”å¤§æ‰¹è¯„é™ˆç‹¬ç§€å³å€¾é”™è¯¯ï¼Œå…­å¤§æå‡ºä¸­å›½é©å‘½çš„æ€§è´¨æ˜¯èµ„äº§é˜¶çº§æ°‘ä¸»é©å‘½ï¼Œä¸ƒå¤§å°†æ¯›ç†è®ºå‘½åä¸ºæ¯›æ€æƒ³ï¼Œå¹¶å°†å…¶ä½œä¸ºå…šçš„æŒ‡å¯¼æ€æƒ³å†™å…¥å…šç« ï¼Œå…«å¤§æå‡ºä¸»è¦çŸ›ç›¾ï¼ŒåäºŒå¤§æå‡ºå»ºè®¾ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç¤¾ä¼šï¼Œåä¸‰å¤§ç³»ç»Ÿåœ°è®ºè¿°äº†å…³äºç¤¾ä¼šä¸»ä¹‰åˆçº§é˜¶æ®µçš„ç†è®ºï¼Œåå››å¤§æ¦‚æ‹¬äº†ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç†è®ºçš„ä¸»è¦å†…å®¹ï¼Œç³»ç»Ÿé‡Šäº†è¿™ä¸€ç†è®ºçš„å†å²åœ°ä½å’ŒæŒ‡å¯¼æ„ä¹‰ï¼Œåäº”å¤§é‚“ç†è®ºè¢«ç¡®ç«‹ä¸ºä¸­å›½å…±äº§å…šçš„æŒ‡å¯¼æ€æƒ³ï¼Œå¹¶å†™å…¥äº†å…šç« ã€‚\n\nä¸€å…š\näºŒçº²\nä¸‰åˆä½œ\nå››æƒ\näº”æ‰¹\nå…­æ€§\nä¸ƒå…¥\nå…«çŸ›\nåäºŒå¤§å»ºä¸­ç‰¹\nåä¸‰å¤§è®ºé˜¶æ®µ ï¼ˆé‚“å°å¹³è½®å»“ï¼‰\nåå››å¤§ç³»é˜é‡Š\nåäº”å¤§é‚“å…¥å…šç« \nåå…«å¤§è¿›å…¥æ–°æ—¶ä»£\n\næ¯›æ€æƒ³ -&gt; ä¸ƒå¤§ï¼ˆæ¯›ä¸ƒä¸ƒï¼‰\né‚“ç†è®º -&gt; åäº”å¤§\nä¸‰ä¸ªä»£è¡¨ -&gt; åå…­å¤§\nç§‘å­¦å‘å±•è§‚ -&gt; åä¸ƒå¤§\nä¹ æ€æƒ³ -&gt; åä¹å¤§\n# ä¸€ä¸ªç¥å¥‡çš„å£è¯€\nä¸‰çº¿äº”çº²ï¼Œå››ä½“å…­åº·\n# åä¸‰å¤§\nå…šçš„åä¸€å±Šä¸‰ä¸­å…¨ä¼šçš„èƒœåˆ©å¬å¼€ï¼Œç»“æŸäº†ç²‰ç¢ â€œå››äººå¸®â€ åå…šå’Œå›½å®¶å·¥ä½œåœ¨å¾˜å¾Šä¸­å‰è¿›çš„å±€é¢ï¼Œæ ‡å¿—ç€ä¸­å›½å…±äº§å…šé‡æ–°ç¡®ç«‹äº†é©¬å…‹æ€ä¸»ä¹‰çš„æ€æƒ³è·¯çº¿ã€æ”¿æ²»è·¯çº¿å’Œç»„ç»‡è·¯çº¿ï¼Œå¼€å¯äº†æˆ‘å›½æ”¹é©å¼€æ”¾å’Œç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å»ºè®¾å†å²æ–°æ—¶æœŸï¼Œå®ç°äº†å†å²æ€§çš„ä¼Ÿå¤§è½¬æŠ˜ã€‚\n# åå…«å¤§\nä¸­å…±åå…«å¤§çš„å¬å¼€ï¼Œæ ‡å¿—ç€ä¸­å›½å·²ç»è¿›å…¥å…¨é¢å»ºæˆå°åº·ç¤¾ä¼šçš„å†³å®šæ€§é˜¶æ®µï¼Œå¼€å¯äº†ä¸­å›½ç‰¹ è‰²ç¤¾ä¼šä¸»ä¹‰æ–°æ—¶ä»£ã€‚\n# æ¯›æ³½ä¸œæ€æƒ³çš„åœ°ä½\næ¯›æ³½ä¸œæ€æƒ³æ˜¯é©¬å…‹æ€ä¸»ä¹‰ä¸­å›½åŒ–çš„ç¬¬ä¸€æ¬¡å†å²æ€§é£è·ƒçš„ç†è®ºæˆ æœï¼›æ˜¯ä¸­å›½é©å‘½å’Œå»ºè®¾çš„ç§‘å­¦æŒ‡å—ï¼›æ˜¯å…šå’Œäººæ°‘çš„å®è´µç²¾ç¥è´¢å¯Œã€‚\n# æœ‰å…³ä¸­å¿ƒé—®é¢˜\nâ‘ æ— äº§é˜¶çº§çš„é¢†å¯¼æƒæ˜¯ä¸­å›½é©å‘½çš„ä¸­å¿ƒé—®é¢˜ã€‚\nâ‘¡åœ¨ä¸­å›½æ°‘ä¸»é©å‘½ä¸­ï¼Œæ— äº§é˜¶çº§é¢†å¯¼æƒçš„ä¸­å¿ƒé—®é¢˜æ˜¯å†œæ°‘é—®é¢˜ã€‚\nâ‘¢æ¯›æ³½ä¸œåœ¨ã€Šå›½æ°‘é©å‘½ä¸å†œæ°‘è¿åŠ¨ã€‹ä¸­è¿˜æåˆ° â€œå†œæ°‘é—®é¢˜ä¹ƒå›½æ°‘é©å‘½çš„ä¸­å¿ƒé—®é¢˜â€ã€‚\nå›ç­”é—®é¢˜çš„æ—¶å€™è¦æ³¨æ„é¢˜å¹²å…·ä½“è€ƒæŸ¥çš„è§’åº¦ã€‚\n# é©å‘½çš„æ€§è´¨ï¼ˆ1948 æ¯›æ³½ä¸œæŒ‡å‡ºâ€¦ï¼‰\nä¸­å›½æ˜¯ä¸€ä¸ªå°å»ºç»æµå æ˜æ˜¾ä¼˜åŠ¿çš„åŠæ®–æ°‘åœ°åŠå°å»ºç¤¾ä¼šï¼Œé©å‘½æ˜¯ä¸ºäº†ç»ˆç»“è¿™ä¸ªåŠæ®–æ°‘åœ°åŠå°å»ºçš„ç¤¾ä¼šå½¢æ€ï¼›ä¸­å›½é©å‘½çš„å¯¹è±¡ä¸»è¦æ˜¯å¸å›½ä¸»ä¹‰å’Œå°å»ºä¸»ä¹‰åŠ¿åŠ›ï¼›é©å‘½çš„æ€§è´¨æ˜¯ä¸ºäº†æ¨ç¿»è¿™ä¸¤ä¸ªä¸»è¦æ•Œäººçš„æ°‘æ—é©å‘½å’Œæ°‘ä¸»é©å‘½\n# è°ï¼Ÿ\nä¸­å›½é©å‘½çš„ä¸­å¿ƒé—®é¢˜ã€æ–°æ°‘ä¸»ä¸»ä¹‰è‹¹å‘½ç†è®ºçš„æ ¸å¿ƒé—®é¢˜ï¼šæ— äº§é˜¶çº§çš„é¢†å¯¼æƒé—®é¢˜\nä¸­å›½é©å‘½çš„å®è´¨ï¼šå…šé¢†å¯¼ä¸‹çš„å†œæ°‘é©å‘½\nä¸­å›½é©å‘½çš„æœ€åŸºæœ¬åŠ¨åŠ›ï¼šæ— äº§é˜¶çº§ï¼›\nä¸»åŠ›å†›ï¼šå†œæ°‘é˜¶çº§\n# æ‰“è°ï¼Ÿ\nä¸­å›½é©å‘½çš„é¦–è¦é—®é¢˜ï¼šåˆ†æ¸…æ•Œå‹\nä¸­å›½é©å‘½çš„å¯¹è±¡ï¼šå¸å›½ä¸»ä¹‰ (é¦–è¦å¯¹è±¡)ã€å°å»ºä¸»ä¹‰å’Œå®˜åƒšèµ„æœ¬ä¸»ä¹‰\n# ä¸ºä»€ä¹ˆæ‰“ï¼Ÿ\nä¸­å›½é©å‘½çš„æ ¹æœ¬é—®é¢˜ï¼šå›½å®¶æ”¿æƒé—®é¢˜\nä¸­å›½é©å‘½çš„åŸºæœ¬é—®é¢˜ï¼šå†œæ°‘é—®é¢˜\n# æ€ä¹ˆæ‰“ï¼Ÿ\nä¸­å›½é©å‘½çš„ä¸»è¦å†…å®¹ï¼šæ²¡æ”¶å°å»ºåœ°ä¸»é˜¶çº§çš„å£«åœ°å½’å†œæ°‘æ‰€æœ‰\n# ä¸­å›½æ°‘ä¸»é©å‘½çš„åŸºæœ¬å†…å®¹\nä¸­å›½é©å‘½èµ°å†œæ‘åŒ…å›´åŸå¸‚ã€æ­¦è£…å¤ºå–æ”¿æƒçš„é“è·¯ï¼Œå¿…é¡»å¤„ç†å¥½åœŸåœ°é©å‘½ã€æ­¦è£…æ–—äº‰ã€å†œæ‘é©å‘½æ ¹æ®åœ°å»ºè®¾ä¸‰è€…ä¹‹é—´çš„å…³ç³»ã€‚åœŸåœ°é©å‘½æ˜¯æ°‘ä¸»é©å‘½çš„åŸºæœ¬å†…å®¹ï¼›æ­¦è£…æ–—äº‰æ˜¯ä¸­å›½é©å‘½çš„ä¸»è¦å½¢å¼ï¼Œæ˜¯å†œæ‘é©å‘½æ ¹æ®åœ°å»ºè®¾å’ŒåœŸåœ°é©å‘½çš„å¼ºæœ‰åŠ›ä¿è¯ï¼›å†œæ‘é©å‘½æ ¹æ®åœ°æ˜¯ä¸­å›½é©å‘½çš„æˆ˜ç•¥é˜µåœ°ï¼Œæ˜¯è¿›è¡Œæ­¦è£…æ–—äº‰å’Œå¼€å±•åœŸåœ°é©å‘½çš„ä¾æ‰˜ã€‚\n# ç»Ÿä¸€æˆ˜çº¿çš„ç»éªŒ\næ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½æ—¶æœŸï¼Œä¸­å›½å…±äº§å…šé¢†å¯¼çš„ç»Ÿä¸€æˆ˜çº¿ï¼Œå…ˆåç»è¿‡äº†ç¬¬ä¸€æ¬¡å›½å…±åˆä½œçš„ç»Ÿä¸€æˆ˜çº¿ã€å·¥å†œæ°‘ä¸»ç»Ÿä¸€æˆ˜çº¿ã€æŠ—æ—¥æ°‘æ—ç»Ÿä¸€æˆ˜çº¿ã€äººæ°‘æ°‘ä¸»ç»Ÿä¸€æˆ˜çº¿ç­‰å‡ ä¸ªæ—¶æœŸï¼Œç§¯ç´¯äº†ä¸°å¯Œçš„ç»éªŒã€‚å…¶ä¸­ï¼Œæœ€æ ¹æœ¬çš„ç»éªŒå°±æ˜¯æ­£ç¡®å¤„ç†å¥½ä¸èµ„äº§é˜¶çº§çš„å…³ç³»å½“å…šèƒ½å¤Ÿæ­£ç¡®å¤„ç†ä¸èµ„äº§é˜¶çº§å»ºç«‹ç»Ÿä¸€æˆ˜çº¿æˆ–è¢«è¿«åˆ†è£‚ç»Ÿä¸€æˆ˜çº¿çš„é—®é¢˜æ—¶ï¼Œå…šçš„å‘å±•å’Œå·©å›ºå°±ä¼šå‰è¿›ï¼›åä¹‹ï¼Œå…šçš„å‘å±•å’Œå·©å›ºå°±ä¼šåé€€ã€‚\n# å»ºç«‹ç»Ÿä¸€æˆ˜çº¿çš„å¿…è¦æ€§\nå»ºç«‹æœ€å¹¿æ³›çš„ç»Ÿä¸€æˆ˜çº¿ï¼Œæ˜¯ç”±ä¸­å›½åŠæ®–æ°‘åœ°åŠå°å»ºç¤¾ä¼šçš„é˜¶çº§çŠ¶å†µæ‰€å†³å®šçš„ã€‚æ¯›æ³½ä¸œæŒ‡å‡ºï¼šâ€œä¸­å›½ç¤¾ä¼šæ˜¯ä¸€ä¸ªä¸¤å¤´å°ä¸­é—´å¤§çš„ç¤¾ä¼šï¼Œæ— äº§é˜¶çº§å’Œåœ°ä¸»å¤§èµ„äº§é˜¶çº§éƒ½åªå å°‘æ•°ï¼Œæœ€å¹¿å¤§çš„äººæ°‘æ˜¯å†œæ°‘ã€åŸå¸‚å°èµ„äº§é˜¶çº§ä»¥åŠå…¶ä»–çš„ä¸­é—´é˜¶çº§ã€‚â€ ä½œä¸ºæ— äº§é˜¶çº§å…ˆé”‹é˜Ÿçš„ä¸­å›½å…±äº§å…šæ‰€é¢†å¯¼çš„é©å‘½åŠ›é‡ï¼Œè¦æˆ˜èƒœä½œä¸ºåœ°ä¸»é˜¶çº§å’Œå®˜åƒšèµ„äº§é˜¶çº§é›†ä¸­ä»£è¡¨çš„å›½æ°‘å…šæ‰€é¢†å¯¼çš„å¼ºå¤§çš„åé©å‘½åŠ›é‡ï¼Œå°±å¿…é¡»æŠŠå†œæ°‘ã€åŸå¸‚å°èµ„äº§é˜¶çº§ä»¥åŠå…¶ä»–çš„ä¸­é—´é˜¶çº§éƒ½å›¢ç»“åœ¨è‡ªå·±çš„å‘¨å›´ï¼Œç»“æˆæœ€å¹¿æ³›çš„ç»Ÿä¸€æˆ˜çº¿ã€‚\n# æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½æ—¶æœŸçš„ç»Ÿä¸€æˆ˜çº¿\nå…šé¢†å¯¼çš„ç»Ÿä¸€æˆ˜çº¿ï¼Œå…ˆåç»è¿‡äº†ç¬¬ä¸€æ¬¡å›½å…±åˆä½œçš„ç»Ÿä¸€æˆ˜çº¿ã€å·¥å†œæ°‘ä¸»ç»Ÿä¸€æˆ˜çº¿ã€æŠ—æ—¥æ°‘æ—ç»Ÿä¸€æˆ˜çº¿ã€äººæ°‘æ°‘ä¸»ç»Ÿä¸€æˆ˜çº¿ç­‰å‡ ä¸ªæ—¶æœŸã€‚\nä»¥å›½å…±åˆä½œä¸ºåŸºç¡€çš„æ˜¯å›½æ°‘é©å‘½è”åˆæˆ˜çº¿ (ç¬¬ä¸€æ¬¡å›½å…±åˆä½œçš„ç»Ÿä¸€æˆ˜çº¿) ä¸æŠ—æ—¥æ°‘æ—ç»Ÿä¸€æˆ˜çº¿ã€‚\nå›½å…±å°±åˆä½œäº† 2 æ¬¡ï¼Œä¸€æ¬¡æ˜¯æ¨ç¿»å°å»ºä¸»ä¹‰åˆ¶åº¦ï¼Œä¸€æ¬¡æ˜¯æŠ—æ—¥åˆä½œ\n# æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½ç†è®ºçš„åŸºæœ¬çº²é¢†\næ–°æ°‘ä¸»ä¸»ä¹‰æ–‡åŒ–æ˜¯ç§‘å­¦çš„ï¼Œæ˜¯åå¯¹ä¸€åˆ‡å°å»ºæ€æƒ³å’Œè¿·ä¿¡æ€æƒ³ä¸»å¼ å®äº‹æ±‚æ˜¯ã€å®¢è§‚çœŸç†åŠç†è®ºå’Œå®è·µçš„ä¸€è‡´æ€§ã€‚å¯¹äºå°å»ºæ—¶ä»£åˆ›é€ çš„æ–‡åŒ–ï¼Œåº”å‰”é™¤å…¶å°å»ºç³Ÿç²•ï¼Œå¸æ”¶å…¶æ°‘ä¸»æ€§ç²¾åã€‚åŒæ—¶ï¼Œè¦å°Šé‡ä¸­å›½çš„å†å²ï¼Œåå¯¹æ°‘æ—è™šæ— ä¸»ä¹‰ï¼Œä»¥å†å²å”¯ç‰©ä¸»ä¹‰çš„æ€åº¦å¯¹å¾…å¤ä»Šä¸­å¤–æ–‡åŒ–ï¼Œå‘å±•æ°‘æ—æ–°æ–‡åŒ–ï¼Œæé«˜æ°‘æ—è‡ªä¿¡å¿ƒã€‚\n# â€ ä¸¤æ­¥èµ° â€œ\nç”±äºä¸­å›½é©å‘½çš„åå¸åå°å»ºçš„åŒé‡ä»»åŠ¡ï¼Œå†³å®šäº†é©å‘½åˆ†ä¸¤æ­¥èµ°ï¼šç¬¬ä¸€æ­¥æ˜¯å…ˆè¿›è¡Œæ¨ç¿»ä¸‰åº§å¤§å±±çš„æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½ï¼Œç¬¬äºŒæ­¥æ˜¯è¿›è¡Œç¤¾ä¼šä¸»ä¹‰é©å‘½ã€‚\n# â€œä¸€æ¬¡é©å‘½è®ºâ€ å’Œ â€œäºŒæ¬¡é©å‘½è®ºâ€ éƒ½æ˜¯é”™è¯¯çš„\nâ€œå·¦â€ å€¾æ•™æ¡ä¸»ä¹‰çš„ â€œä¸€æ¬¡é©å‘½è®ºâ€(å¦‚ â€œæ— é—´æ–­â€ é©å‘½è®º) çš„é”™è¯¯åœ¨äºï¼Œåªçœ‹åˆ°äº†æ°‘ä¸»é©å‘½ä¸ç¤¾ä¼šä¸»ä¹‰é©å‘½çš„è”ç³»ï¼Œè€Œæ··æ·†äº†æ°‘ä¸»é©å‘½ä¸ç¤¾ä¼šä¸»ä¹‰é©å‘½çš„åŒºåˆ«ï¼Œåœ¨åå¸åå°å»ºçš„åŒæ—¶ï¼Œä¹Ÿåå¯¹æ°‘æ—èµ„äº§é˜¶çº§ï¼Œå¦å®šäº†ä¸­å›½é©å‘½çš„é˜¶æ®µæ€§ã€‚è€Œå³çš„ â€œäºŒæ¬¡é©å‘½è®ºâ€ çš„é”™è¯¯åœ¨äºï¼Œåªçœ‹åˆ°äº†æ°‘ä¸»é©å‘½ä¸ç¤¾ä¼šä¸»ä¹‰é©å‘½çš„åŒºåˆ«ï¼Œè€Œæ²¡æœ‰çœ‹åˆ°ä¸¤ä¸ªé©å‘½é˜¶æ®µçš„è”ç³»ï¼Œæ”¾å¼ƒäº†å…šå¯¹æ°‘ä¸»é©å‘½çš„é¢†å¯¼æƒã€‚\n# â€ ä¸¤å¤´å°ä¸­é—´å¤§â€ çš„ç¤¾ä¼š\næ¯›æ³½ä¸œæŒ‡å‡ºï¼šâ€œä¸­å›½ç¤¾ä¼šæ˜¯ä¸€ä¸ªä¸¤å¤´å°ä¸­é—´å¤§çš„ç¤¾ä¼šï¼Œæ— äº§é˜¶çº§å’Œåœ°ä¸»å¤§èµ„äº§é˜¶çº§éƒ½åªå å°‘æ•°ï¼Œæœ€å¹¿å¤§çš„äººæ°‘æ˜¯å†œæ°‘ã€åŸå¸‚å°èµ„äº§é˜¶çº§ä»¥åŠå…¶ä»–çš„ä¸­é—´é˜¶çº§ã€‚â€\n# ä¸‰ä»¶ â€œæ³•å®â€\nç»Ÿä¸€æˆ˜çº¿ã€æ­¦è£…æ–—äº‰ã€å…šçš„å»ºè®¾\n\næˆ˜æ–—å…š\n\n# æˆ˜èƒœæ•Œäººçš„ä¸¤ä¸ªåŸºæœ¬æ­¦å™¨\nç»Ÿä¸€æˆ˜çº¿ã€æ­¦è£…æ–—äº‰\n\næˆ˜æ–—\n\n# ä¸­å›½é©å‘½é“è·¯\nåœŸåœ°é©å‘½ã€æ­¦è£…æ–—äº‰ã€å†œæ‘é©å‘½æ ¹æ®åœ°å»ºè®¾\n\nåœŸæ–—æ ¹\n\n# æ´»çš„çµé­‚\nå®äº‹æ±‚æ˜¯ã€ç¾¤ä¼—è·¯çº¿ã€ç‹¬ç«‹è‡ªä¸»\n\nå®ä¼—ç‹¬\n\n# ä¼˜è‰¯ä½œé£\nç†è®ºè”ç³»å®é™…ã€å¯†åˆ‡è”ç³»ç¾¤ä¼—ã€æ‰¹è¯„ä¸è‡ªæˆ‘æ‰¹è¯„\n# æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½çº²é¢†æœ€å…·ç‰¹è‰²ä¸€é¡¹\nä¿æŠ¤æ°‘æ—å·¥å•†ä¸šï¼Œæ˜¯æ–°æ°‘ä¸»ä¸»ä¹‰ç»æµçº²é¢†ä¸­æå…·ç‰¹è‰²çš„ä¸€é¡¹å†…å®¹ã€‚åœ¨æ–°æ°‘ä¸»ä¸»ä¹‰æ¡ä»¶ä¸‹ä¿æŠ¤æ°‘æ—å·¥å•†ä¸šï¼Œå‘å±•èµ„æœ¬ä¸»ä¹‰ï¼Œæ˜¯ç”±ä¸­å›½è½åçš„ç”Ÿäº§åŠ›å’Œæ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½çš„æ€§è´¨æ‰€å†³å®šçš„ã€‚æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½çš„å¯¹è±¡æ˜¯å¸å›½ä¸»ä¹‰ã€å°å»ºä¸»ä¹‰å’Œå®˜åƒšèµ„æœ¬ä¸»ä¹‰ï¼Œè€Œä¸æ˜¯ä¸€èˆ¬åœ°æ¶ˆç­èµ„æœ¬ä¸»ä¹‰å’Œèµ„äº§é˜¶çº§ã€‚\n# æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½èƒœåˆ©çš„å†å²æ„ä¹‰\næ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½çš„ä¼Ÿå¤§æˆå°±ï¼Œä¸ºå®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´åˆ›é€ äº†æ ¹æœ¬ç¤¾ä¼šæ¡ä»¶ã€‚\n# å„ä¸ªé˜¶æ®µä¸­å›½ç¤¾ä¼šçš„ä¸»è¦çŸ›ç›¾\n1840â€”1949ï¼Œä¸­åæ°‘æ—ä¸å¸å›½ä¸»ä¹‰çš„çŸ›ç›¾ã€‚\n1949â€”1952ï¼Œä¸å¸å›½ä¸»ä¹‰ã€å°å»ºä¸»ä¹‰ã€å›½æ°‘å…šæ®‹ä½™åŠ¿åŠ›ä¹‹é—´çš„çŸ›ç›¾ã€‚\n1952â€”1956ï¼Œå·¥äººé˜¶çº§å’Œèµ„äº§é˜¶çº§ä¹‹é—´çš„çŸ›ç›¾ã€‚ï¼ˆåœŸæ”¹åŸºæœ¬å®Œæˆï¼‰\n1956â€”1978ï¼Œäººæ°‘å¯¹äºå»ºç«‹å…ˆè¿›çš„å·¥ä¸šå›½çš„è¦æ±‚åŒè½åçš„å†œä¸šå›½çš„ç°å®ä¹‹é—´çš„çŸ›ç›¾ï¼Œäººæ°‘å¯¹äºç»æµæ–‡åŒ–è¿…é€Ÿå‘å±•çš„éœ€è¦åŒå½“å‰ç»æµæ–‡åŒ–ä¸èƒ½æ»¡è¶³äººæ°‘éœ€è¦çš„çŠ¶å†µä¹‹é—´çš„çŸ›ç›¾ã€‚\n1978ï¼Œäººæ°‘æ—¥ç›Šå¢é•¿çš„ç‰©è´¨æ–‡åŒ–éœ€è¦åŒè½åçš„ç¤¾ä¼šç”Ÿäº§ä¹‹é—´çš„çŸ›ç›¾ã€‚\n2018ï¼Œäººæ°‘æ—¥ç›Šå¢é•¿çš„ç¾å¥½ç”Ÿæ´»éœ€è¦å’Œä¸å¹³è¡¡ä¸å……åˆ†çš„å‘å±•ä¹‹é—´çš„çŸ›ç›¾ã€‚\n# äº’åŠ©ç»„ã€å¸¸å¹´äº’åŠ©ç»„ã€åˆçº§åˆä½œç¤¾ã€é«˜çº§åˆä½œç¤¾\näº’åŠ©ç»„ (åŒ…æ‹¬ä¸´æ—¶äº’åŠ©ç»„å’Œå¸¸å¹´äº’åŠ©ç»„ä¸¤ç§å½¢å¼) ä¸æ¶‰åŠç”Ÿäº§èµ„æ–™é—®é¢˜ï¼Œåªæ˜¯åœ¨ç”Ÿäº§æ–¹é¢ç»„ç»‡èµ·æ¥ã€äº’å¸®äº’åŠ©ï¼Œæ˜¯å†œä¸šåˆä½œåŒ–çš„æœ€åˆè¿‡æ¸¡å½¢å¼ï¼Œå…·æœ‰ç¤¾ä¼šä¸»ä¹‰èŒèŠ½æ€§è´¨ã€‚åˆçº§å†œä¸šç”Ÿäº§åˆä½œç¤¾ä»¥åœŸåœ°å…¥è‚¡å’Œç»Ÿä¸€ç»è¥ä¸ºç‰¹ç‚¹ï¼Œå®è¡Œé›†ä½“åŠ³åŠ¨ï¼Œäº§å“åˆ†é…é‡‡å–æŒ‰åŠ³åˆ†é…å’ŒåœŸåœ°å…¥è‚¡åˆ†çº¢ç›¸ç»“åˆï¼Œå…·æœ‰åŠç¤¾ä¼šä¸»ä¹‰æ€§è´¨ã€‚é«˜çº§å†œä¸šç”Ÿäº§åˆä½œç¤¾å®è¡Œç”Ÿäº§èµ„æ–™å†œæ°‘é›†ä½“æ‰€æœ‰ï¼Œå®è¡ŒæŒ‰åŠ³åˆ†é…ï¼Œå…·æœ‰å®Œå…¨çš„ç¤¾ä¼šä¸»ä¹‰æ€§è´¨ã€‚\n# æ°‘æ—èµ„äº§é˜¶çº§çš„ä¸¤é¢æ€§\næ—¢æœ‰å‰¥å‰Šå·¥äººå–å¾—åˆ©æ¶¦çš„ä¸€é¢ï¼Œåˆæœ‰æ‹¥æŠ¤ä¸­å›½å…±äº§å…šçš„é¢†å¯¼ã€æ‹¥æŠ¤å®ªæ³•ã€æ„¿æ„æ¥å—ç¤¾ä¼šä¸»ä¹‰æ”¹é€ çš„ä¸€é¢\n# æ°‘æ—èµ„äº§é˜¶çº§ä¸å·¥äººé˜¶çº§çš„çŸ›ç›¾çš„ä¸¤é‡æ€§\næ—¢æœ‰å‰¥å‰Šè€…ä¸è¢«å‰¥å‰Šè€…çš„é˜¶çº§åˆ©ç›Šç›¸äº’å¯¹ç«‹çš„å¯¹æŠ—æ€§çš„ä¸€é¢ï¼Œåˆæœ‰ç›¸äº’åˆä½œã€å…·æœ‰ç›¸åŒåˆ©ç›Šçš„éå¯¹æŠ—æ€§çš„ä¸€é¢\n# èµ„æœ¬ä¸»ä¹‰å·¥å•†ä¸šçš„ç¤¾ä¼šä¸»ä¹‰æ”¹é€ ç»å†äº†ä¸‰ä¸ªæ­¥éª¤\nç¬¬ä¸€æ­¥ (åˆçº§å½¢å¼çš„å›½å®¶èµ„æœ¬ä¸»ä¹‰) å’Œç¬¬äºŒæ­¥ (ä¸ªåˆ«ä¼ä¸šçš„å…¬ç§åˆè¥) çš„ä¼ä¸šåˆ©æ¶¦åˆ†é…éƒ½æ˜¯å››é©¬åˆ†è‚¥ã€‚ç¬¬ä¸‰æ­¥ (å…¨è¡Œä¸šçš„å…¬ç§åˆè¥) åœ¨åˆ†é…ä¸Šå®è¡Œå®šè‚¡å®šæ¯ã€‚\n\nç¬¬ä¸€æ­¥å®è¡Œåˆçº§å½¢å¼çš„å›½å®¶èµ„æœ¬ä¸»ä¹‰ã€‚å›½å®¶åœ¨ç§è¥å·¥ä¸šä¸­å®è¡Œå§”æ‰˜åŠ å·¥ã€è®¡åˆ’è®¢è´§ã€ç»Ÿè´­åŒ…é”€ï¼Œè¿™ä¸»è¦æ˜¯åŒèµ„æœ¬å®¶åœ¨ä¼ä¸šå¤–éƒ¨çš„åˆä½œã€‚\nç¬¬äºŒæ­¥å®è¡Œä¸ªåˆ«ä¼ä¸šçš„å…¬ç§åˆè¥ã€‚è¿™æ˜¯ç¤¾ä¼šä¸»ä¹‰æˆåˆ†åŒèµ„æœ¬ä¸»ä¹‰æˆåˆ†åœ¨ä¼ä¸šå†…éƒ¨çš„åˆä½œã€‚\nç¬¬ä¸‰æ­¥å®è¡Œå…¨è¡Œä¸šçš„å…¬ç§åˆè¥ã€‚å…¨è¡Œä¸šå…¬ç§åˆè¥åï¼Œå›½å®¶å¯¹åˆè¥ä¼ä¸šè¿›è¡Œæ¸…äº§æ ¸èµ„ã€å®šè‚¡å®šæ¯ï¼Œå§”æ´¾äººå‘˜è´Ÿè´£ä¼ä¸šçš„ç”Ÿäº§ç»è¥ç®¡ç†ï¼Œç»Ÿä¸€è°ƒé…ä¼ä¸šçš„äººã€è´¢ã€ç‰©ï¼Œç”Ÿäº§èµ„æ–™ä¸ºå›½å®¶æ‰€æœ‰ã€‚å…¨è¡Œä¸šå…¬ç§åˆè¥åï¼Œä¼ä¸šçš„ç”Ÿäº§å…³ç³»å·²ç»å‘ç”Ÿäº†æ ¹æœ¬çš„å˜åŒ–ï¼ŒåŸºæœ¬ä¸Šæˆä¸ºç¤¾ä¼šä¸»ä¹‰å›½è¥æ€§è´¨çš„ä¼ä¸šã€‚\n\n# æ¨è¿›æ‰‹å·¥ä¸šåˆä½œåŒ–çš„æ–¹é’ˆ\nåœ¨æ¨è¿›æ‰‹å·¥ä¸šåˆä½œåŒ–çš„è¿‡ç¨‹ä¸­ï¼Œä¸­å›½å…±äº§å…šé‡‡å–çš„æ˜¯ç§¯æé¢†å¯¼ã€ç¨³æ­¥å‰è¿›çš„æ–¹é’ˆã€‚\n# æ¨è¿›å†œä¸šç¤¾ä¼šä¸»ä¹‰æ”¹é€ çš„åŸåˆ™\nè¿™æ¡é“è·¯éµå¾ªè‡ªæ„¿äº’åˆ©ã€å…¸å‹ç¤ºèŒƒå’Œå›½å®¶å¸®åŠ©çš„åŸåˆ™ï¼Œä»¥äº’åŠ©åˆä½œçš„ä¼˜è¶Šæ€§å¸å¼•å†œæ°‘èµ°äº’ åŠ©åˆä½œé“è·¯ã€‚\n\nå£«åŠ›æ¶\n\n# èµ„æœ¬ä¸»ä¹‰å·¥å•†ä¸šç¤¾ä¼šä¸»ä¹‰æ”¹é€ çš„æ–¹é’ˆ\nå’Œå¹³èµä¹°\n# ç»æµæˆåˆ†æ„æˆåŠé˜¶çº§æ„æˆ\nä¸‰ç§ä¸»è¦çš„ç»æµæˆåˆ†ï¼šç¤¾ä¼šä¸»ä¹‰ç»æµã€ä¸ªä½“ç»æµã€èµ„æœ¬ä¸»ä¹‰ç»æµ\né˜¶çº§æ„æˆï¼šå·¥äººã€å†œæ°‘ã€æ°‘æ—èµ„äº§é˜¶çº§ã€å…¶ä»–å°èµ„äº§é˜¶çº§\nå…¶ä¸­ï¼ŒåŠç¤¾ä¼šä¸»ä¹‰æ€§è´¨çš„åˆä½œç¤¾ç»æµæ˜¯ä¸ªä½“ç»æµå‘ç¤¾ä¼šä¸»ä¹‰é›†ä½“ç»æµè¿‡æ¸¡çš„å½¢å¼ï¼Œå›½å®¶èµ„æœ¬ä¸»ä¹‰ç»æµæ˜¯ç§äººèµ„æœ¬ä¸»ä¹‰ç»æµå‘ç¤¾ä¼šä¸»ä¹‰å›½è¥ç»æµè¿‡æ¸¡çš„å½¢å¼ã€‚\n# èŒèŠ½æ€§è´¨ã€åŠç¤¾ä¼šä¸»ä¹‰æ€§è´¨ã€å®Œå…¨ç¤¾ä¼šä¸»ä¹‰æ€§è´¨\nç¤¾ä¼šä¸»ä¹‰èŒèŠ½ï¼šå†œä¸šäº’åŠ©ç»„ï¼Œæ‰‹å·¥ä¸šä¾›é”€å°ç»„ï¼Œèµ„æœ¬ä¸»ä¹‰å·¥å•†ä¸šåˆçº§å›½å®¶èµ„æœ¬ä¸»ä¹‰ç»æµ\nåŠç¤¾ä¼šä¸»ä¹‰ï¼šå†œä¸šåˆçº§ç”Ÿäº§åˆä½œç¤¾ï¼Œæ‰‹å·¥ä¸šä¾›é”€åˆä½œç¤¾ï¼Œå·¥å•†ä¸šä¸ªåˆ«ä¼ä¸šå…¬ç§åˆè¥\nå®Œå…¨ç¤¾ä¼šä¸»ä¹‰ï¼šå†œä¸šé«˜çº§ç”Ÿäº§åˆä½œç¤¾ï¼Œæ‰‹å·¥ä¸šç”Ÿäº§åˆä½œç¤¾ï¼Œå·¥å•†ä¸šå…¨è¡Œä¸šå…¬ç§åˆè¥\n\nå·¥å•†ä¸šï¼šé«˜çº§å›½å®¶èµ„æœ¬ä¸»ä¹‰ = ä¸ªåˆ«ä¼ä¸šå…¬ç§åˆè¥ + å…¨è¡Œä¸šå…¬ç§åˆè¥\n\n# 1956 å¹´å¹´åº•ç¤¾ä¼šä¸»ä¹‰æ”¹é€ çš„åŸºæœ¬å®Œæˆ\n\næ ‡å¿—ç€ä¸­å›½å†å²ä¸Šé•¿è¾¾æ•°åƒå¹´çš„é˜¶çº§å‰¥å‰Šåˆ¶åº¦çš„ç»“æŸ\nå®ç°äº†ç”±æ–°æ°‘ä¸»ä¸»ä¹‰å‘ç¤¾ä¼šä¸»ä¹‰çš„è½¬å˜\næ ‡å¿—ç€ç¤¾ä¼šä¸»ä¹‰åŸºæœ¬åˆ¶åº¦åœ¨æˆ‘å›½ç¡®ç«‹\næ ‡å¿—ç€æˆ‘å›½çš„ç¤¾ä¼šä¸»ä¹‰åˆçº§é˜¶æ®µä»æ­¤å¼€å§‹\n\n# ä¸¤ä¸ªç»“åˆå’Œ â€œä¸¤æ¬¡ç»“åˆâ€\næ¯›æ³½ä¸œçš„ä¸¤æ¬¡ç»“åˆï¼šé©¬ + é©å‘½ã€é©¬ + å»ºè®¾é“è·¯\nä¹ è¿‘å¹³çš„ä¸¤ä¸ªç»“åˆï¼šé©¬ + ä¸­å›½å›½æƒ…ã€é©¬ + ä¼ ç»Ÿæ–‡åŒ–\n# ã€Šè®ºåå¤§å…³ç³»ã€‹â€”â€” æ¢ç´¢ä¸­å›½ç¤¾ä¼šä¸»ä¹‰å»ºè®¾é“è·¯çš„è‰¯å¥½å¼€ç«¯\næ¯›æ³½ä¸œåœ¨ 1956 å¹´ 4 æœˆ 25 æ—¥ä¸­å¤®æ”¿æ²»å±€æ‰©å¤§ä¼šè®®å’Œ 5 æœˆ 2 æ—¥æœ€é«˜å›½åŠ¡ä¼šè®®ä¸Šä½œã€Šè®ºåå¤§å…³ç³»ã€‹çš„æŠ¥å‘Šã€‚å¼ºè°ƒä»¥è‹ä¸ºé‰´ã€ç‹¬ç«‹è‡ªä¸»åœ°æ¢ç´¢é€‚åˆä¸­å›½æƒ…å†µçš„ç¤¾ä¼šä¸»ä¹‰å»ºè®¾é“è·¯ã€‚å…¶ä¸­ï¼Œã€Šè®ºåå¤§å…³ç³»ã€‹ä¸­çš„ç¬¬ä¸€å¤§å…³ç³»ï¼Œå³é‡å·¥ä¸šå’Œè½»å·¥ä¸šã€å†œä¸šçš„å…³ç³»ã€‚\nåœ¨ã€Šè®ºåå¤§å…³ç³»ã€‹çš„æŠ¥å‘Šä¸­ï¼Œåˆæ­¥æ€»ç»“äº†æˆ‘å›½ç¤¾ä¼šä¸»ä¹‰å»ºè®¾çš„ç»éªŒï¼Œæ˜ç¡®æå‡ºè¦ä»¥è‹ä¸ºé‰´ï¼Œç‹¬ç«‹è‡ªä¸»åœ°æ¢ç´¢é€‚åˆä¸­å›½æƒ…å†µçš„ç¤¾ä¼šä¸»ä¹‰å»ºè®¾é“è·¯ã€‚ã€Šè®ºåå¤§å…³ç³»ã€‹æ ‡å¿—ç€å…šæ¢ç´¢ä¸­å›½ç¤¾ä¼šä¸»ä¹‰å»ºè®¾é“è·¯çš„è‰¯å¥½å¼€ç«¯ã€‚\n\nåå…¨åç¾è‰¯å¥½å¼€ç«¯\n\n# ã€Šå…³äºæ­£ç¡®å¤„ç†äººæ°‘å†…éƒ¨çŸ›ç›¾çš„é—®é¢˜ã€‹\nã€Šå…³äºæ­£ç¡®å¤„ç†äººæ°‘å†…éƒ¨çŸ›ç›¾çš„é—®é¢˜ã€‹ä¸€æ–‡ï¼Œæ˜¯ä¸€ç¯‡é‡è¦çš„é©¬å…‹æ€ä¸»ä¹‰æ–‡çŒ®ã€‚å®ƒåˆ›é€ æ€§åœ°é˜è¿°äº†ç¤¾ä¼šä¸»ä¹‰ç¤¾ä¼šçŸ›ç›¾å­¦è¯´ï¼Œæ˜¯å¯¹ç§‘å­¦ç¤¾ä¼šä¸»ä¹‰ç†è®ºçš„é‡è¦å‘å±•ï¼Œå¯¹ä¸­å›½ç¤¾ä¼šä¸»ä¹‰äº‹ä¸šå…·æœ‰é•¿è¿œçš„æŒ‡å¯¼æ„ä¹‰ã€‚\nã€Šå…³äºæ­£ç¡®å¤„ç†äººæ°‘å†…éƒ¨çŸ›ç›¾çš„é—®é¢˜ã€‹æŒ‡å‡ºï¼Œå¯¹äºæ”¿æ²»æ€æƒ³é¢†åŸŸçš„äººæ°‘å†…éƒ¨çŸ›ç›¾ï¼Œå®è¡Œ â€œå›¢ç»“ â€” æ‰¹è¯„ â€” å›¢ç»“â€ çš„æ–¹é’ˆï¼ŒåšæŒè¯´æœæ•™è‚²ã€è®¨è®ºçš„æ–¹æ³•ã€‚\n# ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç†è®ºä½“ç³»å½¢æˆå‘å±•çš„å¸½å­é¢˜\nä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç†è®ºä½“ç³»å½¢æˆå‘å±•çš„ç¤¾ä¼šå†å²æ¡ä»¶ï¼šã€å›½é™…èƒŒæ™¯ + å†å²æ¡ä»¶ + å®è·µåŸºç¡€ã€‘\nè€Œå¦‚æœå…‰é—®å†å²æ¡ä»¶å°±ä¸ä¸€æ ·ï¼Œç¤¾ä¼šå†å²æ¡ä»¶èŒƒå›´è¦å¤§ä¸€äº›\n\nå›½é™…å½¢åŠ¿çš„æ·±åˆ»å˜åŒ–å’Œä¸–ç•Œå‘å±•æ–°è¶‹åŠ¿ â€”â€” å›½é™…èƒŒæ™¯ï¼›\nå»ºè®¾ç¤¾ä¼šä¸»ä¹‰æ­£åä¸¤æ–¹é¢ç»éªŒå’Œæˆ‘å›½å‘å±•çš„å†å²æ–¹ä½ â€”â€” å†å²æ¡ä»¶ï¼›\næ”¹é©å¼€æ”¾å’Œç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å»ºè®¾å®è·µ â€”â€” å®è·µåŸºç¡€\n\n# ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç†è®ºä½“ç³»å½¢æˆå‘å±•çš„å†å²æ¡ä»¶\nå…šçš„åä¸€å±Šä¸‰ä¸­å…¨ä¼šä»¥åï¼Œä¸­å›½å…±äº§å…šäººé²œæ˜æŒ‡å‡ºå»ºè®¾ç¤¾ä¼šä¸»ä¹‰æ²¡æœ‰å›ºå®šçš„æ¨¡å¼ï¼Œ** å¿…é¡»ç»“åˆä¸­å›½å®é™…ï¼Œåœ¨å®è·µä¸­ä¸æ‡ˆæ¢ç´¢å’Œå›ç­”ä»€ä¹ˆæ˜¯ç¤¾ä¼šä¸»ä¹‰ã€æ€æ ·å»ºè®¾ç¤¾ä¼šä¸»ä¹‰è¿™ä¸€åŸºæœ¬é—®é¢˜ã€‚** æ­£æ˜¯åœ¨æ¢ç´¢å’Œå›ç­”è¿™ä¸€é¦–è¦çš„åŸºæœ¬çš„ç†è®ºé—®é¢˜çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å…šå¼€åˆ›äº†ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰çš„ä¼Ÿå¤§äº‹ä¸šã€‚\n# é©¬å…‹æ€ä¸»ä¹‰ä¸­å›½åŒ–çš„ç¬¬ä¸€æ¬¡é£è·ƒä¸ç¬¬äºŒæ¬¡é£è·ƒ\n== é©¬å…‹æ€ä¸»ä¹‰ä¸­å›½åŒ–çš„ç¬¬ä¸€æ¬¡é£è·ƒï¼Œæ˜¯å…šåœ¨æ¢ç´¢ä¸­å›½é©å‘½é“è·¯çš„è¿‡ç¨‹ä¸­å®Œæˆçš„ã€‚== åœ¨æ¯›æ³½ä¸œæ€æƒ³çš„æŒ‡å¯¼ä¸‹ï¼Œå…šé¢†å¯¼äººæ°‘èµ°ä»¥å†œæ‘åŒ…å›´åŸå¸‚çš„é“è·¯ï¼Œå–å¾—äº†æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½çš„èƒœåˆ©ï¼›èµ°å…·æœ‰ä¸­å›½ç‰¹è‰²çš„ç¤¾ä¼šä¸»ä¹‰æ”¹é€ çš„é“è·¯ï¼Œç§¯ææ¢ç´¢ç¤¾ä¼šä¸»ä¹‰å»ºè®¾é“è·¯ï¼Œå–å¾—ç¤¾ä¼šä¸»ä¹‰é©å‘½å’Œå»ºè®¾çš„ä¼Ÿå¤§æˆå°±ã€‚\né©¬å…‹æ€ä¸»ä¹‰ä¸­å›½åŒ–æ—¶ä»£åŒ–çš„ç¬¬äºŒæ¬¡é£è·ƒæ˜¯ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ç†è®ºä½“ç³»ã€‚\n# æ¯›æ³½ä¸œæ€æƒ³çš„ç²¾é«“\nå®äº‹æ±‚æ˜¯\n# é‚“å°å¹³ç†è®ºçš„ç²¾é«“\nè§£æ”¾æ€æƒ³ï¼Œå®äº‹æ±‚æ˜¯\n# åä¸‰å¤§æå‡ºç¤¾ä¼šä¸»ä¹‰åˆçº§é˜¶æ®µåŸºæœ¬è·¯çº¿\nåŸºæœ¬é€”å¾„ï¼šä¸€ä¸ªä¸­å¿ƒï¼Œä¸¤ä¸ªåŸºæœ¬ç‚¹ï¼ˆä»¥ç»æµå»ºè®¾ä¸ºä¸­å¿ƒï¼ŒåšæŒæ”¹é©å¼€æ”¾ï¼ŒåšæŒå››é¡¹åŸºæœ¬åŸåˆ™ï¼‰\nè·Ÿæœ¬ç«‹è¶³ç‚¹ï¼šè‡ªåŠ›æ›´ç”Ÿï¼Œè‰°è‹¦åˆ›ä¸š\né¢†å¯¼åŠ›é‡å’Œä¾é åŠ›é‡ï¼šé¢†å¯¼å’Œå›¢ç»“å„æ—äººæ°‘\nå¥‹æ–—ç›®æ ‡ï¼šå»ºè®¾å¯Œå¼ºæ°‘ä¸»æ–‡æ˜çš„ç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å›½å®¶\n# å‡ ä¸ªå¸½å­\næ”¹é© â€”â€” æ˜¯ç¤¾ä¼šä¸»ä¹‰ç¤¾ä¼šå‘å±•çš„ç›´æ¥åŠ¨åŠ›ï¼›\né˜¶çº§æ–—äº‰ â€”â€” æ˜¯é˜¶çº§ç¤¾ä¼šå‘å±•çš„ç›´æ¥åŠ¨åŠ›ï¼›\nç§‘æŠ€ â€”â€” æ˜¯ç¬¬ä¸€ç”Ÿäº§åŠ›ï¼›\nç§‘æŠ€é©å‘½â€“æ˜¯ç¤¾ä¼šå‘å±•çš„é‡è¦åŠ¨åŠ›ã€‚\nè§£æ”¾ç”Ÿäº§åŠ›ï¼Œå‘å±•ç”Ÿäº§åŠ›ï¼Œæ˜¯ç¤¾ä¼šä¸»ä¹‰çš„æ ¹æœ¬ä»»åŠ¡ã€‚\n# ä¸‰ä¸ªæœ‰åˆ©äº\n\næ˜¯å¦æœ‰åˆ©äºå‘å±•ç¤¾ä¼šä¸»ä¹‰ç”Ÿäº§åŠ›\næ˜¯å¦æœ‰åˆ©äºå¢å¼ºç¤¾ä¼šä¸»ä¹‰å›½å®¶çš„ç»¼åˆå›½åŠ›\næ˜¯å¦æœ‰åˆ©äºæé«˜äººæ°‘çš„ç”Ÿæ´»æ°´å¹³\n\n\nç”Ÿå›½äºº\n\n# æ­£ç¡®è®¤è¯†å’Œå¤„ç†æ”¹é©ã€å‘å±•ã€ç¨³å®šçš„å…³ç³»\næ”¹é©æ˜¯åŠ¨åŠ›ï¼Œå‘å±•æ˜¯ç›®çš„ï¼Œç¨³å®šæ˜¯å‰æã€‚è¦æŠŠæ”¹é©çš„åŠ›åº¦ã€å‘å±•çš„é€Ÿåº¦å’Œç¤¾ä¼šå¯æ‰¿å—çš„ç¨‹åº¦ç»Ÿä¸€èµ·æ¥ï¼ŒæŠŠä¸æ–­æ”¹å–„äººæ°‘ç”Ÿæ´»ä½œä¸ºå¤„ç†æ”¹é©ã€å‘å±•ã€ç¨³å®šå…³ç³»çš„é‡è¦ç»“åˆç‚¹ï¼Œåœ¨ç¤¾ä¼šç¨³å®šä¸­æ¨è¿›æ”¹é©å‘å±•ï¼Œé€šè¿‡æ”¹é©å‘å±•ä¿ƒè¿›ç¤¾ä¼šç¨³å®šã€‚\n# â€œä¸‰ä¸ªä»£è¡¨â€ é‡è¦æ€æƒ³çš„â€ èŠ±è¾¹ â€œ\nâ€œä¸‰ä¸ªä»£è¡¨â€ é‡è¦æ€æƒ³æ˜¯åœ¨å¯¹å†·æˆ˜ç»“æŸåå›½é™…å±€åŠ¿ç§‘å­¦åˆ¤æ–­çš„åŸºç¡€ä¸Šå½¢æˆçš„ï¼Œæ˜¯åœ¨ç§‘å­¦åˆ¤æ–­å…šçš„å†å²æ–¹ä½å’Œæ€»ç»“å†å²ç»éªŒçš„åŸºç¡€ä¸Šæå‡ºæ¥çš„ï¼Œæ˜¯åœ¨å»ºè®¾ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰ä¼Ÿå¤§å®è·µçš„åŸºç¡€ä¸Šå½¢æˆçš„ã€‚\n# â€œä¸‰ä¸ªä»£è¡¨â€ é‡è¦æ€æƒ³\n\nä¸­å›½å…±äº§å…šå§‹ç»ˆä»£è¡¨ä¸­å›½å…ˆè¿›ç”Ÿäº§åŠ›çš„å‘å±•è¦æ±‚\nå§‹ç»ˆä»£è¡¨ä¸­å›½å…ˆè¿›æ–‡åŒ–çš„å‰è¿›æ–¹å‘\nå§‹ç»ˆä»£è¡¨ä¸­å›½æœ€å¹¿å¤§äººæ°‘çš„æ ¹æœ¬åˆ©ç›Š\n\n# æ–°æ°‘ä¸»ä¸»ä¹‰é©å‘½æ—¶æœŸ 1921-1949\n\n\n\nå­æ—¶æœŸ\næ—¶é—´\n\n\n\n\nå…šçš„åˆ›ç«‹å’Œå¤§é©å‘½æ—¶æœŸ\n1921-1927\n\n\nåœŸåœ°é©å‘½æˆ˜äº‰æ—¶æœŸ\n1927-1937\n\n\nå…¨æ°‘æ—æŠ—æ—¥æˆ˜äº‰æ—¶æœŸ\n1937-1945\n\n\nè§£æ”¾æˆ˜äº‰æ—¶æœŸ\n1945-1949\n\n\n\n# æ–°æ°‘ä¸»ä¸»ä¹‰ç¤¾ä¼šæ—¶æœŸ 1949-1956\n# ç¤¾ä¼šä¸»ä¹‰å»ºè®¾æ—¶æœŸ 1956-1978\n# 1978 ä¹‹å\n\n\n\nå¤§äº‹ä»¶\næ—¶é—´\n\n\n\n\nåä¸€å±Šä¸‰ä¸­å…¨ä¼šæå‡ºæ”¹é©å¼€æ”¾\n1978\n\n\næå‡ºå‘½é¢˜ â€œå»ºè®¾æœ‰ä¸­å›½ç‰¹è‰²çš„ç¤¾ä¼šä¸»ä¹‰\n1982\n\n\nè‹è”è§£ä½“ï¼Œå†·æˆ˜ç»“æŸ\n1991\n\n\nå—æ–¹è°ˆè¯\n1992\n\n\nä¸­å…±åå››å¤§ï¼Œç¡®ç«‹ç¤¾ä¼šä¸»ä¹‰å¸‚åœºç»æµä½“åˆ¶çš„æ”¹é©ç›®æ ‡\n1992\n\n\né‚“å°å¹³ç†è®ºæå‡º\n1997\n\n\nä¸‰ä¸ªä»£è¡¨æŒ‡å¯¼æ€æƒ³\n2002\n\n\n\n# ç§‘å­¦å‘å±•è§‚\nç¬¬ä¸€è¦ä¹‰ï¼šå‘å±•\næ ¸å¿ƒç«‹åœºï¼šä»¥äººä¸ºæœ¬\nåŸºæœ¬è¦æ±‚ï¼šå…¨é¢å¯æŒç»­å‘å±•\næ ¹æœ¬æ–¹æ³•ï¼šç»Ÿç­¹å…¼é¡¾\nä¿æŒå…ˆè¿›æ€§æ˜¯å…šè‡ªèº«å»ºè®¾çš„æ ¹æœ¬ä»»åŠ¡å’Œæ°¸æ’è¯¾é¢˜\n# ç§‘å­¦å‘å±•è§‚çš„å½¢æˆæ¡ä»¶\n\næ˜¯åœ¨æ·±åˆ»æŠŠæ¡æˆ‘å›½åŸºæœ¬å›½æƒ…å’Œæ–°çš„é˜¶æ®µæ€§ç‰¹å¾çš„åŸºç¡€ ä¸Šå½¢æˆå’Œå‘å±•çš„ã€‚\næ˜¯åœ¨æ·±å…¥æ€»ç»“æ”¹é©å¼€æ”¾ä»¥æ¥å®è·µç»éªŒçš„åŸºç¡€ä¸Šå½¢æˆå’Œå‘å±•çš„ã€‚\næ˜¯åœ¨æ·±åˆ»åˆ†æå›½é™…å½¢åŠ¿åŠå€Ÿé‰´å›½å¤–å‘å±•ç»éªŒåŸºç¡€ä¸Šå½¢æˆå’Œå‘å±•çš„ã€‚\n\n# é¢†å¯¼äººçš„æ€æƒ³ç²¾é«“\næ¯›æ³½ä¸œï¼šå®äº‹æ±‚æ˜¯\né‚“å°å¹³ï¼šè§£æ”¾æ€æƒ³ï¼Œå®äº‹æ±‚æ˜¯\næ±Ÿæ³½æ°‘ï¼šè§£æ”¾æ€æƒ³ï¼Œå®äº‹æ±‚æ˜¯ï¼Œä¸æ—¶ä¿±è¿›\nèƒ¡é”¦æ¶›ï¼šè§£æ”¾æ€æƒ³ï¼Œå®äº‹æ±‚æ˜¯ï¼Œä¸æ—¶ä¿±è¿›ï¼Œæ±‚çœŸåŠ¡å®\n# æ€ä¿®\n# çç¢\nä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰å»ºè®¾å®è·µæ˜¯ç¤¾ä¼šä¸»ä¹‰æ ¸å¿ƒä»·å€¼è§‚çš„ç°å®åŸºç¡€\nå…ˆè¿›æ€§ã€äººæ°‘æ€§å’ŒçœŸå®æ€§æ˜¯ç¤¾ä¼šä¸»ä¹‰æ ¸å¿ƒä»·å€¼è§‚çš„é“ä¹‰åŠ›é‡\n# é“å¾·ä½œç”¨\nè®¤è¯†åŠŸèƒ½ â€” åæ˜ æ­ç¤ºï¼ˆè¡Œä¸ºå‰ï¼‰\nè§„èŒƒåŠŸèƒ½ â€” è§„èŒƒå¼•å¯¼ï¼ˆè¡Œä¸ºä¸­ï¼‰\nè°ƒèŠ‚åŠŸèƒ½ â€” æŒ‡å¯¼çº æ­£ï¼ˆè¡Œä¸ºåï¼‰\n# çˆ±å›½ä¸»ä¹‰\nçˆ±å›½ä¸»ä¹‰æ˜¯ é“å¾·è¦æ±‚ æ”¿æ²»åŸåˆ™ æ³•å¾‹è§„èŒƒ ç²¾ç¥çº½å¸¦\nä»¥çˆ±å›½ä¸»ä¹‰ä¸ºæ ¸å¿ƒçš„æ°‘æ—ç²¾ç¥ï¼Œä»¥æ”¹é©åˆ›æ–°ä¸ºæ ¸å¿ƒçš„æ—¶ä»£ç²¾ç¥\n# ä¿¡å¿µ\næ‰§ç€æ€§ã€æ”¯æ’‘æ€§ã€å¤šæ ·æ€§\n# ç†æƒ³\nè¶…è¶Šæ€§ã€å®è·µæ€§ã€æ—¶ä»£æ€§\n# ä»·å€¼è§‚\nå…ˆè¿›æ€§ã€äººæ°‘æ€§ã€çœŸå®æ€§\n# åŒºåˆ†åˆ›é€ ç²¾ç¥ï¼Œæ¢¦æƒ³ç²¾ç¥ï¼Œå›¢ç»“ç²¾ç¥ï¼Œå’Œå¥‹æ–—ç²¾ç¥\nç¥è¯å°±æ˜¯æ¢¦æƒ³ï¼Œå‘æ˜ä¸€ç±»å°±æ˜¯åˆ›é€ ï¼Œå¼€å¦æ²»ç†æ²³æµä¹‹ç±»çš„å°±æ˜¯å¥‹æ–—ï¼Œå‰©ä¸‹çš„é‚£ä¸ªå°±æ˜¯å›¢ç»“\n# æ–‡åŒ–\næ–‡åŒ–æ˜¯æ¶µå…»æ°‘æ—å¿ƒç†ã€æ°‘æ—ä¸ªæ€§ã€æ°‘æ—ç²¾ç¥çš„æ‘‡ç¯®ï¼Œè€Œä¸æ˜¯ç¥–å›½å¤§å¥½æ²³å±±\n# ç¥–å›½æ²³å±±\nç¥–å›½çš„æ²³å±±åœ¨äººä»¬çš„å¿ƒä¸­å æ®ç€è‡³é«˜æ— ä¸Šçš„åœ°ä½ï¼Œç¥–å›½çš„å±±å±±æ°´æ°´æ»‹å…»å“ºè‚²ç€å¥¹çš„å­å­å­™å­™ã€‚â€œç¦¾è‹—ç¦»åœŸå³æ­»ï¼Œå›½å®¶æ— åœŸéš¾å­˜â€, ç¥–å›½çš„å¤§å¥½æ²³å±±ï¼Œä¸åªæ˜¯è‡ªç„¶é£å…‰ï¼Œæ›´æ˜¯ä¸»æƒã€è´¢å¯Œã€æ°‘æ—å‘ å±•å’Œè¿›æ­¥çš„åŸºæœ¬è½½ä½“ã€‚å› æ­¤ï¼Œæ¯ä¸€ä¸ªçˆ±å›½è€…éƒ½ä¼šæŠŠ â€œä¿æˆ‘å›½åœŸâ€ â€œçˆ±æˆ‘å®¶ä¹¡â€ã€ç»´æŠ¤ç¥–å›½é¢†åœŸçš„å®Œæ•´å’Œç»Ÿä¸€ï¼Œä½œä¸ºè‡ªå·±çš„ç¥åœ£ä½¿å‘½å’Œä¹‰ä¸å®¹è¾çš„è´£ä»»ã€‚\n# ä¸­åä¼ ç»Ÿç¾å¾·çš„æ ¹æœ¬è¦æ±‚\nä¸­åä¼ ç»Ÿç¾å¾·çš„æ ¹æœ¬è¦æ±‚æ˜¯å…¬ä¹‰èƒœç§æ¬²\n# é“å¾·çš„ä½œç”¨\n\né“å¾·ä¸ºç»æµåŸºç¡€çš„å½¢æˆã€å·©å›ºå’Œå‘å±•æœåŠ¡ï¼Œæ˜¯ä¸€ç§é‡è¦çš„ç²¾ç¥åŠ›é‡ã€‚\né“å¾·å¯¹å…¶ä»–ç¤¾ä¼šæ„è¯†å½¢æ€çš„å­˜åœ¨æœ‰ç€é‡å¤§çš„å½±å“\né“å¾·é€šè¿‡è°ƒæ•´äººä»¬ä¹‹é—´çš„å…³ç³»ç»´æŠ¤ç¤¾ä¼šç§©åºå’Œç¨³å®š\né“å¾·æ˜¯æé«˜äººçš„ç²¾ç¥å¢ƒç•Œã€ä¿ƒè¿›äººçš„è‡ªæˆ‘å®Œå–„ï¼Œæ¨åŠ¨äººçš„å…¨é¢å‘å±•çš„å†…åœ¨åŠ¨åŠ›\nåœ¨é˜¶çº§ç¤¾ä¼šä¸­ï¼Œé“å¾·æ˜¯é˜¶çº§æ–—äº‰çš„é‡è¦å·¥å…·\n\n# å…¬å…±ç”Ÿæ´»çš„å››ä¸ªç‰¹å¾\n\nä¸€æ˜¯æ´»åŠ¨èŒƒå›´çš„å¹¿æ³›æ€§\näºŒæ˜¯æ´»åŠ¨å†…å®¹çš„å¼€æ”¾æ€§\nä¸‰æ˜¯äº¤å¾€å¯¹è±¡çš„å¤æ‚æ€§\nå››æ˜¯æ´»åŠ¨æ–¹å¼çš„å¤šæ ·æ€§\n\n# å…¨å¿ƒå…¨æ„ä¸ºäººæ°‘æœåŠ¡æ˜¯è´¯ç©¿ä¸­å›½é©å‘½é“å¾·çš„ä¸€æ ¹çº¢çº¿\n\næ˜¯åšæŒå†å²å”¯ç‰©ä¸»ä¹‰å¿…ç„¶è¦æ±‚\næ˜¯ä¸­å›½å…±äº§å…šè·µè¡Œæ ¹æœ¬å®—æ—¨\nä¹Ÿæ˜¯ç¤¾ä¼šä¸»ä¹‰é“å¾·è§‚é›†ä¸­ä½“ç°\næ˜¯å…¨ä½“ä¸­å›½äººæ°‘å…±åŒéµå¾ªé“å¾·è¦æ±‚\næ˜¯ç¤¾ä¼šä¸»ä¹‰ç»æµåŸºç¡€å’Œäººé™…å…³ç³»çš„å®¢è§‚è¦æ±‚\næ˜¯ç¤¾ä¼šä¸»ä¹‰å¸‚ åœºç»æµå¥åº·å‘å±•çš„è¦æ±‚\næ˜¯å…ˆè¿›æ€§è¦æ±‚å’Œå¹¿æ³›æ€§è¦æ±‚çš„ç»Ÿä¸€\nä¸ºäººæ°‘æœåŠ¡æ˜¯ç¤¾ä¼šä¸»ä¹‰é“å¾·çš„æ ¸å¿ƒ\né›†ä½“ä¸»ä¹‰æ˜¯ç¤¾ä¼šä¸»ä¹‰é“å¾·çš„åŸåˆ™\n\n# æ³•å¾‹çš„ä½œç”¨\n\næ™®éé€‚ç”¨ï¼ˆéµå®ˆï¼‰\nä¼˜å…ˆé€‚ç”¨\nä¸å¯è¿è¿”ï¼ˆéµå®ˆ + åˆ¶è£ï¼‰\n\n# æ—¶æ”¿ï¼ˆ2024 å¹´ï¼‰\n# äºŒåå±Šä¸‰ä¸­å…¨ä¼š\n\né€šè¿‡äº†ã€Šä¸­å…±ä¸­å¤®å…³äºè¿›ä¸€æ­¥å…¨é¢æ·±åŒ–æ”¹é©ã€æ¨è¿›ä¸­å›½å¼ç°ä»£åŒ–çš„å†³å®šã€‹ï¼ˆæœ€é‡è¦æˆæœï¼‰\nå½“å‰å’Œä»Šåä¸€ä¸ªæ—¶æœŸæ˜¯ä»¥ä¸­å›½å¼ç°ä»£åŒ–å…¨é¢æ¨è¿›å¼ºå›½å»ºè®¾ã€æ°‘æ—å¤å…´ä¼Ÿä¸šçš„å…³é”®æ—¶æœŸ\né«˜æ°´å¹³ç¤¾ä¼šä¸»ä½“å¸‚åœºç»æµä½“åˆ¶æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„é‡è¦ä¿éšœ\næ•™è‚²ã€ç§‘æŠ€ã€äººæ‰æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„åŸºç¡€æ€§ã€æˆ˜ç•¥æ€§æ”¯æ’‘\nåŸä¹¡èåˆå‘å±•æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„å¿…ç„¶è¦æ±‚\nå¼€æ”¾æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„é²œæ˜æ ‡è¯†\nå‘å±•å…¨è¿‡ç¨‹äººæ°‘æ°‘ä¸»æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„æœ¬è´¨è¦æ±‚\næ³•æ²»æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„é‡è¦ä¿éšœ\nåœ¨å‘å±•ä¸­ä¿éšœå’Œæ”¹å–„æ°‘ç”Ÿæ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„é‡å¤§ä»»åŠ¡\nå›½å®¶å®‰å…¨æ˜¯ä¸­å›½å¼ç°ä»£åŒ–è¡Œç¨³è‡´è¿œçš„é‡è¦åŸºç¡€\nå›½é˜²å’Œå†›é˜Ÿç°ä»£åŒ–æ˜¯ä¸­å›½å¼ç°ä»£åŒ–çš„é‡è¦ç»„æˆéƒ¨åˆ†\nå…šçš„é¢†å¯¼æ˜¯è¿›ä¸€æ­¥å…¨é¢æ·±åŒ–æ”¹é©ã€æ¨è¿›ä¸­å›½å¼ç°ä»£åŒ–çš„æ ¹æœ¬ä¿è¯\n\n# 2024 å¹´ä¸­éåˆä½œè®ºå›åŒ—äº¬å³°ä¼š\n2024 å¹´ä¸­éåˆä½œè®ºå›åŒ—äº¬å³°ä¼šçš„ä¸»é¢˜ä¸º â€œæºæ‰‹æ¨è¿›ç°ä»£åŒ–ï¼Œå…±ç­‘é«˜æ°´å¹³ä¸­éå‘½è¿å…±åŒä½“â€ã€‚\næ²»å›½ç†æ”¿ã€å·¥ä¸šåŒ–å’Œå†œä¸šç°ä»£åŒ–ã€å’Œå¹³å®‰å…¨ã€é«˜è´¨é‡å…±å»º â€œä¸€å¸¦ä¸€è·¯â€ åˆ†åˆ«æ˜¯ä¸­éåˆä½œè®ºå›åŒ—äº¬å³°ä¼šå››åœºé«˜çº§åˆ«ä¼šè®®çš„è®®é¢˜ã€‚\n# åŸ¹å…»ç¤¾ä¼šä¸»ä¹‰æ³•æ²»æ€ç»´\nå®ªæ³•ä¿éšœã€ç«‹æ³•ä¿éšœã€è¡Œæ”¿ä¿éšœå’Œå¸æ³•ä¿éšœã€‚\nå®ªæ³•ä¿éšœæ˜¯æƒåˆ©ä¿éšœçš„å‰æå’ŒåŸºç¡€ï¼Œ\nç«‹æ³•ä¿éšœæ˜¯æƒåˆ©ä¿éšœçš„é‡è¦æ¡ä»¶ï¼Œ\nè¡Œæ”¿ä¿éšœæ˜¯æƒåˆ©ä¿éšœçš„å…³é”®ç¯èŠ‚ï¼Œ\nå¸æ³•ä¿éšœæ˜¯å…¬æ°‘æƒåˆ©ä¿éšœçš„æœ€åé˜²çº¿ã€‚\n# å»ºè®¾ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ³•æ²»ä½“ç³»\nå»ºè®¾ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ³•æ²»ä½“ç³»ï¼Œå°±æ˜¯è¦å½¢æˆå®Œå¤‡çš„æ³•å¾‹è§„èŒƒä½“ç³»ã€é«˜æ•ˆçš„æ³•æ²»å®æ–½ä½“ç³»ã€ä¸¥å¯†çš„æ³•æ²»ç›‘ç£ä½“ç³»ã€æœ‰åŠ›çš„æ³•æ²»ä¿éšœä½“ç³»ï¼Œå½¢æˆå®Œå–„çš„å…šå†…æ³•è§„ä½“ç³»ã€‚\nå½¢æˆå®Œå¤‡çš„æ³•å¾‹è§„èŒƒä½“ç³»ï¼Œæ˜¯ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ³•æ²»ä½“ç³»çš„å‰æï¼Œæ˜¯æ³•æ²»å›½å®¶ã€æ³•æ²»æ”¿åºœã€æ³•æ²»ç¤¾ä¼šçš„åˆ¶åº¦åŸºç¡€ï¼›\nå»ºè®¾é«˜æ•ˆçš„æ³•æ²»å®æ–½ä½“ç³»ï¼Œæ˜¯å»ºè®¾ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ³•æ²»ä½“ç³»çš„é‡ç‚¹ï¼›\nå½¢æˆä¸¥å¯†çš„æ³•æ²»ç›‘ç£ä½“ç³»ï¼Œæ˜¯å®ªæ³•æ³•å¾‹æœ‰æ•ˆå®æ–½çš„é‡è¦ä¿éšœï¼›\nå»ºè®¾æœ‰åŠ›çš„æ³•æ²»ä¿éšœä½“ç³»ï¼Œæ˜¯å…¨é¢ä¾æ³•æ²»å›½çš„é‡è¦ä¾æ‰˜ï¼›\nå½¢æˆå®Œå–„çš„å…šå†…æ³•è§„ä½“ç³»ï¼Œæ˜¯ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ³•æ²»ä½“ç³»çš„æœ¬è´¨è¦æ±‚å’Œé‡è¦å†…å®¹ã€‚\n# å…­ä¸ªå¿…é¡»åšæŒ\n\n\n\nåšæŒ\næ˜¯â€¦\nä½“ç°äº†\n\n\n\n\näººæ°‘è‡³ä¸Š\næ ¹æœ¬ä»·å€¼ç«‹åœº\nå”¯ç‰©ä¸»ä¹‰ç¾¤ä¼—å²è§‚\n\n\nè‡ªç«‹è‡ªä¿¡\nå†…åœ¨ç²¾ç¥ç‰¹è´¨\nå®¢è§‚è§„å¾‹æ€§å’Œä¸»è§‚èƒ½åŠ¨æ€§çš„æœ‰æœºç»“åˆ\n\n\nå®ˆæ­£åˆ›æ–°\né²œæ˜ç†è®ºå“æ ¼\nå˜ä¸ä¸å˜ï¼Œç»§æ‰¿ä¸å‘å±•çš„å†…åœ¨è”ç³»\n\n\né—®é¢˜å¯¼å‘\né‡è¦å®è·µè¦æ±‚\nçŸ›ç›¾çš„æ™®éæ€§ä¸å®¢è§‚æ€§\n\n\nç³»ç»Ÿè§‚å¿µ\nåŸºæœ¬æ€æƒ³å’Œå·¥ä½œæ–¹æ³•\nè¾©è¯å”¯ç‰©ä¸»ä¹‰æ™®éè”ç³»çš„åŸç†\n\n\nèƒ¸æ€€å¤©ä¸‹\nä¸­å›½å…±äº§å…šäººçš„å¢ƒç•Œæ ¼å±€\né©¬å…‹æ€ä¸»ä¹‰è¿½æ±‚äººç±»è¿›æ­¥å’Œè§£æ”¾çš„å´‡é«˜ç†æƒ³\n\n\n\n\n\n\n\n\n# æ–°è´¨ç”Ÿäº§åŠ›å£è¯€\nå…³è°·æ‚ æ‚ ä¸šåŠ¡åŠ³ç´¯å’³å—½ï¼Œç«‹å¿—å…¨å¿ƒåšç‚¹å¿ƒã€‚\n\nå…³é”®åœ¨äºè´¨ä¼˜ï¼ˆå…³è°·æ‚ æ‚ ï¼‰\né‡ç‚¹ä»»åŠ¡æ˜¯æ–°äº§ä¸šï¼ˆä¸šåŠ¡ï¼‰\nå†…æ¶µ â€”â€” åŠ³åŠ¨è€…ã€åŠ³åŠ¨å¯¹è±¡ã€åŠ³åŠ¨èµ„æ–™ï¼ˆåŠ³ç´¯ï¼‰\næ ¸å¿ƒè¦ç´  â€”â€” ç§‘æŠ€åˆ›æ–°ï¼ˆå’³å—½ï¼‰\næœ¬è´¨ â€”â€” å…ˆè¿›ç”Ÿäº§åŠ›ï¼ˆç«‹å¿—ï¼‰\næ ¸å¿ƒæ ‡å¿— â€”â€” å…¨è¦ç´ ç”Ÿäº§ç‡ï¼ˆå…¨å¿ƒï¼‰\næ˜¾è‘—ç‰¹ç‚¹ â€”â€” åˆ›æ–°ï¼ˆåˆ›æ–°ï¼‰\n\n# å¤šæ°‘æ—å›½å®¶â€¦\nè¡€è„‰ç›¸è â€”â€” å†å²æ ¹åŸº\nä¿¡å¿µç›¸åŒ â€”â€” å†…ç”ŸåŠ¨åŠ›\næ–‡åŒ–ç›¸é€š â€”â€” æ–‡åŒ–åŸºå› \nç»æµç›¸ä¾ â€”â€” å¼ºå¤§åŠ›é‡\n# ç§‘æŠ€åˆ›æ–°å’Œäº§ä¸šåˆ›æ–°æ·±åº¦èåˆ\nåŸºç¡€ â€”â€” é«˜è´¨é‡ç§‘æŠ€ä¾›ç»™\nå…³é”® â€”â€” ä¼ä¸šç§‘æŠ€åˆ›æ–°ä¸»ä½“åœ°ä½\né€”å¾„ â€”â€” ä¿ƒè¿›ç§‘æŠ€æˆæœè½¬åŒ–åº”ç”¨\n# ä¸»è§‚é¢˜è§£é¢˜\n# é—®é¢˜åˆ†ç±»\n\nä¸ºä»€ä¹ˆ\næ˜¯ä»€ä¹ˆâ€¦ å¦‚ä½•ç†è§£ï¼Ÿ\næ„ä¹‰æ˜¯ï¼Ÿ\næ€ä¹ˆåšï¼Ÿæœªæ¥æ€ä¹ˆåšï¼Ÿ\n\nå››å¤§ç±»å‹ + ä¸»è¯­\n# ä¸‡èƒ½ä¸‰æ­¥èµ°\nè§‚ç‚¹ã€å‡ºå‘ç‚¹ã€‘+ è½è„šç‚¹ + è®ºæ®\n# ä¸­å›½å£°éŸ³å…³é”®è¯\næºæ‰‹å…±å»ºäººç±»å‘½è¿å…±åŒä½“ã€å’Œå¹³ã€å…¬é“æ­£ä¹‰ã€å…±åŒå‘å±•ã€å‘å±•ä¸å®‰å…¨ã€å…¬æ­£\nä¸€åˆ‡çš„æ ¸å¿ƒæ˜¯å…±åŒå‘å±•ï¼Œæ„å»ºäººç±»å‘½è¿å…±åŒä½“ã€‚\nå’Œå¹³å…±å¤„äº”é¡¹åŸåˆ™å‘è¡¨ 70 å‘¨å¹´ï¼Œå¼•å‡ºä¸­éåˆä½œè®ºå›å³°ä¼šï¼Œå¼•å‡ºä¸Šæµ·åˆä½œç»„ç»‡ã€å¼•å‡ºå›½é™…å‹å¥½å¤§ä¼šã€å¼•å‡ºé‡‘ç –å›½å®¶é¢†å¯¼äººç¬¬åå…­æ¬¡ä¼šæ™¤ã€å¼•å‡ºäºŒåå›½é›†å›¢é¢†å¯¼äººç¬¬åä¹æ¬¡å³°ä¼šã€‚\næŠ“ä½ä¸»æ—‹å¾‹ï¼š\n\nè§‚ç‚¹ï¼šä¸–ç•Œå’Œå¹³å‘å±•ã€å®‰å…¨ã€å…¬é“æ­£ä¹‰ã€åˆä½œã€å¤šè¾¹ä¸»ä¹‰\nè½è„šç‚¹ï¼šäººç±»å‘½è¿å…±åŒä½“ã€å…¨äººç±»å…±åŒä»·å€¼\n\n# å°å°æ¨¡æ¿\n# 38 æ—¶æ”¿ï¼Œç¬¬ä¸€é—®\nå½“å‰ï¼Œä¸–ç•Œç™¾å¹´å˜å±€åŠ é€Ÿæ¨è¿›ï¼Œä¸€äº›è¥¿æ–¹å›½å®¶ä¸ºç»´æŠ¤è‡ªèº«éœ¸æƒï¼Œå¤§æå•è¾¹ä¸»ä¹‰ã€ä¿æŠ¤ä¸»ä¹‰ï¼Œå»ºç«‹å°é—­æ’ä»–çš„â€œå°åœˆå­â€ï¼Œå±å®³ä¸–ç•Œå’Œå¹³ä¸å…±åŒå‘å±•ã€‚\nâ‘ ï¼ˆä¸»è¯­ã€ææ–™ã€‘é‡‘ç –....ï¼‰åšæŒå¼€æ”¾åŒ…å®¹ã€åˆä½œå…±èµ¢çš„åˆå¿ƒä½¿å‘½ï¼Œé¡ºåº”å…¨çƒå—æ–¹å´›èµ·å¤§åŠ¿ã€‚\nâ‘¡ï¼ˆä¸»è¯­ã€ææ–™ã€‘ä¸­é....ï¼‰èµ°åˆ°ä¸€èµ·ï¼Œé¡ºåº”ä¸–ç•Œå’Œå¹³å’Œå‘å±•å‘å‡ºå’Œå¹³ä¹‹å£°ï¼Œå€¡å¯¼äº’æƒ åŒ…å®¹çš„ç»æµå…¨çƒåŒ–å’Œä¸–ç•Œå¤šæåŒ–ï¼Œåšå®ˆå…±åŒå‘å±•çš„å¤§é“ã€‚\nâ‘¢ï¼ˆä¸»è¯­ã€ææ–™ã€‘å’Œå¹³å…±å¤„äº”é¡¹åŸåˆ™....ï¼‰æ ‘ç«‹äº†å†å²æ ‡æ†ï¼Œä¸ºä¸åŒç¤¾ä¼šåˆ¶åº¦å›½å®¶å»ºç«‹å’Œå‘å±•å…³ç³»æä¾›æ­£ç¡®æŒ‡å¯¼ï¼Œä¸ºå‘å±•ä¸­å›½å®¶å›¢ç»“åˆæ±‡èšå¼ºå¤§åˆåŠ›ï¼Œä¸ºæ¨åŠ¨å›½é™…ç§©åºæœç€æ›´åŠ å…¬æ­£åˆç†çš„æ–¹å‘è´¡çŒ®äº†ä¸­å›½æ™ºæ…§ã€‚\n\n# 38 æ—¶æ”¿ï¼Œç¬¬äºŒé—®\nå†å²å’Œç°å®å‘Šè¯‰æˆ‘ä»¬ï¼Œå„å›½å¿…é¡»å…±æ‹…ç»´æŠ¤å’Œå¹³è´£ä»»ï¼ŒåŒèµ°å’Œå¹³å‘å±•é“è·¯ï¼Œè¦ç§‰æŒå…¬é“æ­£ä¹‰çš„ç†å¿µï¼Œå±•ç°å¼€æ”¾åŒ…å®¹çš„èƒ¸è¥Ÿã€‚\nâ‘ æˆ‘ä»¬è¦å»ºè®¾â€œå’Œå¹³é‡‘ç –â€ã€â€œåˆ›æ–°é‡‘ç –â€ã€â€œç»¿è‰²é‡‘ç –â€ã€â€œå…¬æ­£é‡‘ç –â€ï¼Œâ€œäººæ–‡é‡‘ç –â€ã€‚\nâ‘¡æˆ‘ä»¬è¦åšæŒå’Œå¹³çš„åŸåˆ™ï¼Œå¤¯å®ç›¸äº’å°Šé‡çš„åŸºç¡€ï¼Œå®ç°å’Œå¹³å®‰å…¨çš„æ„¿æ™¯ï¼Œæ±‡èšå…±ç­‘ç¹è£çš„åŠ¨åŠ›ã€‚\nâ‘¢æå‡ºâ€œåšæŒå’Œå¹³ï¼Œå®ç°å…±åŒå®‰å…¨â€ â€œé‡æŒ¯å‘å±•ï¼Œå®ç°æ™®éç¹è£â€ â€œå…±å…´æ–‡æ˜ï¼Œå®ç°å¤šå…ƒå’Œè°å‘å±•â€ä¸‰ç‚¹ä¸»å¼ ã€‚\nåœ¨ä¸–ç•Œå˜å±€ä¹±å±€ä¸­å¼€è¾Ÿé•¿æ²»ä¹…å®‰ã€å…±åŒç¹è£çš„äººé—´æ­£é“ï¼Œå¥‹åŠ›å¼€åˆ›ä¸­å›½ç‰¹è‰²å¤§å›½å¤–äº¤æ›´æœ‰ä½œä¸ºçš„æ–°å±€é¢ï¼Œä¸ºè¿›ä¸€æ­¥å…¨é¢æ·±åŒ–æ”¹é©ã€æ¨è¿›ä¸­å›½å¼ç°åŒ–ã€æ¨ä¸ºæ„å»ºäººç±»å‘½è¿å…±åŒä½“ä½œå‡ºæ–°çš„è´¡çŒ®ã€‚\n\næœ‰é‡‘ç –å†™ä¸€äºŒï¼Œæ— é‡‘ç –é€‰äºŒä¸‰\n# ç­”é¢˜é€»è¾‘\n\næŠ›å‡ºè€ƒç‚¹\nè§£é‡Šè€ƒç‚¹\né˜æ˜å…³ç³»\næ–¹æ³•è®º\nç»“åˆææ–™\n\n# è‚–å›› 25â€”â€” å¤§é¢˜é€»è¾‘ç»ƒä¹ \n# é©¬åŸéƒ¨åˆ†\n\nï¼ˆ1ï¼‰ç»“åˆ â€œè¯¥æ”¹çš„åšå†³æ”¹ï¼Œä¸è¯¥æ”¹çš„ä¸æ”¹â€ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆå¿…é¡»åšæŒå®ˆæ­£åˆ›æ–°ã€‚\n\nâ€œè¯¥æ”¹çš„åšå†³æ”¹ï¼Œä¸è¯¥çš„ä¸æ”¹â€ï¼Œä½“ç°çš„æ­£æ˜¯å®ˆæ­£ä¸åˆ›æ–°çš„è¾©è¯ç»Ÿä¸€ã€‚â€œä¸è¯¥æ”¹çš„ä¸æ”¹â€ï¼Œå®ˆæ­£æ‰èƒ½ä¸è¿·å¤±æ–¹å‘ï¼Œä¸çŠ¯é¢ è¦†æ€§é”™è¯¯ï¼Œâ€œè¯¥æ”¹çš„åšå†³æ”¹â€ï¼Œåˆ›æ–°æ‰èƒ½æŠŠæ¡æ—¶ä»£ï¼Œå¼•é¢†æ—¶ä»£ã€‚\nåšæŒå®ˆæ­£ä¸åŠ¨æ‘‡ï¼Œæ‰€è°“å®ˆæ­£ï¼Œå°±æ˜¯åšæŒå®äº‹æ±‚æ˜¯ï¼ŒåšæŒçœŸç†æ€§è®¤è¯†ï¼ŒåšæŒæ­£ç¡®çš„æ”¿æ²»æ–¹å‘ã€‚\nåšæŒåˆ›æ–°ä¸åœæ­¥ï¼Œæ‰€è°“åˆ›æ–°ï¼Œå°±æ˜¯åšæŒè§£æ”¾æ€æƒ³ï¼Œç§‰æ‰¿ç§‘å­¦çš„æ€æƒ³è§‚å¿µï¼Œå‘ç°å’Œè¿ç”¨äº‹ç‰©çš„æ–°è”ç³»ã€æ–°è§‚ç‚¹ã€æ–°è§„å¾‹ï¼Œæ›´æœ‰æ•ˆçš„è®¤è¯†ä¸–ç•Œæ”¹é€ ä¸–ç•Œã€‚\nå®ˆæ­£æ˜¯åˆ›æ–°çš„å‰æå’ŒåŸºç¡€ï¼Œåˆ›æ–°æ˜¯å®ˆæ­£çš„ç›®çš„å’Œè·¯å¾„ã€‚å®ˆæ­£åˆ›æ–°æ·±åˆ»çš„æ­ç¤ºäº† â€œå˜â€ ä¸ â€œä¸å˜â€ã€ç»§æ‰¿ä¸å‘å±•çš„è¾©è¯ç»Ÿä¸€ã€‚\nå®ˆæ­£åˆ›æ–°ä¸ºå…šå’Œäººæ°‘äº‹ä¸šæä¾›äº†ç§‘å­¦çš„è§‚ç‚¹ã€ç«‹åœºã€æ–¹æ³•ã€‚\n\nï¼ˆ2ï¼‰ä¸ºä»€ä¹ˆè¦ â€œåšæŒç ´å’Œç«‹çš„è¾©è¯ç»Ÿä¸€â€ï¼Ÿ\n\nå”¯ç‰©è¾©è¯æ³•è®¤ä¸ºï¼Œäº‹ç‰©å‘å‘å±•æ˜¯é€šè¿‡å…¶è‡ªèº«çš„çŸ›ç›¾è¿åŠ¨ä»¥è‡ªæˆ‘å¦å®šçš„æ–¹å¼æ¥å®ç°çš„ï¼Œç€è¦æ±‚æˆ‘ä»¬æŒæ¡ç ´ä¸ç«‹çš„è¾©è¯ç»Ÿä¸€å…³ç³»ã€‚\næ‰€è°“ç ´ï¼Œå°±æ˜¯è¦ç ´é™¤ä¸äº‹ç‰©å‘å±•è¿›ç¨‹ä¸ç›¸ç¬¦åˆçš„æ—§è§‚ç‚¹ã€æ—§ç†è®ºã€æ—§æ–¹æ³•ã€‚æ‰€è°“ç«‹ï¼Œå°±æ˜¯ç§‰æ‰¿ç§‘å­¦çš„ç†å¿µï¼Œå¯»æ‰¾å¹¶å‘ç°äº‹ç‰©çš„æ–°è”ç³»ã€æ–°æ–¹æ³•ã€ç†è®ºã€‚\nç ´ä¸ç«‹æ˜¯çŸ›ç›¾ç€çš„å¯¹ç«‹é¢ï¼Œå³ç›¸åŒºåˆ«ï¼Œåˆç›¸è”ç³»ï¼ŒäºŒè€…å¯¹ç«‹ç»Ÿä¸€ï¼Œåœ¨äº‹ç‰©çš„å‘å±•ä¸­èµ·åˆ°é‡è¦çš„ä½œç”¨ã€‚è¯¥åŸç†è¦æ±‚æˆ‘ä»¬æŒæ¡ç ´ä¸ç«‹çš„è¾©è¯ç»Ÿä¸€å…³ç³»ã€‚\n\nï¼ˆ1ï¼‰è¿ç”¨å”¯ç‰©å²è§‚åŸç†ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆ â€œå‘å±•æ–°è´¨ç”Ÿäº§åŠ›ï¼Œå¿…é¡»è¿›ä¸€æ­¥å…¨é¢æ·±åŒ–æ”¹é©ï¼Œå½¢æˆä¸ä¹‹ç›¸é€‚åº”çš„æ–°å‹ç”Ÿäº§å…³ç³»â€ã€‚\n\nå”¯ç‰©å²è§‚è®¤ä¸ºï¼Œç”Ÿäº§åŠ›ä¸ç”Ÿäº§å…³ç³»æ˜¯å¯¹ç«‹ç»Ÿä¸€çš„æœ‰æœºä½“ã€‚\nç”Ÿäº§åŠ›æ—¶ç”Ÿäº§çš„ç‰©è´¨å†…å®¹ï¼Œç”Ÿäº§å…³ç³»æ˜¯ç”Ÿäº§çš„ç¤¾ä¼šå½¢å¼ã€‚\nå‘å±•æ–°è´¨ç”Ÿäº§åŠ›å°±è¦å½¢æˆä¸ä¹‹ç›¸åŒ¹é…çš„ç”Ÿäº§å…³ç³»è¿™æ˜¯å› ä¸ºï¼Œç”Ÿäº§åŠ›å†³å®šç”Ÿäº§å…³ç³»ï¼Œè€Œç”Ÿäº§å…³ç³»å¯¹ç”Ÿäº§åŠ›å…·æœ‰èƒ½åŠ¨çš„åä½œç”¨ã€‚ç”Ÿäº§å…³ç³»å¯¹ç”Ÿäº§åŠ›èƒ½åŠ¨çš„åä½œç”¨ä¸»è¦ä½“ç°åœ¨ä¸¤ä¸ªæ–¹é¢ï¼šå½“ç”Ÿäº§å…³ç³»é€‚åº”ç”Ÿäº§åŠ›çš„å‘å±•æ—¶å°±ç”Ÿäº§åŠ›èµ·åˆ°ä¿ƒè¿›å’Œæ¨åŠ¨çš„ä½œç”¨ï¼Œå½“ç”Ÿäº§å…³ç³»ä¸é€‚åº”ç”Ÿäº§åŠ›çš„å‘å±•æ—¶å°±å¯¹æˆäº§åŠ›èµ·åˆ°é˜»ç¢çš„ä½œç”¨ã€‚\nç”Ÿäº§åŠ›ä¸ç”Ÿäº§å…³ç³»çš„ç›¸äº’ä½œç”¨ï¼Œæ„æˆäº†ç”Ÿäº§å…³ç³»è¦é€‚åº”ç”Ÿäº§åŠ›çš„å®¢è§‚è§„å¾‹ï¼Œè¿™æ˜¯ç¤¾ä¼šå½¢æ€å‘å±•çš„æ™®éè§„å¾‹ã€‚\n\nï¼ˆ2ï¼‰å–„ç”¨å› åœ°åˆ¶å®œçš„ â€œåœŸåŠæ³•â€ ä½“ç°äº†æ€æ ·çš„è¾©è¯æ€ç»´ï¼Ÿï¼ˆæˆ–ï¼šä¸ºä»€ä¹ˆä¸èƒ½ â€œä¸€å“„è€Œä¸Šâ€â€œç®€å• å¥—ç”¨å•ä¸€å‘å±•æ¨¡å¼â€ï¼Œè€Œè¦ â€œå› åœ°åˆ¶å®œâ€ å‘å±•æ–°è´¨ç”Ÿäº§åŠ›ï¼Ÿï¼‰\n\nè¾©è¯æ³•è®¤ä¸ºï¼ŒçŸ›ç›¾å…·æœ‰æ™®éæ€§å’Œç‰¹æ®Šæ€§ï¼ŒäºŒè€…æ˜¯è¾©è¯ç»Ÿä¸€çš„æ•´ä½“ã€‚\nçŸ›ç›¾çš„æ™®éæ€§å°±æ˜¯ï¼ŒçŸ›ç›¾æ— å¤„ä¸åœ¨ï¼Œæ— æ—¶ä¸æœ‰ï¼ŒçŸ›ç›¾å…·æœ‰æ™®éå­˜åœ¨çš„ç‰¹ç‚¹ã€‚çŸ›ç›¾çš„ç‰¹æ®Šæ€§åœ¨äºï¼Œäº‹ç‰©æœ‰ç€ä¸åŒçš„çŸ›ç›¾ä»¥åŠåŒä¸€çŸ›ç›¾åœ¨ä¸åŒæ—¶æœŸä½“ç°å‡ºä¸åŒçš„ç‰¹ç‚¹ï¼Œåªæœ‰å…·ä½“åˆ†æçŸ›ç›¾çš„ç‰¹æ®Šæ€§ï¼Œæ‰èƒ½è®¤æ¸…äº‹ç‰©çš„æœ¬è´¨ä¸å‘å±•è§„å¾‹ã€‚\nçŸ›ç›¾çš„æ™®éæ€§å’Œç‰¹æ®Šæ€§è¾©è¯ç»Ÿä¸€ä¹Ÿæ˜¯å…±æ€§ä¸ä¸ªæ€§çš„è¾©è¯ç»Ÿä¸€ï¼Œå…±æ€§å¯“äºä¸ªæ€§ä¹‹ä¸­ï¼Œä¸ªæ€§ä¹Ÿç¦»ä¸å¼€å…±æ€§ï¼Œä»»ä½•äº‹ç‰©éƒ½æ˜¯ä¸ªæ€§ä¸å…±æ€§çš„ç»Ÿä¸€ä½“ã€‚\nè¿™è¦æ±‚æˆ‘ä»¬æŒæ¡çŸ›ç›¾çš„æ™®éæ€§ä¸ç‰¹æ®Šæ€§çš„å…¶äºŒè€…çš„å…³ç³»ï¼Œæ›´å¥½çš„ç†è§£äº‹ç‰©çš„æœ¬è´¨ã€‚å–„ç”¨ â€œå› åœ°åˆ¶å®œâ€ çš„åŠæ³•æ­£æ˜¯ä½“ç°äº†å…·ä½“é—®é¢˜å…·ä½“åˆ†æçš„è¾©è¯æ€ç»´ã€‚\n\nï¼ˆ3ï¼‰ä»ç†è®ºåˆ›æ–°å’Œå®è·µåˆ›æ–°çš„è¾©è¯å…³ç³»è§’åº¦ï¼Œåˆ†æä¸ºä»€ä¹ˆè¦å°†å·²ç»åœ¨å®è·µä¸­å½¢æˆçš„æ–°è´¨ç”Ÿäº§åŠ› â€œä»ç†è®ºä¸Šè¿›è¡Œæ€»ç»“ã€æ¦‚æ‹¬ï¼Œç”¨ä»¥æŒ‡å¯¼æ–°çš„å‘å±•å®è·µâ€ã€‚\n\näººç±»çš„åˆ›æ–°æ´»åŠ¨ä¸»è¦ä½“ç°åœ¨ç†è®ºåˆ›æ–°å’Œå®è·µåˆ›æ–°ä¸¤ä¸ªæ–¹é¢ï¼Œå®è·µåˆ›æ–°ä¸ºç†è®ºåˆ›æ–°æä¾›äº†ä¸ç«­åŠ¨åŠ›ï¼Œç†è®ºåˆ›æ–°ä¸ºå®è·µåˆ›æ–°æä¾›äº†ç§‘å­¦çš„è¡ŒåŠ¨æŒ‡å—ï¼Œç†è®ºåˆ›æ–°ä¸å®è·µåˆ›æ–°äºŒè€…æ„æˆäº†æœ‰æœºçš„ç»Ÿä¸€ä½“ï¼Œæˆ‘ä»¬è¦åšæŒå°†ç†è®ºåˆ›æ–°ä¸å®è·µåˆ›æ–°ç›¸è”ç³»ã€‚\nç†è®ºä¸å®è·µç›¸ç»Ÿä¸€ï¼Œç†è®ºåˆ›æ–°ä¸ä»…è¦ä»¥å®è·µåˆ›æ–°ä¸ºåŸºç¡€ï¼Œè¿˜è¦ä»¥ç§‘å­¦çš„çŸ¥é“åå“ºå®è·µåˆ›æ–°ã€‚\n","categories":["political"],"tags":["æ”¿æ²»"]},{"title":"è®¡ç®—æœºä¸­çš„é™¤æ³•è¿ç®—","url":"/Principles-of-computer-composition/Division_in_Computers/","content":"# è®¡ç®—æœºä¸­çš„é™¤æ³•è¿ç®—\n# ç®€è¿°\nè®¡ç®—çš„ä¸­çš„é™¤æ³•ååˆ†æœ‰è¶£ã€‚å¯¹äº 6 ä¸ 4ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“çš„åˆ¤æ–­å‡ºé‚£ä¸ªå¤§ï¼Œè¿›è€Œè¿›è¡Œåç»­çš„é™¤æ³•è¿ç®—ï¼Œè€Œè®¡ç®—æœºä¸­å´ä¸æ˜¯ã€‚æ¯”æ­¤æ›´å¤æ‚çš„é™¤æ³•è¿ç®—ï¼Œåˆæ˜¯æ€ä¹ˆå®ç°çš„å‘¢ï¼Ÿ\n# æ–¹æ³•ä¸€ï¼šæ¢å¤ä½™æ•°æ³•\né¢˜ç›®æºè‡ªã€Šè®¡ç®—æœºç»„æˆåŸç†ï¼ˆç¬¬ä¸‰ç‰ˆï¼‰ã€‹ä¾‹ 6.24\n\n\n\n\nè¢«é™¤æ•°ï¼ˆä½™æ•°ï¼‰\nå•†\nè¯´æ˜\n\n\n\n\n0.1011+1.0011=1.1110\nã€0.0000ã€‘\nç¬¬ä¸€æ­¥æ— æ¡ä»¶ - y*\n\n\n1.1110+0.1101=0.1011\nã€0.0000ã€‘\n1.1110 å°äºé›¶ æ¢å¤ä½™æ•°\n\n\n1.0110\nã€0.000ã€‘0\nä¸Š 0 å·¦ç§» ï¼ˆè¡¥ä½æ¥è‡ªå•†ï¼‰\n\n\n1.0110+1.0011=0.1001\nã€0.000ã€‘0\n0.1001 å¤§äº 0 æ— éœ€æ¢å¤\n\n\n1.0010\nã€0.00ã€‘01\nä¸Š 1 å·¦ç§» ï¼ˆè¡¥ä½æ¥è‡ªå•†ï¼‰\n\n\n1.0010+1.0011=0.0101\nã€0.00ã€‘01\n0.0101 å¤§äº 0 æ— éœ€æ¢å¤\n\n\n0.1010\nã€0.0ã€‘011\nä¸Š 1 å·¦ç§» ï¼ˆè¡¥ä½æ¥è‡ªå•†ï¼‰\n\n\n0.1010+1.0011=1.1101\nã€0.0ã€‘011\n1.1101 å°äº 0 æ¢å¤ä½™æ•°\n\n\n1.1101+0.1101=0.1010\nã€0.0ã€‘011\n\n\n\n1.0100\nã€0ã€‘.0110\nä¸Š 0 å·¦ç§»ï¼ˆè¡¥ä½æ¥è‡ªå•†ï¼‰\n\n\n1.0100+1.0011=0.0111\nã€0ã€‘.0110\n0.0111 å¤§äºé›¶ æ— éœ€æ¢å¤\n\n\n0.0111\n0.1101\nä¸Š 1\n\n\n\nå€¼ï¼š0.1101\nç¬¦å·ä½ï¼š\n\næ¢å¤ä½™æ•°æ³•æ€»ç»“ï¼šé¦–å…ˆç¬¬ä¸€æ­¥æ— æ¡ä»¶åŠ  - y*ï¼Œç„¶åçœ‹ä½™æ•°å¤§äºé›¶è¿˜æ˜¯å°äº 0ï¼Œå¦‚æœå¤§äº 0 æ— éœ€æ¢å¤ ä¸Š 1 å·¦ç§»ï¼Œå¦‚æœå°äº 0 éœ€è¦æ¢å¤ ä¸Š 0 å·¦ç§»ï¼Œå¦‚æ­¤å¾ªç¯å¾€å¤ï¼Œç›´åˆ°ç”¨å®Œæ‰€æœ‰çš„å•†ä½ã€‚\n# æ–¹æ³•äºŒï¼šåŠ å‡äº¤æ›¿æ³•\nåŠ å‡äº¤æ›¿æ³•å¯ä»¥è¯´æ˜¯æ¢å¤ä½™æ•°çš„æ”¹è‰¯æ–¹æ³•ï¼Œæˆ‘ä»¬æ— éœ€æ¢å¤ ç›´æ¥è¿›è¡Œè¿ç®—ï¼Œè¯¦æƒ…è§ä¸‹é¢˜ï¼š\né¢˜ç›®æºè‡ªã€Šè®¡ç®—æœºç»„æˆåŸç†ï¼ˆç¬¬ä¸‰ç‰ˆï¼‰ã€‹ä¾‹ 6.25\n\n\n\n\nè¢«é™¤æ•°ï¼ˆä½™æ•°ï¼‰\nå•†\nè¯´æ˜\n\n\n\n\n0.1011+1.0011=1.1110\nã€0.0000ã€‘\næ— æ¡ä»¶åŠ  - y*\n\n\n1.1100\nã€0.000ã€‘0\n1.1110 å°äº 0 ä¸Š 0 å·¦ç§»\n\n\n1.1100+0.1101=0.1001\n\n\n\n\n1.0010\nã€0.00ã€‘01\n0.1001 å¤§äº 0 ä¸Š 1 å·¦ç§»\n\n\n1.0010+1.0011=0.0101\n\n\n\n\n0.1010\nã€0.0ã€‘011\n0.0101 å¤§äº 0 ä¸Š 1 å·¦ç§»\n\n\n0.1010+1.0011=1.1101\n\n\n\n\n1.1010\nã€0ã€‘.0110\n1.1101 å°äº 0 ä¸Š 0 å·¦ç§»\n\n\n1.1010+0.1101=0.0111\n\n\n\n\n0.0111\n0.1101\n0.0111 å¤§äº 0 ä¸Š 1\n\n\n\næ ¸å¿ƒï¼šä¸Š 0 åŠ æ­£ï¼Œä¸Š 1 åŠ è´Ÿï¼Œæ­¤å£è¯€ä¸ºä¸Šä¸€æ­¥ä¸Šçš„ 0 æˆ– 1 åœ¨ä¸‹ä¸€æ­¥ä½“ç°ï¼Œå¦‚æœä¸Šäº† 0 é‚£ä¹ˆä¸‹ä¸€æ­¥å°±åŠ æ­£ï¼Œå¦‚æœä¸Šäº† 1 é‚£ä¹ˆä¸‹ä¸€æ­¥å°±åŠ è´Ÿã€‚é‚£ä¹ˆæˆ‘ä»¬æ€ä¹ˆçŸ¥é“åˆ°åº•æ˜¯ä¸Š 0 è¿˜æ˜¯ 1 å‘¢ï¼Ÿè¿™ä¸ªä¸»è¦çœ‹ä½™æ•°ï¼Œå¦‚æœå®ƒæ˜¯æ­£çš„å°±ä¸Š 1ï¼Œå¦‚æœä»–æ˜¯è´Ÿçš„å°±ä¸Š 0\n","categories":["è®¡ç®—æœºç»„æˆåŸç†"],"tags":["è®¡ç®—æœºç»„æˆåŸç†"]},{"title":"boothç®—æ³•","url":"/Principles-of-computer-composition/booth_algorithm/","content":"# Booth ç®—æ³•\nè¿™é‡Œå†™ç‚¹ä»€ä¹ˆæï¼Ÿå°±å…ˆæ¥ç‚¹ç®€ä»‹å§ï¼ï¼æ¯”è¾ƒæ³•æ˜¯ Booth å¤«å¦‡å…ˆæå‡ºæ¥çš„ï¼Œä¹Ÿç§° booth ç®—æ³•ã€‚\né‚£ä¹ˆï¼ï¼å’±ä»¬æ€ä¹ˆè§£é¢˜å‘¢ï¼Œä¸è¦æ‹…å¿ƒï¼Œå…¶å® booth ç®—æ³•éå¸¸ç®€å•ï¼Œä¸è¦è¢«é•¿é•¿çš„ç®—å¼æ‰€è¿·æƒ‘é¸­ï¼ï¼\næ¥ä¸‹æ¥å°±ç”±æˆ‘æ¥ç®€å•å¿«é€Ÿçš„å™è¿°ä¸€ä¸‹å¦‚ä½•åˆ©ç”¨ booth ç®—æ³•å»åšé¢˜ï¼\n# å‡†å¤‡å¼€å§‹ï¼\né¦–å…ˆé¢˜ç›®é‡Œä¸€èˆ¬ä¼šè¿™æ ·ç»™ï¼šå·²çŸ¥ [x] è¡¥ = xxxxxï¼Œ[y] è¡¥ = xxxxxï¼Œåˆ©ç”¨ booth ç®—æ³•æ±‚è§£ [x*y]ã€‚\nbooth ç®—æ³•çš„ç¬¦å·ä½æ˜¯æˆåŒæˆå¯¹çš„ï¼Œå’Œä½ ä¸ä¸€æ ·ï¼Œå› ä¸ºä½ è¿˜æ²¡æœ‰æˆåŒæˆå¯¹å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆï¼ˆä¸æ˜¯ï¼‰\nå¦å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é¢å¤–è®°ä½çš„å››ä¸ªå›ºå®šå½¢æ€ï¼š\n\n\n\nå°¾æ•°å½¢æ€\nä½œæ³•\n\n\n\n\n00\nå³ç§»ä¸€ä½\n\n\n01\n+[x] è¡¥ å å³ç§»ä¸€ä½\n\n\n10\n+[-x] è¡¥å å³ç§»ä¸€ä½\n\n\n11\nå³ç§»ä¸€ä½\n\n\n\n# ä¾‹é¢˜ä¸€\nå·²çŸ¥ [x] è¡¥ = 0.0101ï¼Œ[y] è¡¥ = 1.0101ï¼Œåˆ©ç”¨ booth ç®—æ³•æ±‚è§£ [x*y]\nåšé¢˜å‰æˆ‘ä»¬éœ€è¦åšä¸€äº›å‡†å¤‡ï¼Œé¦–å…ˆæˆ‘ä»¬å†™å‡ºåŒç¬¦å·ä½å½¢æ€çš„ [x] è¡¥ã€[-x] è¡¥ä»¥åŠ [y] è¡¥ï¼ˆæ— éœ€åŒç¬¦å·ï¼‰\n\n\n[x] è¡¥ = 00.0101\n\n\n[-x] è¡¥ = 11.1011\n\n\n[y] è¡¥ = 1.0101\n\n\nç„¶ååˆ—å‡ºå¦‚ä¸‹è¡¨æ ¼ï¼š\n\n\n\néƒ¨åˆ†ç§¯\nä¹˜æ•°\nè¾…åŠ©\n\n\n\n\n\n\n0\n\n\n\næˆ‘å…ˆå†™åˆ°è¿™ï¼Œå¦‚æœæœ‰æƒ³å…ˆè¯•è¯•çš„å°ä¼™ä¼´å¯ä»¥å…ˆæŒ‰ç…§è‡ªå·±çš„æ€è·¯å»å†™ï¼Œè¿˜æ²¡è®°èµ·æ¥çš„çš„å°ä¼™ä¼´ä»¬å¯ä»¥ç»§ç»­å¾€ä¸‹çœ‹ï¼Œä¸€ä¼šæˆ‘è¿˜ä¼šå†™å‡ºä¸¤é“ä¾‹é¢˜ä¾›å¤§å®¶å»ç»ƒä¹ ã€‚\nè§£ç­”å¼€å§‹ï¼\nè¾…åŠ©ä½ç½®é»˜è®¤ä¸º 0ï¼Œä¹˜æ•°å°±æ˜¯ [y] è¡¥ = 11.0101ï¼Œéƒ¨åˆ†ç§¯åˆå§‹å€¼ä¹Ÿä¸º 0.\n\n\n\n\néƒ¨åˆ†ç§¯\nä¹˜æ•°\nè¾…åŠ©\n\n\n\n\n\n\n00 0000\n1010 1\n0\nä¸€æ¬¡åˆ¤æ–­\n\n\n10 è¿˜è®°å¾—åŠ ä»€ä¹ˆå˜›ï¼Ÿæ²¡é”™å°±æ˜¯åŠ  [-x] è¡¥ +\n11 1011\n\n\n\n\n\n=\n11 1011\n\n\n\n\n\nå³ç§»\n11 1101\n1101 0\n1\näºŒæ¬¡åˆ¤æ–­\n\n\n01 è¿˜è®°å¾—åŠ ä»€ä¹ˆå˜›ï¼Ÿæ²¡é”™å°±æ˜¯åŠ  [x] è¡¥ +\n00 0101\n\n\n\n\n\n=\n00 0010\n\n\n\n\n\nå³ç§»\n00 0001\n0110 1\n0\nä¸‰æ¬¡åˆ¤æ–­\n\n\n10 è¿˜è®°å¾—åŠ ä»€ä¹ˆå˜›ï¼Ÿæ²¡é”™å°±æ˜¯åŠ  [-x] è¡¥ +\n11 1011\n\n\n\n\n\n=\n11 1100\n\n\n\n\n\nå³ç§»\n11 1110\n0011 0\n1\nå››æ¬¡åˆ¤æ–­\n\n\n01 è¿˜è®°å¾—åŠ ä»€ä¹ˆå˜›ï¼Ÿæ²¡é”™å°±æ˜¯åŠ  [x] è¡¥ +\n00 0101\n\n\n\n\n\n=\n00 0011\n\n\n\n\n\nå³ç§»\n00 0001\n1001 1\n0\näº”æ¬¡åˆ¤æ–­\n\n\n10 è¿˜è®°å¾—åŠ ä»€ä¹ˆå˜›ï¼Ÿæ²¡é”™å°±æ˜¯åŠ  [-x] è¡¥ +\n11 1011\n\n\n\n\n\n\n11 1100\n\n\n\n\n\n\nOK å…„å¼Ÿä»¬ï¼Œå°æ•°ç‚¹åæœ‰å››ä½ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦è¿›è¡Œäº”æ¬¡åˆ¤æ–­ï¼Œç°åœ¨å·²ç»å®Œæˆè®¡ç®—è¿‡ç¨‹äº†ï¼Œç­”æ¡ˆå·²ç»å‘¼ä¹‹æ¬²å‡ºäº†ï¼ï¼\n[x*y] = 1.1100 1001ï¼ˆå¦‚æœè¦åŒç¬¦å·ä¸ºå°±è¿™æ ·å»å†™ï¼š[x*y] = 11.1100 1001ï¼‰\næ€»ç»“ä¸€ä¸‹ï¼Œè¾…åŠ©ä½é…åˆä¹˜æ•°æœ€åä¸€ä½ä½œåˆ¤æ–­æ“ä½œï¼Œ00 å’Œ 11 åªéœ€å³ç§»å°±å¥½ï¼Œè€Œ 01 è¦ +[x] è¡¥ï¼Œ11 è¦ +[-x] è¡¥ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½å¾—åˆ°æœ€ç»ˆçš„ç»“æœäº†ã€‚\næ¥ä¸‹æ¥å†æ¥ä¸€é“çˆ½é¢˜ï¼ï¼ï¼\n# ä¾‹é¢˜äºŒ\nå·²çŸ¥ [x] è¡¥ = 1.0101ï¼Œ[y] è¡¥ = 1.0011ï¼Œåˆ©ç”¨ booth ç®—æ³•æ±‚è§£ [x*y]\nè€è§„çŸ©ï¼š\n\n[x] è¡¥ = 11.0101\n[-x] è¡¥ = 00.1011\n[y] è¡¥ = 1.0011\n\nåˆ—è¡¨ï¼š\n\n\n\n\néƒ¨åˆ†ç§¯\nä¹˜æ•°\nè¾…åŠ©\n\n\n\n\n\n\n00 0000\n10011\n0\nä¸€æ¬¡åˆ¤æ–­\n\n\n10 +\n00 1011\n\n\n\n\n\n=\n00 1011\n\n\n\n\n\nå³ç§»\n00 0101\n1100 1\n1\näºŒæ¬¡åˆ¤æ–­\n\n\n11 å³ç§»\n00 0010\n1110 0\n1\nä¸‰æ¬¡åˆ¤æ–­\n\n\n01 +\n11 0101\n\n\n\n\n\n=\n11 0111\n\n\n\n\n\nå³ç§»\n11 1011\n1111 0\n0\nå››æ¬¡åˆ¤æ–­\n\n\n00 å³ç§»\n11 1101\n1111 1\n0\näº”æ¬¡åˆ¤æ–­\n\n\n10 +\n00 1011\n\n\n\n\n\n\n00 1000\n\n\n\n\n\n\nç¬¬äº”æ¬¡åˆ¤æ–­åæ— éœ€ç§»åŠ¨\nç­”æ¡ˆï¼š0.1000 1111\næ€ä¹ˆæ ·ï¼Œæ˜¯ä¸æ˜¯éå¸¸çˆ½ï¼Œåœ¨äº”æ¬¡åˆ¤æ–­ä¸­å‡ºç°äº†ä¸¤æ¬¡æ•°å­—ç›¸åŒçš„æƒ…å†µï¼Œè¿™æ—¶å€™æˆ‘ä»¬åªéœ€è¦è¿›è¡Œå³ç§»ï¼Œæ— éœ€è¿›è¡Œè®¡ç®—ã€‚\næœ€åæˆ‘åœ¨ç»™å¤§å®¶ä¸€é“ç»ƒä¹ é¢˜ï¼Œè‡ªå·±ç»ƒä¹ ä¸€ä¸‹å­ï½ï½ï½\n# ç»ƒä¹ \nå·²çŸ¥ [x] è¡¥ = 0.1101ï¼Œ[y] è¡¥ = 0.1011ï¼Œåˆ©ç”¨ booth ç®—æ³•æ±‚è§£ [x*y]\n\n\n\néƒ¨åˆ†ç§¯\nä¹˜æ•°\nè¾…åŠ©\n\n\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n# é¸£è°¢\næ„Ÿè°¢ B ç«™ up ä¸»åˆ¶ä½œçš„è§†é¢‘ï¼ŒçœŸçš„éå¸¸ä¸é”™\n","categories":["è®¡ç®—æœºç»„æˆåŸç†"],"tags":["è®¡ç®—æœºç»„æˆåŸç†"]},{"title":"åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ç®—æ³•","url":"/experience/CollaborativeFiltering/","content":"# åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ç®—æ³•\næœ¬ç¯‡æ–‡æ¡£å°†ä¼šç”¨é€šä¿—æ˜“æ‡‚çš„æ–¹å¼å¸¦ä½ æ¥äº†è§£å¹¶å®ç°åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ç®—æ³•ï¼Œä¸å†åŸºäºç‰¹å®šå¼€æºåº“ï¼Œä½¿ç”¨åŸç”Ÿä»£ç å®ŒæˆååŒè¿‡æ»¤çš„æ„å»ºï¼Œå®é™…ä¸Šï¼ŒåŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤å¾ˆç®€å•ï¼Œåªéœ€è¦å¼„æ‡‚é‚£å‡ ä¸ªå…¬å¼æ˜¯æ€ä¹ˆç”¨çš„å°±å¥½äº†ï¼ŒçœŸæ­£çš„éš¾ç‚¹æ˜¯å…¬å¼çš„æå‡ºä¸è¯æ˜ï¼Œä¸è¿‡å‘¢ä»Šå¤©æˆ‘ä¸æƒ³è®²ç›¸å…³çš„è¯æ˜äº†ã€‚\næœ¬ç¯‡æ–‡ç« ä¸»è¦æ˜¯å¸¦ä½ æ‰“å¼€ååŒè¿‡æ»¤çš„å¤§é—¨ï¼Œæˆ‘åªæ˜¯æƒ³å‘Šè¯‰ä½ ï¼Œä½œä¸ºäººçš„ä½ æˆ‘å…·æœ‰ä¸æ–­è®¤è¯†çš„èƒ½åŠ›ï¼Œä¸”åœ¨è®¤è¯†ä¸­ä¸æ–­æ¶ˆé™¤è°¬è¯¯ï¼Œå¹¶æ— é™è¶‹è¿‘äºçœŸç†ï¼Œæˆ‘ä»¬æœ‰èƒ½åŠ›ä¹Ÿå¿…å°†è®¤è¯†è¿™ä¸ªä¸–ç•Œï¼Œè€ŒååŒè¿‡æ»¤æ­£æ˜¯å…¶ä¸­ä¹‹ä¸€ï¼Œç©¶å…¶æœ¬è´¨å¹¶ä¸å¤æ‚ã€‚\né‚£ä¹ˆè¯·åå¥½ï¼ŒååŒè¿‡æ»¤çš„åˆ—è½¦è¦å‘è½¦å•¦ï¼\n# ç®—æ³•ä»‹ç»\nåŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ï¼Œå®é™…ä¸Šå°±æ˜¯æ‰¾ä¸ç›®æ ‡ç”¨æˆ·æœ€ä¸ºç›¸ä¼¼çš„ä¸€ä¸ªæˆ–å¤šä¸ªç”¨æˆ·ï¼Œè¿™é‡Œçš„ç›®æ ‡ç”¨æˆ·å®é™…ä¸Šå°±æ˜¯æˆ‘ä»¬è¦ä¸ºå…¶è¿›è¡Œä¿¡æ¯æ¨é€çš„ç”¨æˆ·ã€‚å‡å¦‚ç‘ç‘å–œæ¬¢ A å’Œ Bï¼Œé¸­é¸­å–œæ¬¢ Aã€B å’Œ Cï¼Œä»–ä»¬éƒ½å¯¹å–œæ¬¢çš„å•†å“ç»™äºˆè¾ƒé«˜çš„è¯„ä»·ï¼Œå˜å˜éå¸¸è®¨åŒ A å’Œ Bï¼Œä½†æ˜¯é’Ÿçˆ± Dã€‚\né‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¼¼ä¹é¸­é¸­çš„ A å’Œ B ä¸ç‘ç‘çš„ A å’Œ B æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯é¸­é¸­ä¹°è¿‡ C è€Œç‘ç‘æ²¡æœ‰ä¹°è¿‡ Cï¼Œç‘ç‘å’Œé¸­é¸­æ˜¯é«˜åº¦ç›¸ä¼¼çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥ç»™ç‘ç‘æ¨èé¸­é¸­å–œæ¬¢çš„ Cï¼Œæˆ–è®¸ç‘ç‘ä¹Ÿå–œæ¬¢å‘¢ï¼\nè€Œå¯¹äºå˜å˜æ¥è¯´ç‘ç‘å–œæ¬¢çš„ A å’Œ B æ­£æ˜¯å˜å˜ä»–æ‰€è®¨åŒçš„ï¼Œè€Œå˜å˜å¯¹ D æƒ…æœ‰ç‹¬é’Ÿï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£åˆ°ï¼Œç‘ç‘æˆ–è®¸æ˜¯è®¨åŒå˜å˜æ‰€å–œæ¬¢çš„ï¼Œé‚£ä¹ˆå˜å˜å’Œç‘ç‘æ˜¯ä½ç›¸ä¼¼çš„ï¼Œå˜å˜å–œæ¬¢çš„ D ä¹Ÿè®¸ä¸åº”è¯¥ç»™ç‘ç‘æ¨èï¼\n\n# è®¡ç®—ç”¨æˆ·é—´çš„ç›¸ä¼¼åº¦\n# Jaccard ç›¸ä¼¼ç³»æ•°\nJaccard ç›¸ä¼¼ç³»æ•°ä¸»è¦æ˜¯è¡¡é‡ä¸¤ä¸ªé›†åˆçš„ç›¸ä¼¼åº¦ J (A,B) æ˜¯å®ƒçš„æ•°å­¦è¡¨è¾¾\nJ(A,B)=âˆ£Aâˆ©Bâˆ£âˆ£AâˆªBâˆ£\\begin {array}{c}\nJ(A,B)=\\frac{\\left | A\\cap B \\right | }{\\left | A\\cup  B \\right |}\n\\end {array}\nJ(A,B)=âˆ£AâˆªBâˆ£âˆ£Aâˆ©Bâˆ£â€‹â€‹\nJaccard ç›¸ä¼¼ç³»æ•°ç‰¹åˆ«é€‚ç”¨äºå¤„ç†äºŒå€¼æ•°æ®ï¼ˆå³åªæœ‰ä¸¤ä¸ªå€¼ï¼š0 æˆ– 1ï¼‰ã€‚ä¾‹å¦‚ï¼Œåœ¨æ–‡æœ¬å¤„ç†ä¸­ï¼Œå¯ä»¥é€šè¿‡æ˜¯å¦åŒ…å«æŸä¸ªè¯æ¥è¡¨ç¤ºæ–‡æ¡£ä¸­çš„è¯æ±‡å‡ºç°ä¸å¦ï¼Œè¿™ç§æƒ…å†µä¸‹ Jaccard ç›¸ä¼¼ç³»æ•°éå¸¸æœ‰æ•ˆã€‚ç„¶è€Œ Jaccard ç›¸ä¼¼åº¦ä¸è€ƒè™‘å…ƒç´ çš„æƒé‡æˆ–é¢‘ç‡ã€‚å¦‚æœä¸¤ä¸ªé›†åˆä¸­æœ‰çš„å…ƒç´ å‡ºç°é¢‘ç‡è¾ƒé«˜ï¼Œè€Œæœ‰çš„é¢‘ç‡è¾ƒä½ï¼ŒJaccard ç›¸ä¼¼åº¦ä¼šå°†è¿™äº›å…ƒç´ è§†ä¸ºç­‰ä»·ï¼Œä¸é€‚ç”¨äºéœ€è¦è€ƒè™‘å…ƒç´ é‡è¦æ€§çš„åœºæ™¯ã€‚\n# ä½™å¼¦ç›¸ä¼¼åº¦\nä½™å¼¦ç›¸ä¼¼åº¦æ˜¯ n ç»´ç©ºé—´ä¸­ä¸¤ä¸ª n ç»´å‘é‡ä¹‹é—´è§’åº¦çš„ä½™å¼¦ã€‚å®ƒç­‰äºä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯ï¼ˆå‘é‡ç§¯ï¼‰é™¤ä»¥ä¸¤ä¸ªå‘é‡é•¿åº¦ï¼ˆæˆ–å¤§å°ï¼‰çš„ä¹˜ç§¯ã€‚\nsim(A,B)=Aâ‹…Bâˆ£âˆ£Aâˆ£âˆ£Ã—âˆ£âˆ£Bâˆ£âˆ£=âˆ‘i=1n(AiÃ—Bi)âˆ‘i=1nAi2Ã—âˆ‘i=1nBi2sim(A,B)=\\frac{AÂ·B}{\\left | \\left | A \\right |  \\right | \\times \\left | \\left | B \\right |  \\right | } =\\frac{\\sum_{i=1}^{n}(A_{i}\\times B_{}i)}{\\sqrt{\\sum_{i=1}^{n}A_{i}^{2} } \\times \\sqrt{\\sum_{i=1}^{n}B_{i}^{2} }} \nsim(A,B)=âˆ£âˆ£Aâˆ£âˆ£Ã—âˆ£âˆ£Bâˆ£âˆ£Aâ‹…Bâ€‹=âˆ‘i=1nâ€‹Ai2â€‹â€‹Ã—âˆ‘i=1nâ€‹Bi2â€‹â€‹âˆ‘i=1nâ€‹(Aiâ€‹Ã—Bâ€‹i)â€‹\nsim(A,B)sim(A,B)sim(A,B) æ˜¯æœ‰å–å€¼èŒƒå›´çš„ï¼Œåœ¨[âˆ’1,1][-1,1][âˆ’1,1] ä¹‹é—´ï¼Œ1 æ˜¯å®Œå…¨ç›¸ä¼¼ï¼Œ-1 æ˜¯å®Œå…¨ä¸ç›¸ä¼¼ï¼Œä½™å¼¦ç›¸ä¼¼åº¦çš„è®¡ç®—å…¬å¼ç®€å•ï¼Œé€šå¸¸åªæ¶‰åŠå‘é‡çš„ç‚¹ç§¯å’Œæ¨¡é•¿çš„è¿ç®—ï¼Œå› æ­¤åœ¨å®é™…åº”ç”¨ä¸­è®¡ç®—é€Ÿåº¦è¾ƒå¿«ã€‚\n# çš®å°”é€Šç›¸å…³ç³»æ•°\nçš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œä¹Ÿç§°ä¸ºçš®å°”é€Šç§¯çŸ©ç›¸å…³ç³»æ•°ï¼Œæ˜¯è¡¡é‡ä¸¤ä¸ªå˜é‡ä¹‹é—´çº¿æ€§å…³ç³»çš„å¼ºåº¦å’Œæ–¹å‘çš„ç»Ÿè®¡é‡ã€‚å…¶å€¼èŒƒå›´ä» - 1 åˆ° + 1ï¼Œå¹¿æ³›åº”ç”¨äºç»Ÿè®¡å­¦ã€æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ ç­‰é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨è¡¡é‡å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§æ—¶ã€‚\næ ‡å‡†å·®ï¼š\nS=âˆ‘i=1n(Xiâˆ’Xâ€¾)2Nâˆ’1S=\\sqrt{\\frac{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^2}{N-1}}\nS=Nâˆ’1âˆ‘i=1nâ€‹(Xiâ€‹âˆ’X)2â€‹â€‹\nNNN æ˜¯æ•°æ®æ€»é‡ï¼ŒXâ€¾\\overline{X}X æ˜¯å¹³å‡å€¼ã€‚\nåæ–¹å·®ï¼š\nCov(X,Y)=âˆ‘i=1n(Xiâˆ’Xâ€¾)(Yiâˆ’Yâ€¾)Nâˆ’1Cov(X,Y)=\\frac{\\sum_{i=1}^{n}(X_{i}-\\overline{X})(Y_{i}-\\overline{Y}) }{N-1}\nCov(X,Y)=Nâˆ’1âˆ‘i=1nâ€‹(Xiâ€‹âˆ’X)(Yiâ€‹âˆ’Y)â€‹\nçš®å°”é€Šç›¸å…³ç³»æ•°\nÏ=Cov(X,Y)SxSy\\rho =\\frac{Cov(X,Y)}{S_{x}S_{y}}\nÏ=Sxâ€‹Syâ€‹Cov(X,Y)â€‹\nSxS_{x}Sxâ€‹ æ˜¯ X çš„æ ‡å‡†å·®ã€‚åŒæ ·ä»–æ˜¯æœ‰å–å€¼èŒƒå›´çš„ï¼Œåœ¨[âˆ’1,1][-1,1][âˆ’1,1] ä¹‹é—´ï¼Œ1 æ˜¯å®Œå…¨ç›¸ä¼¼ï¼Œ-1 æ˜¯å®Œå…¨ä¸ç›¸ä¼¼\nçš®å°”é€Šç›¸å…³ç³»æ•°çš„è®¡ç®—å…¬å¼ç›¸å¯¹ç®€å•ï¼Œå®¹æ˜“ç†è§£ï¼Œä¸”å…¶å€¼çš„æ„ä¹‰éå¸¸ç›´è§‚ï¼Œå¯ä»¥æ¸…æ¥šåœ°è¡¨ç¤ºå˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»å¼ºåº¦å’Œæ–¹å‘ã€‚ å®ƒä¸ä»…è¡¡é‡äº†ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„åæ–¹å·®ï¼Œè¿˜è€ƒè™‘äº†å˜é‡çš„æ ‡å‡†å·®ï¼Œå› æ­¤èƒ½å¤Ÿå½’ä¸€åŒ–åæ–¹å·®ï¼Œä½¿å¾—ç›¸å…³ç³»æ•°çš„å€¼ç‹¬ç«‹äºå˜é‡çš„å°ºåº¦ã€‚\n# åº”ç”¨ç¤ºä¾‹\n\n\n\nç”¨æˆ· - å•†å“è¯„åˆ†è¡¨\nç”¨æˆ· 1001\nç”¨æˆ· 1002\nç”¨æˆ· 1003\nç”¨æˆ· 1004\nç”¨æˆ· 1005\n\n\n\n\nå•†å“ 1\n5\n4\n5\n4\n5\n\n\nå•†å“ 2\n4\n3\n4\n4\n4\n\n\nå•†å“ 3\n5\n2\n5\n3\n5\n\n\nå•†å“ 4\n4\n2\n4\n4\n3\n\n\n\nè¿™ä¸ªæ—¶å€™æˆ‘ä»¬è¦æ‰¾ä¸ç”¨æˆ· 1003 æœ€ç›¸ä¼¼çš„ç”¨æˆ·ï¼Œå¯è§ 1003 ç»™å‡ºäº†ï¼ˆ5ï¼Œ4ï¼Œ5ï¼Œ4ï¼‰çš„è¯„åˆ†å‘é‡ï¼Œè¿™ä¸ç”¨æˆ· 1001 çš„ï¼ˆ5ï¼Œ4ï¼Œ5ï¼Œ4ï¼‰è¯„åˆ†å‘é‡å®Œå…¨ä¸€è‡´ï¼Œç”¨æˆ· 1003 ä¸ç”¨æˆ· 1001 é«˜åº¦ç›¸ä¼¼ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ç”¨æˆ· 1005 ç»™å‡ºäº†ï¼ˆ5ï¼Œ4ï¼Œ5ï¼Œ3ï¼‰çš„è¯„åˆ†å‘é‡ï¼Œè¿™ä¹Ÿä¸ç”¨æˆ· 1003 é«˜åº¦ç›¸ä¼¼ã€‚\nè¿™äº›éƒ½æ˜¯æ˜¾ç„¶çš„ï¼Œä½†æ˜¯è®¡ç®—æœºæ€ä¹ˆèƒ½çŸ¥é“å‘¢ï¼Ÿæœ¬ç¯‡æ–‡ç« é‡‡ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°å®ŒæˆååŒè¿‡æ»¤ã€‚\n# è®¡ç®—æ ‡å‡†å·®\ndouble standardDeviationCalculations(int[] ratings) &#123;    double std = 0;        // æ ‡å‡†å·®    double avarage = 0;    // å¹³å‡å€¼    int sum = 0;           // è¯„åˆ†å’Œ    double varianceUP = 0; // æ–¹å·®åˆ†å­    double variance = 0; // æ–¹å·®    for (int i = 0; i &lt; ratings.length; i++) &#123;        sum += ratings[i];    &#125;    avarage = (double) sum / ratings.length;    for (int i = 0; i &lt; 4; i++) &#123; // æ–¹å·®åˆ†å­        varianceUP += Math.pow(ratings[i] - avarage, 2);    &#125;    variance = varianceUP / (ratings.length - 1);    std = Math.sqrt(variance);    return std;&#125;# è®¡ç®—åæ–¹å·®\ndouble covarianceCalculation(int[] X, int[] Y) &#123;    double covariance = 0;       // åæ–¹å·®    double avarageX = 0;         // å¹³å‡å€¼ X    double avarageY = 0;         // å¹³å‡å€¼ Y    for (int i = 0; i &lt; X.length; i++) &#123;        avarageX += X[i];    &#125;    avarageX = avarageX / X.length;    for (int i = 0; i &lt; Y.length; i++) &#123;        avarageY += Y[i];    &#125;    avarageY = avarageY / Y.length;    for (int i = 0; i &lt; X.length; i++) &#123;        covariance += (X[i] - avarageX) * (Y[i] - avarageY);    &#125;    covariance = covariance / (X.length - 1);    return covariance;&#125;# è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°\ndouble pearsonCorrelationCoefficient(double covarianceXY, double stdX, double stdY) &#123;    return covarianceXY / (stdX * stdY);&#125;# è°ƒç”¨\npublic class SuiBianTest &#123;    double standardDeviationCalculations(int[] ratings) &#123;        double std = 0;        // æ ‡å‡†å·®        double avarage = 0;    // å¹³å‡å€¼        int sum = 0;           // è¯„åˆ†å’Œ        double varianceUP = 0; // æ–¹å·®åˆ†å­        double variance = 0; // æ–¹å·®        for (int i = 0; i &lt; ratings.length; i++) &#123;            sum += ratings[i];        &#125;        avarage = (double) sum / ratings.length;        for (int i = 0; i &lt; 4; i++) &#123; // æ–¹å·®åˆ†å­            varianceUP += Math.pow(ratings[i] - avarage, 2);        &#125;        variance = varianceUP / (ratings.length - 1);        std = Math.sqrt(variance);        return std;    &#125;    double covarianceCalculation(int[] X, int[] Y) &#123;        double covariance = 0;       // åæ–¹å·®        double avarageX = 0;         // å¹³å‡å€¼ X        double avarageY = 0;         // å¹³å‡å€¼ Y        for (int i = 0; i &lt; X.length; i++) &#123;            avarageX += X[i];        &#125;        avarageX = avarageX / X.length;        for (int i = 0; i &lt; Y.length; i++) &#123;            avarageY += Y[i];        &#125;        avarageY = avarageY / Y.length;        for (int i = 0; i &lt; X.length; i++) &#123;            covariance += (X[i] - avarageX) * (Y[i] - avarageY);        &#125;        covariance = covariance / (X.length - 1);        return covariance;    &#125;    double pearsonCorrelationCoefficient(double covarianceXY, double stdX, double stdY) &#123;        return covarianceXY / (stdX * stdY);    &#125;    @Test    public void testCollaborativeFiltering() &#123;        int[][] ratings_1_5 = &#123;                &#123;5, 4, 5, 4&#125;,       //1001 å¯¹å•†å“ 1ã€2ã€3ã€4 çš„è¯„åˆ†                &#123;4, 3, 2, 2&#125;,       //1002 å¯¹å•†å“ 1ã€2ã€3ã€4 çš„è¯„åˆ†                &#123;5, 4, 5, 4&#125;,       //1003 å¯¹å•†å“ 1ã€2ã€3ã€4 çš„è¯„åˆ†                &#123;4, 4, 2, 4&#125;,       //1004 å¯¹å•†å“ 1ã€2ã€3ã€4 çš„è¯„åˆ†                &#123;5, 4, 5, 3&#125;,       //1005 å¯¹å•†å“ 1ã€2ã€3ã€4 çš„è¯„åˆ†        &#125;;        //--------------------- è®¡ç®—æ–¹å·® -----------------        ArrayList&lt;Double> stdVector = new ArrayList&lt;>();    // æ–¹å·®å‘é‡        for (int i = 0; i &lt; ratings_1_5.length; i++) &#123;            stdVector.add(standardDeviationCalculations(ratings_1_5[i]));        &#125;        System.out.println(\"æ–¹å·®å‘é‡ï¼š\" + stdVector);        //---------------- åæ–¹å·®è®¡ç®— cov (X,Y)------------        ArrayList&lt;Double> covarianceVector = new ArrayList&lt;>(); // åæ–¹å·®å‘é‡        for (int i = 0; i &lt; ratings_1_5.length; i++) &#123;            covarianceVector.add(covarianceCalculation(ratings_1_5[2], ratings_1_5[i]));        &#125;        System.out.println(\"åæ–¹å·®å‘é‡ï¼š\" + covarianceVector);        //-------------- çš®å°”é€Šç›¸å…³ç³»æ•° ----------------        ArrayList&lt;Double> pearsonVector = new ArrayList&lt;>();    // çš®å°”é€Šç›¸å…³ç³»æ•°å‘é‡        for (int i = 0; i &lt; ratings_1_5.length; i++) &#123;            pearsonVector.add(pearsonCorrelationCoefficient(covarianceVector.get(i), stdVector.get(2), stdVector.get(i)));        &#125;        System.out.println(\"çš®å°”é€Šç›¸å…³ç³»æ•°å‘é‡ï¼š\" + pearsonVector);        System.out.println(\"----------------------------\");        HashMap&lt;String, Double> map = new HashMap&lt;>();        map.put(\"1001\", pearsonVector.get(0));        map.put(\"1002\", pearsonVector.get(1));//        map.put(\"1003\", pearsonVector.get(2));        map.put(\"1004\", pearsonVector.get(3));        map.put(\"1005\", pearsonVector.get(4));        // ä½¿ç”¨ Stream API è·å–æœ€å¤§çš„ä¸¤ä¸ªå€¼åŠå®ƒä»¬å¯¹åº”çš„é”®        List&lt;Map.Entry&lt;String, Double>> topTwoEntries = map.entrySet()                .stream()                .sorted(Map.Entry.&lt;String, Double>comparingByValue().reversed()) // æŒ‰ç…§ value é™åºæ’åº                .limit(2) // åªå–å‰ä¸¤é¡¹                .toList();        // è¾“å‡ºç»“æœ        topTwoEntries.forEach(entry ->                System.out.println(\"æœ€å¤§çš®å°”é€Šç›¸å…³ç³»æ•°ä¹‹ä¸€å¯¹åº”çš„é”®ï¼š\" + entry.getKey() + \"ï¼Œå€¼ä¸ºï¼š\" + entry.getValue())        );        if (topTwoEntries.size() &lt; 2) &#123;            System.out.println(\"æ³¨æ„ï¼šMapä¸­çš„å…ƒç´ ä¸è¶³ä¸¤ä¸ª\");        &#125;    &#125;&#125;# è¾“å‡º\n\n# åç»­\næ­¤æ—¶æˆ‘ä»¬å·²ç»æ‰¾åˆ°äº†ï¼Œä¸ç”¨æˆ· 1003 æœ€ä¸ºç›¸ä¼¼çš„ä¸¤ä¸ªç”¨æˆ·ï¼Œåˆ†åˆ«æ˜¯ç”¨æˆ· 1001â€”â€”1.000 å’Œç”¨æˆ· 1005â€”â€”0.905ï¼Œè¿™ä¸æˆ‘ä»¬ä¹‹å‰çš„â€ æ˜¾ç„¶çŒœæƒ³ â€œç›¸ä¸€è‡´ã€‚\nç„¶åæˆ‘ä»¬å°±å¯ä»¥æ ¹æ®ç”¨æˆ· 1001 å’Œç”¨æˆ· 1005 å·²ç»è´­ä¹°çš„å•†å“ä½†ç”¨æˆ· 1003 æ²¡æœ‰è´­ä¹°çš„å•†å“ï¼Œå°†ä»–ä»¬ä¸¤ä¸ªåŠ æƒç»¼åˆè®¡ç®—ï¼Œä¸ºç”¨æˆ· 1003 æ¨èã€‚\n# å°ç»“\nå…¶å®ï¼Œåˆ©ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°è®¡ç®—ç”¨æˆ·ä¹‹é—´çš„ç›¸å…³æ€§å¹¶ä¸å¤æ‚ï¼Œè€Œåœ¨è®¡ç®—ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥æ€ä¹ˆè®¾è®¡æ ¹æ®ç”¨æˆ· 1003 çš„å·²è´­ä¹°å•†å“çš„è¯„åˆ†ä¿¡æ¯ï¼ŒæŠ½å–ä¸ä»–è´­ä¹°çš„ç›¸åŒå•†å“çš„å…¶ä»–ç”¨æˆ·çš„å•†å“è¯„åˆ†ä¿¡æ¯çš„ SQL æˆ–è€…æ˜¯å…¶ä»–ä¿¡æ¯æå–æ–¹æ³•ï¼Œæˆ‘æƒ³ï¼Œè¿™æ‰æ˜¯æ›´ä¸ºé‡è¦çš„ç‚¹ã€‚\nè¿™å¯èƒ½å°±æ˜¯ç®€å•çš„ â€œæ•°æ®æ¸…æ´—â€ å§ï¼å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆã€‚\n","categories":["å¼€å‘ç»éªŒ"],"tags":["ååŒè¿‡æ»¤"]},{"title":"MD5è®¡ç®—æ—¶é—´","url":"/experience/MD5CalculationTimePractice/","content":"# MD5 è®¡ç®—æ—¶é—´çš„å®è·µ\n# å¼•è¨€\næœ€è¿‘åœ¨åšä¸€ä¸ªé¡¹ç›®ï¼Œé‡Œé¢ç”¨åˆ°äº† MD5 ç®—æ³•æ¥ç”Ÿæˆæ–‡ä»¶åï¼Œå¹¶ä¸”å¯ä»¥å¯¹ç›¸åŒæ–‡ä»¶è¿›è¡Œåˆå¹¶å­˜å‚¨ï¼Œä¸ç¦è®©æˆ‘æƒ³åˆ°äº†ä¸€ä¸ªé—®é¢˜ â€”â€”MD5 çš„è®¡ç®—å¾ˆè€—æ—¶å—è¿˜æ˜¯ MD5 æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ç®—æ³•ï¼Œåœ¨ç½‘ä¸Šç¿»é˜…äº†ä¸€äº›èµ„æ–™ï¼Œå¾—åˆ°äº†ç»“æœï¼Œç¡®å® MD5 çš„è®¡ç®—æ˜¯å¾ˆè½»é‡çš„ã€‚\nä½†æ˜¯ï¼Œä»–åˆ°åº•éœ€è¦å¤šé•¿æ—¶é—´å‘¢ï¼Ÿæˆ‘ç›´æ¥å¼€å§‹å®è·µä¸€ä¸‹ã€‚\n# é…ç½®\næœºå™¨é‡‡ç”¨ï¼šAMD Ryzen 7 5800H å¤„ç†å™¨ + 32GB å†…å­˜ é¢‘ç‡ä¸º 3200 ä½¿ç”¨çº¦ 50%\n# å®è·µ\nå…ˆå¯¹å°æ–‡ä»¶è¿›è¡Œæµ‹è¯•ï¼Œç°é€‰ç”¨æ–‡ä»¶å¤§å°ä¸º 2.83 MB çš„å›¾ç‰‡ï¼Œåœ¨ anaconda ç¯å¢ƒä¸‹ï¼Œå¯¹æ¯”ä¸åŒ chunk_size ä¸‹çš„è®¡ç®—æ—¶é—´ã€‚\nimport hashlibimport timedef file_to_md5(file_path, chunk_size=8192):    md5 = hashlib.md5()    with open(file_path, 'rb') as f:        while chunk := f.read(chunk_size):            md5.update(chunk)    return md5.hexdigest()t = time.perf_counter()file_to_md5('D:\\\\ZzMu\\\\Aping\\\\bz\\\\zb.png')print(f'&#123;time.perf_counter() - t:.8f&#125;s')\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n1024\n0.00551090s\n\n\n2048\n0.00501470s\n\n\n4096\n0.00491630s\n\n\n8192\n0.00470980s\n\n\n16384\n0.00436570s\n\n\n\néšç€ chunk_size çš„å¢å¤§ï¼Œè®¡ç®—æ—¶é—´ä¸æ–­ç¼©çŸ­ï¼Œä¸è¿‡ç¡®å®å¾®ä¹å…¶å¾®ï¼Œ0.00 å‡ çš„æ—¶é—´æ— æ³•æ„ŸçŸ¥ï¼Œé‚£ä¹ˆå¤§ä¸€ç‚¹çš„æ–‡ä»¶èƒ½æ”¾å¤§å½±å“å—ï¼Ÿ\nä¸‹é¢å¯¹æ–‡ä»¶å¤§å°ä¸º 957 MB çš„ 4 åˆ† 44 ç§’çš„ 5k è§†é¢‘è¿›è¡Œè®¡ç®—ã€‚\n\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n1024\n1.68504020s\n\n\n2048\n1.61570920s\n\n\n4096\n1.57428070s\n\n\n8192\n1.55151410s\n\n\n16384\n1.35576710s\n\n\n32768\n1.28117580s\n\n\n\nå¤§æ–‡ä»¶å¯¹ chunk_size çš„æ„ŸçŸ¥æ›´ä¸ºæ˜æ˜¾ï¼Œå˜ç°ä¸º 0. å‡ çš„æ³¢åŠ¨ã€‚\nä¸‹é¢è¯•è¯•æ›´å¤§çš„æ–‡ä»¶ï¼Œæ–‡ä»¶å¤§å°ä¸º 9.58 GB çš„ Linux å®‰è£…æ–‡ä»¶ CentOS-7-x86_64-Everything-2207-02.iso è¿›è¡Œè®¡ç®—ã€‚\n\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n1024\n17.36447650s\n\n\n2048\n17.03117640s\n\n\n4096\n16.44976660s\n\n\n8192\n16.01030290s\n\n\n16384\n14.48009140s\n\n\n32768\n13.57228980s\n\n\n\nå¾—å‡ºç»“è®ºï¼Œè¶Šå¤§çš„æ–‡ä»¶å¯¹ chunk_size è¶Šæ•æ„Ÿã€‚åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»ç„¶å¯¹è¿™ä¸ªæ‰§è¡Œæ—¶é—´æœ‰ç–‘é—®ï¼Œä¸åŒçš„å˜æˆè¯­è¨€å¯¹è®¡ç®—æ—¶é—´æœ‰ä»€ä¹ˆå½±å“å‘¢ï¼Œä»¥ä¸Šæ˜¯ä½¿ç”¨ Python è¯­è¨€å®Œæˆçš„æµ‹è¯•ï¼Œæ¥ä¸‹æ¥è¯•è¯• Java çš„è¯­è¨€ã€‚\nåŸç”Ÿï¼š\nimport java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public class Main &#123;    private static final int BUFFER_SIZE = 32768;    public static String fileToMD5(String filePath) throws IOException, NoSuchAlgorithmException &#123;        try (InputStream is = new FileInputStream(filePath)) &#123;            MessageDigest md5Digest = MessageDigest.getInstance(\"MD5\");            byte[] buffer = new byte[BUFFER_SIZE];            int bytesRead;            while ((bytesRead = is.read(buffer)) != -1) &#123;                md5Digest.update(buffer, 0, bytesRead);            &#125;            return bytesToHex(md5Digest.digest());        &#125;    &#125;    private static String bytesToHex(byte[] bytes) &#123;        StringBuilder hexString = new StringBuilder();        for (byte b : bytes) &#123;            String hex = Integer.toHexString(0xff &amp; b);            if (hex.length() == 1) hexString.append('0');            hexString.append(hex);        &#125;        return hexString.toString();    &#125;    public static void main(String[] args) throws IOException, NoSuchAlgorithmException &#123;        long startTime = System.nanoTime();        fileToMD5(\"D:\\\\ZzMu\\\\Aping\\\\bz\\\\zb.png\");        long endTime = System.nanoTime();        System.out.printf(\"Time taken: %.8fs%n\", (endTime - startTime) / 1e9);    &#125;&#125;ä½¿ç”¨ java 8ï¼š\n\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n8192\n22.89824750\n\n\n16384\n21.72088020\n\n\n32768\n20.98676390\n\n\n\næ²¡æƒ³åˆ°å•Šï¼Œjava è¡¨ç°çš„æ›´ä¸ºç³Ÿç³•ï¼Œæ˜¯ä¸æ˜¯å’Œ java ç‰ˆæœ¬æœ‰å…³ç³»å‘¢ï¼Ÿ\nä½¿ç”¨ java 17ï¼š\n\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n1024\n27.40612860\n\n\n8192\n15.47918140\n\n\n16384\n14.53450360\n\n\n32768\n13.85291620\n\n\n\nç¡®å® java 17 çš„è¡¨ç°è¦æ¯” java 8 çš„è¡¨ç°å¥½ã€‚ä¸è¿‡è¿˜æ˜¯å¼±äº Pythonï¼Ÿéš¾é“æ˜¯æˆ‘å†™çš„ä»£ç å¤ªçƒ‚äº†ï¼Ÿ\nåˆå¼•å…¥äº† DigestUtils å·¥å…·ç±»ï¼ŒDigestUtils æ˜¯ apache. commons åŒ…ä¸‹çš„çš„ MD5 è®¡ç®—å·¥å…·ï¼Œé»˜è®¤ chunk_size å¤§å°ä¸º 1024ã€‚\nimport org.apache.commons.codec.digest.DigestUtils;import org.junit.jupiter.api.Test;import java.io.FileInputStream;import java.io.IOException;public class MD5 &#123;    @Test    public void test() throws IOException &#123;        FileInputStream inputStream = new FileInputStream(\"E:\\\\LinuxIso\\\\CentOS-7-x86_64-Everything-2207-02.iso\");        long startTime = System.nanoTime();        DigestUtils.md5Hex(inputStream);        long endTime = System.nanoTime();        System.out.printf(\"Time taken: %.8fs%n\", (endTime - startTime) / 1e9);    &#125;&#125;\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n1024\n27.50305870\n\n\n\nå½¼æ­¤å½¼æ­¤å§ï¼Œå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆã€‚\nä¸‹é¢åˆå¼•å…¥äº† SecureUtilï¼Œè¯¥å·¥å…·æ˜¯ HuTool åŒ…ä¸‹ä¸€ä¸ªè®¡ç®— MD5 çš„å·¥å…·ï¼Œé»˜è®¤ chunk_size ä¸º 1024ã€‚\nimport cn.hutool.crypto.SecureUtil;import org.junit.jupiter.api.Test;import java.io.FileInputStream;import java.io.IOException;public class MD5 &#123;    @Test    public void test() throws IOException &#123;        FileInputStream inputStream = new FileInputStream(\"E:\\\\LinuxIso\\\\CentOS-7-x86_64-Everything-2207-02.iso\");        long startTime = System.nanoTime();        SecureUtil.md5(inputStream);        long endTime = System.nanoTime();        System.out.printf(\"Time taken: %.8fs%n\", (endTime - startTime) / 1e9);    &#125;&#125;\n\n\nchunk_size\næ—¶é—´\n\n\n\n\n1024\n15.42640900\n\n\n\nHuTool çš„ SecureUtil ç¡®å®æ›´é«˜æ•ˆï¼Œåº”è¯¥æ˜¯åšäº†ä¸€äº›ç‰¹æ®Šä¼˜åŒ–ï¼Œæºç ä¸­æ˜¾ç¤ºçš„æ˜¯ MD5 æ²¡æœ‰ä½¿ç”¨ BC åº“ï¼Œå®Œå…¨ä¾èµ–äº jdk åº“ã€‚\n","categories":["å¼€å‘ç»éªŒ"],"tags":["MD5"]},{"title":"DBä¸­çš„èŒƒå¼","url":"/database/DataBase01/","content":"# æ•°æ®åº“èŒƒå¼\n# ä»€ä¹ˆæ˜¯æ•°æ®åº“èŒƒå¼\næ•°æ®åº“èŒƒå¼ï¼ˆNormalizationï¼‰æ˜¯ä¸€ç§è®¾è®¡å…³ç³»å‹æ•°æ®åº“çš„æ–¹æ³•ï¼Œå®ƒæ—¨åœ¨å‡å°‘æ•°æ®å†—ä½™ï¼Œæé«˜æ•°æ®çš„ä¸€è‡´æ€§å’Œå¯é æ€§ï¼Œé¿å…æ•°æ®ä¿®æ”¹æ—¶å‡ºç°å¼‚å¸¸ã€‚æ•°æ®åº“èŒƒå¼é€šå¸¸åˆ†ä¸ºä¸€åˆ°äº”ä¸ªçº§åˆ«ï¼Œæ¯ä¸ªçº§åˆ«å¯¹åº”ä¸€ç»„è®¾è®¡è§„åˆ™ã€‚\nèŒƒå¼è¶Šé«˜ï¼Œæ•°æ®å†—ä½™è¶Šå°‘ï¼Œæ•°æ®ä¸€è‡´æ€§å’Œå¯é æ€§è¶Šé«˜ã€‚ä½†æ˜¯ï¼ŒèŒƒå¼è¿‡é«˜ä¹Ÿå¯èƒ½ä¼šå¸¦æ¥ä¸€äº›é—®é¢˜ï¼Œå¦‚å¢åŠ äº†æ•°æ®åº“çš„å¤æ‚æ€§å’ŒæŸ¥è¯¢çš„å¼€é”€ï¼Œéœ€è¦æ ¹æ®å®é™…åº”ç”¨åœºæ™¯æ¥ç¡®å®šä½¿ç”¨å“ªä¸ªèŒƒå¼ã€‚\n# å±‚çº§åˆ†ç±»\n# 1NFï¼ˆç¬¬ä¸€èŒƒå¼ï¼‰\nå…³ç³»æ¨¡å¼ä¸­çš„æ‰€æœ‰å±æ€§éƒ½æ˜¯åŸå­æ€§çš„ï¼Œå³ä¸å¯å†åˆ†ã€‚\n# 2NFï¼ˆç¬¬äºŒèŒƒå¼ï¼‰\nå…³ç³»æ¨¡å¼å¿…é¡»æ»¡è¶³ç¬¬ä¸€èŒƒå¼ï¼Œä¸”ä¸å­˜åœ¨éå…³é”®å­—å±æ€§å¯¹ä¸»é”®çš„éƒ¨åˆ†ä¾èµ–ã€‚\n# 3NFï¼ˆç¬¬ä¸‰èŒƒå¼ï¼‰\nå…³ç³»æ¨¡å¼å¿…é¡»æ»¡è¶³ç¬¬äºŒèŒƒå¼ï¼Œä¸”ä¸å­˜åœ¨éå…³é”®å­—å±æ€§å¯¹å…¶ä»–éå…³é”®å­—å±æ€§çš„ä¼ é€’ä¾èµ–ã€‚\n# BCNFï¼ˆBoyce-Codd èŒƒå¼ï¼‰\nå…³ç³»æ¨¡å¼å¿…é¡»æ»¡è¶³ç¬¬ä¸€èŒƒå¼ï¼Œä¸”ä¸å­˜åœ¨éä¸»å±æ€§å¯¹ä¸»å±æ€§çš„éå¹³å‡¡ä¾èµ–å…³ç³»ã€‚\n# 4NFï¼ˆç¬¬å››èŒƒå¼ï¼‰\nå…³ç³»æ¨¡å¼å¿…é¡»æ»¡è¶³ç¬¬ä¸‰èŒƒå¼ï¼Œä¸”ä¸å­˜åœ¨å¤šå€¼ä¾èµ–ã€‚\n# 5NFï¼ˆç¬¬äº”èŒƒå¼ï¼‰\nå…³ç³»æ¨¡å¼å¿…é¡»æ»¡è¶³ç¬¬å››èŒƒå¼ï¼Œä¸”ä¸å­˜åœ¨è¿æ¥ä¾èµ–ã€‚\n# å°é¢˜ç›®\nè®©æˆ‘ä»¬é€šè¿‡ä¸€äº›é¢˜ç›®æ¥æ„Ÿå—ä¸€ä¸‹å§ï¼ï¼\n# Ex1\n\nè®¾æœ‰å…³ç³» Rï¼ˆå·¥å·ï¼Œå§“åï¼Œå·¥ç§ï¼Œå®šé¢ï¼‰ï¼Œåˆ™ R æ˜¯å±äºç¬¬ 2 èŒƒå¼ï¼Œå°†å…¶è½¬åŒ–ä¸ºç¬¬ä¸‰èŒƒå¼\n\næ ¹æ®å…³ç³» Rï¼ˆå·¥å·ï¼Œå§“åï¼Œå·¥ç§ï¼Œå®šé¢ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºå·¥å·å’Œå§“åæ˜¯å€™é€‰é”®ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥å”¯ä¸€åœ°æ ‡è¯†æ¯ä¸ªå…ƒç»„ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹å‡ºå·¥ç§å’Œå®šé¢è¿™ä¸¤ä¸ªå±æ€§å®Œå…¨ä¾èµ–äºå€™é€‰é”®ï¼Œå› æ­¤å…³ç³» R ç¬¦åˆ 2NF çš„è¦æ±‚ã€‚\nç°åœ¨æˆ‘ä»¬æ¥è€ƒè™‘å°† R è½¬åŒ–ä¸º 3NF çš„è¿‡ç¨‹ã€‚æ ¹æ® 3NF çš„è¦æ±‚ï¼Œæˆ‘ä»¬éœ€è¦æ¶ˆé™¤ä»»ä½•éä¸»å±æ€§å¯¹ä¸»é”®çš„ä¼ é€’ä¾èµ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥æ¯ä¸ªéä¸»å±æ€§æ˜¯å¦ç›´æ¥ä¾èµ–äºä¸»é”®ï¼Œæˆ–è€…æ˜¯ç›´æ¥ä¾èµ–äºå…¶ä»–éä¸»å±æ€§ã€‚\nåœ¨å…³ç³» R ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°å®šé¢å±æ€§ç›´æ¥ä¾èµ–äºå·¥ç§å±æ€§ï¼Œè€Œå·¥ç§å±æ€§å¹¶ä¸æ˜¯ä¸»é”®çš„ä¸€éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®šé¢å’Œå·¥ç§æ‹†åˆ†åˆ°ä¸€ä¸ªæ–°çš„å…³ç³»ä¸­ï¼Œä»¥æ¶ˆé™¤å®šé¢å¯¹äºå·¥ç§çš„ä¼ é€’ä¾èµ–ï¼Œä»è€Œä½¿å¾—å…³ç³» R æ»¡è¶³ 3NF çš„è¦æ±‚ã€‚\næ‹†åˆ†åçš„ä¸¤ä¸ªå…³ç³»å¦‚ä¸‹ï¼š\n\nR1ï¼ˆå·¥å·ï¼Œå§“åï¼Œå·¥ç§ï¼‰ï¼šè¯¥å…³ç³»åŒ…å«äº†å·¥å·ã€å§“åå’Œå·¥ç§ä¸‰ä¸ªå±æ€§ï¼Œå…¶ä¸­å·¥å·å’Œå§“åä½œä¸ºå€™é€‰é”®ï¼Œå·¥ç§æ˜¯ä¸€ä¸ªéä¸»å±æ€§ï¼Œä½†å®ƒç›´æ¥ä¾èµ–äºä¸»é”®ã€‚å› æ­¤ï¼Œå…³ç³» R1 ç¬¦åˆ 2NF å’Œ 3NF çš„è¦æ±‚ã€‚\nR2ï¼ˆå·¥ç§ï¼Œå®šé¢ï¼‰ï¼šè¯¥å…³ç³»åŒ…å«äº†å·¥ç§å’Œå®šé¢ä¸¤ä¸ªå±æ€§ï¼Œå…¶ä¸­å·¥ç§ä½œä¸ºä¸»é”®ï¼Œå®šé¢æ˜¯ä¸€ä¸ªéä¸»å±æ€§ï¼Œä½†å®ƒç›´æ¥ä¾èµ–äºä¸»é”®ã€‚å› æ­¤ï¼Œå…³ç³» R2 ç¬¦åˆ 2NF å’Œ 3NF çš„è¦æ±‚ã€‚\n\næœ€ç»ˆï¼Œæˆ‘ä»¬å°†å…³ç³» R è½¬åŒ–ä¸ºä¸¤ä¸ªç¬¦åˆ 3NF çš„å…³ç³» R1 å’Œ R2ï¼Œç¬¦åˆ 3NF çš„è¦æ±‚ã€‚\n# Ex2\n\nè®¾æœ‰å…³ç³» STUDENT (S#,SNAME,SDEPT,MNAME,CNAME,GRADE)ï¼ŒS#,CNAME ä¸ºå€™é€‰ç ï¼Œè®¾å…³ç³»ä¸­æœ‰å¦‚ä¸‹å‡½æ•°ä¾èµ–ï¼š\nS#,CNAMEâ†’SNAME,SDEPT,MNAME\nS#â†’SNAME,SDEPT,MNAME\nS#,CNAMEâ†’GRADE\nSDEPTâ†’MNAME\n è¯•æ±‚ä¸‹åˆ—é—®é¢˜ï¼š\nï¼ˆ1ï¼‰å…³ç³» STUDENT å±äºç¬¬å‡ èŒƒå¼ï¼Ÿ\nï¼ˆ2ï¼‰å¦‚æœå…³ç³» STUDENT ä¸å±äº BCNFï¼Œè¯·å°†å…³ç³» STUDENT é€æ­¥åˆ†è§£ä¸º BCNFã€‚\nè¦æ±‚ï¼šå†™å‡ºè¾¾åˆ°æ¯ä¸€çº§èŒƒå¼çš„åˆ†è§£è¿‡ç¨‹ï¼Œå¹¶æŒ‡æ˜æ¶ˆé™¤ä»€ä¹ˆç±»å‹çš„å‡½æ•°ä¾èµ–ã€‚\n\nï¼ˆ1ï¼‰1NF\nï¼ˆ2ï¼‰é¦–å…ˆæ¶ˆé™¤éä¸»å±æ€§å¯¹å€™é€‰ç çš„éƒ¨åˆ†ä¾èµ–ï¼Œå³æ¶ˆé™¤éƒ¨åˆ†å‡½æ•°ä¾èµ–\nï¼ˆS#ï¼ŒCNAMEï¼‰-&gt;ï¼ˆSNAME,SDEPT,MNAMEï¼‰\nR åˆ†è§£ä¸ºï¼š\nR1(S#,SNAME,SDEPT,MNAME)\nR2(S#,CNAME,GRADE)\nR è‡³æ­¤åˆ†è§£ä¸º 2NF\næ­¤æ—¶ R1 ä¸­å­˜åœ¨éä¸»å±æ€§å¯¹å€™é€‰ç çš„ä¼ é€’ä¾èµ–ï¼Œå³æ¶ˆé™¤ä¼ é€’ä¾èµ–\nï¼ˆS#ï¼‰-&gt;ï¼ˆSDEPTï¼‰\nï¼ˆSDEPTï¼‰-&gt;ï¼ˆMNAMEï¼‰\nR1 åˆ†è§£ä¸ºï¼š\nR11(S#,SNAME,SDEPT)\nR12(SDEPT,MNAME)\nR1 è‡³æ­¤åˆ†è§£ä¸º 3NF\næ­¤æ—¶ R11ï¼ŒR12ï¼ŒR2 å¯ä»¥å¾—å‡ºçš„å‡½æ•°ä¾èµ–ï¼š\nï¼ˆS#,CNAMEï¼‰-&gt;ï¼ˆGRADEï¼‰\nï¼ˆS#ï¼‰-&gt;ï¼ˆSNAMEï¼‰,ï¼ˆS#ï¼‰-&gt;ï¼ˆSDEPTï¼‰\nï¼ˆSDEPTï¼‰-&gt;ï¼ˆMNAMEï¼‰\nâ€‹ ç”±æ­¤å¯ä»¥çœ‹å‡ºï¼Œæ•°æ®è¡¨ä¸­çš„æ¯ä¸ªéä¸»å±æ€§éƒ½å®Œå…¨ä¾èµ–äºå€™é€‰é”®ï¼Œå³æ¯ä¸ªéä¸»å±æ€§éƒ½ä¸åªä¾èµ–äºå€™é€‰é”®çš„ä¸€éƒ¨åˆ†ï¼Œä¸”éä¸»å±æ€§æ— æ³•å†³å®šå¦ä¸€ä¸ªéä¸»å±æ€§ï¼Œå³ä¸å­˜åœ¨éå¹³å‡¡å‡½æ•°ä¾èµ–ã€‚\nâ€‹ ä¸Šè¿°å…³ç³»è¡¨ R11ï¼ŒR12ï¼ŒR2 æ»¡è¶³ BCNF\n# Ex3\n\nä¸€ä¸ªå…³ç³»æ¨¡å¼ä¸å±äºç¬¬äºŒèŒƒå¼å¯èƒ½ä¼šäº§ç”Ÿ ()ã€() å’Œ ( ) ç­‰å‡ ä¸ªé—®é¢˜ï¼Œè§£å†³çš„åŠæ³•æ˜¯ ( )ã€‚\n\n\n\nç¬¬ä¸€ç©ºï¼š\næ’å…¥å¼‚å¸¸\n\n\nç¬¬äºŒç©ºï¼š\nåˆ é™¤å¼‚å¸¸\n\n\nç¬¬ä¸‰ç©ºï¼š\nä¿®æ”¹å¼‚å¸¸\n\n\nç¬¬å››ç©ºï¼š\næŠ•å½±åˆ†è§£\n\n\n# å…³é”®è¯\n# å€™é€‰ç å’Œéä¸»å±æ€§\nå€™é€‰ç å’Œéä¸»å±æ€§æ˜¯å…³ç³»æ•°æ®åº“ä¸­çš„ä¸¤ä¸ªæ¦‚å¿µï¼Œå®ƒä»¬ä¹‹é—´æœ‰ä¸€å®šçš„å…³ç³»ã€‚\nå€™é€‰ç ï¼ˆCandidate Keyï¼‰æŒ‡çš„æ˜¯èƒ½å¤Ÿå”¯ä¸€æ ‡è¯†å…³ç³»æ¨¡å¼ä¸­æ¯ä¸€æ¡è®°å½•çš„å±æ€§é›†åˆã€‚ä¸€ä¸ªå…³ç³»æ¨¡å¼å¯èƒ½æœ‰å¤šä¸ªå€™é€‰ç ï¼Œä½†æ˜¯å…¶ä¸­åªæœ‰ä¸€ä¸ªä¼šè¢«é€‰æ‹©ä½œä¸ºä¸»é”®ï¼ˆPrimary Keyï¼‰æ¥æ ‡è¯†æ¯ä¸€æ¡è®°å½•ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œä¸»é”®ä¼šè¢«ç”¨æ¥å»ºç«‹å…³ç³»æ¨¡å¼ä¹‹é—´çš„è”ç³»ï¼Œå› æ­¤é€‰æ‹©ä¸€ä¸ªæ°å½“çš„å€™é€‰ç ä½œä¸ºä¸»é”®æ˜¯å…³ç³»æ•°æ®åº“è®¾è®¡ä¸­çš„é‡è¦æ­¥éª¤ã€‚\néä¸»å±æ€§æŒ‡çš„æ˜¯å…³ç³»æ¨¡å¼ä¸­é™¤äº†ä¸»é”®ä¹‹å¤–çš„å±æ€§ã€‚ä¸€ä¸ªå…³ç³»æ¨¡å¼å¯èƒ½åŒ…å«å¤šä¸ªéä¸»å±æ€§ï¼Œå®ƒä»¬ä¹‹é—´å¯ä»¥å­˜åœ¨ä¾èµ–å…³ç³»ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªå…³ç³»æ¨¡å¼ Rï¼ˆAï¼ŒBï¼ŒCï¼‰ä¸­ï¼Œå¦‚æœå­˜åœ¨å‡½æ•°ä¾èµ– Aâ†’Bï¼Œåˆ™ B æ˜¯éä¸»å±æ€§ã€‚\nå€™é€‰ç å’Œéä¸»å±æ€§ä¹‹é—´çš„å…³ç³»åœ¨äºï¼Œä¸€ä¸ªå€™é€‰ç åŒ…å«äº†æ‰€æœ‰çš„ä¸»å±æ€§ï¼Œè€Œéä¸»å±æ€§å¯èƒ½ä¾èµ–äºä¸»å±æ€§ï¼Œä¹Ÿå¯èƒ½å­˜åœ¨ä¾èµ–äºå…¶ä»–éä¸»å±æ€§çš„æƒ…å†µã€‚åœ¨è¿›è¡Œå…³ç³»æ•°æ®åº“è®¾è®¡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ç¡®å®šå€™é€‰ç å’Œä¾èµ–å…³ç³»æ¥è§„èŒƒåŒ–å…³ç³»æ¨¡å¼ï¼Œä»è€Œæ¶ˆé™¤æ•°æ®å†—ä½™å’Œä¸ä¸€è‡´æ€§çš„é—®é¢˜ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©æœ€å°çš„å€™é€‰ç ä½œä¸ºä¸»é”®ï¼Œå¹¶ç¡®ä¿æ‰€æœ‰éä¸»å±æ€§éƒ½å®Œå…¨ä¾èµ–äºä¸»é”®ï¼Œä»¥ä¿è¯æ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚\n# å¹³å‡¡ä¾èµ–å…³ç³»\nå¹³å‡¡ä¾èµ–å…³ç³»æ˜¯æŒ‡å¯¹äºä¸€ä¸ªå±æ€§é›†åˆ Xï¼Œåœ¨ä¸€ä¸ªå…³ç³» R ä¸­å¦‚æœ X çš„ä»»æ„è¶…é›†éƒ½å¯ä»¥å”¯ä¸€åœ°ç¡®å®š Xï¼Œé‚£ä¹ˆ X å¯¹äº R å°±æ˜¯å¹³å‡¡çš„ä¾èµ–ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªå…³ç³» Rï¼ˆA, B, Cï¼‰ï¼Œå¦‚æœå­˜åœ¨å‡½æ•°ä¾èµ– Aâ†’Aï¼Œé‚£ä¹ˆ A å¯¹äº R æ¥è¯´æ˜¯ä¸€ä¸ªå¹³å‡¡ä¾èµ–ã€‚å› ä¸º A çš„ä»»æ„è¶…é›†éƒ½å¯ä»¥å”¯ä¸€åœ°ç¡®å®š A æœ¬èº«ï¼Œå³ A å·²ç»åŒ…å«äº†å®ƒæ‰€ä¾èµ–çš„å±æ€§ã€‚\nå¯ä»¥è¿™æ ·ç†è§£ï¼Œä¸€ä¸ªå±æ€§é›†åˆå¦‚æœèƒ½å¤Ÿå”¯ä¸€åœ°ç¡®å®šè‡ªå·±ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯å¹³å‡¡çš„ä¾èµ–ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªå…³ç³» Rï¼ˆA, B, Cï¼‰ï¼Œå¦‚æœå­˜åœ¨å‡½æ•°ä¾èµ– Aâ†’Aï¼Œé‚£ä¹ˆ A å¯¹äº R æ¥è¯´æ˜¯ä¸€ä¸ªå¹³å‡¡ä¾èµ–ï¼Œå› ä¸ºå±æ€§é›†åˆ A å·²ç»åŒ…å«äº†å®ƒæ‰€ä¾èµ–çš„å±æ€§ A æœ¬èº«ï¼Œå³ A å·²ç»èƒ½å¤Ÿå”¯ä¸€åœ°ç¡®å®šè‡ªå·±ã€‚è€Œéå¹³å‡¡çš„ä¾èµ–æ˜¯æŒ‡ä¸€ä¸ªå±æ€§é›†åˆä¸èƒ½å”¯ä¸€åœ°ç¡®å®šè‡ªå·±ï¼Œéœ€è¦ä¾èµ–äºå…¶ä»–å±æ€§æ‰èƒ½ç¡®å®šè‡ªå·±ï¼Œä¾‹å¦‚åœ¨å…³ç³» Rï¼ˆA, B, Cï¼‰ä¸­ï¼Œå­˜åœ¨å‡½æ•°ä¾èµ– Aâ†’Bï¼ŒB å°±æ˜¯ä¸€ä¸ªéå¹³å‡¡ä¾èµ–ï¼Œå› ä¸º B ä¸èƒ½å”¯ä¸€åœ°ç¡®å®šè‡ªå·±ï¼Œéœ€è¦ä¾èµ–äº A æ‰èƒ½ç¡®å®šã€‚\n# ä¼ é€’ä¾èµ–\nä¼ é€’ä¾èµ–ï¼ˆTransitive Dependencyï¼‰æŒ‡çš„æ˜¯ä¸€ä¸ªéä¸»å±æ€§ä¾èµ–äºå¦ä¸€ä¸ªéä¸»å±æ€§çš„éä¸»å±æ€§ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªå…³ç³»æ¨¡å¼ Rï¼ˆAï¼ŒBï¼ŒCï¼‰ä¸­ï¼Œå¦‚æœå­˜åœ¨å‡½æ•°ä¾èµ– Aâ†’B å’Œ Bâ†’Cï¼Œåˆ™ C å¯¹ A å­˜åœ¨ä¼ é€’ä¾èµ–ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæˆ‘ä»¬è¦æ›´æ–° A çš„å€¼ï¼Œå°±ä¼šå¯¼è‡´ C çš„å€¼ä¹Ÿéšä¹‹æ”¹å˜ï¼Œä»è€Œå¼•èµ·æ•°æ®ä¸ä¸€è‡´çš„é—®é¢˜ã€‚\n","categories":["æ•°æ®åº“"],"tags":["æ•°æ®åº“"]},{"title":"æ•°æ®åº“è®¾è®¡","url":"/database/DataBase02/","content":"# æ•°æ®åº“è®¾è®¡\n# ä»€ä¹ˆæ˜¯æ•°æ®åº“è®¾è®¡\næ•°æ®åº“è®¾è®¡æ˜¯æŒ‡æ ¹æ®éœ€æ±‚åˆ†æå’Œä¸šåŠ¡æµç¨‹ï¼Œè®¾è®¡å‡ºç¬¦åˆåº”ç”¨éœ€æ±‚çš„æ•°æ®åº“ç»“æ„å’Œè¡¨ç»“æ„çš„è¿‡ç¨‹ã€‚é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n\néœ€æ±‚åˆ†æï¼šå¯¹åº”ç”¨çš„åŠŸèƒ½å’Œæ•°æ®è¿›è¡Œåˆ†æï¼Œç¡®å®šåº”ç”¨æ‰€éœ€çš„æ•°æ®å’Œæ•°æ®é—´çš„å…³ç³»ï¼Œæ˜ç¡®æ•°æ®çš„å±æ€§å’Œçº¦æŸæ¡ä»¶ã€‚\næ¦‚å¿µè®¾è®¡ï¼šå°†éœ€æ±‚åˆ†æçš„ç»“æœè½¬åŒ–ä¸ºæ¦‚å¿µæ¨¡å‹ï¼ŒåŒ…æ‹¬å®ä½“ - å…³ç³»æ¨¡å‹å’Œ E-R å›¾ç­‰ï¼Œä»¥åŠå„ä¸ªå®ä½“ä¹‹é—´çš„è”ç³»ã€å±æ€§åŠçº¦æŸç­‰ã€‚\né€»è¾‘è®¾è®¡ï¼šå°†æ¦‚å¿µæ¨¡å‹è½¬åŒ–ä¸ºé€»è¾‘æ¨¡å‹ï¼ŒåŒ…æ‹¬è¡¨çš„å®šä¹‰ã€å±æ€§å®šä¹‰ã€å…³é”®å­—ã€å®Œæ•´æ€§è§„åˆ™ç­‰ï¼Œç¡®å®šè¡¨ä¸è¡¨ä¹‹é—´çš„è”ç³»ï¼Œæ„å»ºæ•°æ®æ¨¡å‹ã€‚\nç‰©ç†è®¾è®¡ï¼šåœ¨é€»è¾‘è®¾è®¡çš„åŸºç¡€ä¸Šï¼Œç»“åˆå…·ä½“çš„æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆå¦‚ MySQLã€Oracleã€SQL Server ç­‰ï¼‰ï¼Œè€ƒè™‘å®ç°æ–¹å¼å’Œä¼˜åŒ–ç­–ç•¥ï¼Œè®¾è®¡å‡ºç‰©ç†å­˜å‚¨ç»“æ„ï¼ŒåŒ…æ‹¬æ•°æ®è¡¨çš„å­˜å‚¨æ–¹å¼ã€ç´¢å¼•ã€åˆ†åŒºç­‰ç­‰ã€‚\n\nåœ¨æ•°æ®åº“è®¾è®¡çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\n\næ•°æ®åº“çš„è®¾è®¡åº”è¯¥ç¬¦åˆåº”ç”¨éœ€æ±‚å’Œä¸šåŠ¡æµç¨‹ï¼Œå…·æœ‰å¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§å’Œå¯é æ€§ã€‚\næ•°æ®åº“åº”è¯¥éµå¾ªæ•°æ®è§„èŒƒåŒ–çš„åŸåˆ™ï¼Œå‡å°‘æ•°æ®å†—ä½™å’Œæ•°æ®å¼‚å¸¸ï¼Œæé«˜æ•°æ®å­˜å‚¨æ•ˆç‡ã€‚\næ•°æ®åº“è®¾è®¡åº”è¯¥è€ƒè™‘æ•°æ®çš„å®Œæ•´æ€§å’Œå®‰å…¨æ€§ï¼Œé‡‡å–é€‚å½“çš„æƒé™ç®¡ç†å’Œæ•°æ®å¤‡ä»½ç­–ç•¥ï¼Œä¿è¯æ•°æ®çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚\næ•°æ®åº“è®¾è®¡åº”è¯¥éµå¾ªä¸€å®šçš„å‘½åè§„èŒƒï¼Œä½¿æ•°æ®åº“çš„ç»“æ„æ¸…æ™°æ˜“æ‡‚ï¼Œä¾¿äºåæœŸçš„ç»´æŠ¤å’Œç®¡ç†ã€‚\n\nç»¼ä¸Šæ‰€è¿°ï¼Œæ•°æ®åº“è®¾è®¡æ˜¯ä¸€ä¸ªç»¼åˆæ€§è¾ƒå¼ºçš„ä»»åŠ¡ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘å¤šæ–¹é¢çš„å› ç´ ï¼Œæ‰èƒ½è®¾è®¡å‡ºç¬¦åˆåº”ç”¨éœ€æ±‚å’Œä¸šåŠ¡æµç¨‹ï¼Œé«˜æ•ˆå¯é çš„æ•°æ®åº“ç»“æ„ã€‚\n# æ•°æ®åº“è®¾è®¡è¿‡ç¨‹\n\néœ€æ±‚åˆ†æ\næ¦‚å¿µç»“æ„è®¾è®¡\né€»è¾‘ç»“æ„è®¾è®¡\næ•°æ®åº“ç‰©ç†è®¾è®¡\næ•°æ®åº“å®æ–½\næ•°æ®åº“è¿è¡Œä¸ç»´æŠ¤\n\n# æ•°æ®åº“è®¾è®¡è¿‡ç¨‹å„ä¸ªé˜¶æ®µä¸Šçš„è®¾è®¡æè¿°\næ•°æ®åº“è®¾è®¡è¿‡ç¨‹ä¸€èˆ¬åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š\n\néœ€æ±‚åˆ†æé˜¶æ®µï¼šåœ¨éœ€æ±‚åˆ†æé˜¶æ®µï¼Œéœ€è¦è¿›è¡Œæ•°æ®éœ€æ±‚çš„è°ƒç ”å’Œæ”¶é›†ï¼Œæ˜ç¡®ç³»ç»Ÿéœ€è¦å­˜å‚¨çš„æ•°æ®ã€æ•°æ®ä¹‹é—´çš„å…³ç³»ä»¥åŠå¯¹æ•°æ®çš„æ“ä½œç­‰ï¼Œè®¾è®¡æè¿°çš„ä¸»è¦å†…å®¹åŒ…æ‹¬æ•°æ®æµå›¾ã€æ•°æ®å­—å…¸ç­‰ã€‚\næ¦‚å¿µè®¾è®¡é˜¶æ®µï¼šåœ¨æ¦‚å¿µè®¾è®¡é˜¶æ®µï¼Œéœ€è¦å°†éœ€æ±‚åˆ†æå¾—åˆ°çš„æ•°æ®éœ€æ±‚è½¬åŒ–ä¸ºæ¦‚å¿µæ¨¡å‹ï¼Œè®¾è®¡æè¿°çš„ä¸»è¦å†…å®¹åŒ…æ‹¬å®ä½“å…³ç³»å›¾ï¼ˆER å›¾ï¼‰ã€‚\né€»è¾‘è®¾è®¡é˜¶æ®µï¼šåœ¨é€»è¾‘è®¾è®¡é˜¶æ®µï¼Œéœ€è¦å°†æ¦‚å¿µæ¨¡å‹è½¬åŒ–ä¸ºå…·ä½“çš„é€»è¾‘æ¨¡å‹ï¼Œè®¾è®¡æè¿°çš„ä¸»è¦å†…å®¹åŒ…æ‹¬å…³ç³»æ¨¡å¼ã€å±æ€§ã€ä¸»é”®ã€å¤–é”®ã€ç´¢å¼•ç­‰ã€‚\nç‰©ç†è®¾è®¡é˜¶æ®µï¼šåœ¨ç‰©ç†è®¾è®¡é˜¶æ®µï¼Œéœ€è¦å°†é€»è¾‘æ¨¡å‹è½¬åŒ–ä¸ºæ•°æ®åº“å®ç°æ¨¡å‹ï¼Œè®¾è®¡æè¿°çš„ä¸»è¦å†…å®¹åŒ…æ‹¬è¡¨ç»“æ„ã€å­˜å‚¨æ–¹å¼ã€ç‰©ç†ç´¢å¼•ç­‰ã€‚\n\nåœ¨æ¯ä¸ªé˜¶æ®µä¸­ï¼Œè®¾è®¡æè¿°çš„å†…å®¹éƒ½ä¸åŒï¼Œä½†éƒ½æ˜¯åœ¨å°†éœ€æ±‚è½¬åŒ–ä¸ºå…·ä½“çš„æ•°æ®åº“ç»“æ„çš„è¿‡ç¨‹ä¸­æ‰€å¿…éœ€çš„ï¼Œè€Œä¸”åœ¨è®¾è®¡æè¿°çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å¯¹éœ€æ±‚è¿›è¡Œç»†è‡´çš„åˆ†æå’Œç†è§£ï¼Œä»¥ä¿è¯è®¾è®¡ç»“æ„çš„æ­£ç¡®æ€§å’Œå®ç”¨æ€§ã€‚\n","categories":["æ•°æ®åº“"],"tags":["æ•°æ®åº“"]},{"title":"SSMæ¡†æ¶æ•´åˆ","url":"/experience/SSM01/","content":"# æ˜¯ä»€ä¹ˆ SSM\nSSM æ˜¯ä¸‰ä¸ªæ¡†æ¶çš„ç®€å†™ï¼Œæœ¬åˆ«æ˜¯ Springï¼ŒSpringMVCï¼ŒMybatisï¼Œè¿™ä¸‰ä¸ªæ¡†æ¶ä½œä¸º JavaWeb å¼ºæœ‰åŠ›çš„æ”¯æ’‘ä»¶ï¼Œæå¤§åœ°æé«˜äº†å¼€å‘æ•ˆç‡ï¼Œé™ä½äº†ç»´æŠ¤æˆæœ¬ï¼Œæ˜¯ Java ç¨‹åºå‘˜å­¦ä¹  Web æŠ€æœ¯çš„å¿…ç»ä¹‹è·¯ï¼ˆè‡³å°‘ç°åœ¨æ˜¯è¿™æ ·ï¼‰\nåœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½ç†Ÿç»ƒæŒæ¡ï¼Œé¢ï¼Œå“ªæ€•ä¸ç†Ÿç»ƒä¹Ÿè¦äº†è§£ Web éƒ¨åˆ†çš„è€ç¥–ï¼šè¯·æ±‚ï¼Œå“åº”ä»¥åŠ Servlet æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯èƒ½å¸®åŠ©ä½ æ›´å¥½ã€æ›´å¿«ã€æ›´æµç•…çš„æŒæ¡ SSM æŠ€æœ¯ã€‚\nå…¶æ¬¡æœ¬æ–‡ä¸»è¦è®²è§£ SSM æ•´åˆçš„ç›¸å…³ç»†èŠ‚ï¼Œå¹¶ä¸ä¼šæ·±å…¥è®²è§£ Springï¼ŒSpringMVCï¼ŒMybatis æ¯ä¸ªæ¡†æ¶çš„çŸ¥è¯†ï¼Œå¸Œæœ›å¤§å®¶åœ¨çœ‹æœ¬æ–‡ä¹‹å‰èƒ½äº†è§£ Springï¼ŒSpringMVCï¼ŒMybatis å•ä¸ªæ¡†æ¶çš„ä½¿ç”¨æ–¹æ³•ã€‚\n# æ•´åˆå¼€å§‹\né¦–å…ˆæˆ‘å…ˆæ”¾å‡ºæœ€ç»ˆçš„æ•´åˆçŠ¶æ€ï¼Œå…¶å®ä¹Ÿä¸ä¸€å®šéè¦æŒ‰ç…§æˆ‘è¿™æ ·æ¥åšã€‚\n\n\n\n\nbean åŒ…ï¼šå¤§å¤šæ•°çš„å®ä½“ç±»config åŒ…ï¼šæ•´åˆçš„æ ¸å¿ƒé…ç½®ç±»controller åŒ…ï¼šå¤–éƒ¨æ§åˆ¶å™¨æš´éœ²ç‚¹mapper åŒ…ï¼šMybiats SQL æ ‡å‡†åŒ–service åŒ…ï¼šä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…å«æ¥å£ä»¥åŠå®ç°resource åŒ…ï¼šèµ„æºæ–‡ä»¶ã€é…ç½®æ–‡ä»¶webappï¼šå‰ç«¯èµ„æº\n\n\n\né‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘å°†å¸¦ç€å¤§å®¶ä¸€æ­¥ä¸€æ­¥çš„æ¥åšï¼Œä»åˆ›å»ºé¡¹ç›®åˆ°æœ€ç»ˆå®Œæˆæ•´åˆã€‚\n# åˆ›å»ºé¡¹ç›®ï¼ˆMaven æ„å»ºæ–¹å¼ï¼‰\né€‰æ‹©æ–°å»ºä¸€ä¸ªé¡¹ç›®ï¼ˆæˆ–æ¨¡å—ï¼‰ï¼Œé€‰æ‹© Maven Archetype å½¢å¼åˆ›å»ºï¼Œæˆ‘ç»™ä»–å‘½åå«åš SSM_demoã€‚\nJDKï¼š1.8ï¼ˆJava 8ï¼‰\nArchetypeï¼šé€‰æ‹©æœ€åä»¥ webapp ç»“å°¾çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ›å»ºæ¨¡æ¿\nç»„ IDï¼šå…¬å¸åŸŸååå†™\n\n# åˆ›å»ºåŒ…ç»“æ„\nåœ¨ main ç›®å½•ä¸‹åˆ›å»º java ç›®å½•å’Œå¿…è¦çš„åŒ…ç»“æ„\n\n# ä¾èµ–å¯¼å…¥ã€å¿…è¦å¯åŠ¨é…ç½®\næˆ‘ä»¬éœ€è¦åœ¨ pom.xml æ–‡ä»¶ä¸‹å¯¼å…¥æˆ‘ä»¬ SSM æ‰€éœ€è¦çš„ä¾èµ–ï¼Œå¹¶é…ç½®å¿…è¦çš„å¯åŠ¨é¡¹ã€‚\n# å¯¼å…¥è¯¦è§£\nç¬¬ä¸€æ­¥ï¼šå¯¼åŒ…\néœ€è¦æ€è€ƒæˆ‘ä»¬éœ€è¦ä»€ä¹ˆä¾èµ–ï¼š\njunitï¼šå•å…ƒæµ‹è¯•ã€‚\nspring-webmvcï¼šæ•´ä¸ªä¾èµ–å°±æ¯”è¾ƒå¼ºå¤§äº†å¥¹ä¸ä»…åŒ…å«äº† SpringMVC çš„éƒ¨åˆ†ä¹ŸåŒ…å«äº† Spring-Context éƒ¨åˆ†ï¼Œå…¶å®ä¹Ÿä¸éš¾ç†è§£ï¼Œå› ä¸º SpringMVC æ˜¯åŸºäº Spring å¼€å‘çš„ï¼Œé‚£ä¹Ÿå°±å¿…ç„¶åŒ…å«äº† Spring æ¡†æ¶çš„éƒ¨åˆ†ã€‚\nè‡³æ­¤æˆ‘ä»¬è¿˜å‰©ä¸‹æ•°æ®åº“çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬ç»§ç»­å°†å…¶å¡«å……å®Œæ•´ã€‚\nMybatisï¼šè¿™ä¸ªæ˜¯ Mybatis çš„æ ¸å¿ƒä¾èµ–ã€‚\nmybatis-springï¼šæ•´ä¸ªæ˜¯å°† Mybatis ä¸ Spring è¿›è¡Œæ•´åˆã€‚\nspring-jdbcï¼šç®€åŒ– Java åº”ç”¨ç¨‹åºä¸æ•°æ®åº“ä¹‹é—´çš„äº¤äº’ï¼ŒSpring JDBC æ˜¯ MyBatis-Spring çš„åº•å±‚ä¾èµ–ï¼Œæä¾›äº†è¿æ¥ç®¡ç†ã€äº‹åŠ¡ç®¡ç†ç­‰åŸºç¡€åŠŸèƒ½ã€‚\nmysql-connector-javaï¼šè¿™ä¸ªæ˜¯ MySQL çš„é©±åŠ¨ä¾èµ–ã€‚\ndruidï¼šæ•°æ®åº“è¿æ¥æ± ã€‚\nservlet-apiï¼šSpring MVC æ¶æ„æ˜¯åŸºäº Servlet è§„èŒƒçš„ã€‚å®ƒä½¿ç”¨ Servlet API æ¥å¤„ç†å’Œåˆ†å‘ Web è¯·æ±‚ï¼Œä»¥åŠä¸ Web å®¹å™¨è¿›è¡Œäº¤äº’ã€‚\njackson-databindï¼šç”¨äºåœ¨ Java å¯¹è±¡å’Œ JSON æ•°æ®ä¹‹é—´è¿›è¡Œåºåˆ—åŒ–ï¼ˆå¯¹è±¡åˆ° JSONï¼‰å’Œååºåˆ—åŒ–ï¼ˆJSON åˆ°å¯¹è±¡ï¼‰çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚\n&lt;dependencies>  &lt;dependency>    &lt;groupId>junit&lt;/groupId>    &lt;artifactId>junit&lt;/artifactId>    &lt;version>4.13.2&lt;/version>    &lt;scope>test&lt;/scope>  &lt;/dependency>  &lt;dependency>    &lt;groupId>org.springframework&lt;/groupId>    &lt;artifactId>spring-webmvc&lt;/artifactId>    &lt;version>5.2.10.RELEASE&lt;/version>  &lt;/dependency>  &lt;dependency>    &lt;groupId>org.mybatis&lt;/groupId>    &lt;artifactId>mybatis&lt;/artifactId>    &lt;version>3.5.9&lt;/version>  &lt;/dependency>  &lt;dependency>    &lt;groupId>org.mybatis&lt;/groupId>    &lt;artifactId>mybatis-spring&lt;/artifactId>    &lt;version>2.0.7&lt;/version>  &lt;/dependency>  &lt;dependency>    &lt;groupId>org.springframework&lt;/groupId>    &lt;artifactId>spring-jdbc&lt;/artifactId>    &lt;version>6.0.6&lt;/version>  &lt;/dependency>  &lt;dependency>    &lt;groupId>mysql&lt;/groupId>    &lt;artifactId>mysql-connector-java&lt;/artifactId>    &lt;version>8.0.31&lt;/version>  &lt;/dependency>  &lt;dependency>    &lt;groupId>javax.servlet&lt;/groupId>    &lt;artifactId>servlet-api&lt;/artifactId>    &lt;version>2.5&lt;/version>    &lt;scope>provided&lt;/scope>  &lt;/dependency>  &lt;dependency>    &lt;groupId>com.fasterxml.jackson.core&lt;/groupId>    &lt;artifactId>jackson-databind&lt;/artifactId>    &lt;version>2.13.4&lt;/version>  &lt;/dependency>&lt;/dependencies>ä¸€å®šè¦ä¸ºæˆ‘ä»¬çš„ servlet-api é…ç½®ä½œç”¨åŸŸä¸º providedï¼Œè¿™æ˜¯éå¸¸å¤§çš„ä¸€ä¸ªå‘ç‚¹ï¼ï¼ï¼\nå¦‚æœæ‚¨ä¸å°†  servlet-api  çš„ä½œç”¨åŸŸè®¾ç½®ä¸º  provided ï¼Œè€Œæ˜¯å°†å…¶ä½œç”¨åŸŸè®¾ç½®ä¸ºé»˜è®¤çš„  compile ï¼Œåˆ™å¯èƒ½ä¼šå¯¼è‡´ä»¥ä¸‹é—®é¢˜å’Œå½±å“ï¼š\n\nå†²çªé—®é¢˜ï¼š å¦‚æœæ‚¨çš„åº”ç”¨ç¨‹åºåŒ…å«äº†è‡ªå·±çš„ Servlet API å®ç°ï¼ˆä¾‹å¦‚ jar åŒ…ï¼‰ï¼Œè€Œ Web å®¹å™¨ä¹Ÿæä¾›äº†è‡ªå·±çš„å®ç°ï¼Œå¯èƒ½ä¼šå¯¼è‡´å†²çªå’Œä¸ç¨³å®šæ€§ã€‚\nç‰ˆæœ¬ä¸ä¸€è‡´ï¼š ä¸åŒçš„ Web å®¹å™¨å¯èƒ½ä½¿ç”¨ä¸åŒç‰ˆæœ¬çš„ Servlet APIï¼Œå¦‚æœæ‚¨å°† API åŒ…å«åœ¨åº”ç”¨ç¨‹åºä¸­ï¼Œå¯èƒ½ä¼šå¯¼è‡´ç‰ˆæœ¬ä¸ä¸€è‡´çš„é—®é¢˜ã€‚\nåº”ç”¨ç¨‹åºå¤§å°å¢åŠ ï¼š å°† Servlet API åŒ…å«åœ¨åº”ç”¨ç¨‹åºä¸­ä¼šå¢åŠ åº”ç”¨ç¨‹åºçš„å¤§å°ï¼Œå°½ç®¡è¿™åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹å¯èƒ½ä¸ä¼šå¯¹æ€§èƒ½äº§ç”Ÿæ˜æ˜¾å½±å“ï¼Œä½†ä»ç„¶ä¼šæµªè´¹ä¸€äº›èµ„æºã€‚\nç»´æŠ¤å›°éš¾ï¼š å¦‚æœæ‚¨åœ¨å¤šä¸ªé¡¹ç›®ä¸­é‡å¤åœ°åŒ…å« Servlet APIï¼Œå¯èƒ½ä¼šå¯¼è‡´ç»´æŠ¤ä¸Šçš„å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨æ›´æ–°ç‰ˆæœ¬æˆ–åˆ‡æ¢åˆ°ä¸åŒçš„ Web å®¹å™¨æ—¶ã€‚\n\n&lt;scope>provided&lt;/scope>ç¬¬äºŒæ­¥ï¼šå¯åŠ¨é…ç½®\nåœ¨è¿™é‡Œä½ å¯ä»¥é€‰æ‹©å¤–æŒ‚ Tomcat å’Œ Maven æ’ä»¶çš„ä¸¤ç§å¯åŠ¨æ–¹å¼ï¼Œåœ¨è¿™é‡Œæˆ‘é€‰æ‹©æ’ä»¶æ³•ï¼Œå› ä¸ºå¤–æŒ‚å¯åŠ¨çœŸçš„æ˜¯å¤ªæ…¢äº† QWQ\npom.xml æ–‡ä»¶ä¸­çš„ build æ ‡ç­¾ä¸‹é…ç½® tomcat æ’ä»¶ï¼š\n&lt;build>  &lt;finalName>SSM_demo&lt;/finalName>  &lt;plugins>    &lt;plugin>      &lt;groupId>org.apache.tomcat.maven&lt;/groupId>      &lt;artifactId>tomcat7-maven-plugin&lt;/artifactId>      &lt;version>2.2&lt;/version>      &lt;configuration>        &lt;port>80&lt;/port>        &lt;path>/&lt;/path>      &lt;/configuration>    &lt;/plugin>  &lt;/plugins>&lt;/build>80 ç«¯å£ä¸ºå¯åŠ¨ç«¯å£ï¼Œä½ ä¹Ÿå¯ä»¥è¿›è¡Œä¿®æ”¹ï¼Œä¾‹å¦‚ä¿®æ”¹åˆ° 8090\n&lt;port>8090&lt;/port>ç¬¬ä¸‰æ­¥ï¼šJava ç‰ˆæœ¬é…ç½®\nå…¶å®è¿™æ˜¯ä¸€ä¸ªå‘ç‚¹æˆ‘ä»¬éœ€è¦åœ¨ pom æ–‡ä»¶åŠ ä¸Šè¿™ä¸¤è¡Œï¼š\n&lt;properties>  &lt;maven.compiler.source>8&lt;/maven.compiler.source>  &lt;maven.compiler.target>8&lt;/maven.compiler.target>&lt;/properties>è¿™æ˜¯åœ¨å£°æ˜æˆ‘ä»¬çš„ Java ç‰ˆæœ¬ä¸º java8ï¼Œè¿™ä¸ªä¸€å®šè¦æ ¹æ®æˆ‘ä»¬é¡¹ç›®çš„ java ç‰ˆæœ¬æ¥å¡«å†™\n# æœ€ç»ˆå±•ç¤º\npom.xml&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0                       http://maven.apache.org/maven-v4_0_0.xsd\">  &lt;modelVersion>4.0.0&lt;/modelVersion>  &lt;groupId>com.KarryCode&lt;/groupId>  &lt;artifactId>SSM_demo&lt;/artifactId>  &lt;packaging>war&lt;/packaging>  &lt;properties>    &lt;maven.compiler.source>8&lt;/maven.compiler.source>    &lt;maven.compiler.target>8&lt;/maven.compiler.target>  &lt;/properties>  &lt;version>1.0-SNAPSHOT&lt;/version>  &lt;name>SSM_demo Maven Webapp&lt;/name>  &lt;url>http://maven.apache.org&lt;/url>  &lt;dependencies>    &lt;dependency>      &lt;groupId>junit&lt;/groupId>      &lt;artifactId>junit&lt;/artifactId>      &lt;version>4.13.2&lt;/version>      &lt;scope>test&lt;/scope>    &lt;/dependency>    &lt;dependency>      &lt;groupId>org.springframework&lt;/groupId>      &lt;artifactId>spring-webmvc&lt;/artifactId>      &lt;version>5.2.10.RELEASE&lt;/version>    &lt;/dependency>    &lt;dependency>      &lt;groupId>org.mybatis&lt;/groupId>      &lt;artifactId>mybatis&lt;/artifactId>      &lt;version>3.5.9&lt;/version>    &lt;/dependency>    &lt;dependency>      &lt;groupId>org.mybatis&lt;/groupId>      &lt;artifactId>mybatis-spring&lt;/artifactId>      &lt;version>2.0.7&lt;/version>    &lt;/dependency>    &lt;dependency>      &lt;groupId>org.springframework&lt;/groupId>      &lt;artifactId>spring-jdbc&lt;/artifactId>      &lt;version>5.0.2.RELEASE&lt;/version>    &lt;/dependency>    &lt;dependency>      &lt;groupId>mysql&lt;/groupId>      &lt;artifactId>mysql-connector-java&lt;/artifactId>      &lt;version>8.0.31&lt;/version>    &lt;/dependency>    &lt;dependency>      &lt;groupId>com.alibaba&lt;/groupId>      &lt;artifactId>druid&lt;/artifactId>      &lt;version>1.2.16&lt;/version>    &lt;/dependency>    &lt;dependency>      &lt;groupId>javax.servlet&lt;/groupId>      &lt;artifactId>servlet-api&lt;/artifactId>      &lt;version>2.5&lt;/version>      &lt;scope>provided&lt;/scope>    &lt;/dependency>    &lt;dependency>      &lt;groupId>com.fasterxml.jackson.core&lt;/groupId>      &lt;artifactId>jackson-databind&lt;/artifactId>      &lt;version>2.13.4&lt;/version>    &lt;/dependency>  &lt;/dependencies>  &lt;build>    &lt;finalName>SSM_demo&lt;/finalName>    &lt;plugins>      &lt;plugin>        &lt;groupId>org.apache.tomcat.maven&lt;/groupId>        &lt;artifactId>tomcat7-maven-plugin&lt;/artifactId>        &lt;version>2.2&lt;/version>        &lt;configuration>          &lt;port>80&lt;/port>          &lt;path>/&lt;/path>        &lt;/configuration>      &lt;/plugin>    &lt;/plugins>  &lt;/build>&lt;/project># åˆ›å»º JDBC.properties æ–‡ä»¶\nåœ¨ resource  ç›®å½•ä¸‹åˆ›å»º jdbc.properties\nJdbcPropertiesjdbc.driver = com.mysql.cj.jdbc.Driverjdbc.url = jdbc.username = jdbc.password =ç­‰å·åé¢çš„æ ¹æ®è‡ªå·±çš„éœ€è¦è¿›è¡Œå¡«å†™\nä¸ºäº†æµ‹è¯•ï¼Œæˆ‘è¿˜åˆ›å»ºçš„ä¸€å¼ è¡¨ï¼š\n\nè¿™æ˜¯æˆ‘çš„ç”Ÿæˆè„šæœ¬ï¼š\nç”Ÿæˆè„šæœ¬create table tb_book(    id          int auto_increment        primary key,    type        varchar(20)  null,    name        varchar(50)  null,    description varchar(255) null);# åˆ›å»º mapper ä»£ç†åŒ…\né¦–å…ˆåœ¨ resource ç›®å½•ä¸‹åˆ›å»ºä¸ java æºä»£ç ç›®å½•ä¸€æ ·çš„åŒ…ï¼Œåˆ‡è®°ä¸€å®šè¦ä»¥ â€œ/â€ çš„åˆ†å‰²å½¢å¼å»åˆ›å»ºï¼Œ\nä¾‹å¦‚ï¼šcom/KarryCode/mapper\nåˆ›å»ºå¥½åï¼Œåç½®åœ¨è¿™ä¸ªç›®å½•ä¸‹åˆ›å»ºå¯¹åº”çš„ xmlï¼Œæˆ‘ä»¬ç¨åå†è¯´ï¼\n# åˆ›å»ºé…ç½®æ–‡ä»¶ï¼ˆé…ç½®ç±»ï¼‰\nè¿™éƒ¨åˆ†å°†ä»¥é…ç½®ç±»çš„å½¢å¼è¿›è¡Œé…ç½®ã€‚\n# Spring_Mybatis æ•´åˆé…ç½®\né¦–å…ˆåœ¨ config åŒ…ä¸‹åˆ›å»º Spring_Mybatis é…ç½®ç±»\npackage com.KarryCode.config;import com.alibaba.druid.pool.DruidDataSource;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.annotation.MapperScan;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;import org.springframework.transaction.annotation.EnableTransactionManagement;import javax.sql.DataSource;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @ClassName SpringConfig * @Description TODO Spring æ ¸å¿ƒé…ç½®ç±» * @Version 1.0 */@Configuration                                  //TODO æ ¸å¿ƒé…ç½®å”¯ä¸€æ ‡è¯†@ComponentScan(&#123;\"com.KarryCode.service\",\"com.KarryCode.bean\"&#125;)     //TODO æ³¨è§£æ‰«ææŒ‡å®šåŒ…@PropertySource(\"classpath:jdbc.properties\")    //TODO åŠ è½½ JDBC é…ç½®ç±»@MapperScan(\"com.KarryCode.mapper\")             //TODO MyBatis åŸºäºåŒ…æ‰«ææ–¹å¼è¯†åˆ« Mapper@EnableTransactionManagement                    //TODO äº‹åŠ¡çš„è‡ªåŠ¨ä»£ç†ï¼Œæ³¨è§£é©±åŠ¨public class Spring_MybatisConfig &#123;    @Bean    //TODO DruidDataSource æ•°æ®æºçš„äº§ç”Ÿ    public DataSource dataSource(            @Value(\"$&#123;jdbc.driver&#125;\") String driver,            @Value(\"$&#123;jdbc.url&#125;\") String url,            @Value(\"$&#123;jdbc.username&#125;\") String username,            @Value(\"$&#123;jdbc.password&#125;\") String password    ) &#123;        DruidDataSource dataSource = new DruidDataSource();        dataSource.setDriverClassName(driver);        dataSource.setUrl(url);        dataSource.setUsername(username);        dataSource.setPassword(password);        // é‡Œé¢è¿˜å¯ä»¥é…ç½®æ›´å¤šå…³äºæ•°æ®åº“è¿æ¥æ± çš„é€‰é¡¹.......        return dataSource;    &#125;    @Bean    public SqlSessionFactoryBean sqlSessionFactoryBean(DataSource dataSource) &#123;        //TODO sqlSessionFactoryBean MybatisBeans åŠ è½½        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();        sqlSessionFactoryBean.setDataSource(dataSource);        return sqlSessionFactoryBean;    &#125;    @Bean    public PlatformTransactionManager transactionManager(DataSource dataSource) &#123;        //TODO å¹³å°äº‹åŠ¡ç®¡ç†        DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager();        dataSourceTransactionManager.setDataSource(dataSource);        return dataSourceTransactionManager;    &#125;&#125;å…·ä½“å†…å®¹ä¸å±•å¼€è®²è§£ï¼Œä¸»è¦æ¦‚è¿°ä¸€ä¸‹æ³¨è§£ä»¥åŠæ–¹æ³•çš„ä½œç”¨ï¼š\n@MapperScanï¼šæŒ‡å®šåŒ…æ‰«æçš„è·¯å¾„ã€‚\nDataSource dataSourceï¼šæ•°æ®æºçš„äº§ç”Ÿã€‚\nPlatformTransactionManager transactionManagerï¼šäº‹åŠ¡äº¤ç”± Spring ç®¡ç†ã€‚\n# SpringMVC æ•´åˆé…ç½®\nåŒæ ·åœ°ï¼Œåœ¨ config åŒ…ä¸‹åˆ›å»º SpringMvcConfig\npackage com.KarryCode.config;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @PackageName com.KarryCode.config * @ClassName SpringMvcConfig * @Description TODO * @Version 1.0 */@Configuration@EnableWebMvc@ComponentScan(\"com.KarryCode.controller\")public class SpringMvcConfig &#123;&#125;# Servlet-api æ•´åˆé…ç½®\nåŒæ ·åœ°ï¼Œåœ¨ config åŒ…ä¸‹åˆ›å»º ServletConfig\npackage com.KarryCode.config;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;public class ServletConfig extends AbstractAnnotationConfigDispatcherServletInitializer &#123;    @Override    protected Class&lt;?>[] getRootConfigClasses() &#123;        return new Class[]&#123;Spring_MybatisConfig.class&#125;;    &#125;    @Override    protected Class&lt;?>[] getServletConfigClasses() &#123;        return new Class[]&#123;SpringMvcConfig.class&#125;;    &#125;    @Override    protected String[] getServletMappings() &#123;        return new String[]&#123;\"/\"&#125;;    &#125;&#125;æ­¤æ—¶çš„ç›®å½•ç»“æ„æ˜¯è¿™æ ·çš„ï¼š\n\nè‡³æ­¤ï¼Œæ•´åˆå·²ç»åŸºæœ¬å®Œæˆï¼\n# Bean å®ä½“ç±»åˆ›å»º\næ ¹æ®æ•°æ®åº“é‡Œçš„ä»¥åŠé€»è¾‘å…³ç³»åˆ›å»º Bean å®ä½“ï¼Œåœ¨è¿™é‡Œæˆ‘å…ˆåˆ›å»ºä¸€ä¸ª Book å®ä½“\npackage com.KarryCode.bean;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @PackageName com.KarryCode.bean * @ClassName Book * @Description TODO * @Version 1.0 */public class Book &#123;    private Integer id;    private String type;    private String name;    private String description;    // çœç•¥ getter/setter/ æ„é€ å™¨ï¼ˆæœ‰å‚ / æ— å‚ï¼‰/toString&#125;# mapper æ¥å£åˆ›å»º\nåœ¨ mapper åŒ…ä¸‹åˆ›å»ºä¸€ä¸ª mapper æ¥å£ BookMapper\npackage com.KarryCode.mapper;import com.KarryCode.bean.Book;import org.apache.ibatis.annotations.*;import java.util.List;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @PackageName com.KarryCode.mapper * @ClassName BookMapper * @Description TODO * @Version 1.0 */public interface BookMapper &#123;    @Insert(\"insert into ssm_db.tb_book values (null,#&#123;type&#125;,#&#123;name&#125;,#&#123;description&#125;)\")    int save(Book book);    @Update(\"update ssm_db.tb_book set type=#&#123;type&#125;,name=#&#123;name&#125;,description=#&#123;description&#125; where id=#&#123;id&#125;\")    int update(Book book);    @Delete(\"delete from ssm_db.tb_book where tb_book.id=#&#123;id&#125;\")    int delete(Integer id);    @Select(\"select * from ssm_db.tb_book where id=#&#123;id&#125;\")    @ResultType(Book.class)    Book getBookById(Integer id);    @Select(\"select * from ssm_db.tb_book\")    List&lt;Book> getBookList();&#125;é€šè¿‡æ³¨è§£æ–¹å¼é…ç½®äº†å¢åˆ æ”¹æŸ¥å››ç§æ–¹æ³•\n# mapper ä»£ç† xml åˆ›å»º\nè™½ç„¶æ²¡å•¥ç”¨ï¼Œä½†æ˜¯åˆ›å»ºäº†ä¹Ÿæ²¡ä»€ä¹ˆåå¤„ï¼Œåœ¨ resource çš„å¯¹åº”ç›®å½•ä¸‹åˆ›å»º BookMapper.xml\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?>&lt;!DOCTYPE mapper        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"        \"https://mybatis.org/dtd/mybatis-3-mapper.dtd\">&lt;mapper namespace=\"com.KarryCode.mapper.BookMapper\">&lt;/mapper># Service é€»è¾‘åˆ›å»º\nBookService æ¥å£\npackage com.KarryCode.service;import com.KarryCode.bean.Book;import org.springframework.transaction.annotation.Transactional;import java.util.List;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @ClassName BookService * @Description TODO * @Version 1.0 */@Transactionalpublic interface BookService &#123;    /**     * @param book     * @return boolean     * @Author KarryLiu_åˆ˜ç‚ç‘     * @Date 2023/8/14 ä¸‹åˆ 10:58     * @Description TODO ä¿å­˜     */    boolean save(Book book);    /**     * @param book     * @return boolean     * @Author KarryLiu_åˆ˜ç‚ç‘     * @Date 2023/8/14 ä¸‹åˆ 10:58     * @Description TODO ä¿®æ”¹     */    boolean update(Book book);    /**     * @param id     * @return boolean     * @Author KarryLiu_åˆ˜ç‚ç‘     * @Date 2023/8/14 ä¸‹åˆ 10:58     * @Description TODO æ ¹æ® id åˆ é™¤     */    boolean delete(Integer id);    /**     * @param id     * @return edu.beihua.bean.Book     * @Author KarryLiu_åˆ˜ç‚ç‘     * @Date 2023/8/14 ä¸‹åˆ 10:59     * @Description TODO æ ¹æ® id æŸ¥è¯¢     */    Book getBookById(Integer id);    /**     * @param     * @return java.util.List&lt;edu.beihua.bean.Book>     * @Author KarryLiu_åˆ˜ç‚ç‘     * @Date 2023/8/14 ä¸‹åˆ 10:59     * @Description TODO æŸ¥è¯¢å…¨éƒ¨     */    List&lt;Book> getBookList();&#125;BookService æ¥å£å®ç°\npackage com.KarryCode.service.impl;import com.KarryCode.bean.Book;import com.KarryCode.mapper.BookMapper;import com.KarryCode.service.BookService;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.util.List;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @Date 2023/8/14 ä¸‹åˆ 10:43 * @ClassName BookServiceImpl * @Description TODO * @Version 1.0 */@Servicepublic class BookServiceImpl implements BookService &#123;    @Resource    private BookMapper bookMapper;    @Override    public boolean save(Book book) &#123;        System.out.println(\"save=====>Service\");        int save = bookMapper.save(book);        if (save>0)&#123;            return true;        &#125;else &#123;            return false;        &#125;    &#125;    @Override    public boolean update(Book book) &#123;        System.out.println(\"update=====>Service\");        bookMapper.update(book);        return true;    &#125;    @Override    public boolean delete(Integer id) &#123;        System.out.println(\"delete=====>Service\");        bookMapper.delete(id);        return true;    &#125;    @Override    public Book getBookById(Integer id) &#123;        System.out.println(\"getBookById=====>Service\");        Book book = bookMapper.getBookById(id);        return book;    &#125;    @Override    public List&lt;Book> getBookList() &#123;        System.out.println(\"getBookList=====>Service\");        return bookMapper.getBookList();    &#125;&#125;# Springâ€”Mybatis é€šè·¯æ£€æµ‹\nç¼–å†™æµ‹è¯•ç±»ï¼Œè§‚å¯Ÿè¾“å‡º\nimport com.KarryCode.bean.Book;import com.KarryCode.config.Spring_MybatisConfig;import com.KarryCode.service.BookService;import org.junit.Test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import java.util.List;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @PackageName PACKAGE_NAME * @ClassName mybatisTest * @Description TODO * @Version 1.0 */public class mybatisSpringTest &#123;    @Test    public void testMybatisSpring()&#123;        AnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(Spring_MybatisConfig.class);        BookService bookService = annotationConfigApplicationContext.getBean(BookService.class);        List&lt;Book> bookList = bookService.getBookList();        System.out.println(bookList);    &#125;&#125;è¾“å‡º\n\nä¿¡æ¯: {dataSource-1} inited\ngetBookList=====&gt;Service\n [Book {id=1, type=â€˜è®¡ç®—æœºâ€™, name=â€˜è½¯ä»¶å·¥ç¨‹â€™, description=â€˜å¼å¼å¼å¼â€™}, Book {id=2, type=â€˜æ–‡å­¦â€™, name=â€˜å„’å®¶ç»å…¸â€™, description=â€˜å„’å®¶å¥½ä¹¦å•Šï¼ï¼ï¼ï¼ï¼â€™}, Book {id=3, type=â€˜ç§‘æŠ€â€™, name=â€˜ç™¾ç§‘å…¨ä¹¦â€™, description=â€˜çœŸä¸é”™ï¼ï¼ï¼ï¼â€™}, Book {id=4, type=â€˜ç¾æœ¯â€™, name=â€˜å½“ä»£é¡¶æµç¾æœ¯â€™, description=â€˜å¥½ä¹¦å•Šå¥½ä¹¦ï¼ï¼ï¼ï¼â€™}, Book {id=6, type=â€˜ç§‘æŠ€â€™, name=â€˜ç™¾ç§‘å…¨ä¹¦â€™, description=â€˜çœŸä¸é”™ï¼ï¼ï¼ï¼â€™}, Book {id=7, type=â€˜ç§‘æŠ€â€™, name=â€˜ç™¾ç§‘å…¨ä¹¦â€™, description=â€˜çœŸä¸é”™ï¼ï¼ï¼ï¼â€™}]\nè¿›ç¨‹å·²ç»“æŸï¼Œé€€å‡ºä»£ç  0\n\n\nè‡³æ­¤ï¼ŒSpringâ€”Mbatis æ•´åˆå®Œæˆ\n# æ„å»º Controller\nåœ¨ controller åŒ…ä¸‹åˆ›å»º BookController\npackage com.KarryCode.controller;import com.KarryCode.bean.Book;import com.KarryCode.service.BookService;import org.springframework.transaction.annotation.Transactional;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;import java.util.List;/** * @Author KarryLiu * @Creed may all the beauty be blessed * @PackageName com.KarryCode.controller * @ClassName BookController * @Description TODO * @Version 1.0 */@RestController@Transactional@RequestMapping(\"/books\")public class BookController &#123;    @Resource    private BookService bookService;    @PostMapping    public boolean save(@RequestBody Book book) &#123;        return bookService.save(book);    &#125;    @PutMapping    public boolean update(@RequestBody Book book) &#123;        return bookService.update(book);    &#125;    @DeleteMapping(\"/&#123;id&#125;\")    public boolean delete(@PathVariable Integer id) &#123;        return bookService.delete(id);    &#125;    @GetMapping(\"/&#123;id&#125;\")    public Book getBookById(@PathVariable Integer id) &#123;        return bookService.getBookById(id);    &#125;    @GetMapping    public List&lt;Book> getBookList() &#123;        return bookService.getBookList();    &#125;&#125;ç¬¦åˆ Restful è®¾è®¡å»ºè®®ã€‚\n# å¯åŠ¨ Tomcat\n\n# Postman æ¥å£æµ‹è¯•\n# å­˜ä¹¦æµ‹è¯•\n\n\nsuccess\n\n# æŸ¥ä¹¦æµ‹è¯•\n# æŸ¥è¯¢å…¨éƒ¨\n\n# æŒ‡å®š id æŸ¥ä¹¦\n\n# æ›´æ–°ä¹¦\n\n\n# åˆ é™¤æµ‹è¯•\n\n\næ‰€æœ‰æ¥å£æµ‹è¯•è°ƒé€šï¼Œè‡³æ­¤ SSM æ•´åˆå®Œæ¯•\n# æ€»ç»“\nå…¶å® SSM æ•´åˆè¿˜æ˜¯æ¯”è¾ƒç®€å•çš„ï¼Œé€šè¿‡ä¸‰ä¸ªæ¡†æ¶çš„é…ç½®å°±å¯ä»¥å®Œæˆäº†ï¼Œåé¢çš„å·¥ä½œéƒ½æ˜¯åœ¨è¿›è¡Œä¸šåŠ¡åˆ›å»ºã€‚\nå¥½äº†ï¼æœ¬ç¯‡æ–‡ç« åˆ°è¿™é‡Œå°±ç»“æŸäº†ï¼Œæœ‰ä»€ä¹ˆä¸ç†è§£çš„åœ°æ–¹æˆ–è€…æœ‰ç–‘é—®çš„åœ°æ–¹è¯·åœ¨è¯„è®ºåŒºç•™è¨€ï¼Œæˆ–è€…æ·»åŠ æˆ‘çš„è”ç³»æ–¹å¼ï¼Œæ¬¢è¿å„ä½å¤§ä½¬ç§¯ææ‰¹è¯„è®¨è®ºï¼è°¢è°¢ï¼\n","categories":["å¼€å‘ç»éªŒ"],"tags":["SSM"]},{"title":"å›æœ›2025â€”â€”æ°¸ä¸ç†„ç­ä¹‹å…‰","url":"/life/p2025/","content":"# æ°¸ä¸ç†„ç­ä¹‹å…‰\n2025 å¹´ï¼Œæ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜ä¹Ÿå……æ»¡å¸Œæœ›çš„å¹´ä»½ã€‚\nè¿™ä¸€å¹´ï¼Œæˆ‘ç»“æŸäº†å¤§å­¦ç”Ÿæ¶¯ï¼Œè¿›å…¥ç ”ç©¶ç”Ÿé˜¶æ®µã€‚\nè¿™ä¸€å¹´ï¼Œæˆ‘ä¸æ—§æ—¶å¥½å‹æŒ¥æ‰‹å‘Šåˆ«ï¼Œä¹Ÿç»“è¯†äº†è®¸å¤šæ–°æœ‹å‹ã€‚\nè¿™ä¸€å¹´ï¼Œæˆ‘å­¦ä¼šåœ¨ä¸ç¡®å®šä¸­å‰è¡Œï¼Œåœ¨å‹åŠ›ä¸è¿·èŒ«ä¸­å¯»æ‰¾æ–¹å‘ã€‚\nè¿™ä¸€å¹´ï¼Œä¹Ÿæ˜¯è‡ªæˆ‘æ€€ç–‘ä¸é‡å¡‘ä¿¡å¿µå½¼æ­¤äº¤ç»‡çš„ä¸€å¹´ã€‚\né‚£äº›çœ‹ä¼¼å¹³å‡¡çš„æ—¥å­ï¼Œç»ˆå°†åœ¨å›æœ›æ—¶ï¼Œæ±‡èšæˆå€¼å¾—çè—çš„è®°å¿†ã€‚\næˆ‘æ›¾åœ¨æ·±å¤œåå¤å®¡è§†è‡ªå·±çš„é€‰æ‹©ï¼Œä¹Ÿæ›¾åœ¨æ²‰é»˜ä¸­è´¨é—®å‰è·¯çš„æ„ä¹‰ã€‚\næ‰€è°“åšå®šï¼Œå¹¶éä»æœªåŠ¨æ‘‡ï¼Œ\nè€Œæ˜¯åœ¨ä¸€æ¬¡æ¬¡åŠ¨æ‘‡ä¹‹åï¼Œä»æ„¿æ„é€‰æ‹©å‰è¡Œã€‚\né‚£äº›æœªè¢«çœ‹è§çš„åŠªåŠ›ï¼Œé‚£äº›æ— äººçŸ¥æ™“çš„åšæŒï¼Œ\nå¦‚æš—å¤œä¸­çš„æ˜Ÿç«ï¼Œè™½å°ï¼Œå´è¶³ä»¥ç…§äº®æ¼«é•¿çš„è·¯ã€‚\nå¿ƒä¸­çš„é‚£æŸå…‰ï¼Œå†ç»é£é›¨ï¼Œä¾ç„¶æœªæ›¾ç†„ç­ã€‚\n2025 å¹´æˆ‘å¼€å¯äº†å…¨æ–°ç¯‡ç« ï¼Œå­¦ä¹ äº†å¾ˆå¤šæ–°æŠ€æœ¯ï¼Œ\nè¿™äº›çŸ¥è¯†ä¸ä»…æ”¹å˜äº†æˆ‘çš„å­¦ä¹ æ–¹å¼ï¼Œä¹Ÿé‡å¡‘äº†æˆ‘çœ‹å¾…é—®é¢˜çš„è§†è§’ï¼Œ\nè®©æˆ‘åœ¨æœªçŸ¥é¢å‰ï¼Œå°‘äº†ä¸€åˆ†ç•æƒ§ï¼Œå¤šäº†ä¸€åˆ†ä»å®¹ã€‚\nç”±æ­¤ï¼Œæˆ‘å°†å…¶ç§°ä¹‹ä¸ºï¼š2025 æ°¸ä¸ç†„ç­ä¹‹å…‰ã€‚\n\n2026 å¹´æˆ‘ä»å°†æŒç»­åŠªåŠ›ï¼Œä¸æ–­å­¦ä¹ æ–°æŠ€æœ¯ï¼Œå¥‹å‹‡å‰è¡Œã€‚\nç•…æ¸¸åœ¨è‰ºæœ¯ä¸ç¼–ç¨‹çš„æµ·æ´‹ä¸­ï¼Œ ç”¨ä»£ç è‰ºæœ¯ç¼–ç»‡æœªæ¥ã€‚\nSwim in the ocean of art and programming, weave the future with code art.\n","categories":["ç”Ÿæ´»"],"tags":["ç”Ÿæ´»"]},{"title":"å†™ç»™æˆ‘è¿™ä¸€å¹´å¤šçš„è€ƒç ”æ—¶å…‰","url":"/life/shangan/","content":"# 2024.01â€”â€”2025.03\næ˜¨å¤©æ”¶åˆ°äº†å­¦æ ¡çš„æ‹Ÿå½•å–é€šçŸ¥ï¼Œå¾ˆå¹¸è¿æˆ‘çš„åå­—å‡ºç°åœ¨äº†æ‹Ÿå½•å–åå•é‡Œï¼Œä¸€å¹´å¤šçš„åŠªåŠ›äºæ­¤åˆ»å…‘ç°ã€‚å›æƒ³ä¸€å¹´æ¥çš„æ—…é€”ï¼Œæˆ‘çœŸçš„æœ‰å¾ˆå¤šè¯æƒ³è¯´ã€‚\n# å‰å¥\næˆ‘å…¶å®å¾ˆæ—©ä¹‹å‰å°±å†³å®šè€ƒç ”äº†ï¼Œå¹¶ä¸æ˜¯è·Ÿé£è€ƒç ”å…šï¼Œæœ€åˆçš„è€ƒç ”ç›®çš„ä¹Ÿå¾ˆç®€å•ï¼Œä¸€æ˜¯æƒ³ä¸è‡ªå·±å’Œè§£ï¼Œå’Œåå…«å²çš„è‡ªå·±å’Œè§£ï¼Œä»¥æ­¤æ¥å¡«è¡¥é«˜è€ƒçš„é—æ†¾ï¼ŒäºŒæ˜¯å»æå‡ä¸€ä¸‹è‡ªå·±è‡ªèº«çš„ç«äº‰åŠ›ã€‚\nå°±è¿™æ ·ï¼Œæˆ‘åœ¨åˆšåˆšè¿›å…¥å¤§å­¦çš„æ—¶å€™ï¼Œå°±å·²ç»å†³å®šå¥½è€ƒç ”äº†ã€‚äº‹å®ä¸Šï¼Œæˆ‘æ˜¯ä¸€åè½¬ä¸“ä¸šçš„å­¦ç”Ÿï¼Œé«˜è€ƒçš„æ—¶å€™ç”±äºæˆç»©ä¸ç†æƒ³ï¼Œå¯¼è‡´æ²¡èƒ½å­¦ä¸Šè‡ªå·±æƒ³è¦çš„å­¦çš„ä¸“ä¸šï¼Œå¯¹æ­¤æˆ‘ååˆ†æ‡Šæ‚”ã€‚\nå’Œå¤§å¤šæ•°æ™®é€šäººä¸€æ ·ï¼Œæˆ‘æ˜¯ä¸€ä¸ªå ªç§°ç»å¯¹å¹³å‡¡çš„äººã€‚æ™®é€šäººç©¶ç«Ÿè¯¥æ€æ ·å‘ä¸Šï¼Œç©¶ç«Ÿè¯¥å¦‚ä½•ä¸€æ­¥æ­¥çš„æå‡è‡ªå·±ï¼Ÿæˆ‘çš„å›ç­”æ˜¯ï¼šè„šè¸å®åœ°ï¼Œä»°æœ›æ˜Ÿç©ºã€‚\n# å¯ç¨‹\n2024 å¹´ 1 æœˆï¼Œæˆ‘çœŸæ­£æ„ä¹‰ä¸Šçš„å¼€å¯çš„æˆ‘çš„è€ƒç ”ä¹‹è·¯ï¼Œæˆ‘è®¤ä¸ºæˆ‘è¿™ä¸ªæ—¶é—´èŠ‚ç‚¹ä¸ç®—æ—©ä¹Ÿä¸ç®—æ™šã€‚\n2024 çš„ â€œå¹´â€ æ˜¾å¾—æ ¼å¤–å‹æŠ‘ï¼Œæˆ‘è§‰å¾—è€ƒç ”å°±æ˜¯ä¸€åœºå®Œå…¨é»‘æš—çš„æ—…é€”ï¼Œä½ èƒ½ â€œå¬è§â€ åŒå­¦ä»¬çš„å£°éŸ³ï¼Œä½†æ˜¯ â€œçœ‹ä¸è§â€ ä»–ä»¬åœ¨å“ªé‡Œã€‚æœ‰äººè¯´ï¼Œè€ƒç ”å°±æ˜¯åœ¨é»‘å¤œé‡Œæ´—è¡£æœï¼Œä½ ä¸çŸ¥é“ä½ æ˜¯å¦æ´—å¹²å‡€äº†ï¼Œä½ åªèƒ½å°±è¿™æ ·åœ¨é»‘æš—ä¸­ç»§ç»­çš„æ´—ä¸‹å»ï¼Œç›´åˆ°å¤©æ˜ã€‚\n# æœˆå‡\nè¦è¯´ç§‘ç›®æ˜¯æˆ‘æŠ•å…¥æœ€å¤§çš„ï¼Œé‚£ä¸€å®šæ˜¯æ•°å­¦ã€‚æˆ‘æœ¬èº«æ•°å­¦åŸºç¡€è¾ƒå·®ï¼Œæˆ‘æˆ‘èŠ±è´¹å¾ˆé•¿æ—¶é—´å»å­¦ä¹ æ•°å­¦ï¼Œé—æ†¾çš„æ˜¯æœ€ç»ˆçš„æ•°å­¦æˆç»©å¹¶ä¸æ˜¯é‚£ä¹ˆç†æƒ³ï¼Œåœ¨è¿™é‡Œæˆ‘å°±ä¸çŒ®ä¸‘å»è®²æˆ‘æ˜¯æ€ä¹ˆå­¦ä¹ æ•°å­¦çš„äº†ï¼Œæˆ‘ä¸€å®šæ˜¯å¤´å·åé¢æ•™æã€‚è®²ä¸€å¥å°±æ˜¯å°‘çœ‹è¯¾ï¼Œå¤šç»ƒé¢˜ï¼Œå¤šç»ƒé¢˜ï¼Œå¤šç»ƒé¢˜ã€‚\nè‹±è¯­æ˜¯æˆ‘çš„è€å¤§éš¾é—®é¢˜ï¼Œè‹±è¯­çš„é—®é¢˜å®é™…ä¸Šè¦æ¯”æ•°å­¦è¿˜ç³Ÿç³•ï¼Œåœ¨å¤§å­¦æœŸé—´ï¼Œæˆ‘ä»…ä»…æ˜¯ 470 åˆ†è¿‡äº†å››çº§ï¼Œå…­çº§è€ƒäº†ä¸‰æ¬¡æ²¡è€ƒè¿‡ï¼Œæœ€åä¸€æ¬¡å…­çº§å·®äº†ä¸€é“é€‰æ‹©é¢˜çš„åˆ†æ•°ã€‚æˆ‘æƒ³è¯´ï¼Œè‹±è¯­ä½ è¦æŒæ¡è¶³å¤Ÿçš„è¯æ±‡é‡ï¼Œä¸€å®šè¦å¤šèƒŒå•è¯ï¼Œåªæœ‰ä½ è®¤è¯†å•è¯äº†ï¼Œæ‰ä¼šçœ‹æ‡‚ä¸€å¥è¯ï¼Œæ‰çŸ¥é“ä»–æƒ³è¡¨è¾¾ä»€ä¹ˆæ„æ€ï¼Œå…¶æ¬¡æ˜¯è¯­æ³•ï¼Œè¯­æ³•ä¹Ÿå¾ˆé‡è¦ï¼Œä½†æˆ‘è®¤ä¸ºï¼Œè¯­æ³•æ˜¯ä¸€ä¸ªé”¦ä¸Šæ·»èŠ±çš„ã€‚å•è¯ä¸€å®šæ˜¯å‰æï¼Œè®¤è¯†äº†è¶³å¤Ÿå¤šçš„å•è¯ä¹‹åï¼Œå†å­¦ä¸€å­¦è¯­æ³•ï¼Œé‚£ä¼šè®©ä½ æ›´åŠ å¦‚é±¼å¾—æ°´ã€‚å…¶æ¬¡æ˜¯åšé¢˜æŠ€å·§ï¼Œå°¤å…¶æ˜¯é˜…è¯»çš„åšé¢˜æŠ€å·§ï¼Œå¤šå’Œç½‘ä¸Šçš„è€å¸ˆå­¦ä¸€å­¦ï¼Œä½†æ˜¯ä¸è¦ä¾èµ–è¿™ä¸ªï¼Œåœ¨å­¦ä¹ ä¹‹åä¸€å®šè¦å½¢æˆä¸€å¥—è‡ªå·±çš„è§£é¢˜æ–¹å¼ã€‚ä½œæ–‡æˆ‘è§‰å¾—æ²¡ä»€ä¹ˆå¥½è¯´çš„ï¼Œå¤šèƒŒå¤šå†™å°±å¥½äº†ã€‚\næˆ‘æ˜¯ä¸€åçº¯çº¯ç†å·¥ç§‘çš„å­¦ç”Ÿï¼Œä¸Šä¸€æ¬¡è®¤çœŸå­¦æ”¿æ²»è¿˜æ˜¯åœ¨åˆä¸­ï¼Œæˆ‘åœ¨è¿™é‡Œè®²ä¸€è®²æ€ä¹ˆç”¨ç†å·¥ç§‘çš„æ€ç»´å»å­¦æ”¿æ²»ï¼Œæˆ‘å†è¡¥å……ä¸€å¥ï¼Œå¦‚æœä½ å®Œå…¨ç”¨ç†å·¥çš„æ€ç»´å»å­¦æ”¿æ²»ï¼Œé‚£æˆ‘æƒ³è¯´ï¼Œé‚£å¾ˆéš¾å­¦å¥½æ”¿æ²»ã€‚è¿™é‡Œçš„ç†å·¥æ€ç»´ä¸€å®šè¦èå…¥ä¸€äº›æ–‡ç§‘æ€æƒ³ã€‚æ”¿æ²»ä¸€å®šè¦å»äº†è§£å†å²ï¼Œå†å²æ˜¯ç”±äººæ°‘ç¾¤ä¼—åˆ›é€ çš„ï¼Œåªæœ‰ä½ äº†è§£äº†å†å²ï¼Œç†è§£å½“æ—¶ä»–ä»¬çš„å¤„å¢ƒï¼Œä¸ä¹‹å…±æƒ…ï¼Œä½ æ‰èƒ½æ˜ç™½ï¼Œä¸ºä»€ä¹ˆä»–ä»¬è¿™æ ·åšï¼Œä»¥åŠè¿™æ ·åšçš„å¥½å¤„ã€‚åœ¨ç­”é¢˜æ—¶å€™ï¼ŒåŠ å…¥ä¸€äº›ç†å·¥æ€ç»´çš„å…¬å¼ï¼Œå¦‚æœçœŸæ­£æƒ³å­¦å¥½ä»…é ä¸€äº›ç­”é¢˜å…¬å¼è¿˜æ˜¯ä¸è¡Œçš„ï¼Œä½†æ˜¯å‘¢æˆ‘ä»¬è¿™ä¸ªæ˜¯ä¸€ä¸ªé€Ÿæˆï¼Œæˆ–è€…æ˜¯é¢å¯¹ä¸€ä¸ªå®Œå…¨æ²¡æ€ä¹ˆå¥½å¥½å­¦è¿‡æ”¿æ²»çš„äººæ¥è¯´çš„ã€‚å¿…è¦æ—¶ç”¨ä¸€äº›æ¨¡æ¿ï¼Œå…¬å¼åŒ–ç­”é¢˜ï¼Œæ˜¯ååˆ†æœ‰åˆ©çš„ã€‚\nä¸“ä¸šè¯¾æ–¹é¢æˆ‘å°±ä¸å¤šè®²äº†ï¼Œæˆ‘è®¤ä¸ºæˆ‘è¿™æ–¹é¢è¿˜æ˜¯æ¯”è¾ƒæ“…é•¿çš„ã€‚è¿˜æ˜¯å¤šç»ƒå¤šç†è§£ï¼Œæ¯•ç«Ÿè¿™æ˜¯ä½ åƒé¥­çš„å·¥å…·å‘€ã€‚\n# æœˆè½\né»æ˜å‰çš„æ—¥å­æœ€ç…ç†¬ï¼Œç½‘ä¸Šæˆ‘å¥½åƒä»æ¥æ²¡çœ‹è§è¿‡ï¼Œæœ‰äººè¯´åˆè¯•ç»“æŸåï¼Œå¤è¯•æœ‰å¤šéš¾ã€‚å…¶å®ä¹Ÿä¸èƒ½è¯´éš¾ï¼Œä½†æ˜¯è¿™æ®µæ—¥å­æå…¶ç—›è‹¦ã€æŠ˜ç£¨ä¸éš¾ç†¬ã€‚\næˆç»©å‡ºæ¥åï¼Œå­¦æ ¡ä¸å…¬å¸ƒæ’åï¼ŒåŒå­¦ä»¬è‡ªå‘åœ¨ç½‘ä¸Šå»æ’åï¼Œæ¯ä¸€å¤©ä½ çœ‹è§ä½ çš„æ’åå¾€ä¸‹æ‰ï¼Œæ•´ä¸ªäººéƒ½ down down çš„ï¼Œè¿™ç§æ„Ÿè§‰å¾ˆéš¾å½¢å®¹ï¼Œå¾ˆéš¾å—ã€‚æœ€ååœ¨å¤è¯•å‰ï¼Œå­¦æ ¡è¿˜æ˜¯å…¬å¸ƒäº†æ’åã€‚ä»Šå¹´æ‹›ç”Ÿäººæ•° 35 äººï¼Œè¿›å¤è¯• 44 äººï¼Œæˆ‘æ’åœ¨ 35 åã€‚è¿™ä¸ªæ—¶å€™æˆ‘è§‰å¾—çœŸçš„å¾ˆéš¾ä¿æŒä¸€ä¸ªè‰¯å¥½çš„å¿ƒæ€ï¼Œè¿™æ˜¯æˆ‘è§‰å¾—è€ƒç ”æœ€æŠ˜ç£¨çš„ä¸€ä¸ªç‚¹ã€‚æ²¡åŠæ³•ï¼Œå¤è¯•è¿˜è¦ç»§ç»­å‡†å¤‡ï¼Œæ­¤åˆ»ä¾¿æ˜¯è‡³æš—ã€‚\n# å¾®å…‰\nå¤è¯•ç»“æŸï¼Œä¸€å¤©åå…¬å¸ƒäº†æœ€ç»ˆæ’åï¼Œæˆ‘ä»¥å¤è¯•ç¬”è¯•ç¬¬ä¸€åï¼Œå¤è¯•æˆç»©ç¬¬å››åï¼Œæ€»æˆç»©ç¬¬åä¸ƒåæ‹Ÿå½•å–äº†ã€‚\næˆ‘æƒ³è¯´å¤è¯•çœŸçš„å¾ˆé‡è¦ï¼Œæˆ‘ä»¬å­¦æ ¡çš„å¤è¯• 1 åˆ†ï¼Œå°±æ˜¯åˆè¯• 1.07 åˆ†ï¼Œå¤è¯•å’Œåˆå§‹åŒç­‰é‡è¦ã€‚æ‹Ÿå½•å–çš„é‚£ä¸€åˆ»çŠ¹å¦‚åšæ¢¦ä¸€æ ·ï¼Œæˆ‘ä¸æ•¢ç›¸ä¿¡ï¼Œæˆ‘åå¤ç¡®è®¤æˆ‘çœŸçš„æ‹Ÿå½•å–äº†ï¼Œç”Ÿæ€•è¿™ä¸€åˆ‡å…¨æ˜¯æ¢¦å¢ƒã€‚\næ˜¯çœŸçš„ã€‚\n# å›æœ›\nå›æœ›æˆ‘è¿™ä¸€å¹´å¤šçš„æ—…ç¨‹ï¼Œæœ‰æ¬¢ç¬‘ï¼Œæœ‰æ³ªæ°´ï¼Œæ­¤åˆ»æˆ‘æƒ³å¯¹è‡ªå·±è¯´ï¼Œä½ çœŸçš„å¾ˆæ£’ï¼Œä½ ç«™åœ¨ä½ æ›¾ç»å¹»æƒ³è¿‡çš„æœªæ¥ï¼Œäºæ­¤åˆ»ï¼Œä¸å†æ˜¯å¹»æƒ³ã€‚\nâ€œå¤¹å²¸ç¾¤èŠ³ç›¸é€è¿œå¸†è¿‡åƒéšœç¢â€\n","categories":["ä¸Šå²¸"],"tags":["ç”Ÿæ´»"]},{"title":"çŸ©é˜µè®º","url":"/math/matrix_anl/","content":"# çŸ©é˜µè®º\n# çº¿æ€§å˜æ¢ T åœ¨åŸºåº•ä¸‹çš„çŸ©é˜µ\nå®šä¹‰å¦‚ä¸‹ï¼š\nT(Î±1,Î±2,Î±3â€¦Î±n)=(Î±1,Î±2,Î±3â€¦Î±n)AT(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)=(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)A\nT(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)=(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)A\nè¿™ä¸ªé¢˜ç›®è¾ƒä¸ºçµæ´»ï¼Œæœ€å¤æ‚æƒ…å†µå¦‚ä¸‹ï¼š\nT(Î±1,Î±2,Î±3â€¦Î±n)=(Î±1,Î±2,Î±3â€¦Î±n)AT(Î²1,Î²2,Î²3â€¦Î²n)=(Î²1,Î²2,Î²3â€¦Î²n)B(Î²1,Î²2,Î²3â€¦Î²n)=(Î±1,Î±2,Î±3â€¦Î±n)CT(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)=(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)A\n\\\\\nT(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)=(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)B\n\\\\\n(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)=(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)C\nT(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)=(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)AT(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)=(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)B(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)=(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)C\nä¸€èˆ¬å·²çŸ¥è¿‡åº¦çŸ©é˜µ C å’ŒåŸºä¸‹çŸ©é˜µ Aï¼ŒC æ˜¯ç”±Î±\\alphaÎ±ï¼Œè¿‡æ¸¡åˆ°Î²\\betaÎ² çš„ï¼Œæ ¸å¿ƒåœ¨äºæ±‚ Bï¼š\nT(Î±1,Î±2,Î±3â€¦Î±n)=(Î±1,Î±2,Î±3â€¦Î±n)A(Î²1,Î²2,Î²3â€¦Î²n)Câˆ’1=(Î±1,Î±2,Î±3â€¦Î±n)T(Î²1,Î²2,Î²3â€¦Î²n)Câˆ’1=(Î²1,Î²2,Î²3â€¦Î²n)Câˆ’1AT(Î²1,Î²2,Î²3â€¦Î²n)=(Î²1,Î²2,Î²3â€¦Î²n)Câˆ’1AC(Î²1,Î²2,Î²3â€¦Î²n)Câˆ’1AC=(Î²1,Î²2,Î²3â€¦Î²n)BB=Câˆ’1ACT(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)=(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)A\n\\\\\n(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)C^{-1}=(\\alpha_1,\\alpha_2,\\alpha_3\\dots\\alpha_n)\n\\\\\nT(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)C^{-1}=(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)C^{-1}A\n\\\\\nT(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)=(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)C^{-1}AC\n\\\\\n(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)C^{-1}AC=(\\beta_1,\\beta_2,\\beta_3\\dots\\beta_n)B\n\\\\\nB=C^{-1}AC\nT(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)=(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)A(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)Câˆ’1=(Î±1â€‹,Î±2â€‹,Î±3â€‹â€¦Î±nâ€‹)T(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)Câˆ’1=(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)Câˆ’1AT(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)=(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)Câˆ’1AC(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)Câˆ’1AC=(Î²1â€‹,Î²2â€‹,Î²3â€‹â€¦Î²nâ€‹)BB=Câˆ’1AC\n\nä¾‹ä¸€ï¼šå·²çŸ¥çº¿æ€§å˜æ¢ T åœ¨åŸºåº•Î·1=(âˆ’1,1,1)T,Î·2=(1,0,âˆ’1)T,Î·3=(0,1,1)T\\eta_1=(-1,1,1)^T,\\eta_2=(1,0,-1)^T,\\eta_3=(0,1,1)^TÎ·1â€‹=(âˆ’1,1,1)T,Î·2â€‹=(1,0,âˆ’1)T,Î·3â€‹=(0,1,1)T ä¸‹çš„çŸ©é˜µ\nA=[101110âˆ’121]A=\\begin{bmatrix}\n 1 &amp; 0 &amp; 1\\\\\n 1 &amp; 1 &amp; 0\\\\\n -1 &amp; 2 &amp; 1\n\\end{bmatrix}\nA=â£â¢â¡â€‹11âˆ’1â€‹012â€‹101â€‹â¦â¥â¤â€‹\næ±‚åœ¨åŸºåº•e1=(1,0,0)T,e2=(0,1,0)T,e3=(0,0,1)Te_1=(1,0,0)^T,e_2=(0,1,0)^T,e_3=(0,0,1)^Te1â€‹=(1,0,0)T,e2â€‹=(0,1,0)T,e3â€‹=(0,0,1)T ä¸‹çš„çŸ©é˜µã€‚\nè§£\nç”±é¢˜å¯çŸ¥ï¼š\nT(Î·1,Î·2,Î·3)=(Î·1,Î·2,Î·3)AT(e1,e2,e3)=(e1,e2,e3)B(e1,e2,e3)=(Î·1,Î·2,Î·3)CT(\\eta_1,\\eta_2,\\eta_3)=(\\eta_1,\\eta_2,\\eta_3)A\n\\\\\nT(e_1,e_2,e_3)=(e_1,e_2,e_3)B\n\\\\\n(e_1,e_2,e_3)=(\\eta_1,\\eta_2,\\eta_3)C\nT(Î·1â€‹,Î·2â€‹,Î·3â€‹)=(Î·1â€‹,Î·2â€‹,Î·3â€‹)AT(e1â€‹,e2â€‹,e3â€‹)=(e1â€‹,e2â€‹,e3â€‹)B(e1â€‹,e2â€‹,e3â€‹)=(Î·1â€‹,Î·2â€‹,Î·3â€‹)C\nC å¯ä»¥è½»æ˜“çš„æ±‚è§£å‡ºæ¥ï¼š\nC=(Î·1,Î·2,Î·3)âˆ’1(e1,e2,e3)=[âˆ’1101011âˆ’11]âˆ’1â‹…[100010001]=[âˆ’11âˆ’101âˆ’1101]Câˆ’1=[âˆ’1101011âˆ’11]C=(\\eta_1,\\eta_2,\\eta_3)^{-1}(e_1,e_2,e_3)=\\begin{bmatrix}\n -1 &amp; 1 &amp; 0\\\\\n 1 &amp; 0 &amp; 1\\\\\n 1 &amp; -1 &amp; 1\n\\end{bmatrix}^{-1} \\cdot \\begin{bmatrix}\n 1 &amp; 0 &amp; 0\\\\\n 0 &amp; 1 &amp; 0\\\\\n 0 &amp; 0 &amp; 1\n\\end{bmatrix}=\\begin{bmatrix}\n -1 &amp; 1 &amp; -1\\\\\n 0 &amp; 1 &amp; -1\\\\\n 1 &amp; 0 &amp; 1\n\\end{bmatrix}\n\\\\\nC^{-1}=\\begin{bmatrix}\n -1 &amp; 1 &amp; 0\\\\\n 1 &amp; 0 &amp; 1\\\\\n 1 &amp; -1 &amp; 1\n\\end{bmatrix}\nC=(Î·1â€‹,Î·2â€‹,Î·3â€‹)âˆ’1(e1â€‹,e2â€‹,e3â€‹)=â£â¢â¡â€‹âˆ’111â€‹10âˆ’1â€‹011â€‹â¦â¥â¤â€‹âˆ’1â‹…â£â¢â¡â€‹100â€‹010â€‹001â€‹â¦â¥â¤â€‹=â£â¢â¡â€‹âˆ’101â€‹110â€‹âˆ’1âˆ’11â€‹â¦â¥â¤â€‹Câˆ’1=â£â¢â¡â€‹âˆ’111â€‹10âˆ’1â€‹011â€‹â¦â¥â¤â€‹\næ±‚åŸºåº• e ä¸‹çš„çŸ©é˜µæ­£æ˜¯çŸ©é˜µ Bï¼Œäºæ˜¯æœ‰ï¼š\nB=Câˆ’1ACB=C^{-1}AC\nB=Câˆ’1AC\n\n# åŸºä¸‹çš„åæ ‡\nä¸€èˆ¬æ˜¯å·²çŸ¥åæ ‡(y1,y2,y3)T(y_1,y_2,y_3)^{T}(y1â€‹,y2â€‹,y3â€‹)Tï¼Œæ±‚å…¶åœ¨åŸºåº•(Î·1,Î·2,Î·3)(\\eta_1,\\eta_2,\\eta_3)(Î·1â€‹,Î·2â€‹,Î·3â€‹)ï¼Œä¸‹çš„åæ ‡(x1,x2,x3)T(x_1,x_2,x_3)^T(x1â€‹,x2â€‹,x3â€‹)Tï¼Œä¸€èˆ¬è¡¨ç¤ºä¸ºï¼š\nY=AX[y1y2y3]=[Î·1,Î·2,Î·3]â‹…[x1x2x3]Y=AX\n\\\\\n\\begin{bmatrix}\n y_1 \\\\\n y_2 \\\\\n y_3 \n\\end{bmatrix}=\\begin{bmatrix}\\eta_1,\\eta_2,\\eta_3\\end{bmatrix}\\cdot\\begin{bmatrix}\n x_1 \\\\\n x_2 \\\\\n x_3 \n\\end{bmatrix}\nY=AXâ£â¢â¡â€‹y1â€‹y2â€‹y3â€‹â€‹â¦â¥â¤â€‹=[Î·1â€‹,Î·2â€‹,Î·3â€‹â€‹]â‹…â£â¢â¡â€‹x1â€‹x2â€‹x3â€‹â€‹â¦â¥â¤â€‹\næ±‚è§£ xï¼š\n[x1x2x3]=[Î·1,Î·2,Î·3]âˆ’1â‹…[y1y2y3]\\begin{bmatrix}\n x_1 \\\\\n x_2 \\\\\n x_3 \n\\end{bmatrix}=\\begin{bmatrix}\\eta_1,\\eta_2,\\eta_3\\end{bmatrix}^{-1}\\cdot\\begin{bmatrix}\n y_1 \\\\\n y_2 \\\\\n y_3 \n\\end{bmatrix}\nâ£â¢â¡â€‹x1â€‹x2â€‹x3â€‹â€‹â¦â¥â¤â€‹=[Î·1â€‹,Î·2â€‹,Î·3â€‹â€‹]âˆ’1â‹…â£â¢â¡â€‹y1â€‹y2â€‹y3â€‹â€‹â¦â¥â¤â€‹\n# å†…ç§¯çš„è¯æ˜\nè¦æ»¡è¶³å¦‚ä¸‹æ€§è´¨ï¼š\n(Î±,Î²)=(Î²,Î±)â€¾(kÎ±,Î²)=k(Î±,Î²)(Î±+Î²,Î³)=(Î±,Î³)+(Î²,Î³)å½“Î±â‰ 0æ—¶(Î±,Î±)&gt;0(\\alpha,\\beta)=\\overline{(\\beta,\\alpha)}\\\\\n(k\\alpha,\\beta)=k(\\alpha,\\beta)\\\\\n(\\alpha+\\beta,\\gamma)=(\\alpha,\\gamma)+(\\beta,\\gamma)\\\\\nå½“\\alpha\\ne 0æ—¶(\\alpha,\\alpha)&gt;0\n(Î±,Î²)=(Î²,Î±)â€‹(kÎ±,Î²)=k(Î±,Î²)(Î±+Î²,Î³)=(Î±,Î³)+(Î²,Î³)å½“Î±î€ =0æ—¶(Î±,Î±)&gt;0\n# æ±‚çŸ©é˜µ A çš„æœ€å°å¤šé¡¹å¼\n\nå…ˆç”¨Î»Eâˆ’A\\lambda E-AÎ»Eâˆ’A æ±‚å‡ºç‰¹å¾å¤šé¡¹å¼ã€‚\nç”±ä½æ¬¡æ–¹å‘é«˜æ¬¡æ–¹éªŒè¯Aâˆ’Î»EA-\\lambda EAâˆ’Î»Eï¼Œç›´åˆ°å‡ºç°é›¶çŸ©é˜µã€‚\n\n\nä¾‹ä¸€ï¼šæ±‚çŸ©é˜µ\nA=[3âˆ’32âˆ’15âˆ’2âˆ’130]A=\\begin{bmatrix}\n 3 &amp; -3 &amp; 2\\\\\n -1 &amp; 5 &amp; -2\\\\\n -1 &amp; 3 &amp; 0\n\\end{bmatrix}\nA=â£â¢â¡â€‹3âˆ’1âˆ’1â€‹âˆ’353â€‹2âˆ’20â€‹â¦â¥â¤â€‹\nçš„æœ€å°å¤šé¡¹å¼ã€‚\nè§£\nâˆ£Î»Eâˆ’Aâˆ£=(Î»âˆ’2)2(Î»âˆ’4)|\\lambda E-A|=(\\lambda-2)^2(\\lambda-4)\nâˆ£Î»Eâˆ’Aâˆ£=(Î»âˆ’2)2(Î»âˆ’4)\nç”±æ­¤æœ€å°ç‰¹å¾æ˜¯å¯èƒ½æ˜¯(Î»âˆ’2)2(Î»âˆ’4)(\\lambda-2)^2(\\lambda-4)(Î»âˆ’2)2(Î»âˆ’4) æˆ–è€…(Î»âˆ’2)(Î»âˆ’4)(\\lambda-2)(\\lambda-4)(Î»âˆ’2)(Î»âˆ’4)ï¼Œå…ˆä»ä½æ¬¡å¼€å§‹éªŒè¯ï¼Œä¹Ÿå°±æ˜¯(Î»âˆ’2)(Î»âˆ’4)(\\lambda-2)(\\lambda-4)(Î»âˆ’2)(Î»âˆ’4)ã€‚\n(Aâˆ’2E)(Aâˆ’4E)=[1âˆ’32âˆ’13âˆ’2âˆ’13âˆ’2]â‹…[âˆ’1âˆ’32âˆ’11âˆ’2âˆ’13âˆ’4]=[000000000](A-2E)(A-4E)=\\begin{bmatrix}\n 1 &amp; -3 &amp; 2\\\\\n -1 &amp; 3 &amp; -2\\\\\n -1 &amp; 3 &amp; -2\n\\end{bmatrix}\\cdot\\begin{bmatrix}\n -1 &amp; -3 &amp; 2\\\\\n -1 &amp; 1 &amp; -2\\\\\n -1 &amp; 3 &amp; -4\n\\end{bmatrix}=\\begin{bmatrix}\n 0 &amp; 0 &amp; 0\\\\\n 0 &amp; 0 &amp; 0\\\\\n 0 &amp; 0 &amp; 0\n\\end{bmatrix}\n(Aâˆ’2E)(Aâˆ’4E)=â£â¢â¡â€‹1âˆ’1âˆ’1â€‹âˆ’333â€‹2âˆ’2âˆ’2â€‹â¦â¥â¤â€‹â‹…â£â¢â¡â€‹âˆ’1âˆ’1âˆ’1â€‹âˆ’313â€‹2âˆ’2âˆ’4â€‹â¦â¥â¤â€‹=â£â¢â¡â€‹000â€‹000â€‹000â€‹â¦â¥â¤â€‹\nç”±æ­¤å¯çŸ¥ï¼Œç”±(Î»âˆ’2)(Î»âˆ’4)(\\lambda-2)(\\lambda-4)(Î»âˆ’2)(Î»âˆ’4) å¯æ„æˆé›¶çŸ©é˜µï¼Œ(Î»âˆ’2)(Î»âˆ’4)(\\lambda-2)(\\lambda-4)(Î»âˆ’2)(Î»âˆ’4) å°±æ˜¯æœ€å°å¤šé¡¹å¼ã€‚\n\n# è¡Œåˆ—å¼å› å­ã€ä¸å˜å› å­ã€åˆç­‰å› å­ä¸ Jordan æ ‡å‡†å‹\næ¨èé€šè¿‡ Smith æ ‡å‡†å‹æ¥æ±‚è§£ä¸€èˆ¬è¿™ä¸ªæœ€å¿«ä¸”å‡ºé”™ç‡è¾ƒä½ï¼Œå¦‚æœ Smith æ ‡å‡†å‹æ±‚è§£å›°éš¾ï¼Œå†é€šè¿‡å­å¼æ¥æ±‚ã€‚\næ±‚çŸ©é˜µ\nA=[âˆ’1âˆ’26âˆ’103âˆ’1âˆ’14]A =\\begin{bmatrix}\n -1 &amp; -2 &amp; 6\\\\\n -1 &amp; 0 &amp; 3\\\\\n -1 &amp; -1 &amp; 4\n\\end{bmatrix}\nA=â£â¢â¡â€‹âˆ’1âˆ’1âˆ’1â€‹âˆ’20âˆ’1â€‹634â€‹â¦â¥â¤â€‹\nçš„è¡Œåˆ—å¼å› å­ã€ä¸å˜å› å­ã€åˆç­‰å› å­ä¸ Jordan æ ‡å‡†å‹ã€‚\nè§£\næ„é€ âˆ£Î»Eâˆ’Aâˆ£|\\lambda E-A|âˆ£Î»Eâˆ’Aâˆ£ï¼š\nâˆ£Î»Eâˆ’Aâˆ£=[Î»+12âˆ’61Î»âˆ’311Î»âˆ’4]|\\lambda E-A|=\\begin{bmatrix}\n \\lambda+1 &amp; 2 &amp; -6\\\\\n 1 &amp; \\lambda &amp; -3\\\\\n 1 &amp; 1 &amp; \\lambda-4\n\\end{bmatrix}\nâˆ£Î»Eâˆ’Aâˆ£=â£â¢â¡â€‹Î»+111â€‹2Î»1â€‹âˆ’6âˆ’3Î»âˆ’4â€‹â¦â¥â¤â€‹\nè§‚å¯Ÿæ˜¯å¦æœ‰å…¬å› å­ï¼Œå¹¶æ²¡æœ‰ï¼Œ1 è¡Œ 1 åˆ—å¿…æ˜¯ 1ï¼š\n[1Î»âˆ’311Î»âˆ’4Î»+126]â‰ƒ[10001âˆ’Î»1âˆ’Î»01âˆ’Î»Î»2âˆ’3Î»+2]\\begin{bmatrix}\n 1 &amp; \\lambda &amp; -3\\\\\n 1 &amp; 1 &amp; \\lambda-4\\\\\n \\lambda+1 &amp; 2 &amp; 6\\\\\n\\end{bmatrix}\\simeq\\begin{bmatrix}\n 1 &amp; 0 &amp; 0\\\\\n 0 &amp; 1-\\lambda &amp; 1-\\lambda\\\\\n 0 &amp; 1-\\lambda &amp; \\lambda^2-3\\lambda+2\\\\\n\\end{bmatrix}\nâ£â¢â¡â€‹11Î»+1â€‹Î»12â€‹âˆ’3Î»âˆ’46â€‹â¦â¥â¤â€‹â‰ƒâ£â¢â¡â€‹100â€‹01âˆ’Î»1âˆ’Î»â€‹01âˆ’Î»Î»2âˆ’3Î»+2â€‹â¦â¥â¤â€‹\nè§‚å¯Ÿå³ä¸‹è§’ 2x2 å­å¼æ˜¯å¦æœ‰å…¬å› å­ï¼Œæœ‰çš„ï¼Œæ˜¯(1âˆ’Î»)(1-\\lambda)(1âˆ’Î»)ï¼Œæ‰€ä»¥ 2 è¡Œ 2 åˆ—å¿…æ˜¯(1âˆ’Î»)(1-\\lambda)(1âˆ’Î»)ã€‚\n[10001âˆ’Î»1âˆ’Î»01âˆ’Î»âˆ’Î»2+3Î»âˆ’2]â‰ƒ[1000Î»âˆ’1000(Î»âˆ’1)2]\\begin{bmatrix}\n 1 &amp; 0 &amp; 0\\\\\n 0 &amp; 1-\\lambda &amp; 1-\\lambda\\\\\n 0 &amp; 1-\\lambda &amp; -\\lambda^2+3\\lambda-2\\\\\n\\end{bmatrix}\\simeq\\begin{bmatrix}\n 1 &amp; 0 &amp; 0\\\\\n 0 &amp; \\lambda-1 &amp; 0\\\\\n 0 &amp; 0 &amp; (\\lambda-1)^2\\\\\n\\end{bmatrix}\nâ£â¢â¡â€‹100â€‹01âˆ’Î»1âˆ’Î»â€‹01âˆ’Î»âˆ’Î»2+3Î»âˆ’2â€‹â¦â¥â¤â€‹â‰ƒâ£â¢â¡â€‹100â€‹0Î»âˆ’10â€‹00(Î»âˆ’1)2â€‹â¦â¥â¤â€‹\nç”±æ­¤å¯çŸ¥\nä¸å˜å› å­ï¼šd1=1,d2=Î»âˆ’1,d3=(Î»âˆ’1)2d_1=1,d_2=\\lambda-1,d_3=(\\lambda-1)^2d1â€‹=1,d2â€‹=Î»âˆ’1,d3â€‹=(Î»âˆ’1)2\nè¡Œåˆ—å¼å› å­ï¼šD1=1,D2=Î»âˆ’1,D3=(Î»âˆ’1)(Î»âˆ’1)2D_1=1,D_2=\\lambda-1,D_3=(\\lambda-1)(\\lambda-1)^2D1â€‹=1,D2â€‹=Î»âˆ’1,D3â€‹=(Î»âˆ’1)(Î»âˆ’1)2\nåˆç­‰å› å­ï¼š(Î»âˆ’1),(Î»âˆ’1)2(\\lambda-1),(\\lambda-1)^2(Î»âˆ’1),(Î»âˆ’1)2\nç”±æ­¤å¯å¾—å‡º Jordan æ ‡å‡†å‹ï¼š\nJ=[100011001]J=\\begin{bmatrix}\n 1 &amp; 0 &amp; 0\\\\\n 0 &amp; 1 &amp; 1\\\\\n 0 &amp; 0 &amp; 1\\\\\n\\end{bmatrix}\nJ=â£â¢â¡â€‹100â€‹010â€‹011â€‹â¦â¥â¤â€‹\n# è¯æ˜å‘é‡èŒƒæ•°\néè´Ÿæ€§\nxâ‰ 0æ—¶âˆ£âˆ£xâˆ£âˆ£&gt;0,å½“ä¸”ä»…å½“x=0æ—¶âˆ£âˆ£xâˆ£âˆ£=0x\\ne 0æ—¶||x||&gt;0,å½“ä¸”ä»…å½“x=0æ—¶||x||=0\nxî€ =0æ—¶âˆ£âˆ£xâˆ£âˆ£&gt;0,å½“ä¸”ä»…å½“x=0æ—¶âˆ£âˆ£xâˆ£âˆ£=0\né½æ¬¡æ€§\nâˆ£âˆ£kxâˆ£âˆ£=âˆ£kâˆ£â‹…âˆ£âˆ£xâˆ£âˆ£||kx||=|k|\\cdot||x||\nâˆ£âˆ£kxâˆ£âˆ£=âˆ£kâˆ£â‹…âˆ£âˆ£xâˆ£âˆ£\nä¸‰è§’ä¸ç­‰å¼\nâˆ£âˆ£x+yâˆ£âˆ£â‰¤âˆ£âˆ£xâˆ£âˆ£+âˆ£âˆ£yâˆ£âˆ£||x+y||\\le ||x||+||y||\nâˆ£âˆ£x+yâˆ£âˆ£â‰¤âˆ£âˆ£xâˆ£âˆ£+âˆ£âˆ£yâˆ£âˆ£\n# å‘é‡èŒƒæ•°\nä¸€èŒƒæ•°\nâˆ£âˆ£xâˆ£âˆ£1=âˆ‘i=1nâˆ£xiâˆ£||x||_1=\\sum_{i=1}^{n}|x_i|\nâˆ£âˆ£xâˆ£âˆ£1â€‹=i=1âˆ‘nâ€‹âˆ£xiâ€‹âˆ£\näºŒèŒƒæ•°\nâˆ£âˆ£xâˆ£âˆ£2=âˆ‘i=1nxi2||x||_2=\\sqrt{\\sum_{i=1}^{n}x_i^2}\nâˆ£âˆ£xâˆ£âˆ£2â€‹=i=1âˆ‘nâ€‹xi2â€‹â€‹\næ— ç©·èŒƒæ•°\nâˆ£âˆ£xâˆ£âˆ£âˆ=maxâˆ£xiâˆ£||x||_\\infty=max|x_i|\nâˆ£âˆ£xâˆ£âˆ£âˆâ€‹=maxâˆ£xiâ€‹âˆ£\n# è¯æ˜çŸ©é˜µèŒƒæ•°\néè´Ÿæ€§\nâˆ£âˆ£Aâˆ£âˆ£&gt;0,å½“ä¸”ä»…å½“A=0æ—¶âˆ£âˆ£Aâˆ£âˆ£=0||A||&gt;0,å½“ä¸”ä»…å½“A=0æ—¶||A||=0\nâˆ£âˆ£Aâˆ£âˆ£&gt;0,å½“ä¸”ä»…å½“A=0æ—¶âˆ£âˆ£Aâˆ£âˆ£=0\né½æ¬¡æ€§\nâˆ£âˆ£kAâˆ£âˆ£=âˆ£kâˆ£â‹…âˆ£âˆ£Aâˆ£âˆ£||kA||=|k|\\cdot||A||\nâˆ£âˆ£kAâˆ£âˆ£=âˆ£kâˆ£â‹…âˆ£âˆ£Aâˆ£âˆ£\nä¸‰è§’ä¸ç­‰å¼\nâˆ£âˆ£A+Bâˆ£âˆ£â‰¤âˆ£Aâˆ£+âˆ£Bâˆ£||A+B||\\le|A|+|B|\nâˆ£âˆ£A+Bâˆ£âˆ£â‰¤âˆ£Aâˆ£+âˆ£Bâˆ£\nç›¸å®¹æ€§\nâˆ£âˆ£Aâ‹…Bâˆ£âˆ£â‰¤âˆ£âˆ£Aâˆ£âˆ£â‹…âˆ£âˆ£Bâˆ£âˆ£||A\\cdot B||\\le||A||\\cdot||B||\nâˆ£âˆ£Aâ‹…Bâˆ£âˆ£â‰¤âˆ£âˆ£Aâˆ£âˆ£â‹…âˆ£âˆ£Bâˆ£âˆ£\n# çŸ©é˜µèŒƒæ•°\nä¸€èŒƒæ•°\nâˆ£âˆ£Aâˆ£âˆ£1=max(åˆ—æ¨¡é•¿ä¹‹å’Œ)||A||_1=max(åˆ—æ¨¡é•¿ä¹‹å’Œ)\nâˆ£âˆ£Aâˆ£âˆ£1â€‹=max(åˆ—æ¨¡é•¿ä¹‹å’Œ)\näºŒèŒƒæ•°\nâˆ£âˆ£Aâˆ£âˆ£2=Î»max,å…¶ä¸­Î»maxæ˜¯AHAçš„æœ€å¤§ç‰¹å¾å€¼||A||_2=\\sqrt {\\lambda_{max}},å…¶ä¸­\\lambda_{max}æ˜¯A^HAçš„æœ€å¤§ç‰¹å¾å€¼\nâˆ£âˆ£Aâˆ£âˆ£2â€‹=Î»maxâ€‹â€‹,å…¶ä¸­Î»maxâ€‹æ˜¯AHAçš„æœ€å¤§ç‰¹å¾å€¼\næ— ç©·èŒƒæ•°\nâˆ£âˆ£Aâˆ£âˆ£âˆ=max(è¡Œæ¨¡é•¿ä¹‹å’Œ)||A||_\\infty=max(è¡Œæ¨¡é•¿ä¹‹å’Œ)\nâˆ£âˆ£Aâˆ£âˆ£âˆâ€‹=max(è¡Œæ¨¡é•¿ä¹‹å’Œ)\nM1 èŒƒæ•°\nâˆ£âˆ£AM1âˆ£âˆ£=âˆ‘i=1mâˆ‘j=1nâˆ£aijâˆ£||A_{M1}||=\\sum_{i=1}^{m}\\sum_{j=1}^{n}|a_{ij}|\nâˆ£âˆ£AM1â€‹âˆ£âˆ£=i=1âˆ‘mâ€‹j=1âˆ‘nâ€‹âˆ£aijâ€‹âˆ£\nM2 èŒƒæ•°\nâˆ£âˆ£AM2âˆ£âˆ£=âˆ‘i=1mâˆ‘j=1nâˆ£aijâˆ£2||A_{M2}||=\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\sqrt{|a_{ij}|^2}\nâˆ£âˆ£AM2â€‹âˆ£âˆ£=i=1âˆ‘mâ€‹j=1âˆ‘nâ€‹âˆ£aijâ€‹âˆ£2â€‹\nM æ— ç©·èŒƒæ•°\nâˆ£âˆ£AMâˆâˆ£âˆ£=max(aij)||A_{M\\infty}||=max(a_{ij})\nâˆ£âˆ£AMâˆâ€‹âˆ£âˆ£=max(aijâ€‹)\n# QR åˆ†è§£\nå…ˆå°†æºçŸ©é˜µå†™æˆåˆ—å‘é‡\nA=[a11a12a13a21a22a23a31a32a33]=[Î±1Î±2Î±3]A=\\begin{bmatrix}\n a_{11} &amp; a_{12} &amp; a_{13}\\\\\n a_{21} &amp; a_{22} &amp; a_{23}\\\\\n a_{31} &amp; a_{32} &amp; a_{33}\\\\\n\\end{bmatrix}=\\begin{bmatrix}\n \\alpha_{1} &amp; \\alpha_{2} &amp; \\alpha_{3}\\\\\n\\end{bmatrix}\nA=â£â¢â¡â€‹a11â€‹a21â€‹a31â€‹â€‹a12â€‹a22â€‹a32â€‹â€‹a13â€‹a23â€‹a33â€‹â€‹â¦â¥â¤â€‹=[Î±1â€‹â€‹Î±2â€‹â€‹Î±3â€‹â€‹]\næ­£äº¤åŒ–ï¼Œå¹¶ä¿ç•™æ­£äº¤åŒ–è¿‡ç¨‹è®°å½•\nÎ²1=Î±1Î²2=Î±2âˆ’(Î±2,Î²1)(Î²1,Î²1)Î²1Î²3=Î±3âˆ’(Î±3,Î²1)(Î²1,Î²1)Î²1âˆ’(Î±3,Î²2)(Î²2,Î²2)Î²2\\beta_1=\\alpha_1\\\\\n\\beta_2=\\alpha_2-\\frac{(\\alpha_2,\\beta_1)}{(\\beta_1,\\beta_1)}\\beta_1\\\\\n\\beta_3=\\alpha_3-\\frac{(\\alpha_3,\\beta_1)}{(\\beta_1,\\beta_1)}\\beta_1-\\frac{(\\alpha_3,\\beta_2)}{(\\beta_2,\\beta_2)}\\beta_2\\\\\nÎ²1â€‹=Î±1â€‹Î²2â€‹=Î±2â€‹âˆ’(Î²1â€‹,Î²1â€‹)(Î±2â€‹,Î²1â€‹)â€‹Î²1â€‹Î²3â€‹=Î±3â€‹âˆ’(Î²1â€‹,Î²1â€‹)(Î±3â€‹,Î²1â€‹)â€‹Î²1â€‹âˆ’(Î²2â€‹,Î²2â€‹)(Î±3â€‹,Î²2â€‹)â€‹Î²2â€‹\nåå†™æ­£äº¤åŒ–ï¼ˆç”¨Î²\\betaÎ² è¡¨ç¤ºÎ±\\alphaÎ±ï¼‰\nÎ±1=Î²1Î±2=(Î±2,Î²1)(Î²1,Î²1)Î²1+Î²2Î±3=(Î±3,Î²1)(Î²1,Î²1)Î²1+(Î±3,Î²2)(Î²2,Î²2)Î²2+Î²3\\alpha_1=\\beta_1\\\\\n\\alpha_2=\\frac{(\\alpha_2,\\beta_1)}{(\\beta_1,\\beta_1)}\\beta_1+\\beta_2\\\\\n\\alpha_3=\\frac{(\\alpha_3,\\beta_1)}{(\\beta_1,\\beta_1)}\\beta_1+\\frac{(\\alpha_3,\\beta_2)}{(\\beta_2,\\beta_2)}\\beta_2+\\beta_3\nÎ±1â€‹=Î²1â€‹Î±2â€‹=(Î²1â€‹,Î²1â€‹)(Î±2â€‹,Î²1â€‹)â€‹Î²1â€‹+Î²2â€‹Î±3â€‹=(Î²1â€‹,Î²1â€‹)(Î±3â€‹,Î²1â€‹)â€‹Î²1â€‹+(Î²2â€‹,Î²2â€‹)(Î±3â€‹,Î²2â€‹)â€‹Î²2â€‹+Î²3â€‹\nå•ä½åŒ–Î²\\betaÎ²\nÎ³1=Î²1âˆ£Î²1âˆ£Î³2=Î²2âˆ£Î²2âˆ£Î³3=Î²3âˆ£Î²3âˆ£\\gamma_1=\\frac{\\beta_1}{|\\beta_1|}\\\\\n\\gamma_2=\\frac{\\beta_2}{|\\beta_2|}\\\\\n\\gamma_3=\\frac{\\beta_3}{|\\beta_3|}\\\\\nÎ³1â€‹=âˆ£Î²1â€‹âˆ£Î²1â€‹â€‹Î³2â€‹=âˆ£Î²2â€‹âˆ£Î²2â€‹â€‹Î³3â€‹=âˆ£Î²3â€‹âˆ£Î²3â€‹â€‹\næŠŠÎ²\\betaÎ² ç”¨Î³\\gammaÎ³ æ¢æ‰\nÎ±1=âˆ£Î²1âˆ£Î³1Î±2=(Î±2,Î²1)(Î²1,Î²1)âˆ£Î²1âˆ£Î³1+âˆ£Î²2âˆ£Î³2Î±3=(Î±3,Î²1)(Î²1,Î²1)âˆ£Î²1âˆ£Î³1+(Î±3,Î²2)(Î²2,Î²2)âˆ£Î²2âˆ£Î³2+âˆ£Î²3âˆ£Î³3\\alpha_1=|\\beta_1|\\gamma_1\\\\\n\\alpha_2=\\frac{(\\alpha_2,\\beta_1)}{(\\beta_1,\\beta_1)}|\\beta_1|\\gamma_1+|\\beta_2|\\gamma_2\\\\\n\\alpha_3=\\frac{(\\alpha_3,\\beta_1)}{(\\beta_1,\\beta_1)}|\\beta_1|\\gamma_1+\\frac{(\\alpha_3,\\beta_2)}{(\\beta_2,\\beta_2)}|\\beta_2|\\gamma_2+|\\beta_3|\\gamma_3\nÎ±1â€‹=âˆ£Î²1â€‹âˆ£Î³1â€‹Î±2â€‹=(Î²1â€‹,Î²1â€‹)(Î±2â€‹,Î²1â€‹)â€‹âˆ£Î²1â€‹âˆ£Î³1â€‹+âˆ£Î²2â€‹âˆ£Î³2â€‹Î±3â€‹=(Î²1â€‹,Î²1â€‹)(Î±3â€‹,Î²1â€‹)â€‹âˆ£Î²1â€‹âˆ£Î³1â€‹+(Î²2â€‹,Î²2â€‹)(Î±3â€‹,Î²2â€‹)â€‹âˆ£Î²2â€‹âˆ£Î³2â€‹+âˆ£Î²3â€‹âˆ£Î³3â€‹\nÎ³\\gammaÎ³ ç³»åˆ—å°±æ˜¯ Qï¼Œä¸Šè¿°æ›¿æ¢è¿‡çš„å°±æ˜¯ R\nA=[Î³1Î³2Î³3]â‹…[âˆ£Î²1âˆ£(Î±2,Î²1)(Î²1,Î²1)âˆ£Î²1âˆ£(Î±3,Î²1)(Î²1,Î²1)âˆ£Î²1âˆ£0âˆ£Î²2âˆ£(Î±3,Î²2)(Î²2,Î²2)âˆ£Î²2âˆ£00âˆ£Î²3âˆ£]A=\\begin{bmatrix}\n \\gamma_1 &amp; \\gamma_2 &amp; \\gamma_3\n\\end{bmatrix}\\cdot\\begin{bmatrix}\n |\\beta_1| &amp; \\frac{(\\alpha_2,\\beta_1)}{(\\beta_1,\\beta_1)}|\\beta_1| &amp; \\frac{(\\alpha_3,\\beta_1)}{(\\beta_1,\\beta_1)}|\\beta_1|\\\\\n 0 &amp; |\\beta_2| &amp; \\frac{(\\alpha_3,\\beta_2)}{(\\beta_2,\\beta_2)}|\\beta_2|\\\\\n 0 &amp; 0 &amp; |\\beta_3|\\\\\n\\end{bmatrix}\nA=[Î³1â€‹â€‹Î³2â€‹â€‹Î³3â€‹â€‹]â‹…â£â¢â¢â¡â€‹âˆ£Î²1â€‹âˆ£00â€‹(Î²1â€‹,Î²1â€‹)(Î±2â€‹,Î²1â€‹)â€‹âˆ£Î²1â€‹âˆ£âˆ£Î²2â€‹âˆ£0â€‹(Î²1â€‹,Î²1â€‹)(Î±3â€‹,Î²1â€‹)â€‹âˆ£Î²1â€‹âˆ£(Î²2â€‹,Î²2â€‹)(Î±3â€‹,Î²2â€‹)â€‹âˆ£Î²2â€‹âˆ£âˆ£Î²3â€‹âˆ£â€‹â¦â¥â¥â¤â€‹\nQR åˆ†è§£å®Œæ¯•ã€‚\n# æ­£äº¤çŸ©é˜µè°±åˆ†è§£\næ±‚ç‰¹å¾å€¼ï¼Œç‰¹å¾å‘é‡ï¼Œæ­£äº¤åŒ–å•ä½åŒ–å¾—åˆ°Î·1,Î·2,Î·3\\eta_1,\\eta_2,\\eta_3Î·1â€‹,Î·2â€‹,Î·3â€‹\nA1=Î·1Tâ‹…Î·1A2=Î·2Tâ‹…Î·2â€¦A_1=\\eta_1^T\\cdot\\eta_1\\\\\nA_2=\\eta_2^T\\cdot\\eta_2\\\\\n\\dots\nA1â€‹=Î·1Tâ€‹â‹…Î·1â€‹A2â€‹=Î·2Tâ€‹â‹…Î·2â€‹â€¦\nA=Î»1A1+Î»2A2+â€¦A=\\lambda_1A_1+\\lambda_2A_2+\\dots\nA=Î»1â€‹A1â€‹+Î»2â€‹A2â€‹+â€¦\n# å¯å¯¹è§’åŒ– / å¼‚æ ¹è°±åˆ†è§£\næ±‚ç‰¹å¾å€¼ï¼Œè®¾ç‰¹å¾å‡½æ•°ï¼Œå¦‚æœæœ‰é‡æ ¹åªè®¡ç®—ä¸€æ¬¡ï¼Œè¿™é‡Œåªåšå¯¹æ–¹çš„ç‰¹å¾å€¼ï¼Œä¸ç®¡è‡ªå·±çš„ç‰¹å¾å€¼\nÏ†1(Î»)=(Î»âˆ’Î»2)(Î»âˆ’Î»3)Ï†2(Î»)=(Î»âˆ’Î»1)(Î»âˆ’Î»3)Ï†3(Î»)=(Î»âˆ’Î»1)(Î»âˆ’Î»2)\\varphi _1(\\lambda)=(\\lambda-\\lambda_2)(\\lambda-\\lambda_3)\\\\\n\\varphi _2(\\lambda)=(\\lambda-\\lambda_1)(\\lambda-\\lambda_3)\\\\\n\\varphi _3(\\lambda)=(\\lambda-\\lambda_1)(\\lambda-\\lambda_2)\\\\\nÏ†1â€‹(Î»)=(Î»âˆ’Î»2â€‹)(Î»âˆ’Î»3â€‹)Ï†2â€‹(Î»)=(Î»âˆ’Î»1â€‹)(Î»âˆ’Î»3â€‹)Ï†3â€‹(Î»)=(Î»âˆ’Î»1â€‹)(Î»âˆ’Î»2â€‹)\næŠŠç‰¹å¾å€¼å’ŒçŸ©é˜µå¸¦å…¥\nA1=Ï†1(A)Ï†1(Î»1)A2=Ï†2(A)Ï†2(Î»2)A3=Ï†3(A)Ï†3(Î»3)A_1=\\frac{\\varphi _1(A)}{\\varphi _1(\\lambda_1)}\\\\\nA_2=\\frac{\\varphi _2(A)}{\\varphi _2(\\lambda_2)}\\\\\nA_3=\\frac{\\varphi _3(A)}{\\varphi _3(\\lambda_3)}\nA1â€‹=Ï†1â€‹(Î»1â€‹)Ï†1â€‹(A)â€‹A2â€‹=Ï†2â€‹(Î»2â€‹)Ï†2â€‹(A)â€‹A3â€‹=Ï†3â€‹(Î»3â€‹)Ï†3â€‹(A)â€‹\nA=Î»1A1+Î»2A2+Î»3A3â€¦A=\\lambda_1A_1+\\lambda_2A_2+\\lambda_3A_3\\dots\nA=Î»1â€‹A1â€‹+Î»2â€‹A2â€‹+Î»3â€‹A3â€‹â€¦\n# æ»¡ç§©åˆ†è§£\næ»¡ç§©åˆ†è§£å…ˆå°†çŸ©é˜µåŒ–ä¸ºè¡Œæœ€ç®€ï¼Œç„¶åé€‰å–æŒ‡å®šçš„ n åˆ—ï¼ŒæŒ‡å®š n è¡Œï¼Œè¿™é‡Œå‰åæŒ‡çš„æ˜¯åŒ–ç®€å‰åï¼Œè€Œå…·ä½“æŒ‡å®šå“ªåˆ—ç”±åŒ–ç®€åçš„é˜¶æ¢¯çŸ©é˜µå†³å®šã€‚\nA=[14âˆ’1562000âˆ’14âˆ’12âˆ’40126âˆ’55âˆ’7]A=\\begin{bmatrix}\n 1 &amp; 4 &amp; -1 &amp; 5 &amp; 6\\\\\n 2 &amp; 0 &amp; 0 &amp; 0 &amp; -14 \\\\\n -1 &amp; 2 &amp; -4 &amp; 0 &amp; 1\\\\\n 2 &amp; 6 &amp; -5 &amp; 5 &amp; -7\\\\\n\\end{bmatrix}\nA=â£â¢â¢â¢â¡â€‹12âˆ’12â€‹4026â€‹âˆ’10âˆ’4âˆ’5â€‹5005â€‹6âˆ’141âˆ’7â€‹â¦â¥â¥â¥â¤â€‹\n[1000âˆ’70101072970015725700000]\\begin{bmatrix}\n 1 &amp; 0 &amp; 0 &amp; 0 &amp; -7\\\\\n 0 &amp; 1 &amp; 0 &amp; \\frac{10}{7} &amp; \\frac{29}{7} \\\\\n 0 &amp; 0 &amp; 1 &amp; \\frac{5}{7} &amp; \\frac{25}{7}\\\\\n 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\\n\\end{bmatrix}\nâ£â¢â¢â¢â¡â€‹1000â€‹0100â€‹0010â€‹0710â€‹75â€‹0â€‹âˆ’7729â€‹725â€‹0â€‹â¦â¥â¥â¥â¤â€‹\nå‰åˆ—åè¡Œ\nB=[14âˆ’1200âˆ’12âˆ’426âˆ’5]B=\\begin{bmatrix}\n 1 &amp; 4 &amp; -1\\\\\n 2 &amp; 0 &amp; 0\\\\\n -1 &amp; 2 &amp; -4\\\\\n 2 &amp; 6 &amp; -5 \\\\\n\\end{bmatrix}\nB=â£â¢â¢â¢â¡â€‹12âˆ’12â€‹4026â€‹âˆ’10âˆ’4âˆ’5â€‹â¦â¥â¥â¥â¤â€‹\nC=[1000âˆ’701010729700157257]C=\\begin{bmatrix}\n 1 &amp; 0 &amp; 0 &amp; 0 &amp; -7\\\\\n 0 &amp; 1 &amp; 0 &amp; \\frac{10}{7} &amp; \\frac{29}{7} \\\\\n 0 &amp; 0 &amp; 1 &amp; \\frac{5}{7} &amp; \\frac{25}{7}\\\\\n\\end{bmatrix}\nC=â£â¢â¡â€‹100â€‹010â€‹001â€‹0710â€‹75â€‹â€‹âˆ’7729â€‹725â€‹â€‹â¦â¥â¤â€‹\nA=BCA=BC\nA=BC\nå…·ä½“æµç¨‹è¯·çœ‹ä¹¦ P74-P75\n# å¥‡å¼‚å€¼åˆ†è§£\nå…·ä½“æµç¨‹è¯·çœ‹ä¹¦ P85\næ ¸å¿ƒåœ¨äºè¿™ä¸¤ä¸ªå…¬å¼ï¼Œä¸‹é¢æˆ‘ä¼šç»™äºˆåšé¢˜æç¤ºã€‚\nUn=AVnÎ”âˆ’1A=USVHU_n=AV_n\\Delta^{-1}\\\\\nA=USV^H\nUnâ€‹=AVnâ€‹Î”âˆ’1A=USVH\nå…¶ä¸­ S ä¸€å®šä¸ A åŒå‹ï¼ŒÎ”\\DeltaÎ” æ˜¯éé›¶å¥‡å¼‚å€¼å¼ æˆçš„çŸ©é˜µä¸”ä¸€å®šæ˜¯æ–¹é˜µï¼Œå¦‚æœæ—¶é—´ç´§å¼ æˆ‘ä»¬å¯ä»¥é€šè¿‡ Aã€Sã€Î”\\DeltaÎ” çš„å¤§å°çŒœæµ‹å‡ºå…¶ä»–å…ƒç´ çš„å¤§å°ã€‚æ³¨æ„ï¼å¥‡å¼‚å€¼è¦å¼€æ ¹å·ï¼ï¼ï¼Î”âˆ’1\\Delta^{-1}Î”âˆ’1 ä¸€å®šè¦æ±‚é€†ï¼ï¼ï¼\n\næ±‚å‡ºAHAA^HAAHA çš„å…¨éƒ¨ç‰¹å¾å€¼åŠå¥‡å¼‚å€¼ï¼Œç”±æ‰€æœ‰éé›¶å¥‡å¼‚å€¼å¾—åˆ°æ­£çº¿å¯¹è§’çŸ©é˜µÎ”\\DeltaÎ” è¿›è€Œå¾—åˆ°å¥‡å¼‚çŸ©é˜µSSS\nå¯¹äºAHAA^HAAHA çš„æ¯ä¸€ä¸ªä¸åŒçš„ç‰¹å¾æ ¹ï¼Œæ±‚å‡ºä¸ä¹‹ç›¸åº”çš„ç‰¹å¾å‘é‡çš„æå¤§æ— å…³ç»„ï¼Œç»æ­£äº¤åŒ–ã€å•ä½åŒ–å¾—AHAA^HAAHA ç›¸åº”äºè¯¥ç‰¹å¾æ ¹çš„æ ‡å‡†æ­£äº¤ç‰¹å¾å‘é‡ç»„ã€‚å°†å…¶ä¸­ä¸éé›¶ç‰¹å¾æ ¹ç›¸åº”çš„é‚£äº›å°ç»„ï¼ˆä½œä¸ºä¸€äº›åˆ—å‘é‡ï¼‰é¡ºåºæ’æˆçŸ©é˜µV1V_1V1â€‹ å…¶æ¬¡åºåº”ä¸Î”\\DeltaÎ” ä¸­ç›¸å…³å¥‡å¼‚å€¼åœ¨å¯¹è§’çº¿ä¸Šçš„æ’åˆ—é¡ºåºç›¸ä¸€è‡´ã€‚å†ä»¥AHAA^HAAHA ç›¸åº”äºé›¶ç‰¹å¾æ ¹çš„æ ‡å‡†æ­£äº¤ç‰¹å¾å‘é‡ï¼ˆæå¤§æ— å…³ï¼‰ç»„æ’æˆçŸ©é˜µV2V_2V2â€‹ã€‚äºæ˜¯å¯å¾—é…‰çŸ©é˜µV=(V1,V2)V=(V_1,V_2)V=(V1â€‹,V2â€‹)\nè®¡ç®—U1=AV1Î”âˆ’1U_1=AV_1\\Delta^{-1} \\kern 0.1ptU1â€‹=AV1â€‹Î”âˆ’1\næ±‚å‡ºAAHAA^HAAH ç›¸åº”äºé›¶ç‰¹å¾æ ¹çš„ä¸€ä¸ªæ ‡å‡†æ­£äº¤ç‰¹å¾å‘é‡ï¼ˆæå¤§æ— å…³ï¼‰ç»„ï¼Œç”±å®ƒä»¬æ’æˆmâˆ—(mâˆ’r)m*(m-r)mâˆ—(mâˆ’r) çš„éƒ¨åˆ†é…‰é˜µU2U_2U2â€‹ï¼Œå¯å¾—U=(U1,U2)U=(U_1,U_2)U=(U1â€‹,U2â€‹) ç»¼ä¸Šï¼Œä¾¿å¾—åˆ°å¥‡å¼‚å€¼åˆ†è§£A=USVHA=USV^HA=USVH\n\n# çŸ©é˜µå‡½æ•°\næ¨èä½¿ç”¨å¾…å®šç³»æ•°æ³•æ±‚è§£ï¼š\n\nå†™å‡ºâˆ£Î»Eâˆ’Aâˆ£|\\lambda E-A|âˆ£Î»Eâˆ’Aâˆ£ï¼Œæ±‚å‡ºç‰¹å¾å¤šé¡¹å¼\næ±‚å‡ºæœ€å°å¤šé¡¹å¼ï¼Œè¯¦è§æœ€å°å¤šé¡¹å¼ç« èŠ‚\nè§‚å¯Ÿæœ€å°å¤šé¡¹å¼æ¬¡æ•° nï¼Œè®¾ n-1 æ¬¡å¤šé¡¹å¼\nå°†ç‰¹å¾å€¼å¸¦å…¥å³ä¾§ç­‰äºç›®æ ‡å‡½æ•°ï¼Œå½“æœ‰é‡æ ¹æ—¶ä¸¤ä¾§åŒæ—¶æ±‚å¯¼å†å¸¦å…¥\n\nä¾‹ï¼šå·²çŸ¥çŸ©é˜µ\nA=[221âˆ’261004]A=\\begin{bmatrix}\n 2 &amp; 2 &amp; 1\\\\\n -2 &amp; 6 &amp; 1\\\\\n 0 &amp; 0 &amp; 4\\\\\n\\end{bmatrix}\nA=â£â¢â¡â€‹2âˆ’20â€‹260â€‹114â€‹â¦â¥â¤â€‹\næ±‚çŸ©é˜µå‡½æ•°A\\sqrt{A} \\kern 0.1ptAâ€‹\n\nâˆ£Î»Eâˆ’Aâˆ£=(Î»âˆ’4)3|\\lambda E-A|=(\\lambda-4)^3\nâˆ£Î»Eâˆ’Aâˆ£=(Î»âˆ’4)3\nå°†çŸ©é˜µ A å¸¦å…¥ï¼Œå…ˆä»æœ€ä½æ¬¡è¯•èµ·\n(Aâˆ’4E)â‰ O(Aâˆ’4E)2=O(A-4E)\\ne O\\\\\n(A-4E)^2= O\n(Aâˆ’4E)î€ =O(Aâˆ’4E)2=O\nå› æ­¤æœ€å°å¤šé¡¹å¼å°±æ˜¯(Î»âˆ’4)2(\\lambda-4)^2(Î»âˆ’4)2ï¼Œå¹³æ–¹é¡¹è®¾ 1 æ¬¡å¼\naÎ»+b=Î»a\\lambda +b=\\sqrt{\\lambda}\naÎ»+b=Î»â€‹\nç‰¹å¾å€¼å¸¦å…¥ï¼Œé‡æ ¹æ±‚å¯¼\n4a+b=2a=144a+b=2\\\\\na=\\frac{1}{4}\n4a+b=2a=41â€‹\nè§£å¾— a ä¸ bï¼Œb=1\nA=14A+E\\sqrt{A}=\\frac{1}{4}A+E\nAâ€‹=41â€‹A+E\n# 2011\n\nè®¾Îµ1,Îµ2,Îµ3\\varepsilon_1,\\varepsilon_2,\\varepsilon_3Îµ1â€‹,Îµ2â€‹,Îµ3â€‹ æ˜¯çº¿æ€§ç©ºé—´VVV çš„ä¸€ç»„åŸºï¼Œçº¿æ€§å˜æ¢Î´\\deltaÎ´ ä½¿Î´(Îµ1)=Îµ3,Î´(Îµ2)=Îµ2,Î´(Îµ3)=Îµ1\\delta(\\varepsilon_1)=\\varepsilon_3,\\delta(\\varepsilon_2)=\\varepsilon_2,\\delta(\\varepsilon_3)=\\varepsilon_1Î´(Îµ1â€‹)=Îµ3â€‹,Î´(Îµ2â€‹)=Îµ2â€‹,Î´(Îµ3â€‹)=Îµ1â€‹ï¼Œæ±‚Î´\\deltaÎ´ çš„æ‰€æœ‰ç‰¹å¾æ ¹åŠå…¨éƒ¨ç‰¹å¾å‘é‡ã€‚\nÎ´(Îµ1,Îµ2,Îµ3)=(Îµ1,Îµ2,Îµ3)[001010100]\\delta(\\varepsilon_1,\\varepsilon_2,\\varepsilon_3)=(\\varepsilon_1,\\varepsilon_2,\\varepsilon_3)\\begin{bmatrix}\n 0 &amp; 0 &amp; 1\\\\\n 0 &amp; 1 &amp; 0\\\\\n 1 &amp; 0 &amp; 0\\\\\n\\end{bmatrix}\nÎ´(Îµ1â€‹,Îµ2â€‹,Îµ3â€‹)=(Îµ1â€‹,Îµ2â€‹,Îµ3â€‹)â£â¢â¡â€‹001â€‹010â€‹100â€‹â¦â¥â¤â€‹\nâˆ£Î»Eâˆ’Aâˆ£=[Î»0âˆ’10Î»âˆ’10âˆ’10Î»]|\\lambda E-A|=\\begin{bmatrix}\n \\lambda &amp; 0 &amp; -1\\\\\n 0 &amp; \\lambda-1 &amp; 0\\\\\n -1 &amp; 0 &amp; \\lambda\\\\\n\\end{bmatrix}\nâˆ£Î»Eâˆ’Aâˆ£=â£â¢â¡â€‹Î»0âˆ’1â€‹0Î»âˆ’10â€‹âˆ’10Î»â€‹â¦â¥â¤â€‹\nå¾—åˆ°ç‰¹å¾å€¼Î»1=Î»2=1,Î»3=âˆ’1\\lambda_1=\\lambda_2=1,\\lambda_3=-1Î»1â€‹=Î»2â€‹=1,Î»3â€‹=âˆ’1\nå¾—åˆ°ç‰¹å¾å‘é‡\nl1=(âˆ’1,0,1)Tl2=(1,0,1)Tl3=(0,1,0)Tl_1=(-1,0,1)^T\\\\\nl_2=(1,0,1)^T\\\\\nl_3=(0,1,0)^T\nl1â€‹=(âˆ’1,0,1)Tl2â€‹=(1,0,1)Tl3â€‹=(0,1,0)T\nå¯¹äºç‰¹å¾å€¼1k1(Îµ1+Îµ3)+k2(Îµ2)å¯¹äºç‰¹å¾å€¼âˆ’1k3(âˆ’Îµ1+Îµ3)å¯¹äºç‰¹å¾å€¼1\\\\\nk_1(\\varepsilon_1+\\varepsilon_3)+k_2(\\varepsilon_2)\\\\\nå¯¹äºç‰¹å¾å€¼-1\\\\\nk3(-\\varepsilon_1+\\varepsilon_3)\nå¯¹äºç‰¹å¾å€¼1k1â€‹(Îµ1â€‹+Îµ3â€‹)+k2â€‹(Îµ2â€‹)å¯¹äºç‰¹å¾å€¼âˆ’1k3(âˆ’Îµ1â€‹+Îµ3â€‹)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC æ˜¯ nxn çš„ç¬”è¯¯äº†ã€‚ã€‚\n\n\n\n# 2013-J\n\n\n# 2021\n\n\n\n\n\n\n\n\n\n\n\n# 2022-?\nè¿™é‡Œé’ˆå¯¹é•¿æ˜¥ç†å·¥å¤§å­¦ 2022-2023 å¹´çŸ©é˜µè®ºæœŸæœ«è€ƒè¯•æœ€åä¸€é“é¢˜ï¼ˆ8 é¢˜ï¼‰çš„ç›¸å…³å†…å®¹åšå‡ºä¸ªäººè§£é¢˜è§è§£ã€‚\næˆ‘è®¤ä¸º PDF ä¸­çš„é¢˜è§£æœ‰é—®é¢˜ï¼Œå¦‚æœåŒæ ·å¯¹è¿™é“é¢˜æœ‰ç–‘é—®çš„åŒå­¦ï¼Œå¯åœ¨æ–‡ç« è¯„è®ºåŒºï¼ˆæˆ‘å¯èƒ½çœ‹ä¸åˆ°ï¼‰ï¼Œå¾®ä¿¡ï¼ˆSa9329Mxzï¼‰ï¼ŒQQï¼ˆ735690757ï¼‰è¿›ä¸€æ­¥è®¨è®ºã€‚\n\n\nåŸºå˜æ¢å…¬å¼æ¥è‡ªäº p8\n åæ ‡å˜æ¢å…¬å¼æ¥è‡ªäº p9\n çº¿æ€§å˜æ¢åœ¨åŸºä¸‹çŸ©é˜µå…¬å¼æ¥è‡ªäº p19\n çº¿æ€§å˜æ¢ä½œç”¨åœ¨åæ ‡ä¸‹å…¬å¼æ¥è‡ªäº p22\n\n\n\n\n# æ‰‹å†™ç‰ˆ\nè¿™ä¸ªæ‰‹å†™ç‰ˆæˆ‘ä¼šæ”¾åœ¨æˆ‘çš„ä¹¦é‡Œï¼Œä½†æ˜¯å¯èƒ½ä¼šå¼„ä¸¢äº†ï¼Œä¿é™©èµ·è§æˆ‘æŠŠå®ƒæ‰«æä¸Šæ¥äº†ã€‚\n\n\n\n\n\n\n\n# ç‰¹åˆ«é¸£è°¢\nç‰¹åˆ«é¸£è°¢æˆ‘çš„å®¤å‹ï¼šæ±‚æ±‚ä½ åˆ«éª—æˆ‘ï¼Œå¯¹æœ¬æ–‡è¯¦ç»†å®¡é˜…ã€‚\n","categories":["ç¬”è®°"],"tags":["çŸ©é˜µè®ºè§£é¢˜ç¬”è®°"]},{"title":"æ¨¡ç³Šæ•°å­¦25ä¹ é¢˜","url":"/math/mh_math/","content":"# ç¬¬ä¸€ç« \n\n\n\n\n\n\n\n\n# ç¬¬äºŒç« \n\n\n\n\n\n\n\n \n# ç¬¬ä¸‰ç« \n\n\n\n\n\n\n\n\n# ç¬¬å››ç« \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# å±…å¡è«ç‰¹æ–¹æ³• â€”â€” å“¥å¼Ÿå§å¦¹å…¬å¼\nå±…å¡è«ç‰¹æ–¹æ³•æ˜¯æ±‚è§£æ¨¡ç³Šå…³ç³»æ–¹ç¨‹çš„æ ¸å¿ƒæ‰€åœ¨ï¼Œå¯¹äºè€ƒè¯•æ¥è¯´ï¼Œä¸»è¦ç›®çš„åœ¨äºæ±‚è§£å½¢å¦‚ï¼š\n\nè¿™æ ·çš„é¢˜ã€‚\nå±…å¡è«ç‰¹æ–¹æ³•å®šä¹‰äº†å¦‚ä¸‹ä¸¤ç§è¿ç®—æ–¹æ³•ï¼š\nbÎµa={b,å½“a&gt;bæ—¶[b,1],å½“a=bæ—¶âˆ…,å½“b&gt;aæ—¶b\\varepsilon a=\\left\\{\\begin{matrix}\n b, &amp; å½“a&gt;bæ—¶\\\\\n [b,1], &amp; å½“a=bæ—¶\\\\\n \\emptyset , &amp; å½“b&gt;aæ—¶\n\\end{matrix}\\right.\nbÎµa=â©âªâ¨âªâ§â€‹b,[b,1],âˆ…,â€‹å½“a&gt;bæ—¶å½“a=bæ—¶å½“b&gt;aæ—¶â€‹\nbÎµ^a={[0,b],å½“a&gt;bæ—¶[0,1],å½“aâ‰¤bæ—¶b \\hat{\\varepsilon} a=\\left\\{\\begin{matrix}\n [0,b], &amp; å½“a&gt;bæ—¶\\\\\n [0,1], &amp; å½“a\\le bæ—¶\n\\end{matrix}\\right.\nbÎµ^a={[0,b],[0,1],â€‹å½“a&gt;bæ—¶å½“aâ‰¤bæ—¶â€‹\nèƒŒä¸‹æ¥å°±è¡Œï¼Œé—®é¢˜æ˜¯æ€ä¹ˆèƒŒï¼Œæˆ‘åœ¨è¿™é‡Œæå‡ºä¸€ä¸ªåŸåˆ›æ•…äº‹æ¥å¸®åŠ©ä½ è®°å¿† â€”â€” å“¥å¼Ÿå§å¦¹å…¬å¼ã€‚\nä¸å¸¦å¸½å­çš„ç§°ä¸ºå“¥å¼Ÿå…¬å¼ï¼Œb æ˜¯å“¥å“¥ï¼Œa æ˜¯å¼Ÿå¼Ÿã€‚\nbÎµa={b,å½“a&gt;bæ—¶[b,1],å½“a=bæ—¶âˆ…,å½“b&gt;aæ—¶b\\varepsilon a=\\left\\{\\begin{matrix}\n b, &amp; å½“a&gt;bæ—¶\\\\\n [b,1], &amp; å½“a=bæ—¶\\\\\n \\emptyset , &amp; å½“b&gt;aæ—¶\n\\end{matrix}\\right.\nbÎµa=â©âªâ¨âªâ§â€‹b,[b,1],âˆ…,â€‹å½“a&gt;bæ—¶å½“a=bæ—¶å½“b&gt;aæ—¶â€‹\næ•…äº‹å¼€å§‹äº†â€¦\nå“¥å“¥è®©ç€å¼Ÿå¼Ÿï¼ˆå½“ a&gt;b æ—¶ï¼‰ï¼Œæˆ‘ä»¬è¯´è¿™æ˜¯ä¸€ä¸ªæœ‰æ‹…å½“çš„å“¥å“¥ï¼Œæˆ‘ä»¬åº”è¯¥è¤’å¥–å“¥å“¥ï¼ˆbï¼‰\nå“¥å“¥ä¸å¼Ÿå¼Ÿä¸€æ ·æ—¶ï¼Œè¿™è¯´æ˜å…„å¼ŸäºŒäººç›¸å¤„è‰¯å¥½ï¼Œå“¥å“¥çˆ±ç€å¼Ÿå¼Ÿï¼ˆè¿™ä¸ª [b, 1] å¯ä»¥ç†è§£ä¸º b æ˜¯å“¥å“¥ï¼Œ1 å°±åƒå­—æ¯ i ä¸€æ ·ï¼Œå“¥å“¥ bï¼Œi å¼Ÿå¼Ÿï¼Œ[b, 1]ï¼‰\nå½“å“¥å“¥æ¯”å¼Ÿå¼Ÿå¤§ï¼Œä¹Ÿå°±æ˜¯è¯´ä»–ä¸çˆ±å¼Ÿå¼Ÿï¼Œçˆ±å½’äºç©ºå¯‚ï¼Œæ‰€ä»¥ä¸çˆ±äº†æ˜¯ç©ºé›†ã€‚\næœ‰å¸½å­çš„ç§°ä¸ºå§å¦¹å…¬å¼ï¼Œb æ˜¯å§å§ï¼Œa æ˜¯å¦¹å¦¹ã€‚\nbÎµ^a={[0,b],å½“a&gt;bæ—¶[0,1],å½“aâ‰¤bæ—¶b \\hat{\\varepsilon} a=\\left\\{\\begin{matrix}\n [0,b], &amp; å½“a&gt;bæ—¶\\\\\n [0,1], &amp; å½“a\\le bæ—¶\n\\end{matrix}\\right.\nbÎµ^a={[0,b],[0,1],â€‹å½“a&gt;bæ—¶å½“aâ‰¤bæ—¶â€‹\næ•…äº‹å¼€å§‹äº†â€¦\nå¦¹å¦¹æ¯”è¾ƒç‰›ï¼Œå½“å¦¹å¦¹ç”Ÿæ°”çš„æ—¶å€™ï¼ˆa&gt;bï¼‰ï¼Œè¿™ä¸ªæ—¶å€™å§å§ä¹Ÿå¾ˆç”Ÿæ°”ï¼Œæ— è®ºå¦¹å¦¹åšä»€ä¹ˆå§å§éƒ½ä¸æƒ³ç†å¦¹å¦¹ï¼Œå§å§çä¸€åªçœ¼é—­ä¸€åªçœ¼ï¼ˆçä¸€åªçœ¼é—­ä¸€åªçœ¼ï¼Œ[0,b]ï¼Œè¿™ä¸ªçä¸€åªçœ¼å°±åƒ 0 ä¸€æ ·ï¼Œé—­ä¸€åªçœ¼å°±æ˜¯ bï¼Œæ‰€ä»¥æ˜¯ [0,b]ï¼‰ã€‚\nåæ¥ï¼ˆå…¶ä»–æƒ…å†µï¼‰ï¼Œåµæ¥åµå»ç»ˆç©¶å§å¦¹é‡å½’äºå¥½ï¼Œä»–ä»¬è¦å…±åŒæˆé•¿ï¼Œå…±èµ´æœªæ¥ï¼ˆ[0,1] ä»é›¶åˆ°ä¸€æç»˜äº†ä»å°åˆ°å¤§ï¼Œå…±åŒæˆé•¿ï¼‰ã€‚\n# ç¢ç¢å¿µ\næ¨¡ç³Šæ•°å­¦å¤ä¹ å°±åˆ°è¿™é‡Œäº†ï¼Œæ„Ÿè°¢ä½ èƒ½çœ‹åˆ°è¿™é‡Œï¼Œç¥å¤ä¹ é¡ºåˆ©ã€‚\n# ç‰¹åˆ«é¸£è°¢\nç‰¹åˆ«é¸£è°¢æˆ‘çš„å®¤å‹ï¼šæ±‚æ±‚ä½ åˆ«éª—æˆ‘ï¼Œå¯¹æœ¬æ–‡è¯¦ç»†å®¡é˜…ã€‚\n","categories":["ç¬”è®°"],"tags":["æ¨¡ç³Šæ•°å­¦è§£é¢˜ç¬”è®°"]},{"title":"è®¡ç®—æœºç½‘ç»œå¤è¯•é€Ÿè§ˆ","url":"/network/computer_network_retest/","content":"# è®¡ç®—æœºç½‘ç»œå¤è¯•\n# ç‰©ç†å±‚\nä¼ è¾“æ¯”ç‰¹æµï¼Œè§„å®šæœºæ¢°ç‰¹æ€§ã€ç”µæ°”ç‰¹æ€§ã€åŠŸèƒ½ç‰¹æ€§ã€‚\n# æ•°æ®é“¾è·¯å±‚\nå°†åŸå§‹æ¯”ç‰¹æµå°è£…æˆå¸§ï¼Œå°†ç‰©ç†å±‚æä¾›çš„å¯èƒ½å‡ºé”™çš„ç‰©ç†è¿æ¥æ”¹é€ ä¸ºé€»è¾‘ä¸Šæ— å·®é”™çš„æ•°æ®é“¾è·¯ï¼Œæ˜¯å¯¹ç‰©ç†å±‚çš„ä¸€æ¬¡å¢å¼ºã€‚\n# ç½‘ç»œå±‚\nä¼ è¾“å•ä½æ˜¯æ•°æ®æŠ¥ï¼Œè¿›è¡Œè·¯ç”±é€‰æ‹©ï¼Œå®ç°æµé‡æ§åˆ¶ã€æ‹¥å¡æ§åˆ¶ã€å·®é”™æ§åˆ¶ã€ç½‘é™…äº’è¿ã€‚\n# ä¼ è¾“å±‚\nè´Ÿè´£ä¸»æœºä¸­ä¸¤ä¸ªè¿›ç¨‹é€šä¿¡ï¼Œæä¾›ç«¯åˆ°ç«¯çš„å¯é ä¼ è¾“ã€‚\nç«¯åˆ°ç«¯ï¼šè¿›ç¨‹çš„ç«¯å£å·ä¹‹é—´\nç‚¹å¯¹ç‚¹ï¼šIP ä¹‹é—´\n# åº”ç”¨å±‚\nOSI æœ€é«˜å±‚ï¼Œæ˜¯ç”¨æˆ·ä¸ç½‘ç»œä¹‹é—´çš„æ¥å£ã€‚\n# ä¿¡é“ã€ä¸²è¡Œä¸å¹¶è¡Œ\næ˜¯é€šä¿¡çš„é€šé“ï¼Œå³ä¼ è¾“ä»‹è´¨ã€‚ä¸²è¡Œé€‚åˆé•¿è·ç¦»é€šä¿¡ï¼Œå¹¶è¡Œé€‚ç”¨äºå¹¶è¡Œé€šä¿¡ã€‚\n# å•å·¥ã€åŠåŒå·¥ä¸å…¨åŒå·¥\nå•å·¥ï¼šåªå•å‘ä¼ è¾“ã€‚\nåŠåŒå·¥ï¼šåŒå‘ï¼Œä½†æ˜¯ä¸èƒ½åŒæ—¶ã€‚\nå…¨åŒå·¥ï¼šåŒå‘ï¼Œå…è®¸åŒæ—¶ã€‚\n# å¥ˆå¥æ–¯ç‰¹å®šç†\nç†æƒ³ä¿¡é“ä¸­ï¼Œä¸ºé¿å…ä¸²ç å¹²æ‰°æé™é€Ÿç‡ã€‚\n# é¦™å†œå®šç†\nå®é™…ä¿¡é“ä¸­ï¼Œä¼ è¾“é€Ÿç‡ä¸Šç•Œã€‚\n# åŒç»çº¿ã€åŒè½´ç”µç¼†ã€å…‰çº¤ä¸æ— çº¿ä¼ è¾“\nåŒç»çº¿ã€åŒè½´ç”µç¼†ã€å…‰çº¤ä¸æ— çº¿ä¼ è¾“è¿™äº›éƒ½æ˜¯ç‰©ç†å±‚çš„ä¼ è¾“ä»‹è´¨ã€‚\n# ç‰©ç†å±‚è®¾å¤‡\nä¸­ç»§å™¨ï¼šä¿¡å·çš„è½¬å‘ã€æ”¾å¤§ã€æ•´å½¢ï¼Œä»¥é˜²æ­¢å¤±çœŸï¼Œæ— å·®é”™æ§åˆ¶ã€‚\né›†çº¿å™¨ï¼šå®é™…ä¸Šé›†çº¿å™¨æ˜¯ä¸€ä¸ªå¤šç«¯å£ä¸­ç»§å™¨ã€‚\n# å¸§\næ˜¯æ•°æ®é“¾è·¯å±‚å¯¹ç­‰å®ä½“ä¹‹é—´è¿›è¡Œçš„é€»è¾‘é€šä¿¡å•å…ƒã€‚\n# ä¸ºç½‘ç»œå±‚æä¾›çš„ä¸‰ç§æœåŠ¡\n\næ— ç¡®è®¤ã€æ— è¿æ¥çš„æœåŠ¡ï¼Œé€‚ç”¨äºè¯¯ç ç‡ä½çš„æ¯”å¦‚ä»¥å¤ªç½‘\næœ‰ç¡®è®¤ã€æ— è¿æ¥çš„æœåŠ¡ï¼Œé€‚ç”¨äºæ— çº¿é€šä¿¡\næœ‰ç¡®è®¤çš„é¢å‘è¿æ¥çš„æœåŠ¡ï¼Œé€‚ç”¨äºæœ‰é«˜å¯é è¦æ±‚çš„ç½‘ç»œ\n\n# å°è£…æˆå¸§\nåœ¨ä¸€ç‚¹æ•°æ®çš„å¤´å’Œå°¾åŠ ä¸€äº›ä¿¡æ¯ï¼Œæ„æˆå¸§ï¼Œä¸»è¦æ˜¯ï¼šæ ‡å¿—ã€åœ°å€ã€æ§åˆ¶ã€ä¿¡æ¯ã€å¸§æ£€éªŒåºåˆ—ã€æ ‡å¿—ç»„æˆã€‚\n# é€æ˜ä¼ è¾“\né€æ˜ä¼ è¾“çš„ä½œç”¨æ˜¯ä½ æ— è®ºä¼ è¾“äº†ä»€ä¹ˆæ•°æ®ï¼Œéƒ½ä¼šä¿è¯ä½ çš„ä¼ è¾“åŸæ•°æ®ï¼Œä¸ä¼šè¢«â€ è¯¯è§£ â€œ\n# æµé‡æ§åˆ¶\né“¾è·¯ä¸¤ç«¯å­˜åœ¨å·¥ä½œé€Ÿç‡å·®å¼‚ï¼Œä¸ºä»¥é˜²æ·¹æ²¡ç°è±¡ï¼Œä½¿ç”¨æµé‡æ§åˆ¶ã€‚æ¥æ”¶æ–¹æ§åˆ¶å‘é€æ–¹ã€‚\n# å·®é”™æ£€æµ‹\nä¼ è¾“æ—¶å¯èƒ½äº§ç”Ÿé”™è¯¯ï¼Œä¸ºä¿®å¤è¿™äº›é”™è¯¯ä½¿ç”¨å·®é”™æ£€æµ‹æœºåˆ¶\n\nä½é”™ï¼šç”¨ CRC å†—ä½™æ ¡éªŒ\nå¸§é”™ï¼šè¿™ä¸ªæ˜¯ä¼ è¾“é”™è¯¯\n\n# å­—èŠ‚å¡«å……æ³•\nåœ¨å¼€å¤´å¡«å……å’Œæœ«å°¾å¡«å……\n# é›¶æ¯”ç‰¹å¡«å……æ³•\næ¯é‡äº”ä¸ªâ€˜1â€™åœ¨åé¢å¡«å……ä¸€ä¸ªâ€˜0â€™\n# å·®é”™æ§åˆ¶\nè‡ªåŠ¨é‡ä¼ è¯·æ±‚ ARQ / å‰å‘çº é”™ FECï¼šARQ æ˜¯ä¸€ç§åŸºäºé‡ä¼ çš„é”™è¯¯æ§åˆ¶æœºåˆ¶ã€‚å½“æ¥æ”¶ç«¯æ£€æµ‹åˆ°æ•°æ®åŒ…é”™è¯¯æˆ–ä¸¢å¤±æ—¶ï¼Œä¼šè¯·æ±‚å‘é€ç«¯é‡æ–°å‘é€æ•°æ®ã€‚FEC æ˜¯ä¸€ç§é€šè¿‡åœ¨å‘é€çš„æ•°æ®ä¸­æ·»åŠ å†—ä½™ä¿¡æ¯æ¥çº æ­£é”™è¯¯çš„æœºåˆ¶ã€‚æ¥æ”¶ç«¯åˆ©ç”¨è¿™äº›å†—ä½™ä¿¡æ¯æ£€æµ‹å¹¶çº æ­£é”™è¯¯ï¼Œè€Œæ— éœ€è¯·æ±‚é‡ä¼ ã€‚\nå·®é”™æ§åˆ¶åˆå¯åˆ†ä¸ºï¼šæ£€é”™ç¼–ç ï¼ˆå¥‡å¶æ ¡éªŒç ã€å¾ªç¯å†—ä½™ç ï¼‰å’Œçº é”™ç¼–ç ï¼ˆæµ·æ˜ç ï¼‰\n\nå¥‡å¶æ ¡éªŒç ï¼ˆæ£€é”™ï¼‰å°±æ˜¯è®© 1 çš„ä¸ªæ•°æ˜¯å¥‡æ•°ä¸ªè¿˜æ˜¯å¶æ•°ä¸ª\næµ·æ˜ç ï¼ˆçº é”™ï¼‰å°±æ˜¯åœ¨ä¿¡æ¯ä½ä¸­åŠ å…¥å‡ ä¸ªå°±é”™ä½\n\n# åœæ­¢ - ç­‰å¾…æµé‡æ§åˆ¶ï¼ˆä¸€ä¸ªä¸€ä¸ªçš„ï¼‰\nå‘é€æ–¹æ¯æ¬¡å‘é€ä¸€ä¸ªå¸§ï¼Œåªæœ‰æ¥æ”¶æ–¹å›å¤ç¡®è®¤å¸§æ‰å‘ä¸‹ä¸€å¸§\n# æ»‘åŠ¨çª—å£æµé‡æ§åˆ¶ï¼ˆä¸€å—ä¸€å—çš„ï¼‰\né›†ä¸­å‘é€ä¸€å—ï¼Œæ”¶åˆ°æœ€å·¦ä¾§çš„å¸§åå‘å³æ»‘åŠ¨ï¼Œå¦‚æœæœªæ”¶ç¡®è®¤æ¶ˆæ¯åˆ°é‚£å°±é‡å‘ã€‚\n# ARQ åè®®ï¼ˆè‡ªåŠ¨é‡ä¼ è¯·æ±‚ï¼‰!\n\nåœæ­¢ - ç­‰å¾… Stop-and-Waitï¼šå‘é€ç«¯å‘é€ä¸€ä¸ªæ•°æ®åŒ…åï¼Œç­‰å¾…æ¥æ”¶ç«¯çš„ç¡®è®¤ï¼ˆACKï¼‰ã€‚å¦‚æœæ”¶åˆ° ACKï¼Œå‘é€ä¸‹ä¸€ä¸ªæ•°æ®åŒ…ï¼›å¦‚æœè¶…æ—¶æœªæ”¶åˆ° ACKï¼Œåˆ™é‡ä¼ ã€‚ç®€å•ä½†æ•ˆç‡è¾ƒä½ï¼Œé€‚åˆä½é€Ÿç‡é€šä¿¡ã€‚\nåé€€ N å¸§ Go-Back-Nï¼šå¦‚æœæŸä¸ªæ•°æ®åŒ…å‡ºé”™ï¼Œæ¥æ”¶ç«¯ä¼šä¸¢å¼ƒè¯¥åŒ…åŠå…¶åç»­çš„æ‰€æœ‰åŒ…ï¼Œå‘é€ç«¯éœ€è¦ä»å‡ºé”™çš„æ•°æ®åŒ…å¼€å§‹é‡ä¼ ã€‚\né€‰æ‹©æ€§é‡ä¼  Selective Repeatï¼šå¦‚æœæŸä¸ªæ•°æ®åŒ…å‡ºé”™ï¼Œåªé‡ä¼ å‡ºé”™çš„æ•°æ®åŒ…ï¼Œè€Œä¸æ˜¯åç»­çš„æ‰€æœ‰åŒ…ã€‚\n\n1-&gt;2-&gt;3ï¼Œè¶Šæ¥è¶Šä¼˜ç§€ã€‚\n# ä»‹è´¨è®¿é—®æ§åˆ¶\næ•°æ®é“¾è·¯å±‚çš„ä¸€ä¸ªå­å±‚ï¼Œä¸»è¦è´Ÿè´£ç®¡ç†å¤šä¸ªè®¾å¤‡å…±äº«åŒä¸€é€šä¿¡ä»‹è´¨æ—¶çš„è®¿é—®æƒé™ã€‚å®ƒçš„æ ¸å¿ƒç›®æ ‡æ˜¯è§£å†³å¤šè·¯è®¿é—®é—®é¢˜ï¼Œå³å¦‚ä½•é«˜æ•ˆã€å…¬å¹³åœ°åè°ƒå¤šä¸ªè®¾å¤‡å¯¹å…±äº«ä»‹è´¨çš„è®¿é—®ï¼Œä»¥é¿å…å†²çªå¹¶æé«˜ç½‘ç»œæ€§èƒ½ã€‚\n\né¢‘åˆ†å¤ç”¨ FDMï¼šå°†æ€»å¸¦å®½åˆ’åˆ†ä¸ºå¤šä¸ªå­é¢‘å¸¦ï¼Œæ¯ä¸ªå­é¢‘å¸¦åˆ†é…ç»™ä¸€ä¸ªä¿¡é“ï¼ˆç”¨æˆ·æˆ–è®¾å¤‡ï¼‰\næ—¶åˆ†å¤ç”¨ TDMï¼šå°†æ—¶é—´åˆ’åˆ†ä¸ºå›ºå®šé•¿åº¦çš„æ—¶éš™ï¼Œæ¯ä¸ªæ—¶éš™åˆ†é…ç»™ä¸€ä¸ªä¿¡é“ã€‚\næ³¢åˆ†å¤ç”¨ WDMï¼šåœ¨å…‰çº¤é€šä¿¡ä¸­ï¼Œå°†ä¸åŒæ³¢é•¿çš„å…‰ä¿¡å·å¤ç”¨åˆ°åŒä¸€æ ¹å…‰çº¤ä¸­ä¼ è¾“ã€‚\nç åˆ†å¤ç”¨ CDMï¼šæ¯ä¸ªä¿¡é“ä½¿ç”¨å”¯ä¸€çš„ç¼–ç åºåˆ—å¯¹æ•°æ®è¿›è¡Œè°ƒåˆ¶ï¼Œå¤šä¸ªä¿¡é“å¯ä»¥åœ¨åŒä¸€é¢‘ç‡å’Œæ—¶é—´å†…ä¼ è¾“ã€‚\n\n\n\n\næŠ€æœ¯\nåˆ’åˆ†ä¾æ®\né€‚ç”¨åœºæ™¯\nä¼˜ç‚¹\nç¼ºç‚¹\n\n\n\n\nFDM\né¢‘ç‡\nå¹¿æ’­ã€æ¨¡æ‹Ÿé€šä¿¡\nç®€å•ã€é€‚åˆæ’å®šé€Ÿç‡æ•°æ®\né¢‘ç‡åˆ©ç”¨ç‡ä½\n\n\nTDM\næ—¶é—´\næ•°å­—ç”µè¯ã€æ•°å­—é€šä¿¡\né«˜æ•ˆã€é€‚åˆæ•°å­—ä¿¡å·\nå¯¹åŒæ­¥è¦æ±‚é«˜\n\n\nWDM\næ³¢é•¿ï¼ˆå…‰é¢‘ç‡ï¼‰\nå…‰çº¤é€šä¿¡\né«˜å®¹é‡ã€é•¿è·ç¦»ä¼ è¾“\nè®¾å¤‡æˆæœ¬é«˜\n\n\nCDM\nç¼–ç \nç§»åŠ¨é€šä¿¡ã€å«æ˜Ÿé€šä¿¡\næŠ—å¹²æ‰°ã€å¤šç”¨æˆ·åŒæ—¶é€šä¿¡\nå®ç°å¤æ‚\n\n\n\n# ALOHA\næœ€ç®€å•çš„éšæœºè®¿é—®åè®®ï¼Œè®¾å¤‡éšæ—¶å‘é€æ•°æ®ã€‚å¦‚æœå‘ç”Ÿå†²çªï¼Œéšæœºç­‰å¾…ä¸€æ®µæ—¶é—´åé‡ä¼ ã€‚æ•ˆç‡è¾ƒä½ï¼Œæœ€å¤§ä¿¡é“åˆ©ç”¨ç‡ä¸º 18.4%ã€‚\n# è½½æ³¢ä¾¦å¬å¤šè·¯è®¿é—®ï¼ˆCSMAï¼‰\nè®¾å¤‡åœ¨å‘é€æ•°æ®å‰å…ˆä¾¦å¬ä»‹è´¨æ˜¯å¦ç©ºé—²ã€‚å¦‚æœä»‹è´¨ç©ºé—²ï¼Œåˆ™å‘é€æ•°æ®ï¼›å¦åˆ™ç­‰å¾…ã€‚\n\n\nCSMA/CDï¼ˆå†²çªæ£€æµ‹ï¼‰ï¼šç”¨äºæœ‰çº¿ä»¥å¤ªç½‘ï¼Œæ£€æµ‹åˆ°å†²çªåç«‹å³åœæ­¢å‘é€ã€‚\n\n\nCSMA/CAï¼ˆå†²çªé¿å…ï¼‰ï¼šç”¨äºæ— çº¿ç½‘ç»œï¼ˆå¦‚ Wi-Fiï¼‰ï¼Œé€šè¿‡éšæœºé€€é¿é¿å…å†²çªã€‚\n\n\nCSMA æœ‰ï¼š1 - åšæŒ CSMAã€éåšæŒ CSMAã€p - åšæŒ CSMA\n\nâ€œ1 - åšæŒâ€ è¡¨ç¤ºè®¾å¤‡ä»¥æ¦‚ç‡ 1 å‘é€æ•°æ®ï¼ˆå³ä¸€æ—¦ä»‹è´¨ç©ºé—²ï¼Œå¿…å®šå‘é€ï¼‰ã€‚\nè®¾å¤‡ä¸ä¼šæŒç»­ä¾¦å¬ä»‹è´¨ï¼Œè€Œæ˜¯éšæœºé€€é¿ã€‚\np æ˜¯ä¸€ä¸ªå¯è°ƒå‚æ•°ï¼Œç”¨äºæ§åˆ¶å‘é€æ¦‚ç‡ï¼Œç»“åˆäº† 1 - åšæŒå’ŒéåšæŒçš„ç‰¹ç‚¹ã€‚\n\n# è½½æ³¢ä¾¦å¬å¤šè·¯è®¿é—® / å†²çªæ£€æµ‹ CSMA/CD ï¼ˆæœ‰çº¿ç½‘ç»œï¼‰\n# è½½æ³¢ä¾¦å¬ï¼ˆCarrier Senseï¼‰\n\nè®¾å¤‡åœ¨å‘é€æ•°æ®å‰å…ˆä¾¦å¬ä»‹è´¨æ˜¯å¦ç©ºé—²ã€‚\nå¦‚æœä»‹è´¨ç©ºé—²ï¼Œåˆ™å¼€å§‹å‘é€æ•°æ®ã€‚\nå¦‚æœä»‹è´¨å¿™ï¼Œåˆ™ç­‰å¾…ç›´åˆ°ä»‹è´¨ç©ºé—²ã€‚\n\n# å¤šè·¯è®¿é—®ï¼ˆMultiple Accessï¼‰\n\nå¤šä¸ªè®¾å¤‡å…±äº«åŒä¸€é€šä¿¡ä»‹è´¨ï¼Œå¯èƒ½åŒæ—¶å°è¯•å‘é€æ•°æ®ã€‚\n\n# å†²çªæ£€æµ‹ï¼ˆCollision Detectionï¼‰ï¼ˆCDï¼‰\n\nè®¾å¤‡åœ¨å‘é€æ•°æ®çš„åŒæ—¶ç»§ç»­ä¾¦å¬ä»‹è´¨ã€‚\nå¦‚æœæ£€æµ‹åˆ°å†²çªï¼ˆå³ä¿¡å·å¼ºåº¦å¼‚å¸¸ï¼‰ï¼Œç«‹å³åœæ­¢å‘é€æ•°æ®ã€‚\nå‘é€ä¸€ä¸ªå†²çªå¼ºåŒ–ä¿¡å·ï¼ˆJamming Signalï¼‰ï¼Œé€šçŸ¥å…¶ä»–è®¾å¤‡å‘ç”Ÿäº†å†²çªã€‚\n\n# éšæœºé€€é¿ï¼ˆRandom Backoffï¼‰\n\nè®¾å¤‡ç­‰å¾…ä¸€ä¸ªéšæœºæ—¶é—´åé‡æ–°å°è¯•å‘é€æ•°æ®ã€‚\néšæœºæ—¶é—´é€šè¿‡äºŒè¿›åˆ¶æŒ‡æ•°é€€é¿ç®—æ³•è®¡ç®—ï¼Œä»¥å‡å°‘å†æ¬¡å†²çªçš„æ¦‚ç‡ã€‚\n\nå…ˆå¬å†å‘ã€è¾¹å‘è¾¹å¬ã€å†²çªåœå‘ã€éšæœºé‡å‘\n# äº‰ç”¨æœŸ 2Ï„\nÏ„ æ˜¯ä¿¡å·åœ¨ç½‘ç»œä¸­ä¼ æ’­çš„å•ç¨‹æœ€å¤§ä¼ æ’­æ—¶å»¶ï¼Œäº‰ç”¨æœŸï¼ˆ2Ï„ï¼‰ æ˜¯ CSMA/CD åè®®ä¸­å†²çªæ£€æµ‹çš„æ—¶é—´çª—å£ã€‚å†³å®šäº†ç½‘ç»œçš„æœ€å¤§ç‰©ç†èŒƒå›´å’Œæœ€å°å¸§é•¿ã€‚é€šè¿‡åˆç†è®¾è®¡äº‰ç”¨æœŸï¼Œå¯ä»¥ç¡®ä¿å†²çªæ£€æµ‹çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œæé«˜ç½‘ç»œçš„å¯é æ€§ã€‚\n# äºŒè¿›åˆ¶æŒ‡æ•°é€€é¿ç®—æ³•\nå†²çªä¹‹åè¦ç­‰å¾…ï¼Œç­‰ï¼Ÿåˆ°åº•ç­‰å¤šä¹…ï¼Ÿåˆ©ç”¨äºŒè¿›åˆ¶æŒ‡æ•°é€€é¿ç®—æ³•å°±èƒ½çŸ¥é“ã€‚\n# å†²çªé¿å…ï¼ˆCAï¼‰\nå†²çªé¿å…é€šè¿‡é¢„å…ˆåè°ƒå’Œéšæœºé€€é¿æ¥å°½é‡é¿å…å†²çªçš„å‘ç”Ÿï¼Œè€Œä¸æ˜¯åœ¨å†²çªå‘ç”Ÿåå†è¿›è¡Œå¤„ç†ã€‚\n# è½½æ³¢ä¾¦å¬å¤šè·¯è®¿é—® / å†²çªé¿å… CSMA/CA ï¼ˆæ— çº¿ç½‘ç»œï¼‰\næ˜¯ä¸€ç§ç”¨äºæ— çº¿ç½‘ç»œï¼ˆå¦‚ Wi-Fiï¼‰çš„ä»‹è´¨è®¿é—®æ§åˆ¶åè®®ã€‚\n# CSMA/CA ä¸ CSMA/CD çš„åŒºåˆ«\n\n\n\nç‰¹æ€§\nCSMA/CAï¼ˆå†²çªé¿å…ï¼‰\nCSMA/CDï¼ˆå†²çªæ£€æµ‹ï¼‰\n\n\n\n\né€‚ç”¨ç½‘ç»œ\næ— çº¿ç½‘ç»œï¼ˆå¦‚ Wi-Fiï¼‰\næœ‰çº¿ç½‘ç»œï¼ˆå¦‚ä»¥å¤ªç½‘ï¼‰\n\n\nå†²çªå¤„ç†\né€šè¿‡ RTS/CTS å’Œé€€é¿é¿å…å†²çª\né€šè¿‡æ£€æµ‹å†²çªå¹¶é‡å‘æ•°æ®\n\n\néšè—ç»ˆç«¯é—®é¢˜\næœ‰æ•ˆè§£å†³\næ— æ³•è§£å†³\n\n\nå¼€é”€\nè¾ƒé«˜ï¼ˆRTS/CTS å’Œé€€é¿æœºåˆ¶ï¼‰\nè¾ƒä½\n\n\nå»¶è¿Ÿ\nè¾ƒé«˜\nè¾ƒä½\n\n\n\n# å¸¸è§æ‹“æ‰‘ç»“æ„\n\næ˜Ÿå‹\nç¯å‹\næ€»çº¿å‹\n\n# ä»¥å¤ªç½‘\né€»è¾‘æ‹“æ‰‘ç»“æ„æ˜¯æ€»çº¿å‹ï¼Œç‰©ç†æ‹“æ‰‘æ˜¯æ˜Ÿå‹ç»“æ„\nä»¥å¤ªç½‘é‡‡ç”¨ä¸¤é¡¹æªæ–½ç®€åŒ–é€šä¿¡\n\né‡‡ç”¨æ— è¿æ¥å·¥ä½œæ–¹å¼\nä½¿ç”¨æ›¼å½»æ–¯ç‰¹ç¼–ç \n\n# MAC åœ°å€\nè®¾å¤‡èº«ä»½è¯ï¼Œç»å¯¹å”¯ä¸€çš„åœ°å€ï¼ŒMAC åœ°å€ 48 ä½ã€‚\n# å•æ’­ã€å¤šæ’­ã€å¹¿æ’­\n\nå•æ’­ï¼šä¸€å¯¹ä¸€\nå¤šæ’­ï¼šä¸€å¯¹å¤š\nå¹¿æ’­ï¼šä¸€å¯¹æ‰€æœ‰\n\n# ä»¥å¤ªç½‘çš„ç›®çš„åœ°å€ã€æºåœ°å€\n\nç›®çš„åœ°å€ï¼šæ ‡è¯†å¸§çš„æ¥æ”¶æ–¹ã€‚\næºåœ°å€ï¼šæ ‡è¯†å¸§çš„å‘é€æ–¹ã€‚\nç±»å‹ï¼šæŒ‡ç¤ºå¸§å†…æ•°æ®çš„åè®®ç±»å‹ã€‚ï¼ˆIPV4ã€IPV6ã€ARPï¼‰\n\n# VLAN è™šæ‹Ÿå±€åŸŸç½‘\nVLANï¼ˆVirtual Local Area Networkï¼‰ æ˜¯ä¸€ç§å°†ç‰©ç†å±€åŸŸç½‘åˆ’åˆ†ä¸ºå¤šä¸ªé€»è¾‘å±€åŸŸç½‘çš„æŠ€æœ¯ã€‚é€šè¿‡ VLANï¼Œå¯ä»¥åœ¨åŒä¸€ç‰©ç†ç½‘ç»œè®¾å¤‡ï¼ˆå¦‚äº¤æ¢æœºï¼‰ä¸Šåˆ›å»ºå¤šä¸ªç‹¬ç«‹çš„å¹¿æ’­åŸŸï¼Œä»è€Œå®ç°ç½‘ç»œçš„é€»è¾‘éš”ç¦»å’Œä¼˜åŒ–ã€‚\n# PPP åè®®ï¼ˆPoint-to-Point Protocolï¼‰\nPPPï¼ˆç‚¹å¯¹ç‚¹åè®®ï¼‰ æ˜¯ä¸€ç§æ•°æ®é“¾è·¯å±‚åè®®ï¼Œç”¨äºåœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´ç›´æ¥ä¼ è¾“æ•°æ®ã€‚å®ƒå¹¿æ³›åº”ç”¨äºæ‹¨å·è¿æ¥ã€DSLã€ä¸²è¡Œé€šä¿¡ç­‰åœºæ™¯ï¼Œæ”¯æŒå¤šç§ç½‘ç»œå±‚åè®®ï¼ˆå¦‚ IPã€IPX ç­‰ï¼‰ï¼Œå¹¶æä¾›äº†èº«ä»½éªŒè¯ã€é”™è¯¯æ£€æµ‹å’Œå‹ç¼©ç­‰åŠŸèƒ½ã€‚\n\nåªä¿è¯æ— å·®é”™æ¥æ”¶ï¼ˆCRC æ ¡éªŒï¼‰ï¼Œæ˜¯ä¸å¯é çš„æœåŠ¡\nåªæ”¯æŒå…¨åŒå·¥çš„ç‚¹å¯¹ç‚¹é“¾è·¯\nPPP ä¸¤ç«¯å¯ä»¥è¿è¡Œä¸åŒçš„ç½‘ç»œå±‚åè®®\n\nPPP æ— è¿æ¥ã€ä¸å¯é ã€é€Ÿåº¦å¿«\n# é›†çº¿å™¨\nå¹¿æ’­ä¼ è¾“ï¼šæ•°æ®ä¼šè¢«å‘é€åˆ°æ‰€æœ‰ç«¯å£ï¼Œæ— è®ºç›®æ ‡è®¾å¤‡æ˜¯å“ªä¸€ä¸ªã€‚\næ— æ™ºèƒ½è¿‡æ»¤ï¼šé›†çº¿å™¨æ— æ³•è¯†åˆ«æ•°æ®çš„ç›®æ ‡åœ°å€ï¼Œå› æ­¤æ— æ³•ä¼˜åŒ–æ•°æ®ä¼ è¾“ã€‚\nå†²çªåŸŸï¼šæ‰€æœ‰è®¾å¤‡å…±äº«åŒä¸€ä¸ªå†²çªåŸŸï¼Œå®¹æ˜“å‘ç”Ÿæ•°æ®å†²çªï¼Œå¯¼è‡´ç½‘ç»œæ•ˆç‡ä½ä¸‹ã€‚\nå¸¦å®½å…±äº«ï¼šæ‰€æœ‰ç«¯å£å…±äº«æ€»å¸¦å®½ï¼ˆä¾‹å¦‚ï¼Œ10 Mbps çš„é›†çº¿å™¨è¿æ¥ 5 å°è®¾å¤‡ï¼Œæ¯å°è®¾å¤‡å¹³å‡åªèƒ½ä½¿ç”¨ 2 Mbpsï¼‰ã€‚\n# ç½‘æ¡¥\nç½‘æ¡¥å¯ä»¥è¯†åˆ«å¸§è½¬å‘å¸§ï¼Œè§£å†³å†²çªçš„é—®é¢˜\n# é›†çº¿å™¨ä¸ç½‘æ¡¥çš„ä¸»è¦åŒºåˆ«\n\n\n\nç‰¹æ€§\né›†çº¿å™¨ï¼ˆHubï¼‰\nç½‘æ¡¥ï¼ˆBridgeï¼‰\n\n\n\n\nå·¥ä½œå±‚æ¬¡\nç‰©ç†å±‚ï¼ˆLayer 1ï¼‰\næ•°æ®é“¾è·¯å±‚ï¼ˆLayer 2ï¼‰\n\n\næ•°æ®ä¼ è¾“æ–¹å¼\nå¹¿æ’­åˆ°æ‰€æœ‰ç«¯å£\næ ¹æ® MAC åœ°å€è½¬å‘åˆ°ç›®æ ‡ç«¯å£\n\n\nå†²çªåŸŸ\næ‰€æœ‰ç«¯å£å…±äº«ä¸€ä¸ªå†²çªåŸŸ\næ¯ä¸ªç«¯å£æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å†²çªåŸŸ\n\n\nå¹¿æ’­åŸŸ\næ‰€æœ‰ç«¯å£å…±äº«ä¸€ä¸ªå¹¿æ’­åŸŸ\næ‰€æœ‰ç«¯å£å…±äº«ä¸€ä¸ªå¹¿æ’­åŸŸ\n\n\nå¸¦å®½ç®¡ç†\næ‰€æœ‰ç«¯å£å…±äº«æ€»å¸¦å®½\næ¯ä¸ªç«¯å£æœ‰ç‹¬ç«‹å¸¦å®½\n\n\næ™ºèƒ½è¿‡æ»¤\næ— \næœ‰ï¼ˆåŸºäº MAC åœ°å€ï¼‰\n\n\nåº”ç”¨åœºæ™¯\nå°å‹ç½‘ç»œæˆ–ä¸´æ—¶è¿æ¥\nè¿æ¥ä¸¤ä¸ªå±€åŸŸç½‘æˆ–æ‰©å±•ç½‘ç»œ\n\n\nç°ä»£æ›¿ä»£å“\näº¤æ¢æœº\näº¤æ¢æœº\n\n\n\n# äº¤æ¢æœº\næ˜¯å¤šæ¥å£çš„ç½‘æ¡¥ï¼Œæ˜¯ç½‘æ¡¥çš„å¢å¼ºç‰ˆï¼Œæ‹¥æœ‰è‡ªå­¦ä¹ ç®—æ³•\nè®°å½•å„ä¸ªç«¯å£çš„ MAC åœ°å€ï¼ˆäº¤æ¢è¡¨ï¼‰ï¼Œå†·å¯åŠ¨é˜¶æ®µé€šè¿‡æ³›æ´ªï¼Œæ‰¾åˆ°å¯¹åº”çš„ MAC\n# é›†çº¿å™¨ã€äº¤æ¢æœº\né›†çº¿å™¨ä¸éš”ç¦»å†²çªåŸŸï¼Œä¹Ÿä¸éš”ç¦»å¹¿æ’­åŸŸã€‚\näº¤æ¢æœºéš”ç¦»å†²çªåŸŸï¼Œä½†ä¸éš”ç¦»å¹¿æ’­åŸŸã€‚\n# è®¾å¤‡\n\n\n\nç‰¹æ€§\nèƒ½å¦éš”ç¦»å†²çªåŸŸ\nèƒ½å¦éš”ç¦»å¹¿æ’­åŸŸ\n\n\n\n\né›†çº¿å™¨\nä¸èƒ½\nä¸èƒ½\n\n\nä¸­ç»§å™¨\nä¸èƒ½\nä¸èƒ½\n\n\näº¤æ¢æœº\nèƒ½\nä¸èƒ½\n\n\nç½‘æ¡¥\nèƒ½\nä¸èƒ½\n\n\nè·¯ç”±å™¨\nèƒ½\nèƒ½\n\n\n\n# ç½‘ç»œå±‚åŠŸèƒ½\n\nè·¯ç”±é€‰æ‹©ï¼šé€‰æ‹©æ•°æ®ä»æºè®¾å¤‡åˆ°ç›®æ ‡è®¾å¤‡çš„æœ€ä½³è·¯å¾„ã€‚\nåˆ†ç»„è½¬å‘ï¼šæ ¹æ®è·¯ç”±è¡¨å°†æ•°æ®åŒ…ä»è¾“å…¥æ¥å£è½¬å‘åˆ°è¾“å‡ºæ¥å£ã€‚\né€»è¾‘å¯»å€ï¼šä¸ºç½‘ç»œä¸­çš„è®¾å¤‡åˆ†é…å”¯ä¸€çš„é€»è¾‘åœ°å€ï¼ˆå¦‚ IP åœ°å€ï¼‰ã€‚\nåˆ†æ®µä¸é‡ç»„ï¼šå°†å¤§æ•°æ®åŒ…åˆ†å‰²æˆé€‚åˆä¼ è¾“çš„å°æ•°æ®åŒ…ï¼Œå¹¶åœ¨ç›®æ ‡è®¾å¤‡å¤„é‡æ–°ç»„è£…ã€‚\næ‹¥å¡æ§åˆ¶ï¼šé˜²æ­¢ç½‘ç»œå› æ•°æ®æµé‡è¿‡å¤§è€Œå‡ºç°æ‹¥å¡ã€‚\nå¼‚æ„ç½‘ç»œäº’è”ï¼šè¿æ¥ä¸åŒç±»å‹çš„ç½‘ç»œï¼ˆå¦‚ä»¥å¤ªç½‘ã€Wi-Fiã€å¸§ä¸­ç»§ç­‰ï¼‰ã€‚\né”™è¯¯å¤„ç†ä¸è¯Šæ–­ï¼šæ£€æµ‹å’Œå¤„ç†ç½‘ç»œä¸­çš„é”™è¯¯ã€‚\næœåŠ¡è´¨é‡ï¼šä¸ºä¸åŒç±»å‹çš„æ•°æ®æµæä¾›ä¼˜å…ˆçº§å’Œå¸¦å®½ä¿éšœã€‚\nå®‰å…¨æ€§ï¼šä¿æŠ¤ç½‘ç»œå±‚æ•°æ®çš„å®‰å…¨æ€§å’Œéšç§æ€§ã€‚\n\n# è·¯ç”±å™¨åŠŸèƒ½\n\nè·¯ç”±é€‰æ‹©\nåˆ†ç»„è½¬å‘\n\n# SDN è½¯ä»¶å®šä¹‰ç½‘ç»œ\nè½¯ä»¶å®šä¹‰ç½‘ç»œï¼ˆSDNï¼ŒSoftware-Defined Networkingï¼‰ æ˜¯ä¸€ç§ç½‘ç»œæ¶æ„ï¼Œæ—¨åœ¨é€šè¿‡å°†ç½‘ç»œæ§åˆ¶å¹³é¢ä¸æ•°æ®å¹³é¢åˆ†ç¦»ï¼Œæå‡ç½‘ç»œçš„å¯ç¼–ç¨‹æ€§ã€çµæ´»æ€§å’Œç®¡ç†æ•ˆç‡ã€‚SDN çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡é›†ä¸­å¼çš„æ§åˆ¶å™¨æ¥ç®¡ç†ç½‘ç»œè®¾å¤‡ï¼Œç®€åŒ–é…ç½®å’Œä¼˜åŒ–æµé‡ã€‚\nSDN çš„ä¼˜åŠ¿\n\né›†ä¸­æ§åˆ¶ï¼š\n\né€šè¿‡é›†ä¸­æ§åˆ¶å™¨ç®¡ç†ç½‘ç»œï¼Œç®€åŒ–é…ç½®å’Œæ•…éšœæ’æŸ¥ã€‚\n\n\nçµæ´»æ€§ä¸å¯ç¼–ç¨‹æ€§ï¼š\n\nç½‘ç»œè¡Œä¸ºå¯é€šè¿‡è½¯ä»¶ç¼–ç¨‹åŠ¨æ€è°ƒæ•´ï¼Œé€‚åº”ä¸åŒéœ€æ±‚ã€‚\n\n\nè‡ªåŠ¨åŒ–ä¸æ™ºèƒ½åŒ–ï¼š\n\næ”¯æŒè‡ªåŠ¨åŒ–é…ç½®å’Œä¼˜åŒ–ï¼Œå‡å°‘äººå·¥å¹²é¢„ã€‚\n\n\nç½‘ç»œè™šæ‹ŸåŒ–ï¼š\n\næ”¯æŒå¤šç§Ÿæˆ·ç½‘ç»œè™šæ‹ŸåŒ–ï¼Œæå‡èµ„æºåˆ©ç”¨ç‡ã€‚\n\n\nå¿«é€Ÿåˆ›æ–°ï¼š\n\næ–°åŠŸèƒ½å¯é€šè¿‡è½¯ä»¶å¿«é€Ÿéƒ¨ç½²ï¼Œæ— éœ€æ›´æ¢ç¡¬ä»¶ã€‚\n\n\n\n# æ‹¥å¡æ§åˆ¶\nå› ä¸ºç½‘ç»œä¸­å‡ºç°è¿‡å¤šçš„åˆ†ç»„è€Œå¼•èµ·çš„ç½‘ç»œæ€§èƒ½ä¸‹é™ã€‚\næ§åˆ¶æ‹¥å¡çš„ä¸¤ç§æ–¹æ³•ï¼š\n\nå¼€ç¯æ§åˆ¶ï¼šäº‹å‘å‰\né—­ç¯æ§åˆ¶ï¼šäº‹å‘ä¸­ / å\n\n# IPv4ï¼ˆ32 ä½ï¼‰\næ§åˆ¶ç½‘ç»œæ•°æ®ä¼ é€çš„ç½‘ç»œåè®®ã€‚å…¶ä¸»è¦ç”±é¦–éƒ¨ï¼ˆ20 å­—èŠ‚ï¼‰åŠ æ•°æ®éƒ¨\nç½‘ç»œå· + ä¸»æœºå·\nå…¨ 0 æ˜¯æœ¬æœºåœ°å€\nå…¨ 1 æ˜¯å¹¿æ’­åœ°å€\n# IPv6ï¼ˆ128 ä½ï¼‰\n# æºåœ°å€å­—æ®µã€ç›®çš„åœ°å€å­—æ®µ\n# MTUï¼ˆæœ€å¤§ä¼ é€å•å…ƒï¼‰\n# OSI äº”å±‚æ¨¡å‹ vs OSI ä¸ƒå±‚æ¨¡å‹\n\n\n\nOSI äº”å±‚æ¨¡å‹\nOSI ä¸ƒå±‚æ¨¡å‹\nåŠŸèƒ½æè¿°\n\n\n\n\nåº”ç”¨å±‚\nåº”ç”¨å±‚ï¼ˆApplicationï¼‰\næä¾›åº”ç”¨ç¨‹åºæ¥å£å’ŒæœåŠ¡ï¼ˆå¦‚ HTTPã€FTPã€DNS ç­‰ï¼‰ã€‚\n\n\n\nè¡¨ç¤ºå±‚ï¼ˆPresentationï¼‰\næ•°æ®æ ¼å¼åŒ–ã€åŠ å¯†å’Œè§£å¯†ï¼ˆå¦‚ SSL/TLSï¼‰ã€‚\n\n\n\nä¼šè¯å±‚ï¼ˆSessionï¼‰\nå»ºç«‹ã€ç®¡ç†å’Œç»ˆæ­¢ä¼šè¯ï¼ˆå¦‚ RPCã€NetBIOSï¼‰ã€‚\n\n\nä¼ è¾“å±‚\nä¼ è¾“å±‚ï¼ˆTransportï¼‰\næä¾›ç«¯åˆ°ç«¯çš„å¯é æ•°æ®ä¼ è¾“ï¼ˆå¦‚ TCPã€UDPï¼‰ã€‚\n\n\nç½‘ç»œå±‚\nç½‘ç»œå±‚ï¼ˆNetworkï¼‰\nè´Ÿè´£é€»è¾‘åœ°å€å¯»å€å’Œè·¯ç”±é€‰æ‹©ï¼ˆå¦‚ IPã€ICMPï¼‰ã€‚\n\n\næ•°æ®é“¾è·¯å±‚\næ•°æ®é“¾è·¯å±‚ï¼ˆData Linkï¼‰\næä¾›èŠ‚ç‚¹åˆ°èŠ‚ç‚¹çš„å¯é æ•°æ®ä¼ è¾“ï¼ˆå¦‚ Ethernetã€PPPï¼‰ã€‚\n\n\nç‰©ç†å±‚\nç‰©ç†å±‚ï¼ˆPhysicalï¼‰\nä¼ è¾“åŸå§‹çš„æ¯”ç‰¹æµï¼ˆå¦‚ç½‘çº¿ã€å…‰çº¤ã€Wi-Fiï¼‰ã€‚\n\n\n\n# NAT ç½‘ç»œåœ°å€è½¬æ¢\nNATï¼ˆNetwork Address Translationï¼Œç½‘ç»œåœ°å€è½¬æ¢ï¼‰ æ˜¯ä¸€ç§ç”¨äºå°†ç§æœ‰ç½‘ç»œä¸­çš„ IP åœ°å€æ˜ å°„åˆ°å…¬å…± IP åœ°å€çš„æŠ€æœ¯ã€‚å®ƒä¸»è¦ç”¨äºè§£å†³ IPv4 åœ°å€ä¸è¶³çš„é—®é¢˜ï¼Œå¹¶æé«˜ç½‘ç»œçš„å®‰å…¨æ€§ã€‚\n# å­ç½‘æ©ç \nå­ç½‘æ©ç ï¼ˆSubnet Maskï¼‰ æ˜¯ç”¨äºåˆ’åˆ† IP åœ°å€çš„ç½‘ç»œéƒ¨åˆ†å’Œä¸»æœºéƒ¨åˆ†çš„å…³é”®å·¥å…·ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å¸®åŠ©ç½‘ç»œè®¾å¤‡ç¡®å®šä¸€ä¸ª IP åœ°å€å±äºå“ªä¸ªå­ç½‘ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„è·¯ç”±å’Œç½‘ç»œç®¡ç†ã€‚\n\nåˆ’åˆ†ç½‘ç»œå’Œä¸»æœº\næ”¯æŒå­ç½‘åˆ’åˆ†\nè·¯ç”±é€‰æ‹©\nå¹¿æ’­åŸŸæ§åˆ¶\n\n# IP åœ°å€çš„åˆ†ç±»\n\n\n\nç±»åˆ«\nå‰ç¼€\nåœ°å€èŒƒå›´\né»˜è®¤å­ç½‘æ©ç \nç”¨é€”\n\n\n\n\nA ç±»\n0\n1.0.0.0  åˆ°  126.0.0.0\n255.0.0.0\nå¤§å‹ç½‘ç»œ\n\n\nB ç±»\n10\n128.0.0.0  åˆ°  191.255.0.0\n255.255.0.0\nä¸­å‹ç½‘ç»œ\n\n\nC ç±»\n110\n192.0.0.0  åˆ°  223.255.255.0\n255.255.255.0\nå°å‹ç½‘ç»œ\n\n\nD ç±»\n1110\n224.0.0.0  åˆ°  239.255.255.255\næ— \nå¤šæ’­ï¼ˆMulticastï¼‰\n\n\nE ç±»\n1111\n240.0.0.0  åˆ°  255.255.255.255\næ— \nä¿ç•™ï¼ˆå®éªŒç”¨é€”ï¼‰\n\n\n\n# è·¯ç”±èšåˆ\nå°†å¥½å‡ ä¸ªè·¯ç”±å™¨é€»è¾‘ä¸Šè§†ä¸ºä¸€ä¸ªï¼Œæ˜¯åœ°å€èšåˆã€‚\n# æœ€é•¿å‰ç¼€åŒ¹é…\n# ARP åœ°å€è§£æåè®®\n# DHCP åŠ¨æ€ä¸»æœºé…ç½®åè®®\nåŠ¨æ€åˆ†é… IP åœ°å€ï¼Œå…è®¸ä¸€å°ä¸»æœºæ— éœ€æ‰‹åŠ¨é…ç½®å³å¯è·å–åˆ° IP åœ°å€ï¼ŒåŸºäº UDPã€‚\n# ICMP ç½‘é™…æ§åˆ¶æŠ¥æ–‡åè®®\nICMP æ˜¯ä¼ è¾“äº†ä¸€ä¸ªæ§åˆ¶æŠ¥æ–‡ï¼Œä¸“é—¨ç”¨æ¥æŠ¥å‘ŠæŠ¥å‘Šé”™è¯¯å’Œå¼‚å¸¸çš„æƒ…å†µ\n# RIP çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿\nå¥½æ¶ˆæ¯ä¼ å¾—å¿«ã€åæ¶ˆæ¯ä¼ å¾—æ…¢\n","categories":["è®¡ç®—æœºç½‘ç»œ"],"tags":["è®¡ç®—æœºç½‘ç»œ"]},{"title":"Attention is all you need","url":"/paper/attention_is_all_your_need/","content":"# Attention is all you need\n\n\nã€Original Linkã€‘ Attention Is All You Need\nUpdated on Aug 2023\nAuthors\n\nAshish Vaswani Google Brain  avaswani@google.com\nNoam Shazeer Google Brain  noam@google.com\nNiki Parmar Google Research nikip@google.com\nJakob Uszkoreit Google Research usz@google.com\nLlion Jones Google Research llion@google.com\nAidan N. Gomez â€  University of Toronto aidan@cs.toronto.edu\nÅukasz Kaiser Google Brain  lukaszkaiser@google.com\nIllia Polosukhin â€¡  illia.polosukhin@gmail.com\n\n\n\n\n# Abstract\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder.\næ˜¾æ€§åºåˆ—è½¬å¯¼æ¨¡å‹åŸºäºå¤æ‚çš„å¾ªç¯æˆ–å·ç§¯ç¥ç»ç½‘ç»œï¼Œå…¶ä¸­åŒ…æ‹¬ç¼–ç å™¨å’Œè§£ç å™¨ã€‚\nThe best performing models also connect the encoder and decoder through an attention mechanism.\næ€§èƒ½æœ€ä½³çš„æ¨¡å‹è¿˜é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è¿æ¥ç¼–ç å™¨å’Œè§£ç å™¨ã€‚\nWe propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\næˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç®€å•ç½‘ç»œæ¶æ„ï¼Œå³ Transformerï¼Œå®ƒä»…åŸºäºæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®Œå…¨çœå»äº†é‡å¤å’Œå·ç§¯ã€‚\nExperiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.\nå¯¹ä¸¤é¡¹æœºå™¨ç¿»è¯‘ä»»åŠ¡çš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹åœ¨è´¨é‡ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶æ›´å…·å¯å¹¶è¡ŒåŒ–æ€§ï¼Œå¹¶ä¸”éœ€è¦æ›´å°‘çš„è®­ç»ƒæ—¶é—´ã€‚\nOur model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU.\næˆ‘ä»¬çš„æ¨¡å‹åœ¨ WMT 2014 è‹±å¾·ç¿»è¯‘ä»»åŠ¡ä¸­è¾¾åˆ°äº† 28.4 BLEUï¼Œæ¯”ç°æœ‰çš„æœ€ä½³ç»“æœï¼ˆåŒ…æ‹¬åˆå¥ï¼‰æé«˜äº† 2 BLEU ä»¥ä¸Šã€‚\nOn the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.\nåœ¨ WMT 2014 è‹±æ³•ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ 8 ä¸ª GPU ä¸Šè®­ç»ƒ 3.5 å¤©åï¼Œå»ºç«‹äº†æ–°çš„å•æ¨¡å‹æœ€å…ˆè¿›çš„ BLEU åˆ†æ•° 41.8ï¼Œè¿™åªæ˜¯æ–‡çŒ®ä¸­æœ€ä½³æ¨¡å‹è®­ç»ƒæˆæœ¬çš„ä¸€å°éƒ¨åˆ†ã€‚\nWe show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\næˆ‘ä»¬è¯æ˜äº† Transformer æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°æ¨å¹¿åˆ°å…¶ä»–ä»»åŠ¡ï¼Œé€šè¿‡å°†å…¶æˆåŠŸåº”ç”¨äºè‹±è¯­æˆåˆ†å¥æ³•åˆ†æï¼Œæ— è®ºæ˜¯åœ¨å¤§é‡è®­ç»ƒæ•°æ®è¿˜æ˜¯æœ‰é™è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ã€‚\n# Introduction\nRecurrent neural networks, long short-term memory and gated recurrent neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation.\nå¾ªç¯ç¥ç»ç½‘ç»œï¼Œå°¤å…¶æ˜¯é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰å’Œé—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰ï¼Œå·²ç»åœ¨åºåˆ—å»ºæ¨¡å’Œè½¬å¯¼é—®é¢˜ï¼ˆå¦‚è¯­è¨€å»ºæ¨¡å’Œæœºå™¨ç¿»è¯‘ï¼‰ä¸­è¢«ç‰¢å›ºåœ°ç¡®ç«‹ä¸ºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚\nNumerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures.\nè‡ªé‚£ä»¥åï¼Œäººä»¬ä¸æ–­åŠªåŠ›çªç ´å¾ªç¯è¯­è¨€æ¨¡å‹å’Œç¼–ç å™¨ - è§£ç å™¨æ¶æ„çš„æé™ã€‚\nRecurrent models typically factor computation along the symbol positions of the input and output sequences.\nå¾ªç¯æ¨¡å‹é€šå¸¸æ²¿ç€è¾“å…¥å’Œè¾“å‡ºåºåˆ—çš„ç¬¦å·ä½ç½®è¿›è¡Œè®¡ç®—åˆ†è§£ã€‚\nAligning the positions to steps in computation time, they generate a sequence of hidden states hth_thtâ€‹, as a function of the previous hidden state htâˆ’1h_tâˆ’1htâ€‹âˆ’1 and the input for position ttt.\nå°†ä½ç½®ä¸è®¡ç®—æ—¶é—´çš„æ­¥éª¤å¯¹é½ï¼Œå®ƒä»¬ç”Ÿæˆä¸€ç³»åˆ—éšè—çŠ¶æ€hth_thtâ€‹ï¼Œè¿™äº›éšè—çŠ¶æ€æ˜¯å‰ä¸€ä¸ªéšè—çŠ¶æ€htâˆ’1h_tâˆ’1htâ€‹âˆ’1 å’Œä½ç½®ttt çš„è¾“å…¥çš„å‡½æ•°ã€‚\nThis inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples.\nè¿™ç§å›ºæœ‰çš„é¡ºåºæ€§ä½¿å¾—åœ¨è®­ç»ƒæ ·æœ¬å†…éƒ¨æ— æ³•è¿›è¡Œå¹¶è¡ŒåŒ–å¤„ç†ï¼Œè¿™åœ¨åºåˆ—é•¿åº¦è¾ƒé•¿æ—¶å˜å¾—å°¤ä¸ºå…³é”®ï¼Œå› ä¸ºå†…å­˜é™åˆ¶ä¼šé™åˆ¶è·¨æ ·æœ¬çš„æ‰¹å¤„ç†ã€‚\nRecent work has achieved significant improvements in computational efficiency through factorization tricks and conditional computation, while also improving model performance in case of the latter. The fundamental constraint of sequential computation, however, remains.\næœ€è¿‘çš„ç ”ç©¶é€šè¿‡åˆ†è§£æŠ€å·§å’Œæ¡ä»¶è®¡ç®—åœ¨è®¡ç®—æ•ˆç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼ŒåŒæ—¶ä¹Ÿæé«˜äº†åè€…çš„æ¨¡å‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œé¡ºåºè®¡ç®—çš„åŸºæœ¬é™åˆ¶ä»ç„¶å­˜åœ¨ã€‚\n\nåˆ†è§£æŠ€å·§å¯ä»¥ç”¨äºä¼˜åŒ–çŸ©é˜µä¹˜æ³•ã€å·ç§¯æ“ä½œç­‰ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡å°†ä¸€ä¸ªå¤§çš„çŸ©é˜µä¹˜æ³•åˆ†è§£ä¸ºå¤šä¸ªå°çš„çŸ©é˜µä¹˜æ³•ï¼Œå¯ä»¥åˆ©ç”¨ç°ä»£ç¡¬ä»¶çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ã€‚\næ¡ä»¶è®¡ç®—å¯ä»¥ç”¨äºåŠ¨æ€è°ƒæ•´æ¨¡å‹çš„è®¡ç®—é‡ï¼Œä¾‹å¦‚åœ¨æŸäº›æƒ…å†µä¸‹è·³è¿‡æŸäº›å±‚çš„è®¡ç®—ï¼Œæˆ–è€…æ ¹æ®è¾“å…¥æ•°æ®çš„ç‰¹å¾é€‰æ‹©æ€§åœ°æ¿€æ´»æŸäº›ç¥ç»å…ƒã€‚\n\nAttention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences\næ³¨æ„åŠ›æœºåˆ¶å·²ç»æˆä¸ºå„ç§ä»»åŠ¡ä¸­ä»¤äººä¿¡æœçš„åºåˆ—å»ºæ¨¡å’Œè½¬å¯¼æ¨¡å‹çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒå…è®¸åœ¨ä¸è€ƒè™‘è¾“å…¥æˆ–è¾“å‡ºåºåˆ—ä¸­ä¾èµ–é¡¹è·ç¦»çš„æƒ…å†µä¸‹å¯¹ä¾èµ–å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚\nIn all but a few cases, however, such attention mechanisms are used in conjunction with a recurrent network.\nç„¶è€Œï¼Œåœ¨å‡ ä¹æ‰€æœ‰æƒ…å†µä¸‹ï¼Œè¿™äº›æ³¨æ„åŠ›æœºåˆ¶éƒ½æ˜¯ä¸å¾ªç¯ç½‘ç»œç»“åˆä½¿ç”¨çš„ã€‚\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.\nåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† Transformer æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§æ‘’å¼ƒäº†å¾ªç¯ç»“æ„ï¼Œå®Œå…¨ä¾èµ–äºæ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å…¨å±€ä¾èµ–å…³ç³»çš„æ¶æ„ã€‚Transformer æ¨¡å‹èƒ½å¤Ÿå®ç°æ˜¾è‘—æ›´é«˜çš„å¹¶è¡ŒåŒ–ç¨‹åº¦ï¼Œå¹¶ä¸”åœ¨ä»…ä½¿ç”¨å…«å— P100 GPU è®­ç»ƒåäºŒå°æ—¶åï¼Œå°±èƒ½åœ¨ç¿»è¯‘è´¨é‡ä¸Šè¾¾åˆ°æ–°çš„æœ€é«˜æ°´å¹³ã€‚\n# Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU, ByteNet and ConvS2S, all of which use convolutional neural networks as basic building block, computing hidden representations in parallel for all input and output positions.\nå‡å°‘é¡ºåºè®¡ç®—çš„ç›®æ ‡ä¹Ÿæ˜¯æ‰©å±•å‹ç¥ç» GPUï¼ˆExtended Neural GPUï¼‰ã€ByteNet å’Œ ConvS2S çš„åŸºç¡€ï¼Œè¿™äº›æ¨¡å‹éƒ½ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä½œä¸ºåŸºæœ¬æ„å»ºå—ï¼Œèƒ½å¤Ÿå¹¶è¡Œè®¡ç®—æ‰€æœ‰è¾“å…¥å’Œè¾“å‡ºä½ç½®çš„éšè—è¡¨ç¤ºã€‚\nIn these models, the number of operations required to relate signals from two arbitrary input or output positions grows in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet.\nåœ¨è¿™äº›æ¨¡å‹ä¸­ï¼Œå°†ä¸¤ä¸ªä»»æ„è¾“å…¥æˆ–è¾“å‡ºä½ç½®çš„ä¿¡å·å…³è”èµ·æ¥æ‰€éœ€çš„è¿ç®—æ¬¡æ•°ä¼šéšç€è¿™ä¸¤ä¸ªä½ç½®ä¹‹é—´çš„è·ç¦»å¢åŠ è€Œå¢é•¿ã€‚å¯¹äº ConvS2S æ¨¡å‹ï¼Œè¿™ç§å¢é•¿æ˜¯çº¿æ€§çš„ï¼›è€Œå¯¹äº ByteNet æ¨¡å‹ï¼Œè¿™ç§å¢é•¿æ˜¯å¯¹æ•°çš„ã€‚\nit more difficult to learn dependencies between distant positions. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2.\nè¿™ä½¿å¾—å­¦ä¹ è¿œè·ç¦»ä½ç½®ä¹‹é—´çš„ä¾èµ–å…³ç³»å˜å¾—æ›´åŠ å›°éš¾ã€‚åœ¨ Transformer æ¨¡å‹ä¸­ï¼Œè¿™ç§å›°éš¾è¢«å‡å°‘åˆ°äº†ä¸€ä¸ªå›ºå®šçš„è¿ç®—æ¬¡æ•°ï¼Œå°½ç®¡è¿™ä»¥å¹³å‡æ³¨æ„åŠ›åŠ æƒä½ç½®å¯¼è‡´çš„æœ‰æ•ˆåˆ†è¾¨ç‡é™ä½ä¸ºä»£ä»·ï¼Œè€Œæˆ‘ä»¬é€šè¿‡ç¬¬ 3.2 èŠ‚ä¸­æè¿°çš„å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰æœºåˆ¶æ¥æŠµæ¶ˆè¿™ç§å½±å“ã€‚\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations\nè‡ªæ³¨æ„åŠ›ï¼ˆSelf-attentionï¼‰ï¼Œæœ‰æ—¶ä¹Ÿç§°ä¸ºå†…éƒ¨æ³¨æ„åŠ›ï¼ˆintra-attentionï¼‰ï¼Œæ˜¯ä¸€ç§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒé€šè¿‡å…³è”å•ä¸ªåºåˆ—ä¸­ä¸åŒä½ç½®çš„ä¿¡æ¯æ¥è®¡ç®—è¯¥åºåˆ—çš„è¡¨ç¤ºã€‚è‡ªæ³¨æ„åŠ›å·²ç»åœ¨å¤šç§ä»»åŠ¡ä¸­æˆåŠŸåº”ç”¨ï¼ŒåŒ…æ‹¬é˜…è¯»ç†è§£ã€æ‘˜è¦ç”Ÿæˆã€æ–‡æœ¬è•´å«ä»¥åŠå­¦ä¹ ä¸ä»»åŠ¡æ— å…³çš„å¥å­è¡¨ç¤ºã€‚\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequencealigned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks.\nç«¯åˆ°ç«¯è®°å¿†ç½‘ç»œï¼ˆEnd-to-end Memory Networksï¼‰åŸºäºä¸€ç§å¾ªç¯æ³¨æ„åŠ›æœºåˆ¶ï¼Œè€Œä¸æ˜¯åŸºäºåºåˆ—å¯¹é½çš„å¾ªç¯ï¼Œå·²ç»åœ¨ç®€å•è¯­è¨€é—®ç­”å’Œè¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ã€‚\nTo the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequencealigned RNNs or convolution. In the following sections, we will describe the Transformer, motivate self-attention and discuss its advantages over models such as and.\nç„¶è€Œï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒTransformer æ˜¯ç¬¬ä¸€ä¸ªå®Œå…¨ä¾èµ–è‡ªæ³¨æ„åŠ›æ¥è®¡ç®—å…¶è¾“å…¥å’Œè¾“å‡ºçš„è¡¨ç¤ºçš„è½¬å¯¼æ¨¡å‹ï¼Œè€Œä¸ä½¿ç”¨åºåˆ—å¯¹é½çš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–å·ç§¯ã€‚åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç» Transformer æ¨¡å‹ï¼Œé˜è¿°è‡ªæ³¨æ„åŠ›çš„åŠ¨æœºï¼Œå¹¶è®¨è®ºå…¶ç›¸å¯¹äºå…¶ä»–æ¨¡å‹ï¼ˆå¦‚ RNN å’Œå·ç§¯æ¨¡å‹ï¼‰çš„ä¼˜åŠ¿ã€‚\n# Model Architecture\nMost competitive neural sequence transduction models have an encoder-decoder structure. Here, the encoder maps an input sequence of symbol representations (x1,...,xn)(x_1, ..., x_n)(x1â€‹,...,xnâ€‹) to a sequence of continuous representations z=(z1,...,zn)z = (z_1, ..., z_n)z=(z1â€‹,...,znâ€‹).\nå¤§å¤šæ•°å…·æœ‰ç«äº‰åŠ›çš„ç¥ç»åºåˆ—è½¬å¯¼æ¨¡å‹éƒ½é‡‡ç”¨äº†ç¼–ç å™¨ - è§£ç å™¨ç»“æ„ã€‚åœ¨è¿™ç§ç»“æ„ä¸­ï¼Œç¼–ç å™¨å°†è¾“å…¥ç¬¦å·åºåˆ—çš„è¡¨ç¤º(x1,...,xn)(x_1, ..., x_n)(x1â€‹,...,xnâ€‹) æ˜ å°„åˆ°ä¸€ä¸ªè¿ç»­è¡¨ç¤ºçš„åºåˆ— z=(z1,...,zn)z = (z_1, ..., z_n)z=(z1â€‹,...,znâ€‹)ã€‚\nGiven zzz, the decoder then generates an output sequence (y1,...,ym)(y_1, ..., y_m)(y1â€‹,...,ymâ€‹) of symbols one element at a time.\nç»™å®š zzzï¼Œè§£ç å™¨éšåé€ä¸ªç”Ÿæˆç¬¦å·çš„è¾“å‡ºåºåˆ— (y1,...,ym)(y_1, ..., y_m)(y1â€‹,...,ymâ€‹)ã€‚\nAt each step the model is auto-regressive, consuming the previously generated symbols as additional input when generating the next.\nåœ¨æ¯ä¸€æ­¥ä¸­ï¼Œæ¨¡å‹éƒ½æ˜¯è‡ªå›å½’çš„ï¼Œåœ¨ç”Ÿæˆä¸‹ä¸€ä¸ªç¬¦å·æ—¶ï¼Œä¼šå°†ä¹‹å‰ç”Ÿæˆçš„ç¬¦å·ä½œä¸ºé¢å¤–çš„è¾“å…¥ã€‚\n\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\nTransformer æ¨¡å‹éµå¾ªè¿™ç§æ€»ä½“æ¶æ„ï¼Œä½¿ç”¨å †å çš„è‡ªæ³¨æ„åŠ›å±‚å’Œé€ç‚¹å…¨è¿æ¥å±‚æ¥æ„å»ºç¼–ç å™¨å’Œè§£ç å™¨ï¼Œåˆ†åˆ«å¦‚å›¾ 1 çš„å·¦åŠéƒ¨åˆ†å’Œå³åŠéƒ¨åˆ†æ‰€ç¤ºã€‚\n# Encoder and Decoder Stacks\nEncoder: The encoder is composed of a stack of N=6N = 6N=6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, positionwise fully connected feed-forward network. We employ a residual connection around each of the two sub-layers, followed by layer normalization. That is, the output of each sub-layer is LayerNorm(x+Sublayer(x))LayerNorm(x + Sublayer(x))LayerNorm(x+Sublayer(x)), where Sublayer(x)Sublayer(x)Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel=512.d_{model} = 512.dmodelâ€‹=512.\nç¼–ç å™¨ç”± N=6N = 6N=6 ä¸ªç›¸åŒçš„å±‚å †å è€Œæˆã€‚æ¯ä¸€å±‚åŒ…å«ä¸¤ä¸ªå­å±‚ã€‚ç¬¬ä¸€ä¸ªå­å±‚æ˜¯å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆMulti-Head Self-Attentionï¼‰ï¼Œç¬¬äºŒä¸ªå­å±‚æ˜¯ä¸€ä¸ªç®€å•çš„é€ç‚¹å…¨è¿æ¥å‰é¦ˆç½‘ç»œï¼ˆPosition-wise Fully Connected Feed-Forward Networkï¼‰ã€‚æˆ‘ä»¬åœ¨æ¯ä¸ªå­å±‚å‘¨å›´ä½¿ç”¨æ®‹å·®è¿æ¥ï¼ˆResidual Connectionï¼‰ï¼Œå¹¶éšåè¿›è¡Œå±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªå­å±‚çš„è¾“å‡ºæ˜¯LayerNorm(x+Sublayer(x))LayerNorm(x + Sublayer(x))LayerNorm(x+Sublayer(x))ï¼Œå…¶ä¸­Sublayer(x)Sublayer(x)Sublayer(x) æ˜¯å­å±‚è‡ªèº«å®ç°çš„å‡½æ•°ã€‚ä¸ºäº†ä¾¿äºå®ç°è¿™äº›æ®‹å·®è¿æ¥ï¼Œæ¨¡å‹ä¸­çš„æ‰€æœ‰å­å±‚ä»¥åŠåµŒå…¥å±‚éƒ½äº§ç”Ÿç»´åº¦ä¸º dmodel=512d_{model} = 512dmodelâ€‹=512 çš„è¾“å‡ºã€‚\nDecoder: The decoder is also composed of a stack of N=6N = 6N=6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position iii can depend only on the known outputs at positions less than iii.\nè§£ç å™¨åŒæ ·ç”±N=6N = 6N=6 ä¸ªç›¸åŒçš„å±‚å †å è€Œæˆã€‚é™¤äº†ç¼–ç å™¨å±‚ä¸­çš„ä¸¤ä¸ªå­å±‚å¤–ï¼Œè§£ç å™¨æ’å…¥äº†ä¸€ä¸ªç¬¬ä¸‰ä¸ªå­å±‚ï¼Œè¯¥å­å±‚å¯¹ç¼–ç å™¨å †æ ˆçš„è¾“å‡ºæ‰§è¡Œå¤šå¤´æ³¨æ„åŠ›æ“ä½œã€‚ä¸ç¼–ç å™¨ç±»ä¼¼ï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªå­å±‚å‘¨å›´ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œå¹¶éšåè¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚æˆ‘ä»¬è¿˜ä¿®æ”¹äº†è§£ç å™¨å †æ ˆä¸­çš„è‡ªæ³¨æ„åŠ›å­å±‚ï¼Œä»¥é˜²æ­¢ä½ç½®å…³æ³¨åç»­ä½ç½®ã€‚è¿™ç§æ©ç ï¼ˆmaskingï¼‰ä¸è¾“å‡ºåµŒå…¥åç§»ä¸€ä¸ªä½ç½®çš„äº‹å®ç›¸ç»“åˆï¼Œç¡®ä¿äº†ä½ç½® iii çš„é¢„æµ‹åªèƒ½ä¾èµ–äºå°äº iii çš„å·²çŸ¥è¾“å‡ºã€‚\n# Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\næ³¨æ„åŠ›å‡½æ•°å¯ä»¥è¢«æè¿°ä¸ºå°†ä¸€ä¸ªæŸ¥è¯¢ï¼ˆqueryï¼‰å’Œä¸€ç»„é”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰æ˜ å°„åˆ°ä¸€ä¸ªè¾“å‡ºï¼Œå…¶ä¸­æŸ¥è¯¢ã€é”®ã€å€¼å’Œè¾“å‡ºéƒ½æ˜¯å‘é‡ã€‚è¾“å‡ºæ˜¯å€¼çš„åŠ æƒå’Œï¼Œå…¶ä¸­æ¯ä¸ªå€¼çš„æƒé‡æ˜¯ç”±æŸ¥è¯¢ä¸ç›¸åº”é”®çš„å…¼å®¹æ€§å‡½æ•°è®¡ç®—å¾—å‡ºçš„ã€‚\n\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel.\nå›¾ 2ï¼šï¼ˆå·¦ï¼‰ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ã€‚ï¼ˆå³ï¼‰å¤šå¤´æ³¨æ„åŠ›ç”±å¹¶è¡Œè¿è¡Œçš„å¤šä¸ªæ³¨æ„åŠ›å±‚ç»„æˆã€‚\n# Scaled Dot-Product Attention (ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›)\nWe call our particular attention â€œScaled Dot-Product Attentionâ€ (Figure 2).\næˆ‘ä»¬å°†æˆ‘ä»¬çš„ç‰¹æ®Šæ³¨æ„åŠ›ç§°ä¸º â€œå°ºåº¦ç‚¹ç§¯æ³¨æ„åŠ›â€ï¼ˆå›¾ 2ï¼‰ã€‚\nThe input consists of queries and keys of dimension dkd_kdkâ€‹, and values of dimension dvd_vdvâ€‹. We compute the dot products of the  query with all keys, divide each by dk\\sqrt{d_k}dkâ€‹â€‹, and apply a softmax function to obtain the weights on the values.\nè¾“å…¥ç”±ç»´åº¦ dkd_kdkâ€‹ çš„æŸ¥è¯¢å’Œé”®ä»¥åŠç»´åº¦ dvd_vdvâ€‹ çš„å€¼ç»„æˆã€‚æˆ‘ä»¬è®¡ç®—æ‰€æœ‰é”®çš„æŸ¥è¯¢çš„ç‚¹ç§¯ï¼Œå°†æ¯ä¸ªé”®é™¤ä»¥ dk\\sqrt{d_k}dkâ€‹â€‹ï¼Œå¹¶åº”ç”¨ softmax å‡½æ•°æ¥è·å¾—å€¼çš„æƒé‡ã€‚\nIn practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix QQQ. The keys and values are also packed together into matrices KKK and V . We compute the matrix of outputs as:\nåœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬åŒæ—¶è®¡ç®—ä¸€ç»„æŸ¥è¯¢çš„æ³¨æ„åŠ›å‡½æ•°ï¼Œå¹¶æ‰“åŒ…æˆçŸ©é˜µ QQQã€‚é”®å’Œå€¼ä¹Ÿæ‰“åŒ…åˆ°çŸ©é˜µ KKK å’Œ VVV ä¸­ã€‚æˆ‘ä»¬å°†è¾“å‡ºçŸ©é˜µè®¡ç®—ä¸ºï¼š\nAttention(Q,K,V)=softmax(QKTdk)V\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\nAttention(Q,K,V)=softmax(dkâ€‹â€‹QKTâ€‹)V\nThe two most commonly used attention functions are additive attention, and dot-product (multiplicative) attention.\nä¸¤ä¸ªæœ€å¸¸ç”¨çš„æ³¨æ„åŠ›å‡½æ•°æ˜¯åŠ æ³•æ³¨æ„åŠ›å’Œç‚¹ç§¯ï¼ˆä¹˜æ³•ï¼‰æ³¨æ„åŠ›ã€‚\nDot-product attention is identical to our algorithm, except for the scaling factor of 1dk\\frac{1}{\\sqrt{d_k}}dkâ€‹â€‹1â€‹  .\nç‚¹ç§¯æ³¨æ„åŠ›ä¸æˆ‘ä»¬çš„ç®—æ³•ç›¸åŒï¼Œåªæ˜¯ç¼©æ”¾å› å­ä¸º 1dk\\frac{1}{\\sqrt{d_k}}dkâ€‹â€‹1â€‹ ã€‚\nAdditive attention computes the compatibility function using a feed-forward network with  a single hidden layer\nåŠ æ€§æ³¨æ„åŠ›ä½¿ç”¨å…·æœ‰å•ä¸ªéšè—å±‚çš„å‰é¦ˆç½‘ç»œè®¡ç®—å…¼å®¹æ€§å‡½æ•°\nWhile the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.\nè™½ç„¶ä¸¤è€…åœ¨ç†è®ºå¤æ‚æ€§ä¸Šç›¸ä¼¼ï¼Œä½†ç‚¹ç§¯æ³¨æ„åŠ›åœ¨å®è·µä¸­é€Ÿåº¦æ›´å¿«ã€ç©ºé—´æ•ˆç‡æ›´é«˜ï¼Œå› ä¸ºå®ƒå¯ä»¥ä½¿ç”¨é«˜åº¦ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•ä»£ç æ¥å®ç°ã€‚\nWhile for small values of dkd_kdkâ€‹ the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of dkd_kdkâ€‹\nè™½ç„¶å¯¹äºè¾ƒå°çš„ dkd_kdkâ€‹ å€¼ï¼Œè¿™ä¸¤ç§æœºåˆ¶çš„æ€§èƒ½ç›¸ä¼¼ï¼Œä½†å¯¹äºè¾ƒå¤§çš„ dkd_kdkâ€‹ å€¼ï¼ŒåŠ æ³•æ³¨æ„åŠ›åœ¨ä¸ç¼©æ”¾çš„æƒ…å†µä¸‹ä¼˜äºç‚¹ç§¯æ³¨æ„åŠ›ã€‚\nWe suspect that for large values of dkd_kdkâ€‹, the dot products grow large in magnitude, pushing the softmax function into regions where it has  extremely small gradients\næˆ‘ä»¬æ€€ç–‘ï¼Œå¯¹äºè¾ƒå¤§çš„ dkd_kdkâ€‹ å€¼ï¼Œç‚¹ç§¯çš„å¹…åº¦ä¼šå˜å¤§ï¼Œå°† softmax å‡½æ•°æ¨å…¥æ¢¯åº¦æå°çš„åŒºåŸŸ\nTo counteract this effect, we scale the dot products by âˆš1dk\nä¸ºäº†æŠµæ¶ˆè¿™ç§å½±å“ï¼Œæˆ‘ä»¬å°†ç‚¹ç§¯ç¼©æ”¾ä¸º1dk\\frac{1}{\\sqrt{d_k}}dkâ€‹â€‹1â€‹\n# Multi-Head Attentionï¼ˆå¤šå¤´æ³¨æ„åŠ›ï¼‰\nInstead of performing a single attention function with dmodeld_{model}dmodelâ€‹-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dkd_kdkâ€‹, dkd_kdkâ€‹ and dvd_vdvâ€‹ dimensions, respectively.\næˆ‘ä»¬å‘ç°ï¼Œä¸å…¶å¯¹ dmodeld_{model}dmodelâ€‹ ç»´åº¦çš„é”®ã€å€¼å’ŒæŸ¥è¯¢æ‰§è¡Œå•ä¸ªæ³¨æ„åŠ›å‡½æ•°ï¼Œä¸å¦‚åˆ†åˆ«ä½¿ç”¨ä¸åŒçš„å­¦ä¹ çº¿æ€§æŠ•å½±å°†æŸ¥è¯¢ã€é”®å’Œå€¼çº¿æ€§æŠ•å½±åˆ° dkd_kdkâ€‹, dkd_kdkâ€‹ å’Œdvd_vdvâ€‹ ç»´åº¦ã€‚\nOn each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dvd_vdvâ€‹-dimensional output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\nåœ¨è¿™äº›æŸ¥è¯¢ã€é”®å’Œå€¼çš„æŠ•å½±ç‰ˆæœ¬ä¸Šï¼Œæˆ‘ä»¬å¹¶è¡Œåœ°æ‰§è¡Œæ³¨æ„åŠ›å‡½æ•°ï¼Œå¾—åˆ°ç»´åº¦ä¸º dvd_vdvâ€‹ çš„è¾“å‡ºå€¼ã€‚è¿™äº›è¾“å‡ºå€¼è¢«æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå¹¶å†æ¬¡è¿›è¡ŒæŠ•å½±ï¼Œä»è€Œå¾—åˆ°æœ€ç»ˆçš„å€¼ï¼Œå¦‚å›¾ 2 æ‰€ç¤ºã€‚\n\nå‡è®¾æŸ¥è¯¢ QQQã€é”® KKK  å’Œå€¼ VVV çš„ç»´åº¦åˆ†åˆ«ä¸º  dmodeld_{\\text{model}}dmodelâ€‹ ï¼Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥è¡¨ç¤ºä¸ºï¼š\n\næŠ•å½±\n\nQi=QWiQ,Ki=KWiK,Vi=VWiVforÂ i=1,â€¦,hQ_i = Q W_i^Q, \\quad K_i = K W_i^K, \\quad V_i = V W_i^V \\quad \\text{for } i = 1, \\ldots, h\nQiâ€‹=QWiQâ€‹,Kiâ€‹=KWiKâ€‹,Viâ€‹=VWiVâ€‹forÂ i=1,â€¦,h\nå…¶ä¸­ï¼ŒWiQW_i^QWiQâ€‹ã€WiKW_i^KWiKâ€‹ å’Œ WiVW_i^VWiVâ€‹ æ˜¯æ¯ä¸ªå¤´çš„æƒé‡çŸ©é˜µï¼Œhhh æ˜¯å¤´çš„æ•°é‡ã€‚\n\n\nå¹¶è¡Œæ‰§è¡Œæ³¨æ„åŠ›å‡½æ•°\nheadi=Attention(Qi,Ki,Vi)=softmax(QiKiTdk)Vi\\text{head}_i = \\text{Attention}(Q_i, K_i, V_i) = \\text{softmax}\\left(\\frac{Q_i K_i^T}{\\sqrt{d_k}}\\right) V_i\nheadiâ€‹=Attention(Qiâ€‹,Kiâ€‹,Viâ€‹)=softmax(dkâ€‹â€‹Qiâ€‹KiTâ€‹â€‹)Viâ€‹\n\n\næ‹¼æ¥\nConcat(head1,head2,â€¦,headh)\\text{Concat}(\\text{head}_1, \\text{head}_2, \\ldots, \\text{head}_h)\nConcat(head1â€‹,head2â€‹,â€¦,headhâ€‹)\n\n\nå†æ¬¡æŠ•å½±\nMultiHead(Q,K,V)=Concat(head1,head2,â€¦,headh)WO\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\text{head}_2, \\ldots, \\text{head}_h) W^O\nMultiHead(Q,K,V)=Concat(head1â€‹,head2â€‹,â€¦,headhâ€‹)WO\n\n\n\nMulti-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\nå¤šå¤´æ³¨æ„åŠ›å…è®¸æ¨¡å‹å…±åŒå…³æ³¨æ¥è‡ªä¸åŒä½ç½®çš„ä¸åŒè¡¨ç¤ºå­ç©ºé—´çš„ä¿¡æ¯ã€‚å¯¹äºå•ä¸ªæ³¨æ„åŠ›å¤´ï¼Œå¹³å‡ä¼šæŠ‘åˆ¶è¿™ç§æƒ…å†µã€‚\nMultiHead(Q,K,V)=Concat(head1,head2,â€¦,headh)whereÂ headi=Attention(QWiQ,KWiK,VWiV)\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\text{head}_2, \\ldots, \\text{head}_h)\\\\\n\\text{where} \\ head_i=Attention(QW_{i}^Q,KW_{i}^K,VW_{i}^V)\nMultiHead(Q,K,V)=Concat(head1â€‹,head2â€‹,â€¦,headhâ€‹)whereÂ headiâ€‹=Attention(QWiQâ€‹,KWiKâ€‹,VWiVâ€‹)\nWhere the projections are parameter matrices WiQâˆˆRdmodelÃ—dk,WiKâˆˆRdmodelÃ—dk,WiVâˆˆRdmodelÃ—dvW^Q_i\\in\\mathbb{R^{d_{model}\\times d_k}}, W^K_i\\in\\mathbb{R^{d_{model}\\times d_k}}, W^V_i\\in\\mathbb{R^{d_{model}\\times d_v}}WiQâ€‹âˆˆRdmodelâ€‹Ã—dkâ€‹,WiKâ€‹âˆˆRdmodelâ€‹Ã—dkâ€‹,WiVâ€‹âˆˆRdmodelâ€‹Ã—dvâ€‹ and WiQâˆˆRhdmodelÃ—dkW^Q_i\\in\\mathbb{R^{hd_{model}\\times d_k}}WiQâ€‹âˆˆRhdmodelâ€‹Ã—dkâ€‹\nå…¶ä¸­æŠ•å½±æ˜¯å‚æ•°çŸ©é˜µWiQâˆˆRdmodelÃ—dk,WiKâˆˆRdmodelÃ—dk,WiVâˆˆRdmodelÃ—dvW^Q_i\\in\\mathbb{R^{d_{model}\\times d_k}}, W^K_i\\in\\mathbb{R^{d_{model}\\times d_k}}, W^V_i\\in\\mathbb{R^{d_{model}\\times d_v}}WiQâ€‹âˆˆRdmodelâ€‹Ã—dkâ€‹,WiKâ€‹âˆˆRdmodelâ€‹Ã—dkâ€‹,WiVâ€‹âˆˆRdmodelâ€‹Ã—dvâ€‹ å’Œ WiQâˆˆRhdmodelÃ—dkW^Q_i\\in\\mathbb{R^{hd_{model}\\times d_k}}WiQâ€‹âˆˆRhdmodelâ€‹Ã—dkâ€‹\nIn this work we employ h=8h = 8h=8 parallel attention layers, or heads. For each of these we use dk=dv=dmodelh=64d_k = d_v = \\frac{d_{\\text{model}}}{h} = 64dkâ€‹=dvâ€‹=hdmodelâ€‹â€‹=64.Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\nåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†h=8h = 8h=8 ä¸ªå¹¶è¡Œçš„æ³¨æ„åŠ›å±‚ï¼Œæˆ–è€…ç§°ä¸ºå¤´ã€‚å¯¹äºæ¯ä¸€ä¸ªå¤´ï¼Œæˆ‘ä»¬ä½¿ç”¨dk=dv=dmodelh=64d_k = d_v = \\frac{d_{\\text{model}}}{h} = 64dkâ€‹=dvâ€‹=hdmodelâ€‹â€‹=64ã€‚ç”±äºæ¯ä¸ªå¤´çš„ç»´åº¦å‡å°ï¼Œæ€»è®¡ç®—æˆæœ¬ä¸å…¨ç»´çš„å•å¤´æ³¨æ„åŠ›ç›¸ä¼¼ã€‚\n# Applications of Attention in our Model (æ³¨æ„åŠ›åœ¨æˆ‘ä»¬æ¨¡å‹ä¸­çš„åº”ç”¨)\nThe Transformer uses multi-head attention in three different ways:\nTransformer ä»¥ä¸‰ç§ä¸åŒçš„æ–¹å¼ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ï¼š\n\nIn â€œencoder-decoder attentionâ€ layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. åœ¨ â€œç¼–ç å™¨ - è§£ç å™¨æ³¨æ„â€ å±‚ä¸­ï¼ŒæŸ¥è¯¢æ¥è‡ªå‰ä¸€ä¸ªè§£ç å™¨å±‚ï¼Œå†…å­˜é”®å’Œå€¼æ¥è‡ªç¼–ç å™¨çš„è¾“å‡ºã€‚This allows every position in the decoder to attend over all positions in the input sequence. è¿™å…è®¸è§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®ã€‚This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9]. è¿™æ¨¡ä»¿äº†åºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼ˆå¦‚ [38,2,9]ï¼‰ä¸­å…¸å‹çš„ç¼–ç å™¨ - è§£ç å™¨æ³¨æ„åŠ›æœºåˆ¶ã€‚\nThe encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder. ç¼–ç å™¨åŒ…å«è‡ªæ³¨æ„åŠ›å±‚ã€‚åœ¨è‡ªæ³¨æ„åŠ›å±‚ä¸­ï¼Œæ‰€æœ‰é”®ã€å€¼å’ŒæŸ¥è¯¢éƒ½æ¥è‡ªåŒä¸€ä¸ªä½ç½®ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œæ˜¯ç¼–ç å™¨ä¸­ä¸Šä¸€å±‚çš„è¾“å‡ºã€‚ç¼–ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½å¯ä»¥å…³æ³¨ç¼–ç å™¨ä¸Šä¸€å±‚ä¸­çš„æ‰€æœ‰ä½ç½®ã€‚\nSimilarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. ç±»ä¼¼åœ°ï¼Œè§£ç å™¨ä¸­çš„è‡ªæ³¨æ„åŠ›å±‚å…è®¸è§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®å…³æ³¨è§£ç å™¨ä¸­çš„æ‰€æœ‰ä½ç½®ï¼Œç›´åˆ°è¯¥ä½ç½®å¹¶åŒ…æ‹¬è¯¥ä½ç½®ã€‚We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to âˆ’âˆ) all values in the input of the softmax which correspond to illegal connections. See Figure 2. æˆ‘ä»¬éœ€è¦é˜²æ­¢è§£ç å™¨ä¸­ä¿¡æ¯å‘å·¦æµåŠ¨ï¼Œä»¥ä¿ç•™è‡ªå›å½’å±æ€§ã€‚æˆ‘ä»¬é€šè¿‡å±è”½ï¼ˆè®¾ç½®ä¸º -âˆï¼‰softmax è¾“å…¥ä¸­å¯¹åº”äºéæ³•è¿æ¥çš„æ‰€æœ‰å€¼æ¥å®ç°è¿™ä¸€ç‚¹ã€‚å‚è§å›¾ 2ã€‚\n\n# Position-wise Feed-Forward Networksï¼ˆä½ç½®å‰é¦ˆç½‘ç»œï¼‰\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.\né™¤äº†æ³¨æ„åŠ›å­å±‚å¤–ï¼Œæˆ‘ä»¬çš„ç¼–ç å™¨å’Œè§£ç å™¨ä¸­çš„æ¯ä¸€å±‚éƒ½åŒ…å«ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å‰é¦ˆç½‘ç»œï¼Œè¯¥ç½‘ç»œåˆ†åˆ«ä¸”ç›¸åŒåœ°åº”ç”¨äºæ¯ä¸ªä½ç½®ã€‚è¿™åŒ…æ‹¬ä¸¤ä¸ªçº¿æ€§å˜æ¢ï¼Œä¸­é—´æœ‰ä¸€ä¸ª ReLU æ¿€æ´»ã€‚\nFFN(x)=max(0,xW1+b1)W2+b2FFN(x)=max(0,xW_1+b_1)W_2+b_2\nFFN(x)=max(0,xW1â€‹+b1â€‹)W2â€‹+b2â€‹\nWhile the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convolutions with kernel size 1.\nè™½ç„¶çº¿æ€§å˜æ¢åœ¨ä¸åŒä½ç½®ä¸Šæ˜¯ç›¸åŒçš„ï¼Œä½†å®ƒä»¬åœ¨å±‚ä¸å±‚ä¹‹é—´ä½¿ç”¨ä¸åŒçš„å‚æ•°ã€‚å¦ä¸€ç§æè¿°è¿™ä¸€ç‚¹çš„æ–¹æ³•æ˜¯ä¸¤ä¸ªå†…æ ¸å¤§å°ä¸º 1 çš„å·ç§¯ã€‚\nThe dimensionality of input and output is dmdoel=512d_{mdoel}=512dmdoelâ€‹=512,and the inner-layer has dimensionalitydff=2048d_{ff}=2048dffâ€‹=2048\nè¾“å…¥å’Œè¾“å‡ºçš„ç»´æ•°ä¸º dmdoel=512d_{mdoel}=512dmdoelâ€‹=512ï¼Œå†…å±‚çš„ç»´æ•°ä¸º dff=2048d_{ff}=2048dffâ€‹=2048ã€‚\n# Embeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodeld_{model}dmodelâ€‹.\nä¸å…¶ä»–åºåˆ—è½¬å¯¼æ¨¡å‹ç±»ä¼¼ï¼Œæˆ‘ä»¬ä½¿ç”¨å­¦ä¹ çš„åµŒå…¥å°†è¾“å…¥æ ‡è®°å’Œè¾“å‡ºæ ‡è®°è½¬æ¢ä¸ºç»´åº¦  dmodeld_{model}dmodelâ€‹ çš„å‘é‡ã€‚\nWe also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities.\nä»¬è¿˜ä½¿ç”¨é€šå¸¸å­¦ä¹ çš„çº¿æ€§å˜æ¢å’Œ softmax å‡½æ•°å°†è§£ç å™¨è¾“å‡ºè½¬æ¢ä¸ºé¢„æµ‹çš„ä¸‹ä¸€ä¸ªæ ‡è®°æ¦‚ç‡ã€‚\nIn our model, we share the same weight matrix between the two embedding layers and the pre-softmax  linear transformation, similar to [30].In the embedding layers, we multiply those weights by dmodel\\sqrt{d_{model}}dmodelâ€‹â€‹\nåœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªåµŒå…¥å±‚å’Œé¢„ softmax çº¿æ€§å˜æ¢ä¹‹é—´å…±äº«ç›¸åŒçš„æƒé‡çŸ©é˜µï¼Œç±»ä¼¼äº [30]ã€‚åœ¨åµŒå…¥å±‚ä¸­ï¼Œæˆ‘ä»¬å°†è¿™äº›æƒé‡ä¹˜ä»¥dmodel\\sqrt{d_{model}}dmodelâ€‹â€‹\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["python","æ·±åº¦å­¦ä¹ ","attention","transformer"]},{"title":"CNNç»å…¸å·ç§¯ç¥ç»ç½‘ç»œä¸å®æˆ˜","url":"/python/CNN_Acc/","content":"# å·ç§¯ç¥ç»ç½‘ç»œ\nå­¦ä¹ å†…å®¹åŸºäºï¼šPytorch æ¡†æ¶ä¸ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œä¸å®æˆ˜\n# CNN å·ç§¯ç¥ç»ç½‘ç»œç®—æ³•åŸç†\n# å…¨è¿æ¥ç¥ç»ç½‘ç»œ\n\nè¾“å…¥å±‚æ˜¯æˆ‘ä»¬è¾“å…¥çš„æ•°æ®ï¼Œè¿™é‡Œçœ‹åˆ°çš„ç¬¬ä¸€åˆ—èŠ‚ç‚¹å¹¶ä¸æ˜¯è¾“å…¥å±‚ï¼Œä¸­é—´ä¸ºéšè—å±‚ã€‚\nè¾“å…¥å±‚å°±åƒ Xï¼ˆè‡ªå˜é‡ï¼‰ï¼Œæ¨¡å‹æˆ–è€…è¯´è¿™äº›ç½‘ç»œå°±æ˜¯ Fï¼ˆå‡½æ•°ï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ°çš„è¾“å‡ºå°±æ˜¯ Yï¼ˆå› å˜é‡ï¼‰ã€‚\n# ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ¿€æ´»å‡½æ•°\nåœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨æ¿€æ´»å‡½æ•°çš„æ ¹æœ¬åŸå› æ˜¯å¼•å…¥éçº¿æ€§ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ‹Ÿåˆå’Œè¡¨è¾¾å¤æ‚çš„å‡½æ•°å…³ç³»ã€‚å¦‚æœæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œç¥ç»ç½‘ç»œæ— è®ºå †å å¤šå°‘å±‚ï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼Œèƒ½åŠ›æå…¶æœ‰é™ã€‚å¤šå±‚çº¿æ€§å˜æ¢çš„å åŠ ä¾ç„¶æ˜¯çº¿æ€§å˜æ¢ï¼Œæœ€ç»ˆçš„æ¨¡å‹åªèƒ½æ‹Ÿåˆç›´çº¿ / å¹³é¢ï¼Œå®Œå…¨æ— æ³•å¤„ç†å¤æ‚çš„æ•°æ®æ¨¡å¼\n# Sigmoid æ¿€æ´»å‡½æ•°\n\nä¼˜ç‚¹ï¼šç®€å•ã€éå¸¸é€‚ç”¨åˆ†ç±»ä»»åŠ¡ã€‚\nç¼ºç‚¹ï¼šåå‘ä¼ æ’­è®­ç»ƒæ—¶æœ‰æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼›è¾“å‡ºå€¼åŒºé—´ä¸º (0,1)ï¼Œå…³äº 0 ä¸å¯¹ç§°ï¼›æ¢¯åº¦æ›´æ–°åœ¨ä¸åŒæ–¹å‘èµ°å¾—å¤ªè¿œï¼Œä½¿å¾—ä¼˜åŒ–éš¾åº¦å¢å¤§ï¼Œè®­ç»ƒè€—æ—¶ã€‚\n# Tanh æ¿€æ´»å‡½æ•°\n\nä¼˜ç‚¹ï¼šè§£å†³äº† Sigmoid å‡½æ•°è¾“å‡ºå€¼é 0 å¯¹ç§°çš„é—®é¢˜ï¼Œè®­ç»ƒæ¯” Sigmoid å‡½æ•°å¿«ï¼Œæ›´å®¹æ˜“æ”¶æ•›\nç¼ºç‚¹ï¼šåå‘ä¼ æ’­è®­ç»ƒæ—¶æœ‰æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼ŒTanh å‡½æ•°å’Œ Sigmoid å‡½æ•°éå¸¸ç›¸ä¼¼ã€‚\n# ReLU æ¿€æ´»å‡½æ•°\n\nä¼˜ç‚¹ï¼šè§£å†³äº†æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼›è®¡ç®—æ›´ä¸ºç®€å•ï¼Œæ²¡æœ‰ Sigmoid å‡½æ•°å’Œ Tanh å‡½æ•°çš„æŒ‡æ•°è¿ç®—\nç¼ºç‚¹ï¼šè®­ç»ƒæ—¶å¯èƒ½å‡ºç°ç¥ç»å…ƒæ­»äº¡\n# Leaky ReLU æ¿€æ´»å‡½æ•°\n\nä¼˜ç‚¹ï¼šè§£å†³äº† ReLU çš„ç¥ç»å…ƒæ­»äº¡é—®é¢˜\nç¼ºç‚¹ï¼šæ— æ³•ä¸ºæ­£è´Ÿè¾“å…¥å€¼æä¾›ä¸€è‡´çš„å…³ç³»é¢„æµ‹ (ä¸åŒåŒºé—´å‡½æ•°ä¸åŒ)\n# å‰å‘ä¼ æ’­\nå‰å‘ä¼ æ’­æ˜¯ç¥ç»ç½‘ç»œä¸­æ•°æ®ä»è¾“å…¥å±‚ä¾æ¬¡æµå‘è¾“å‡ºå±‚çš„è¿‡ç¨‹ï¼Œå®ƒçš„æ ¸å¿ƒç›®æ ‡æ˜¯æ ¹æ®å½“å‰çš„æ¨¡å‹å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰è®¡ç®—å‡ºé¢„æµ‹ç»“æœã€‚\nå‰å‘ä¼ æ’­å°±æ˜¯ â€œæŠŠè¾“å…¥æ•°æ®ä¾æ¬¡å–‚ç»™æ¯ä¸€å±‚ï¼Œç»è¿‡çº¿æ€§è®¡ç®— + æ¿€æ´»å‡½æ•°ï¼Œé€å±‚è¾“å‡ºï¼Œæœ€åå¾—åˆ°é¢„æµ‹å€¼â€ çš„è¿‡ç¨‹ã€‚\n# æŸå¤±å‡½æ•°\n# å‡æ–¹è¯¯å·®\n\n\n\n\n\n\n\n\nå‰é¢æœ‰å¯èƒ½æœ‰å‡ºç° 1/2ï¼Œé‚£åªæ˜¯ä¸ºäº†æ–¹ä¾¿æ±‚å¯¼ï¼Œéƒ½æ˜¯å‡æ–¹è¯¯å·®ã€‚\n# æ¢¯åº¦ä¸‹é™æ³•\n\n\n# å…¨è¿æ¥ç¥ç»ç½‘ç»œåœ¨å›¾ç‰‡ä¸­å­˜åœ¨çš„é—®é¢˜\n# 1. å‚æ•°é‡å·¨å¤§\n\nå…¨è¿æ¥å±‚çš„æ¯ä¸€ä¸ªç¥ç»å…ƒéƒ½ä¸ä¸Šä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒç›¸è¿ã€‚\nå¯¹äºå›¾ç‰‡æ¥è¯´ï¼Œè¾“å…¥é€šå¸¸æ˜¯é«˜ç»´çš„ï¼Œä¾‹å¦‚ä¸€å¼  224Ã—224 çš„ RGB å›¾ç‰‡å°±æ˜¯ 224Ã—224Ã—3 = 150,528 ä¸ªè¾“å…¥ç‰¹å¾ã€‚\nå‡è®¾ç¬¬ä¸€å±‚æœ‰ 1000 ä¸ªç¥ç»å…ƒï¼Œé‚£ä¹ˆæƒé‡æ•°é‡å°±æ˜¯ 150,528 Ã— 1000 â‰ˆ 1.5 äº¿ä¸ªå‚æ•°ï¼\né—®é¢˜ï¼šå‚æ•°å¤ªå¤š â†’ å®¹æ˜“è¿‡æ‹Ÿåˆ â†’ è®­ç»ƒæ—¶é—´é•¿ â†’ éœ€è¦å¤§é‡æ˜¾å­˜ã€‚\n\n\n# 2. å¿½ç•¥ç©ºé—´ç»“æ„\n\nå›¾ç‰‡æ˜¯äºŒç»´æˆ–ä¸‰ç»´ï¼ˆRGBï¼‰çš„ç½‘æ ¼æ•°æ®ï¼Œæœ‰å±€éƒ¨ç©ºé—´ç›¸å…³æ€§ï¼ˆé‚»è¿‘åƒç´ å¾€å¾€ç›¸å…³ï¼‰ã€‚\nå…¨è¿æ¥å±‚æŠŠå›¾ç‰‡ â€œæ‹‰å¹³â€ æˆä¸€ç»´å‘é‡ï¼Œç„¶åå†è¿›è¡ŒçŸ©é˜µä¹˜æ³•ã€‚\né—®é¢˜ï¼šä¸¢å¤±äº†å›¾ç‰‡çš„ç©ºé—´ä¿¡æ¯ï¼ˆå¦‚è¾¹ç¼˜ã€çº¹ç†ã€å½¢çŠ¶ï¼‰ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰å±€éƒ¨ç‰¹å¾ã€‚\n\n\n# 3. ç¼ºä¹å¹³ç§»ä¸å˜æ€§\n\nå›¾åƒä¸­ç‰©ä½“çš„ä½ç½®å¯èƒ½å˜åŒ–ã€‚\nå…¨è¿æ¥ç½‘ç»œå¯¹è¾“å…¥çš„æ¯ä¸ªä½ç½®éƒ½å›ºå®šï¼Œç‰©ä½“ç¨å¾®ç§»åŠ¨ï¼Œè¾“å‡ºå¯èƒ½å®Œå…¨ä¸åŒã€‚\né—®é¢˜ï¼šæ— æ³•è‡ªåŠ¨è¯†åˆ«å›¾åƒä¸­çš„å¹³ç§»æˆ–å±€éƒ¨ä½ç§»ï¼Œæ³›åŒ–èƒ½åŠ›å·®ã€‚\n\n\n# 4. è®¡ç®—æ•ˆç‡ä½\n\nå…¨è¿æ¥å±‚è®¡ç®—å¤æ‚åº¦é«˜ï¼ˆçŸ©é˜µä¹˜æ³•é‡å¤§ï¼‰ã€‚\nå¯¹é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œè®­ç»ƒå’Œæ¨ç†é€Ÿåº¦éƒ½å¾ˆæ…¢ã€‚\nå¯¹æ¯”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œåè€…é€šè¿‡å·ç§¯æ ¸å…±äº«æƒé‡å¤§å¹…å‡å°‘è®¡ç®—é‡ã€‚\n\n\n# 5. ä¸é€‚åˆæ•æ‰å±‚æ¬¡ç‰¹å¾\n\nå›¾ç‰‡çš„ç‰¹å¾æ˜¯æœ‰å±‚æ¬¡ç»“æ„çš„ï¼šè¾¹ç¼˜ â†’ çº¹ç† â†’ å½¢çŠ¶ â†’ å¯¹è±¡ã€‚\nå…¨è¿æ¥å±‚ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰åƒç´ ï¼Œæ— æ³•è‡ªç„¶å­¦ä¹ å±‚æ¬¡ç‰¹å¾ã€‚\nCNN åˆ™é€šè¿‡å·ç§¯å’Œæ± åŒ–å±‚é€æ­¥æŠ½è±¡ç‰¹å¾ï¼Œæ›´ç¬¦åˆè§†è§‰è®¤çŸ¥è§„å¾‹ã€‚\n\n# å·ç§¯ã€æ­¥å¹…ã€å¡«å……ã€æ± åŒ–\nè¿™éƒ¨åˆ†è¯·çœ‹ï¼š\n\n          \n          PyTorchæ·±åº¦å­¦ä¹ convolution å·ç§¯æ“ä½œ\n          https://735690757.github.io/python/pytorch\n          \n# ç»è¿‡å·ç§¯åç‰¹å¾å›¾å¤§å°\n\nFHï¼šå·ç§¯æ ¸ï¼ˆfilterï¼‰çš„é«˜åº¦ï¼ˆFilter Heightï¼‰\nFWï¼šå·ç§¯æ ¸çš„å®½åº¦ï¼ˆFilter Widthï¼‰\nC_inï¼šè¾“å…¥é€šé“æ•°ï¼ˆInput Channelsï¼‰\nC_outï¼šè¾“å‡ºé€šé“æ•°ï¼ˆOutput Channelsï¼‰\nSï¼šæ­¥å¹…ï¼ˆStrideï¼‰\nPï¼šå¡«å……ï¼ˆPaddingï¼‰\nå¦‚æœç®—å‡ºæ¥æ˜¯å°æ•°ï¼Œä¸€èˆ¬æ˜¯å‘ä¸‹å–æ•´ã€‚\n# LeNet ä¸ AlexNet åŸç†\n# LeNet-5 è¯ç”ŸèƒŒæ™¯\nç®€å•æ¥è¯´ï¼ŒLeNet-5 çš„è¯ç”ŸèƒŒæ™¯æ˜¯ä¸ºäº†è§£å†³æ‰‹å†™æ•°å­—è¯†åˆ«è¿™ä¸€å®é™…åº”ç”¨é—®é¢˜ï¼Œå®ƒæ˜¯ä¸–ç•Œä¸Šé¦–ä¸ªæˆåŠŸå•†ç”¨çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå¥ å®šäº†ç°ä»£æ·±åº¦å­¦ä¹ çš„åŸºç¡€ã€‚\n# LeNet-5 ç½‘ç»œç»“æ„\n\n\nè¾“å…¥ 1 * 28 * 28\n5 * 5 å·ç§¯ï¼ˆ6ï¼‰ï¼Œå¡«å…… 2\n2 * 2 å¹³å‡æ± åŒ–å±‚ï¼Œæ­¥å¹… 2\n5 * 5 å·ç§¯ï¼ˆ16ï¼‰ï¼Œå¡«å…… 0\n2 * 2 å¹³å‡æ± åŒ–å±‚ï¼Œæ­¥å¹… 2\nå…¨è¿æ¥ï¼ˆ120ï¼‰\nå…¨è¿æ¥ï¼ˆ84ï¼‰\nå…¨è¿æ¥ï¼ˆ10ï¼‰\n\n\nå†å¼ºè°ƒä¸€ä¸‹ï¼š\n\nè¿™ä¸ªè®¡ç®—å…¬å¼éå¸¸é‡è¦ã€‚\n\n# AlexNet è¯ç”ŸèƒŒæ™¯\nåœ¨ç®—åŠ›è¾¾åˆ°ä¸´ç•Œç‚¹ã€å¤§æ•°æ®å·²ç»å°±ä½çš„ç¯å¢ƒä¸‹ï¼Œä¸€ä¸ªå¤è€ä½†æ›¾è¢«å¿½è§†çš„ç®—æ³•ï¼ˆæ·±åº¦å­¦ä¹  / å·ç§¯ç¥ç»ç½‘ç»œï¼‰è¿æ¥äº†è¯æ˜è‡ªå·±çš„æœ€ä½³æ—¶æœºã€‚AlexNet ä¸ä»…ä»…æ˜¯ä¸€ä¸ªä¼˜ç§€çš„æ¨¡å‹ï¼Œå®ƒæ›´æ˜¯ä¸€ä¸ªæ—¶ä»£çš„å¼€åˆ›è€…ï¼Œæ˜¯äººå·¥æ™ºèƒ½å‘å±•å²ä¸Šçš„ä¸€ä¸ªå…³é”®è½¬æŠ˜ç‚¹ã€‚\n# AlexNet ç½‘ç»œç»“æ„\n\n5 å±‚å·ç§¯ï¼Œ3 å±‚å…¨è¿æ¥ï¼Œå…± 8 å±‚ï¼Œæ¿€æ´»å‡½æ•°ä½¿ç”¨ ReLUã€‚\n\nè¾“å…¥ 3 * 227 * 227ï¼ˆï¼Ÿè¿™ä¸ªå¯èƒ½æœ‰é—®é¢˜ï¼‰\n11 * 11 å·ç§¯ï¼ˆ96ï¼‰ï¼Œæ­¥å¹… 4ï¼ŒReLU\n3 * 3 æœ€å¤§æ± åŒ–ï¼Œæ­¥å¹… 2\n5 * 5 å·ç§¯ï¼ˆ256ï¼‰ï¼Œå¡«å…… 2ï¼ŒReLU\n3 * 3 æœ€å¤§æ± åŒ–ï¼Œæ­¥å¹… 2\n3 * 3 å·ç§¯ï¼ˆ384ï¼‰ï¼Œå¡«å…… 1ï¼ŒReLU\n3 * 3 å·ç§¯ï¼ˆ384ï¼‰ï¼Œå¡«å…… 1ï¼ŒReLU\n3 * 3 å·ç§¯ï¼ˆ256ï¼‰ï¼Œå¡«å…… 1ï¼ŒReLU\n3 * 3 æœ€å¤§æ± åŒ–ï¼Œæ­¥å¹… 2\nå…¨è¿æ¥ï¼ˆ4096ï¼‰\nå…¨è¿æ¥ï¼ˆ4096ï¼‰\nå…¨è¿æ¥ï¼ˆ10ï¼‰\n\nè¿™é‡Œåœ¨å…¨è¿æ¥å±‚æœ‰å¾ˆå¤šçš„å‚æ•°ï¼Œå‚æ•°å¤ªå¤šå®¹æ˜“è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬å¼•å…¥äº† Dropout æ“ä½œã€‚\n# å›¾åƒå¢å¼º - æ°´å¹³ç¿»è½¬\n\n# å›¾åƒå¢å¼º - éšæœºè£å‰ª\n\n# å›¾åƒå¢å¼º - PCA\n\n\n\n\næ–¹é¢\næè¿°\n\n\n\n\næ ¸å¿ƒæ€æƒ³\nåˆ©ç”¨ PCA æ‰¾åˆ°å›¾åƒé¢œè‰²çš„ä¸»è¦å˜åŒ–æ–¹å‘ï¼Œå¹¶æ²¿è¿™äº›æ–¹å‘æ·»åŠ éšæœºæ‰°åŠ¨æ¥æ¨¡æ‹Ÿå…‰ç…§å˜åŒ–ã€‚\n\n\nç›®çš„\nå¢å¼ºæ¨¡å‹å¯¹é¢œè‰²å’Œå…‰ç…§å˜åŒ–çš„é²æ£’æ€§ï¼Œæ˜¯ä¸€ç§é«˜æ•ˆçš„æ•°æ®å¢å¼ºæ‰‹æ®µã€‚\n\n\nä¼˜ç‚¹\nå˜åŒ–æ–¹å¼åŸºäºå›¾åƒè‡ªèº«çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œç”Ÿæˆçš„å›¾åƒé¢œè‰²å˜åŒ–è‡ªç„¶ã€åˆç†ã€‚\n\n\nç¼ºç‚¹\nè®¡ç®—æˆæœ¬ç›¸å¯¹è¾ƒé«˜ï¼ˆéœ€è¦å¯¹æ¯å¼ å›¾æˆ–æ¯æ‰¹å›¾åš PCAï¼‰ã€‚\n\n\né—äº§\næ˜¯ AlexNet çš„ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼Œå¯å‘äº†å¯¹é¢œè‰²å¢å¼ºçš„é‡è§†ï¼Œä½†å·²è¢«æ›´ç®€å•é«˜æ•ˆçš„æ–¹æ³•æ‰€å–ä»£ã€‚\n\n\n\n# LRN æ­£åˆ™åŒ–\nè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹é€šé“é—´çš„è®¡ç®—\n\nå°½ç®¡ LRN æ˜¯ AlexNet çš„ä¸€ä¸ªå…³é”®åˆ›æ–°ï¼Œä½†åœ¨åç»­æ›´æ·±ã€æ›´å…ˆè¿›çš„ç½‘ç»œï¼ˆå¦‚ VGGã€ResNetï¼‰ä¸­ï¼Œå®ƒå‡ ä¹è¢«å®Œå…¨å¼ƒç”¨äº†ã€‚ä¸»è¦åŸå› å¦‚ä¸‹ï¼š\n\næ•ˆæœæœ‰é™ä¸”ä¸ç¨³å®šï¼šåç»­ç ”ç©¶å‘ç°ï¼ŒLRN å¸¦æ¥çš„æ€§èƒ½æå‡éå¸¸å¾®å¼±ï¼Œç”šè‡³æœ‰æ—¶ä¸ç¨³å®šã€‚å…¶æ­£åˆ™åŒ–æ•ˆæœè¿œä¸å¦‚ Dropout å’Œ Batch Normalizationï¼ˆBNï¼‰ é‚£æ ·æ˜¾è‘—å’Œå¯é ã€‚\nè¢«æ›´å¥½çš„æŠ€æœ¯å–ä»£ï¼š\n\nDropoutï¼šé€šè¿‡éšæœºæ–­å¼€ç¥ç»å…ƒè¿æ¥æ¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ›´ä¸ºç›´æ¥æœ‰æ•ˆã€‚\nBatch Normalizationï¼ˆæ‰¹å½’ä¸€åŒ–ï¼‰ï¼šè¿™æ˜¯é©å‘½æ€§çš„æŠ€æœ¯ã€‚BN å¯¹æ•´ä¸ª Batch çš„æ¯ä¸ªé€šé“è¿›è¡Œå½’ä¸€åŒ–ï¼ˆå‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1ï¼‰ï¼Œæå¤§åœ°æ”¹å–„äº†æ¢¯åº¦æµåŠ¨ï¼ŒåŠ é€Ÿäº†è®­ç»ƒï¼ŒåŒæ—¶æœ¬èº«ä¹Ÿå…·æœ‰è½»å¾®çš„æ­£åˆ™åŒ–æ•ˆæœã€‚BN çš„æ•ˆæœè¿œè¶… LRNï¼Œå¹¶ä¸”å·²ç»æˆä¸ºç°ä»£æ·±åº¦ç½‘ç»œçš„æ ‡å‡†ç»„ä»¶ã€‚\n\n\nå¢åŠ è®¡ç®—å¼€é”€å’Œè¶…å‚æ•°ï¼šLRN å¼•å…¥äº†é¢å¤–çš„è®¡ç®—é‡ï¼Œå¹¶ä¸”  k, Î±, Î², n  è¿™äº›è¶…å‚æ•°éœ€è¦è°ƒä¼˜ï¼Œå¢åŠ äº†æ¨¡å‹è®¾è®¡çš„å¤æ‚æ€§ã€‚\n\n# é‡å æ± åŒ–\nä¸ LRN ç±»ä¼¼ï¼Œé‡å æ± åŒ–åœ¨ç°ä»£æ·±åº¦å­¦ä¹ æ¶æ„ä¸­ä¹Ÿå·²ç»ä¸å¸¸ç”¨äº†ã€‚\n\nè®¡ç®—æˆæœ¬æ›´é«˜ï¼šç”±äºå­˜åœ¨é‡å ï¼Œä¸ºäº†å¾—åˆ°ç›¸åŒå°ºå¯¸çš„è¾“å‡ºç‰¹å¾å›¾ï¼Œé‡å æ± åŒ–éœ€è¦è¿›è¡Œæ›´å¤šæ¬¡æ± åŒ–æ“ä½œã€‚ä¾‹å¦‚ï¼Œå°†  5x5  é™é‡‡æ ·åˆ°  2x2 ï¼Œéé‡å æ± åŒ– ( 2x2 , stride=2) éœ€è¦ 4 æ¬¡æ“ä½œï¼Œè€Œé‡å æ± åŒ– ( 3x3 , stride=2) ä¹Ÿéœ€è¦ 4 æ¬¡æ“ä½œï¼Œä½†æ¯æ¬¡æ“ä½œçš„çª—å£æ›´å¤§ï¼Œè®¡ç®—é‡ç¨é«˜ã€‚\nè¢«æ›´æœ‰æ•ˆçš„æŠ€æœ¯å–ä»£ï¼šå¦‚ä»Šï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆå’Œæå‡æ€§èƒ½çš„é‡ä»»æ›´å¤šåœ°ç”± Batch Normalizationã€æ›´æ·±çš„ç½‘ç»œç»“æ„ï¼ˆå¦‚ ResNet çš„æ®‹å·®è¿æ¥ï¼‰ã€æ›´å…ˆè¿›çš„ä¼˜åŒ–å™¨ å’Œ Dropout ç­‰æ–¹æ³•æ¥æ‰¿æ‹…ã€‚\nè®¾è®¡è¶‹åŠ¿å˜åŒ–ï¼šç°ä»£ç½‘ç»œæœ‰æ—¶ç”šè‡³ä¼šå®Œå…¨æ‘’å¼ƒæ± åŒ–å±‚ï¼Œè½¬è€Œä½¿ç”¨æ­¥é•¿å¤§äº 1 çš„å·ç§¯ï¼ˆStrided Convolutionï¼‰ æ¥åŒæ—¶å®ç°ç‰¹å¾æå–å’Œé™é‡‡æ ·ï¼Œè¿™è¢«è®¤ä¸ºèƒ½æä¾›æ›´å¤§çš„æ¨¡å‹å®¹é‡å’Œçµæ´»æ€§ã€‚\n\n# LeNet å®æˆ˜\n# æ¨¡å‹\nclass LeNet(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.block = nn.Sequential(            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),            nn.Sigmoid(),            nn.AvgPool2d(kernel_size=2, stride=2),            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),            nn.Sigmoid(),            nn.AvgPool2d(kernel_size=2, stride=2),            nn.Flatten(),            nn.Linear(in_features=400, out_features=120),            nn.Sigmoid(),            nn.Linear(in_features=120, out_features=84),            nn.Sigmoid(),            nn.Linear(in_features=84, out_features=10)        )    def forward(self, x):        return self.block(x)# è®¾å¤‡ã€å®ä¾‹åŒ–ä¸ summary\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")net = LeNet().to(device)summary(net, (1, 28, 28))\nè¿™é‡Œçš„ -1 ä»£è¡¨çš„æ˜¯ æ‰¹é‡å¤§å°ï¼Œæ›´å…·ä½“åœ°è¯´ï¼š-1 æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œè¡¨ç¤ºè¿™ä¸ªç»´åº¦çš„å¤§å°æ˜¯ç”±å…¶ä»–ç»´åº¦æ¨æ–­å‡ºæ¥çš„ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå›ºå®šå€¼ã€‚\næ‰¹é‡å¤§å°ï¼šåœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ï¼Œæ•°æ®é€šå¸¸æ˜¯æŒ‰æ‰¹æ¬¡ï¼ˆbatchï¼‰è¾“å…¥çš„ã€‚æ¯”å¦‚ï¼Œä½ å¯èƒ½ä¼šä¸€æ¬¡è¾“å…¥ 32 å¼ å›¾ç‰‡ã€64 å¼ å›¾ç‰‡ç­‰ã€‚è¿™ä¸ªæ•°é‡å°±æ˜¯æ‰¹é‡å¤§å°ã€‚\nä¸ºä»€ä¹ˆæ˜¯ -1ï¼Ÿï¼šPyTorch æ¨¡å‹åœ¨è®¾è®¡æ—¶ï¼Œå…¶æ ¸å¿ƒè®¡ç®—é€»è¾‘ä¸ä¾èµ–äºå…·ä½“çš„æ‰¹é‡å¤§å°ã€‚ä¸ºäº†å¢åŠ çµæ´»æ€§ï¼Œåœ¨å®šä¹‰æ¨¡å‹çš„å‰å‘ä¼ æ’­æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å°†è¾“å…¥å¼ é‡çš„ç¬¬ä¸€ä¸ªç»´åº¦è®¾ä¸ºæ‰¹é‡å¤§å°ã€‚å½“æ‰“å°æ¨¡å‹æ‘˜è¦æ—¶ï¼Œåº“ï¼ˆå¦‚ torchsummaryï¼‰æ— æ³•é¢„å…ˆçŸ¥é“ä½ ä¼šç”¨å¤šå¤§çš„æ‰¹é‡å¤§å°æ¥è®­ç»ƒï¼Œæ‰€ä»¥å®ƒä½¿ç”¨ -1 æ¥ä»£è¡¨ â€œä»»ä½•å°ºå¯¸â€ã€‚\nåŠ¨æ€æ¨æ–­ï¼šåœ¨å®é™…è¿è¡Œä¸­ï¼Œè¿™ä¸ª -1 ä¼šè¢«ä½ è¾“å…¥æ•°æ®çš„çœŸå®æ‰¹é‡å¤§å°æ‰€æ›¿ä»£ã€‚\nä¾‹å¦‚ï¼Œå¦‚æœä½ ç”¨ä¸€æ‰¹ 32 å¼ å›¾ç‰‡è¾“å…¥åˆ°æ¨¡å‹ï¼Œé‚£ä¹ˆ [-1, 1, 32, 32] å°±ä¼šå˜æˆ [32, 1, 32, 32]ã€‚\nå¦‚æœä½ ç”¨ 128 å¼ å›¾ç‰‡ï¼Œå®ƒå°±ä¼šå˜æˆ [128, 1, 32, 32]ã€‚\n# åŠ è½½ FashionMNIST\nfrom torchvision.datasets import FashionMNISTfrom torchvision.transforms import transformsimport numpy as nptransform = transforms.Compose([    transforms.Resize((28, 28)),    transforms.ToTensor(),    transforms.Normalize((0.5,), (0.5,))])train_data = FashionMNIST(root=\"./data/FashionMNIST\", train=True, download=True, transform=transform)test_data = FashionMNIST(root=\"./data/FashionMNIST\", train=False, download=True, transform=transform)from torch.utils.data import DataLoadertrain_dataLoader = DataLoader(train_data, batch_size=64, shuffle=True)test_dataLoader = DataLoader(test_data, batch_size=64, shuffle=False)# å±•ç¤º\nimport matplotlib.pyplot as pltfor setp, (features, label) in enumerate(train_dataLoader):    if setp == 0:        x = features.squeeze().numpy()        y = label.numpy()        breakplt.figure(figsize=(12, 5))for ii in np.arange(len(y)):    plt.subplot(4, 16, ii+1)    plt.imshow(x[ii,:,:], cmap=plt.cm.gray)    plt.title(y[ii])    plt.axis(\"off\")plt.show()\n# è®­ç»ƒã€éªŒè¯ï¼ˆæ­¤å¤„ä¸ºæœ€ä½³å®è·µï¼‰\nfrom torch.optim.lr_scheduler import CosineAnnealingLRfrom tqdm import tqdmimport copyimport timeimport pandas as pddef train_model_process(model, train_dataloader, val_dataloader, num_epochs):    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)    scheduler = CosineAnnealingLR(        optimizer,        T_max=num_epochs,        eta_min=1e-6    )    criterion = nn.CrossEntropyLoss().to(device)    model = model.to(device)    best_model_wts = copy.deepcopy(model.state_dict())    best_acc = 0.0    train_loss_all = []    val_loss_all = []    train_acc_all = []    val_acc_all = []    learning_rates = []    since = time.time()    for epoch in range(num_epochs):        print(\"Epoch &#123;&#125;/&#123;&#125;\".format(epoch, num_epochs - 1))        print(\"-\" * 10)        current_lr = optimizer.param_groups[0]['lr']        learning_rates.append(current_lr)        print(f\"å½“å‰å­¦ä¹ ç‡: &#123;current_lr:.6f&#125;\")        train_loss = 0.0        train_corrects = 0        val_loss = 0.0        val_corrects = 0        train_num = 0        val_num = 0        for step, (b_x, b_y) in tqdm(enumerate(train_dataloader), desc=f\"æ€»æ­¥éª¤ï¼š&#123;len(train_dataloader)&#125;\",                                     leave=False, unit=\"step\", total=len(train_dataloader),                                     bar_format=\"&#123;desc&#125;: |&#123;bar:30&#125;| &#123;percentage:3.0f&#125;% å”±è·³RapğŸ€ï¼ŒMusic~\",                                     ascii=\"ğŸ€ğŸ¥°ğŸ¥°ğŸ˜˜\"):            b_x = b_x.to(device)            b_y = b_y.to(device)            model.train()            output = model(b_x)            pre_lab = torch.argmax(output, dim=1)            loss = criterion(output, b_y)            optimizer.zero_grad()            loss.backward()            optimizer.step()            train_loss += loss.item() * b_x.size(0)            # å¦‚æœé¢„æµ‹æ­£ç¡®ï¼Œåˆ™å‡†ç¡®åº¦ train_corrects åŠ  1            train_corrects += torch.sum(pre_lab == b_y.data)            train_num += b_x.size(0)        for step, (b_x, b_y) in enumerate(val_dataloader):            b_x = b_x.to(device)            b_y = b_y.to(device)            model.eval()            output = model(b_x)            pre_lab = torch.argmax(output, dim=1)            loss = criterion(output, b_y)            val_loss += loss.item() * b_x.size(0)            val_corrects += torch.sum(pre_lab == b_y.data)            val_num += b_x.size(0)        train_loss_all.append(train_loss / train_num)        train_acc_all.append(train_corrects.double().item() / train_num)        val_loss_all.append(val_loss / val_num)        val_acc_all.append(val_corrects.double().item() / val_num)        print(\"&#123;&#125; train loss:&#123;:.4f&#125; train acc: &#123;:.4f&#125;\".format(epoch, train_loss_all[-1], train_acc_all[-1]))        print(\"&#123;&#125; val loss:&#123;:.4f&#125; val acc: &#123;:.4f&#125;\".format(epoch, val_loss_all[-1], val_acc_all[-1]))        if val_acc_all[-1] > best_acc:            best_acc = val_acc_all[-1]            best_model_wts = copy.deepcopy(model.state_dict())        time_use = time.time() - since        print(\"è®­ç»ƒå’ŒéªŒè¯è€—è´¹çš„æ—¶é—´&#123;:.0f&#125;m&#123;:.0f&#125;s\".format(time_use // 60, time_use % 60))        scheduler.step()    model.load_state_dict(best_model_wts)    torch.save(best_model_wts, \"models/best_model.pth\")    train_process = pd.DataFrame(data=&#123;\"epoch\": range(num_epochs),                                       \"train_loss_all\": train_loss_all,                                       \"val_loss_all\": val_loss_all,                                       \"train_acc_all\": train_acc_all,                                       \"val_acc_all\": val_acc_all,                                       \"learn_rates\": learning_rates&#125;)    return train_processdef matplot_acc_loss(train_process):    # æ˜¾ç¤ºæ¯ä¸€æ¬¡è¿­ä»£åçš„è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æŸå¤±å‡½æ•°å’Œå‡†ç¡®ç‡    plt.figure(figsize=(12, 4))    plt.subplot(1, 3, 1)    plt.plot(train_process['epoch'], train_process.train_loss_all, \"ro-\", label=\"Train loss\")    plt.plot(train_process['epoch'], train_process.val_loss_all, \"bs-\", label=\"Val loss\")    plt.legend()    plt.xlabel(\"epoch\")    plt.ylabel(\"Loss\")    plt.subplot(1, 3, 2)    plt.plot(train_process['epoch'], train_process.train_acc_all, \"ro-\", label=\"Train acc\")    plt.plot(train_process['epoch'], train_process.val_acc_all, \"bs-\", label=\"Val acc\")    plt.xlabel(\"epoch\")    plt.ylabel(\"acc\")    plt.legend()    plt.subplot(1, 3, 3)    plt.plot(train_process['epoch'], train_process.learn_rates, \"go-\", label=\"Learn rates\")    plt.xlabel(\"epoch\")    plt.ylabel(\"Learn rates\")    plt.legend()    plt.tight_layout()    plt.show()# è¿™é‡Œæ˜¯ä¼˜åŒ–åçš„ç‰ˆæœ¬\nfrom torch.optim import lr_schedulerimport copyimport timeimport pandas as pddef train_model_process(model, train_dataloader, val_dataloader, num_epochs):    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    if not os.path.exists(\"models\"):        os.mkdir(\"models\")    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=0.05)    scheduler = lr_scheduler.SequentialLR(        optimizer,        schedulers=[            lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=15),            lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs-15, eta_min=1e-6)        ],        milestones=[15]    )    criterion = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)    model = model.to(device)    best_model_wts = copy.deepcopy(model.state_dict())    best_acc = 0.0    train_loss_all = []    val_loss_all = []    train_acc_all = []    val_acc_all = []    learning_rates = []    since = time.time()    for epoch in range(num_epochs):        print(\"Epoch &#123;&#125;/&#123;&#125;\".format(epoch, num_epochs - 1))        print(\"-\" * 10)        current_lr = optimizer.param_groups[0]['lr']        learning_rates.append(current_lr)        print(f\"å½“å‰å­¦ä¹ ç‡: &#123;current_lr:.6f&#125;\")        train_loss = 0.0        train_corrects = 0        val_loss = 0.0        val_corrects = 0        train_num = 0        val_num = 0        for step, (b_x, b_y) in tqdm(enumerate(train_dataloader), desc=f\"æ€»æ­¥éª¤ï¼š&#123;len(train_dataloader)&#125;\",                                     leave=False, unit=\"step\", total=len(train_dataloader),                                     bar_format=\"&#123;desc&#125;: |&#123;bar:30&#125;| &#123;percentage:3.0f&#125;% æˆ‘åœ¨åŠªåŠ›è®­ç»ƒï¼Œå”±è·³RapğŸ€ï¼ŒMusic~\",                                     ascii=\"ğŸ€ğŸ¥°ğŸ¥°ğŸ˜˜\"):            b_x = b_x.to(device)            b_y = b_y.to(device)            model.train()            output = model(b_x)            pre_lab = torch.argmax(output, dim=1)            loss = criterion(output, b_y)            optimizer.zero_grad()            loss.backward()            optimizer.step()            train_loss += loss.item() * b_x.size(0)            # å¦‚æœé¢„æµ‹æ­£ç¡®ï¼Œåˆ™å‡†ç¡®åº¦ train_corrects åŠ  1            train_corrects += torch.sum(pre_lab == b_y.data)            train_num += b_x.size(0)        for step, (b_x, b_y) in tqdm(enumerate(val_dataloader), desc=f\"æ€»æ­¥éª¤ï¼š&#123;len(val_dataloader)&#125;\",                                     leave=False, unit=\"step\", total=len(val_dataloader),                                     bar_format=\"&#123;desc&#125;: |&#123;bar:30&#125;| &#123;percentage:3.0f&#125;% è¯¥æˆ‘ä¸Šåœºè¡¨æ¼”äº†ï¼Œå”±è·³RapğŸ€ï¼ŒMusic~\",                                     ascii=\"ğŸ€ğŸ¥°ğŸ¥°ğŸ˜˜\"):            b_x = b_x.to(device)            b_y = b_y.to(device)            model.eval()            output = model(b_x)            pre_lab = torch.argmax(output, dim=1)            loss = criterion(output, b_y)            val_loss += loss.item() * b_x.size(0)            val_corrects += torch.sum(pre_lab == b_y.data)            val_num += b_x.size(0)        train_loss_all.append(train_loss / train_num)        train_acc_all.append(train_corrects.double().item() / train_num)        val_loss_all.append(val_loss / val_num)        val_acc_all.append(val_corrects.double().item() / val_num)        print(\"&#123;&#125; train loss:&#123;:.4f&#125; train acc: &#123;:.4f&#125;\".format(epoch, train_loss_all[-1], train_acc_all[-1]))        print(\"&#123;&#125; val loss:&#123;:.4f&#125; val acc: &#123;:.4f&#125;\".format(epoch, val_loss_all[-1], val_acc_all[-1]))        if val_acc_all[-1] > best_acc:            best_acc = val_acc_all[-1]            best_model_wts = copy.deepcopy(model.state_dict())            checkpoint = &#123;                'epoch': epoch,                'model_state_dict': model.state_dict(),                'optimizer_state_dict': optimizer.state_dict(),                'scheduler_state_dict': scheduler.state_dict(),                'best_acc': best_acc,            &#125;            torch.save(checkpoint, \"models/best_checkpoint.pth\")        time_use = time.time() - since        print(\"è®­ç»ƒå’ŒéªŒè¯è€—è´¹çš„æ—¶é—´&#123;:.0f&#125;m&#123;:.0f&#125;s\".format(time_use // 60, time_use % 60))        scheduler.step()    model.load_state_dict(best_model_wts)    torch.save(best_model_wts, \"models/theBest.pth\")    train_process = pd.DataFrame(data=&#123;\"epoch\": range(num_epochs),                                       \"train_loss_all\": train_loss_all,                                       \"val_loss_all\": val_loss_all,                                       \"train_acc_all\": train_acc_all,                                       \"val_acc_all\": val_acc_all,                                       \"learn_rates\": learning_rates&#125;)    return train_processè¿™é‡Œæ˜¯å­¦ä¹ ç‡ä½¿ç”¨ 0.01ï¼Œå¯ä»¥å¾—åˆ°æ›´å¥½çš„æ•ˆæœï¼Œå­¦ä¹ ç‡ä¸º 0.001 åœ¨å›¾åƒä¸Šæ›´ç¾è§‚ã€‚\n# æµ‹è¯•ï¼ˆæ­¤å¤„ä¸ºæœ€ä½³å®è·µï¼‰\ndef test_model_process(model, test_dataloader):    device = \"cuda\" if torch.cuda.is_available() else 'cpu'    model = model.to(device)    test_corrects = 0.0    test_num = 0    with torch.no_grad():        for test_data_x, test_data_y in test_dataloader:            test_data_x = test_data_x.to(device)            test_data_y = test_data_y.to(device)            model.eval()            output= model(test_data_x)            pre_lab = torch.argmax(output, dim=1)            test_corrects += torch.sum(pre_lab == test_data_y.data)            test_num += test_data_x.size(0)    test_acc = test_corrects.double().item() / test_num    print(\"æµ‹è¯•çš„å‡†ç¡®ç‡ä¸ºï¼š\", test_acc)# AlexNet å®æˆ˜\nclass AlexNet(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.block = nn.Sequential(            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4),            nn.ReLU(),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),            nn.ReLU(),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Flatten(),            nn.Linear(256 * 5 * 5, 4096),            nn.ReLU(),            nn.Dropout(0.5),            nn.Linear(4096, 4096),            nn.ReLU(),            nn.Dropout(0.5),            nn.Linear(4096, 10)        )    def forward(self, x):        x = self.block(x)        return xæ­¤å¤„å¹¶ä¸æ˜¯æ ‡å‡†æ˜¯ AlexNet æ¨¡å‹ï¼Œä¸»è¦æ˜¯ä¸ºäº†é€‚é… FashionMNISTã€‚\ntrain_process = train_model_process(AlexNet(), train_dataloader, val_dataloader, num_epochs=5)matplot_acc_loss(train_process)ç”±äºä¸»åŒ…çš„ GPU å®åœ¨æ˜¯å¤ªæ…¢äº†ï¼Œå°±ä¸æ”¾ç»“æœå›¾äº†ã€‚\n# VGG ç½‘ç»œåŸç†\nVGGNet æœ‰ 6 ç§ä¸åŒçš„ç»“æ„ï¼Œä¸»è¦ä»¥ VGG-16 ä¸ºæ ¸å¿ƒæ‹†è§£ã€‚\n\nvgg-block å†…çš„å·ç§¯å±‚éƒ½æ˜¯åŒç»“æ„çš„ï¼Œæ± åŒ–å±‚éƒ½å¾—ä¸Šä¸€å±‚çš„å·ç§¯å±‚ç‰¹å¾ç¼©å‡ä¸€åŠï¼Œæ·±åº¦è¾ƒæ·±ï¼Œå‚æ•°é‡å¤Ÿå¤§ï¼Œè¾ƒå°çš„ filter size/kernel size\nVGG å¤§é‡ä½¿ç”¨äº† 3 x 3 çš„å·ç§¯æ ¸ï¼Œå‚æ•°å¾ˆå°è€Œä¸”æ•ˆæœè¿˜ä¸é”™ã€‚\nè¿˜æœ‰ VGG ä½¿ç”¨äº†å—çŠ¶ç»“æ„ï¼Œç›¸å½“äºä¸€ä¸ªå°å•å…ƒï¼Œéå¸¸æ–¹ä¾¿ã€‚\n# æ¨¡å‹\nclass VGG16(nn.Module):    def __init__(self):        super(VGG16, self).__init__()        self.block1 = nn.Sequential(            nn.Conv2d(1, 64, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(64, 64, kernel_size=3, padding=1),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2)        )        self.block2 = nn.Sequential(            nn.Conv2d(64, 128, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(128, 128, kernel_size=3, padding=1),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2)        )        self.block3 = nn.Sequential(            nn.Conv2d(128, 256, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(256, 256, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(256, 256, kernel_size=3, padding=1),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2)        )        self.block4 = nn.Sequential(            nn.Conv2d(256, 512, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(512, 512, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(512, 512, kernel_size=3, padding=1),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2)        )        self.block5 = nn.Sequential(            nn.Conv2d(512, 512, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(512, 512, kernel_size=3, padding=1),            nn.ReLU(),            nn.Conv2d(512, 512, kernel_size=3, padding=1),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2)        )        self.block6 = nn.Sequential(            nn.Flatten(),            nn.Linear(512 * 7 * 7, 4096),            nn.ReLU(),            nn.Linear(4096, 4096),            nn.ReLU(),            nn.Linear(4096, 10)        )    def forward(self, x):        x = self.block1(x)        x = self.block2(x)        x = self.block3(x)        x = self.block4(x)        x = self.block5(x)        x = self.block6(x)        return x\n# æœ€ä½³å®è·µ â€”â€” æƒé‡åˆå§‹åŒ–\nåœ¨æˆ‘ä»¬è®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯èƒ½ä¸æ”¶æ•›ï¼Œè®­ç»ƒå‡ºæ¥çš„ç»“æœå›¾å¾ˆéš¾çœ‹ï¼Œå®é™…ä¸Šå¤§æ¦‚ç‡å¯èƒ½æ˜¯å‡ºç°äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæ ¸å¿ƒåŸå› æ˜¯æˆ‘ä»¬çš„æƒé‡åˆå§‹åŒ–è¿‡äºéšæœºäº†ã€‚\nä¸ºä»€ä¹ˆæƒé‡åˆå§‹åŒ–å¦‚æ­¤é‡è¦ï¼Ÿ\nåœ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸­ï¼Œæƒé‡åˆå§‹åŒ–ç›´æ¥å½±å“ï¼š\n\næ¿€æ´»å€¼çš„åˆ†å¸ƒï¼ˆå‰å‘ä¼ æ’­ï¼‰\næ¢¯åº¦çš„å¤§å°å’Œç¨³å®šæ€§ï¼ˆåå‘ä¼ æ’­ï¼‰\næ¨¡å‹æ˜¯å¦æ”¶æ•›ã€æ”¶æ•›é€Ÿåº¦ã€æœ€ç»ˆæ€§èƒ½\n\nå¦‚æœæƒé‡åˆå§‹åŒ–ä¸å½“ï¼Œæ¯”å¦‚ï¼š\n\næƒé‡å¤ªå° â†’ æ¿€æ´»å€¼è¶‹è¿‘äº 0 â†’ æ¢¯åº¦æ¶ˆå¤±\næƒé‡å¤ªå¤§ â†’ æ¿€æ´»å€¼é¥±å’Œ â†’ æ¢¯åº¦çˆ†ç‚¸\n\næ‰€ä»¥æˆ‘ä»¬å¿…é¡»è¦å¼•å…¥æƒé‡åˆå§‹åŒ–ï¼\n# ä½•å‡¯æ˜ - å‡¯æ˜åˆå§‹åŒ–æ³•\nå‡¯æ˜åˆå§‹åŒ–æ³•ï¼ˆKaiming Initializationï¼‰ï¼Œåˆç§° He åˆå§‹åŒ–ï¼Œç”± ä½•æºæ˜ï¼ˆKaiming Heï¼‰ åœ¨ 2015 å¹´æå‡ºï¼Œä¸“ä¸º ReLU åŠå…¶å˜ç§ï¼ˆå¦‚ LeakyReLUï¼‰ è®¾è®¡çš„æƒé‡åˆå§‹åŒ–æ–¹æ³•ã€‚\nfor param in self.modules():    if isinstance(param, nn.Conv2d):        nn.init.kaiming_normal_(param.weight, nonlinearity='relu')        if param.bias is not None:            nn.init.constant_(param.bias, 0)for param in self.modules():    # å·ç§¯å±‚åˆå§‹åŒ–    if isinstance(param, nn.Conv2d):        nn.init.kaiming_normal_(param.weight, nonlinearity='relu')        if param.bias is not None:            nn.init.constant_(param.bias, 0)    # å…¨è¿æ¥å±‚åˆå§‹åŒ–    elif isinstance(param, nn.Linear):        nn.init.normal_(param.weight, 0, 0.01)        if param.bias is not None:            nn.init.constant_(param.bias, 0)ä»¥ä¸Šå¯ä»¥æ”¾åœ¨ï¼š\nclass VGG16_init(nn.Module):    def __init__(self):        super(VGG16, self).__init__()åˆå§‹åŒ–å‡½æ•°ä¹‹ä¸‹ã€‚\n# æœ€ä½³å®è·µ â€”â€” è°ƒæ•´æ‰¹æ¬¡\nåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œè°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼ˆBatch Sizeï¼‰ æ˜¯æœ€æœ‰æ•ˆã€æœ€ä½æˆæœ¬çš„æ€§èƒ½è°ƒä¼˜æ‰‹æ®µä¹‹ä¸€ã€‚â€œæœ€ä½³å®è·µâ€ ä¸æ˜¯è¶Šå¤§è¶Šå¥½ï¼Œä¹Ÿä¸æ˜¯è¶Šå°è¶Šç²¾ï¼Œè€Œæ˜¯æ ¹æ®ç¡¬ä»¶ã€ä»»åŠ¡ã€è®­ç»ƒé˜¶æ®µåŠ¨æ€æƒè¡¡ã€‚\n# GoogLeNet ç½‘ç»œåŸç†\n\nè¿™é‡Œé¢æœ€å”¬äººçš„åœ°æ–¹å°±æ˜¯è¿™ä¸ª Inception å—ï¼Œå®é™…ä¸Šæ²¡æœ‰é‚£ä¹ˆå“äººã€‚\nä»¥å‰æµè¡Œçš„ç½‘ç»œä½¿ç”¨å°åˆ° 1Ã—1ï¼Œå¤§åˆ° 7Ã—7 çš„å·ç§¯æ ¸ã€‚ æœ¬æ–‡çš„ä¸€ä¸ªè§‚ç‚¹ï¼šæœ‰æ—¶ä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸ç»„åˆæ˜¯æœ‰åˆ©çš„ã€‚\n\né€šé“åˆå¹¶ ï¼šå°†å››ä¸ªè·¯çº¿è¾“å‡ºçš„é€šé“åˆå¹¶ã€‚\n# 1 x 1 å·ç§¯çš„ä¼˜ç‚¹\n** åœ¨ä¸æ”¹å˜ç©ºé—´ç»“æ„çš„å‰æä¸‹ï¼Œé«˜æ•ˆåœ°èåˆé€šé“ä¿¡æ¯ã€è°ƒæ•´é€šé“ç»´åº¦ã€å¼•å…¥éçº¿æ€§ï¼Œä»è€Œæå‡æ¨¡å‹è¡¨è¾¾èƒ½åŠ›å¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚** å®ç°è·¨é€šé“çš„äº¤äº’å’Œä¿¡æ¯æ•´åˆï¼Œå·ç§¯æ ¸é€šé“æ•°çš„é™ç»´å’Œå‡ç»´ï¼Œå‡å°‘ç½‘ç»œå‚æ•°ã€‚\n# å…¨å±€å¹³å‡æ± åŒ– GAP\nä¼˜ç‚¹ï¼šâ€œæ— å‚é™ç»´ + æŠ—è¿‡æ‹Ÿåˆâ€â€”â€” æŠŠç‰¹å¾å›¾å…¨å±€å¹³å‡æˆå•ä¸ªæ•°å€¼ï¼Œç›´æ¥å½“åˆ†ç±» logitsï¼Œçœæ‰å…¨è¿æ¥å±‚ï¼Œå¤§å¹…å‡å°‘å‚æ•°é‡ä¸”å¼ºåˆ¶ä¿ç•™é€šé“çº§è¯­ä¹‰ï¼Œé™ä½è¿‡æ‹Ÿåˆé£é™©ã€‚\nç¼ºç‚¹ï¼šâ€œä¸¢ç»†èŠ‚ + å¼ºå‡è®¾â€â€”â€” ç©ºé—´ä¿¡æ¯è¢«å‹æˆä¸€ç‚¹ï¼Œå¯¹ç»†ç²’åº¦ç‰¹å¾æˆ–ç›®æ ‡å®šä½ä»»åŠ¡æ— èƒ½ä¸ºåŠ›ï¼Œå¹¶éšå« â€œé€šé“å³ç±»åˆ«â€ çš„å‡è®¾ï¼Œè‹¥ç±»åˆ«é—´ç‰¹å¾é‡å åˆ™æ˜“æ··æ·†ã€‚\næ³¨æ„åŒºåˆ«ï¼šå…¨å±€å¹³å‡æ± åŒ– GAP ä¸ç›´æ¥ Flatten å¹³å±•çš„åŒºåˆ«\n# å¦‚ä½•è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†\nåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œè®¾è®¡ä¸€ä¸ªè‰¯å¥½çš„æ¨¡å‹éœ€è¦åŸºç¡€çŸ¥è¯†ä¸è¿æ°”ï¼Œåœ¨æ­¤åŸºç¡€ä¹‹ä¸Šï¼Œæ•°æ®çš„é¢„å¤„ç†å¾€å¾€æ˜¯æ‹‰å¼€å·®è·çš„å…³é”®ç‚¹ã€‚\n# æ•°æ®é›†çš„åˆ’åˆ†\nå¦‚ä½•å°†è¿™æ ·çš„æ•°æ®ç›®å½•ï¼š\ndata_cat_dogâ”œâ”€â”€ catâ””â”€â”€ dogå˜æˆï¼š\ndataâ”œâ”€â”€ trainâ”‚   â”œâ”€â”€ catâ”‚   â””â”€â”€ dogâ””â”€â”€ test    â”œâ”€â”€ cat    â””â”€â”€ dogæœ‰è¿™æ ·çš„è„šæœ¬ï¼š\nimport osfrom shutil import copyimport randomdef mkfile(file):    if not os.path.exists(file):        os.makedirs(file)# è·å– data æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶å¤¹åï¼ˆå³éœ€è¦åˆ†ç±»çš„ç±»åï¼‰file_path = 'data_cat_dog'flower_class = [cla for cla in os.listdir(file_path)]# åˆ›å»º è®­ç»ƒé›† train æ–‡ä»¶å¤¹ï¼Œå¹¶ç”±ç±»ååœ¨å…¶ç›®å½•ä¸‹åˆ›å»º 5 ä¸ªå­ç›®å½•mkfile('data/train')for cla in flower_class:    mkfile('data/train/' + cla)# åˆ›å»º éªŒè¯é›† val æ–‡ä»¶å¤¹ï¼Œå¹¶ç”±ç±»ååœ¨å…¶ç›®å½•ä¸‹åˆ›å»ºå­ç›®å½•mkfile('data/test')for cla in flower_class:    mkfile('data/test/' + cla)# åˆ’åˆ†æ¯”ä¾‹ï¼Œè®­ç»ƒé›†ï¼šæµ‹è¯•é›† = 9 : 1split_rate = 0.1# éå†æ‰€æœ‰ç±»åˆ«çš„å…¨éƒ¨å›¾åƒå¹¶æŒ‰æ¯”ä¾‹åˆ†æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†for cla in flower_class:    cla_path = file_path + '/' + cla + '/'  # æŸä¸€ç±»åˆ«çš„å­ç›®å½•    images = os.listdir(cla_path)  # iamges åˆ—è¡¨å­˜å‚¨äº†è¯¥ç›®å½•ä¸‹æ‰€æœ‰å›¾åƒçš„åç§°    num = len(images)    eval_index = random.sample(images, k=int(num * split_rate))  # ä» images åˆ—è¡¨ä¸­éšæœºæŠ½å– k ä¸ªå›¾åƒåç§°    for index, image in enumerate(images):        # eval_index ä¸­ä¿å­˜éªŒè¯é›† val çš„å›¾åƒåç§°        if image in eval_index:            image_path = cla_path + image            new_path = 'data/test/' + cla            copy(image_path, new_path)  # å°†é€‰ä¸­çš„å›¾åƒå¤åˆ¶åˆ°æ–°è·¯å¾„        # å…¶ä½™çš„å›¾åƒä¿å­˜åœ¨è®­ç»ƒé›† train ä¸­        else:            image_path = cla_path + image            new_path = 'data/train/' + cla            copy(image_path, new_path)        print(\"\\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]\".format(cla, index + 1, num), end=\"\")  # processing bar    print()print(\"processing done!\")# æ•°æ®çš„é¢„å¤„ç†\n# é‡è°ƒæ•´\ntransforms.Resize(160)æˆ–\ntransforms.Resize((160,160))ç¬¬ä¸€ä¸ªæ˜¯çš„æ¯”ä¾‹è£å‰ªï¼Œç¬¬äºŒä¸ªæ˜¯æŒ‡å®šåƒç´ è£å‰ªï¼Œä»–ä»¬éƒ½æ˜¯é‡è°ƒæ•´ã€‚\n# éšæœºè£å‰ª\ntransforms.RandomResizedCrop(128, scale=(0.8, 1.0))å…ˆéšæœºåœ¨åŸå›¾é‡Œè£å‡ºä¸€å—é¢ç§¯å  80 %â€“100 % çš„åŒºåŸŸï¼Œå†ç›´æ¥ resize æˆ 128Ã—128ï¼Œæ—¢åšäº†éšæœºè£å‰ªåˆåšäº†å°ºåº¦å¢å¼ºã€‚\n# åŸå§‹æ•°æ®å¢å¼º\ntransforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),è‡ªåŠ¨ä» ImageNet é¢„è®­ç»ƒå¥½çš„ 25 ç§å¢å¼ºç­–ç•¥é‡Œï¼ŒéšæœºæŒ‘ä¸€æ¡å­ç­–ç•¥ï¼ˆå« 5 ç§å¼ºåº¦å¯å˜çš„å›¾åƒå˜æ¢ï¼‰ä½œç”¨åˆ°è¾“å…¥å›¾ä¸Šï¼Œå±äº â€œè‡ªåŠ¨æ•°æ®å¢å¼ºâ€ é‡Œçš„ç»å…¸ç®—æ³•ï¼Œæ— éœ€æ‰‹å·¥è®¾è®¡ç»„åˆã€‚\n\nç­–ç•¥æœç´¢é˜¶æ®µç”¨å¼ºåŒ–å­¦ä¹ åœ¨ ImageNet ä¸Šç¦»çº¿æœå‡º 25 æ¡å­ç­–ç•¥ï¼ˆæ¯æ¡å« 5 ä¸ªå˜æ¢ï¼‰ã€‚\næ¯æ¬¡è®­ç»ƒè¿­ä»£æ—¶ï¼š\n\néšæœºé€‰ä¸€æ¡å­ç­–ç•¥ï¼›\næŒ‰è¯¥å­ç­–ç•¥é‡ŒæŒ‡å®šçš„æ¦‚ç‡ã€å¹…åº¦ä¾æ¬¡å¯¹å›¾åƒåš 5 æ¬¡å˜æ¢ï¼›\nå˜æ¢åˆ—è¡¨åŒ…æ‹¬  ShearX/Y ,  TranslateX/Y ,  Rotate ,  Color ,  Posterize ,  Solarize ,  Contrast ,  Sharpness ,  Brightness ,  AutoContrast ,  Equalize  ç­‰ã€‚\n\n\n\n# æ ‡å‡†åŒ–\ntransforms.ToTensor()æœ¬èº«å°±å…·æœ‰å½’ä¸€åŒ–çš„åŠŸèƒ½ï¼Œä»–å°†æ•°å€¼è½¬åŒ–ä¸º 0-1 çš„åŒºé—´ï¼Œä½†è¿™åªæ˜¯ â€œçº¿æ€§ç¼©æ”¾â€ï¼Œä¸æ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„ â€œæ ‡å‡†åŒ– (normalization)â€ã€‚\ntransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])è¿™æ‰æ˜¯çœŸæ­£çš„æ ‡å‡†åŒ–ï¼šæŠŠæ•°å€¼å˜æˆå‡å€¼ä¸º 0ã€æ–¹å·®ä¸º 1 çš„åˆ†å¸ƒï¼ŒåŠ é€Ÿæ¨¡å‹æ”¶æ•›ã€‚\næ€ä¹ˆç®—å‘¢ï¼Ÿè¿˜æ˜¯æ¥ä¸€ä¸ªé¢„å¤„ç†ã€‚\nfrom PIL import Imageimport osimport numpy as np# æ–‡ä»¶å¤¹è·¯å¾„ï¼ŒåŒ…å«æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶folder_path = 'data_cat_dog'# åˆå§‹åŒ–ç´¯ç§¯å˜é‡total_pixels = 0sum_normalized_pixel_values = np.zeros(3)  # å¦‚æœæ˜¯ RGB å›¾åƒï¼Œéœ€è¦ä¸‰ä¸ªé€šé“çš„å‡å€¼å’Œæ–¹å·®# éå†æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡æ–‡ä»¶for root, dirs, files in os.walk(folder_path):    for filename in files:        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):            image_path = os.path.join(root, filename)            image = Image.open(image_path)            image_array = np.array(image)            # å½’ä¸€åŒ–åƒç´ å€¼åˆ° 0-1 ä¹‹é—´            normalized_image_array = image_array / 255.0            # ç´¯ç§¯å½’ä¸€åŒ–åçš„åƒç´ å€¼å’Œåƒç´ æ•°é‡            total_pixels += normalized_image_array.size            sum_normalized_pixel_values += np.sum(normalized_image_array, axis=(0, 1))# è®¡ç®—å‡å€¼å’Œæ–¹å·®mean = sum_normalized_pixel_values / total_pixelssum_squared_diff = np.zeros(3)for root, dirs, files in os.walk(folder_path):    for filename in files:        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):            image_path = os.path.join(root, filename)            image = Image.open(image_path)            image_array = np.array(image)            # å½’ä¸€åŒ–åƒç´ å€¼åˆ° 0-1 ä¹‹é—´            normalized_image_array = image_array / 255.0            try:                diff = (normalized_image_array - mean) ** 2                sum_squared_diff += np.sum(diff, axis=(0, 1))            except:                print(f\"æ•è·åˆ°è‡ªå®šä¹‰å¼‚å¸¸\")variance = sum_squared_diff / total_pixelsprint(\"Mean:\", mean)print(\"Variance:\", variance)# éšæœºæ“¦é™¤\ntransforms.RandomErasing(p=0.3, scale=(0.02, 0.2))ä»¥ 30 % çš„æ¦‚ç‡åœ¨å›¾åƒä¸ŠéšæœºæŒ–æ‰ä¸€å—çŸ©å½¢åŒºåŸŸï¼ˆé¢ç§¯å å›¾ 2 %â€“20 %ï¼‰ï¼Œç”¨éšæœºå€¼ï¼ˆç°è‰²ã€ç™½è‰²æˆ–é»‘è‰²ï¼‰å¡«å¹³ï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¼š â€œé å±€éƒ¨ä¹Ÿèƒ½çŒœå¯¹â€ï¼Œå±äºç®€å•çš„æ­£åˆ™åŒ– / æŠ—é®æŒ¡å¢å¼ºã€‚\n# ResNet åŸç†ä¸å®æˆ˜\n\n# ç½‘ç»œæŒç»­åŠ æ·±å¸¦æ¥é‚£äº›é—®é¢˜\nä¸€ã€ä¼˜åŒ–éš¾é¢˜ï¼šç½‘ç»œè¶Šæ·±è¶Š â€œå­¦ä¸åŠ¨â€\näºŒã€è¡¨è¾¾éš¾é¢˜ï¼šç½‘ç»œè¶Šæ·±è¶Š â€œè®°ä¸ä½â€\nä¸‰ã€å·¥ç¨‹éš¾é¢˜ï¼šç½‘ç»œè¶Šæ·±è¶Š â€œå…»ä¸èµ·â€\nâ€œæ·±â€ æœ¬èº«ä¸æ˜¯é”™ï¼Œé”™çš„æ˜¯æ·± + Plain å †å ï¼›ï¼Œ\n\nPlain Network = åªæœ‰ â€œå·ç§¯â€“BNâ€“ReLUâ€ ä¸€è·¯ä¸²è¡Œä¸‹å»ï¼Œä¸å¸¦ä»»ä½•è·³è·ƒè¿æ¥çš„ç›´ç­’å¼æ¶æ„ã€‚\n\nâ€œé“¾å¼æ±‚å¯¼â€ æœ¬èº«å°±æ˜¯æ ¹æº â€”â€” ä½†è¦æŠŠè¯æ‹†æˆä¸¤å¥è¯´ï¼š\n\né“¾å¼æ±‚å¯¼å¿…ç„¶å¯¼è‡´æ·±åº¦ç½‘ç»œé‡Œçš„æ¢¯åº¦æ˜¯ â€œè¿ä¹˜â€ å½¢å¼ï¼›\nè¿ä¹˜çš„å› å­ä¸€æ—¦æŒç»­å°äº 1ï¼ˆæˆ–å¤§äº 1ï¼‰ï¼Œå±‚æ•°ä¸€å¤šå°±æŒ‡æ•°çº§è¡°å‡ / çˆ†ç‚¸ï¼Œè¿™å°±æ˜¯æ¢¯åº¦æ¶ˆå¤± / çˆ†ç‚¸çš„æ•°å­¦æœ¬è´¨ã€‚\n\næ‰€ä»¥ Plain Net çš„é€€åŒ–é—®é¢˜è™½ç„¶è¡¨ç°å½¢å¼æ˜¯ â€œè¶Šæ·±å±‚è®­ç»ƒè¯¯å·®è¶Šå¤§â€ï¼Œä½†åº•å±‚æœºåˆ¶ä»ç„¶ç»•ä¸å¼€é“¾å¼æ±‚å¯¼å¸¦æ¥çš„æ•°å€¼ä¸ç¨³å®šã€‚\nResNet çš„ skip connection æ­£æ˜¯äººä¸ºåœ¨é“¾å¼ä¹˜ç§¯é‡Œæ’è¿›ä¸€é¡¹ 1ï¼ŒæŠŠ â€œè¿ä¹˜â€ æ”¹å†™æˆ â€œè¿ä¹˜ + 1â€ï¼Œä»è€Œæ‰“æ–­æŒ‡æ•°è¡°å‡ â€”â€” ç”¨åŠ æ³•ç»™é“¾å¼æ³•åˆ™æ‰“äº†ä¸€ä¸ªè¡¥ä¸ã€‚\n# æ®‹å·®å—\nResNetï¼ˆResidual Networkï¼‰çš„æ ¸å¿ƒåˆ›æ–°å°±æ˜¯æ®‹å·®è¿æ¥ï¼ˆResidual Connectionï¼‰ï¼Œå®ƒè§£å†³äº†æ·±å±‚ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—è®­ç»ƒéå¸¸æ·±çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚\næ®‹å·®å—çš„è®¾è®¡æ˜¯æ·±åº¦å­¦ä¹ é¢†åŸŸçš„é‡å¤§çªç ´ï¼Œå®ƒä¸ä»…åœ¨å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¿˜è¢«å¹¿æ³›åº”ç”¨äºå„ç§æ·±åº¦å­¦ä¹ æ¶æ„ä¸­ã€‚a = h (x) + x\n\nä¸Šå›¾æœ‰ä¸€ä¸ªé”™è¯¯ï¼Œå¡«å……åº”è¯¥æ˜¯ 0ï¼Œæ­¥å¹…æ˜¯ 1ã€‚\n# Batch Normalization å½’ä¸€åŒ–\nBatch Normalizationï¼ˆæ‰¹å½’ä¸€åŒ–ï¼Œç®€ç§° BNï¼‰ çš„ç›®çš„æ˜¯ è®©ç¥ç»ç½‘ç»œè®­ç»ƒæ›´å¿«ã€æ›´ç¨³å®šã€æ›´å®¹æ˜“æ”¶æ•›ã€‚\n\nBatchNorm ä¸æ˜¯ â€œé”¦ä¸Šæ·»èŠ±â€ï¼Œè€Œæ˜¯ â€œæ·±åº¦ç½‘ç»œèƒ½è®­å¾—åŠ¨â€ çš„åˆšéœ€ â€”â€” å®ƒæŠŠæ¯å±‚çš„è¾“å…¥åˆ†å¸ƒå¼ºè¡Œæ‹‰å› N (0,1)ï¼Œåˆ‡æ–­æ¢¯åº¦æ¶ˆå¤± / çˆ†ç‚¸ä¸å†…éƒ¨åå˜é‡åç§»çš„æ¶æ€§å¾ªç¯ï¼Œè®©é“¾å¼æ±‚å¯¼çš„è¿ä¹˜å› å­å§‹ç»ˆè½åœ¨ 1 é™„è¿‘ï¼Œäºæ˜¯éå¸¸æ·±çš„ Plain/ResNet æ‰åƒå¾—ä¸‹å¤§å­¦ä¹ ç‡ã€å¿«é€Ÿæ”¶æ•›ä¸”ä¸ç”¨ç‰¹åˆ«ç²¾è°ƒåˆå§‹åŒ–ã€‚\nBN çš„è§£å†³æ–¹æ¡ˆéå¸¸ç›´è§‚æœ‰åŠ›ï¼šæ—¢ç„¶å±‚è¾“å…¥çš„åˆ†å¸ƒè€åœ¨å˜ï¼Œé‚£æˆ‘ä»¬å°±å¼ºåˆ¶æŠŠå®ƒæ‹‰å›ä¸€ä¸ªç¨³å®šã€æ ‡å‡†çš„åˆ†å¸ƒã€‚\nBN çš„ä½ç½®é€šå¸¸æ”¾åœ¨ï¼š\nå…¨è¿æ¥å±‚/å·ç§¯å±‚ â†’ BatchNorm â†’ æ¿€æ´»å‡½æ•°(ReLUç­‰)# ResNet çš„åŸºæœ¬å®ç°\n# æ®‹å·®å—\nclass ResidualBlock(nn.Module):    def __init__(self, in_channels, out_channels, use_conv1x1=False, stride=1) -> None:        super(ResidualBlock).__init__()        self.RelU = nn.ReLU(inplace=True)        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride,                               padding=1)        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride,                               padding=1)        self.BN1 = nn.BatchNorm2d(out_channels)        self.BN2 = nn.BatchNorm2d(out_channels)        if use_conv1x1:            self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=stride,                                   stride=stride, padding=0)        else:            self.conv3 = None    def forward(self, x):        y = self.RelU(self.BN1(self.conv1(x)))        y = self.BN2(self.conv2(y))        if self.conv3 is not None:            x = self.conv3(x)        y = self.RelU(y + x)        return y# ResNet18\nclass ResNet18(nn.Module):    def __init__(self, ResidualBlock) -> None:        super(ResNet18, self).__init__()        self.b1 = nn.Sequential(            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3),            nn.BatchNorm2d(64),            nn.ReLU(inplace=True),            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)        )        self.b2 = nn.Sequential(            ResidualBlock(64, 64, use_conv1x1=False, stride=1),            ResidualBlock(64, 64, use_conv1x1=False, stride=1)        )        self.b3 = nn.Sequential(            ResidualBlock(64, 128, use_conv1x1=True, stride=2),            ResidualBlock(128, 128, use_conv1x1=False, stride=1)        )        self.b4 = nn.Sequential(            ResidualBlock(128, 256, use_conv1x1=True, stride=2),            ResidualBlock(256, 256, use_conv1x1=False, stride=1)        )        self.b5 = nn.Sequential(            ResidualBlock(256, 512, use_conv1x1=True, stride=2),            ResidualBlock(512, 512, use_conv1x1=False, stride=1)        )        self.b6 = nn.Sequential(            nn.AdaptiveAvgPool2d((1, 1)),            nn.Flatten(),            nn.Linear(512, 10)        )    def forward(self, x):        x = self.b1(x)        x = self.b2(x)        x = self.b3(x)        x = self.b4(x)        x = self.b5(x)        x = self.b6(x)        return x","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN"]},{"title":"3DCNN ç½‘ç»œç»“æ„","url":"/python/3D_CNN/","content":"# 3DCNN ç½‘ç»œç»“æ„\nå­¦ä¹ å†…å®¹åŸºäºï¼šhttps://www.bilibili.com/video/BV1kc411Q7Tj\n# å›¾åƒçš„æœ¬è´¨\nå›¾åƒæ˜¯ç”± RGB ä¸‰é€šé“ç»„æˆçš„ï¼Œä¸€èˆ¬æ•°å€¼èŒƒå›´æ˜¯ 0 åˆ° 255.\nå› æ­¤åƒç´ çŸ©é˜µä¸ºï¼šH * W * 3ï¼Œå…¶ä¸­ H ä¸ºé«˜ï¼ŒW æ˜¯å®½ã€‚\n# ä»å›¾åƒåˆ°è§†é¢‘\nè§†é¢‘æœ¬è´¨ä¸Šæ˜¯ç”±è¿ç»­çš„å›¾ç‰‡ï¼ˆè§†é¢‘å¸§ï¼‰ï¼Œå¿«é€Ÿæ’­æ”¾æ„æˆçš„ã€‚\nå›¾ç‰‡çš„åƒç´ çŸ©é˜µæ˜¯ H * W * 3\nè§†é¢‘å°±æ˜¯ D * H * W * 3ï¼Œå…¶ä¸­ D æ˜¯æ·±åº¦ï¼Œæ˜¯è§†é¢‘å¸§çš„å åŠ ã€‚\nä¸åŒçš„åº“å¯¹ä¸è¿™ 4 ä¸ªç»´åº¦é¡ºåºè¡¨è¿°ä¸åŒï¼Œä½†è¿™å››ä¸ªç»´åº¦è¯šç„¶å¦‚æ­¤ã€‚\n# 2D æ£€æµ‹æ–¹æ³•å¯¹æ¯”\n\n\n\n# C3D ç½‘ç»œæµç¨‹\n\nè¿™ä¸ªï¼ˆ1ï¼Œ1ï¼Œ1ï¼‰ï¼Œä¸‰ä¸ªæ•°å­—æ˜¯æœ‰ç‚¹æ‰‹æ³•çš„ï¼Œç¬¬ä¸€ä¸ªæ•°æ˜¯ä»£è¡¨äº†æ·±åº¦ï¼Œç¬¬äºŒä¸ªã€ç¬¬ä¸‰ä¸ªä»£è¡¨äº†é«˜å’Œå®½ã€‚\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸€èˆ¬æ¥è¯´è¿™ä¸ªå·ç§¯æ ¸å¤§å°ä¸€èˆ¬æ˜¯ï¼ˆ3ï¼Œ3ï¼Œ3ï¼‰ï¼Œå¡«å……æ˜¯ï¼ˆ1ï¼Œ1ï¼Œ1ï¼‰ï¼Œç»è¿‡è¿™æ ·çš„å·ç§¯è¿‡åï¼Œç‰¹å¾å›¾å¤§å°ä¸å˜ã€‚\n\nè¿™é‡Œæ˜¯ up çš„è§£é‡Šï¼Œå·²ç»æ˜¯éå¸¸çš„ç›´è§‚æ˜“æ‡‚ã€‚\n# åŠ¨æ‰‹æ­å»ºä¸€ä¸ª C3D\nimport torchfrom torch import nnfrom torchsummary import summaryclass C3D(nn.Module):    def __init__(self, num_classes, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.block1 = nn.Sequential(            nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))        )        self.block2 = nn.Sequential(            nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))        )        self.block3 = nn.Sequential(            nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))        )        self.block4 = nn.Sequential(            nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))        )        self.block5 = nn.Sequential(            nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1)),            nn.ReLU(),            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))        )        self.fc = nn.Sequential(            nn.Linear(8192, 4096),            nn.ReLU(),            nn.Dropout(p=0.5),            nn.Linear(4096, 4096),            nn.ReLU(),            nn.Dropout(p=0.5),            nn.Linear(4096, num_classes)        )        self._init_weights()    def forward(self, x):        x = self.block1(x)        x = self.block2(x)        x = self.block3(x)        x = self.block4(x)        x = self.block5(x)        x = x.flatten(start_dim=1)        x = self.fc(x)        return x    def _init_weights(self):        for m in self.modules():            if isinstance(m, nn.Conv3d):                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')                if m.bias is not None:                    nn.init.constant_(m.bias, 0)            elif isinstance(m, nn.Linear):                nn.init.normal_(m.weight, 0, 0.01)if __name__ == '__main__':    model = C3D(num_classes=101)    print(summary(model, (3, 16, 112, 112), device='cpu'))# é¢„è®­ç»ƒæƒé‡\næ¯”å¦‚ï¼Œæœ‰ä¸€ä¸ªçŒ«ç‹—åˆ†ç±»çš„æ¨¡å‹ï¼Œæƒé‡å’Œåç½®å·²ç»è®­ç»ƒå¥½äº†ï¼Œä½†æ˜¯ç°åœ¨æœ‰ä¸€ä¸ªæ–°ä»»åŠ¡ï¼Œå°±æ˜¯ç‹¼å’Œè€è™è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨çŒ«ç‹—åˆ†ç±»çš„æƒé‡æ¥ç»§ç»­è®­ç»ƒç‹¼å’Œè€è™åˆ†ç±»ï¼Œè¿™æ ·çš„è¯ä¼šåŠ é€Ÿæˆ‘ä»¬çš„è®­ç»ƒé€Ÿåº¦ï¼Œéå¸¸æ–¹ä¾¿ã€‚\n@staticmethod    def __load__pretrained_model():        p_dict = torch.load('./ucf101-caffe.pth')        s_dict = model.state_dict()        corresp_name = &#123;            'features.0.weight': 'block1.0.weight',            'features.0.bias': 'block1.0.bias',            'features.3.weight': 'block2.0.weight',            'features.3.bias': 'block2.0.bias',            'features.6.weight': 'block3.0.weight',            'features.6.bias': 'block3.0.bias',            'features.8.weight': 'block3.2.weight',            'features.8.bias': 'block3.2.bias',            'features.11.weight': 'block4.0.weight',            'features.11.bias': 'block4.0.bias',            'features.13.weight': 'block4.2.weight',            'features.13.bias': 'block4.2.bias',            'features.16.weight': 'block5.0.weight',            'features.16.bias': 'block5.0.bias',            'features.18.weight': 'block5.2.weight',            'features.18.bias': 'block5.2.bias',            'classifier.0.weight': 'fc.0.weight',            'classifier.0.bias': 'fc.0.bias',            'classifier.3.weight': 'fc.3.weight',            'classifier.3.bias': 'fc.3.bias'        &#125;        for name in p_dict:            if name not in corresp_name:                continue            s_dict[corresp_name[name]] = p_dict[name]åƒè¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥åšå‚æ•°ç§»æ¤äº†\n","categories":["æ·±åº¦å­¦ä¹ ","é¡¹ç›®ä¸å®æˆ˜"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","3D_CNN"]},{"title":"ä»å…¬å¼è§’åº¦çœ‹æ·±åº¦å­¦ä¹ ","url":"/python/DLFromFormula/","content":"# ä»å…¬å¼è§’åº¦çœ‹æ·±åº¦å­¦ä¹ \nå­¦ä¹ åŸºäºå°šç¡…è°·ï¼šhttps://www.bilibili.com/video/BV1MRJmzSEaa\n# æŸå¤±å‡½æ•°\n# å‡æ–¹è¯¯å·® MSE / L2 Lossï¼ˆå›å½’é—®é¢˜è¾ƒé€‚ç”¨ï¼‰\nMean Squared Errorï¼ˆMSEï¼‰\nL=1nâˆ‘i=1n(yiâˆ’ti)2\\begin {array}{c}\nL=\\frac{1}{n} \\sum_{i=1}^{n}(y_{i}-t_{i})^{2}  \n\\end{array}\nL=n1â€‹âˆ‘i=1nâ€‹(yiâ€‹âˆ’tiâ€‹)2â€‹\nè¿™ä¸ª ti æ˜¯ç›®æ ‡æ ‡ç­¾ (å‘é‡)ï¼Œyi æ˜¯é¢„æµ‹æ ‡ç­¾ (å‘é‡)ï¼Œn æ˜¯æ€»ä¸ªæ•°ã€‚\nå¾€å¾€æˆ‘ä»¬åœ¨æ˜¯å®é™…ä½¿ç”¨çš„æ˜¯æ—¶å€™ï¼Œä½¿ç”¨ä¸‹é¢è¿™ä¸ªå…¬å¼ã€‚\nL=12nâˆ‘i=1n(yiâˆ’ti)2\\begin {array}{c}\nL=\\frac{1}{2n} \\sum_{i=1}^{n}(y_{i}-t_{i})^{2}\n\\end{array}\nL=2n1â€‹âˆ‘i=1nâ€‹(yiâ€‹âˆ’tiâ€‹)2â€‹\nL2 Loss å¯¹å¼‚å¸¸å€¼æ•æ„Ÿï¼Œé‡åˆ°å¼‚å¸¸å€¼æ—¶æ˜“å‘ç”Ÿæ¢¯åº¦çˆ†ç‚¸ã€‚\ndef mean_squared_error(y, t):    return 0.5 * np.sum((y-t)**2)# äº¤å‰ç†µè¯¯å·® CEEï¼ˆåˆ†ç±»é—®é¢˜è¾ƒé€‚ç”¨ï¼‰\nCross Entropy Errorï¼ˆCEEï¼‰\nL=âˆ’1nâˆ‘i=1ntilogâ¡(yi)\\begin {array}{c}\nL=-\\frac{1}{n} \\sum_{i=1}^{n} t_{i} \\log (y_{i})\n\\end{array}\nL=âˆ’n1â€‹âˆ‘i=1nâ€‹tiâ€‹log(yiâ€‹)â€‹\nyi è¡¨ç¤ºç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼Œti è¡¨ç¤ºæ­£ç¡®è§£æ ‡ç­¾ï¼›è€Œä¸”ï¼Œti ä¸­åªæœ‰æ­£ç¡®è§£æ ‡ç­¾å¯¹åº”çš„å€¼ä¸º 1ï¼Œå…¶å®ƒå‡ä¸º 0ï¼ˆone-hot è¡¨ç¤ºï¼‰ã€‚\ndef cross_entropy_error(y, t):    if y.ndim == 1:        t = t.reshape(1, t.size)        y = y.reshape(1, y.size)            # ç›‘ç£æ•°æ®æ˜¯ one-hot å‘é‡çš„æƒ…å†µä¸‹ï¼Œè½¬æ¢ä¸ºæ­£ç¡®è§£æ ‡ç­¾çš„ç´¢å¼•    if t.size == y.size:        t = t.argmax(axis=1)                 batch_size = y.shape[0]    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size# äºŒå…ƒäº¤å‰ç†µè¯¯å·® BCEE\nBinary Cross-Entropy Loss\nL=âˆ’1nâˆ‘i=1ntilogâ¡(yi)+(1âˆ’ti)logâ¡(1âˆ’yi)\\begin {array}{c}\nL=-\\frac{1}{n} \\sum_{i=1}^{n} t_{i} \\log (y_{i})+(1-t_{i}) \\log (1-y_{i})\n\\end{array}\nL=âˆ’n1â€‹âˆ‘i=1nâ€‹tiâ€‹log(yiâ€‹)+(1âˆ’tiâ€‹)log(1âˆ’yiâ€‹)â€‹\n# å¤šç±»äº¤å‰ç†µè¯¯å·® CCEE\nCategorical Cross-Entropy Loss\nL=âˆ’1nâˆ‘i=1nâˆ‘j=1Ctijlogâ¡(yij)\\begin {array}{c}\nL=-\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{C} t_{i j} \\log (y_{i j})\n\\end{array}\nL=âˆ’n1â€‹âˆ‘i=1nâ€‹âˆ‘j=1Câ€‹tijâ€‹log(yijâ€‹)â€‹\n# å¹³å‡ç»å¯¹è¯¯å·® MAE / L1 Loss\nMean Absolute Erro\nL=1nâˆ‘i=1nâˆ£yiâˆ’tiâˆ£\\begin {array}{c}\nL=\\frac{1}{n} \\sum_{i=1}^{n}|y_{i}-t_{i}|\n\\end{array}\nL=n1â€‹âˆ‘i=1nâ€‹âˆ£yiâ€‹âˆ’tiâ€‹âˆ£â€‹\nL1 Loss å¯¹å¼‚å¸¸å€¼é²æ£’ï¼Œä½†åœ¨ 0 ç‚¹å¤„ä¸å¯å¯¼ã€‚\n# å¹³æ»‘ L1 è¯¯å·® / Smooth L1\nSmooth L1\nSmoothÂ L1={12(yiâˆ’y^i)2,ifÂ âˆ£yiâˆ’y^iâˆ£&lt;1âˆ£yiâˆ’y^iâˆ£âˆ’12,ifÂ âˆ£yiâˆ’y^iâˆ£â‰¥1\\begin {array}{c}\n\\text{Smooth } L1 =\n\\begin{cases}\n\\frac{1}{2}(y_i - \\hat{y}_i)^2, &amp; \\text{if } |y_i - \\hat{y}_i| &lt; 1 \\\\\n|y_i - \\hat{y}_i| - \\frac{1}{2}, &amp; \\text{if } |y_i - \\hat{y}_i| \\geq 1\n\\end{cases}\n\\end{array}\nSmoothÂ L1={21â€‹(yiâ€‹âˆ’y^â€‹iâ€‹)2,âˆ£yiâ€‹âˆ’y^â€‹iâ€‹âˆ£âˆ’21â€‹,â€‹ifÂ âˆ£yiâ€‹âˆ’y^â€‹iâ€‹âˆ£&lt;1ifÂ âˆ£yiâ€‹âˆ’y^â€‹iâ€‹âˆ£â‰¥1â€‹â€‹\n# æ¢¯åº¦\næ¢¯åº¦\nâˆ‡L=âˆ‚Lâˆ‚w1âˆ‚w1âˆ‚x+âˆ‚Lâˆ‚w2âˆ‚w2âˆ‚x+â‹¯+âˆ‚Lâˆ‚wnâˆ‚wnâˆ‚x\\begin {array}{c}\n\\nabla L=\\frac{\\partial L}{\\partial w_{1}} \\frac{\\partial w_{1}}{\\partial x}+\\frac{\\partial L}{\\partial w_{2}} \\frac{\\partial w_{2}}{\\partial x}+\\cdots+\\frac{\\partial L}{\\partial w_{n}} \\frac{\\partial w_{n}}{\\partial x}\n\\end{array}\nâˆ‡L=âˆ‚w1â€‹âˆ‚Lâ€‹âˆ‚xâˆ‚w1â€‹â€‹+âˆ‚w2â€‹âˆ‚Lâ€‹âˆ‚xâˆ‚w2â€‹â€‹+â‹¯+âˆ‚wnâ€‹âˆ‚Lâ€‹âˆ‚xâˆ‚wnâ€‹â€‹â€‹\næ¢¯åº¦æ˜¯å…³äºå‚æ•°çš„å¯¼æ•°ï¼Œå³å¯¹äºå‚æ•° w1ï¼Œw2ï¼Œw3ï¼Œw4ï¼Œw5â€¦wnï¼Œæ±‚å…³äº x çš„å¯¼æ•°ï¼Œè¿™äº›åå¯¼æ•°ç»„æˆçš„å‘é‡å°±æ˜¯æ¢¯åº¦ï¼Œå¦‚ä¸‹é¢è¿™ä¸ªå½¢å¼ã€‚\nâˆ‡L=[âˆ‚Lâˆ‚w1,âˆ‚Lâˆ‚w2,âˆ‚Lâˆ‚w3,âˆ‚Lâˆ‚w4,âˆ‚Lâˆ‚w5,â‹¯â€‰,âˆ‚Lâˆ‚wn]\\begin {array}{c}\n\\nabla L=\\left[\\frac{\\partial L}{\\partial w_{1}}, \\frac{\\partial L}{\\partial w_{2}}, \\frac{\\partial L}{\\partial w_{3}}, \\frac{\\partial L}{\\partial w_{4}}, \\frac{\\partial L}{\\partial w_{5}}, \\cdots, \\frac{\\partial L}{\\partial w_{n}}\\right]\n\\end{array}\nâˆ‡L=[âˆ‚w1â€‹âˆ‚Lâ€‹,âˆ‚w2â€‹âˆ‚Lâ€‹,âˆ‚w3â€‹âˆ‚Lâ€‹,âˆ‚w4â€‹âˆ‚Lâ€‹,âˆ‚w5â€‹âˆ‚Lâ€‹,â‹¯,âˆ‚wnâ€‹âˆ‚Lâ€‹]â€‹\nåœ¨æå°å€¼å¤„ã€æå¤§å€¼å¤„å’Œéç‚¹å¤„ï¼Œæ¢¯åº¦å‘é‡éƒ½ä¸º 0ã€‚\næ¢¯åº¦ä»£è¡¨çš„å…¶å®æ˜¯å‡½æ•°å€¼å¢å¤§æœ€å¿«çš„æ–¹å‘ï¼›åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å¯»æ‰¾æŸå¤±å‡½æ•°çš„æœ€å°å€¼ï¼Œæ‰€ä»¥ä¸€èˆ¬é€‰æ‹©è´Ÿæ¢¯åº¦\nå‘é‡ã€‚åŒæ ·åœ°ï¼Œè´Ÿæ¢¯åº¦ä»£è¡¨çš„æ˜¯å‡½æ•°å€¼å‡å°æœ€å¿«çš„æ–¹å‘ï¼Œå¹¶ä¸ä¸€å®šç›´æ¥æŒ‡å‘å‡½æ•°å›¾åƒçš„æœ€ä½ç‚¹ã€‚\n# ä¼˜åŒ–å‡½æ•°\n# éšæœºæ¢¯åº¦ä¸‹é™ SGD\nstochastic Gradient Descent\nwt+1=wtâˆ’Î·âˆ‡L(wt)\\begin {array}{c}\nw_{t+1}=w_{t}-\\eta \\nabla L(w_{t})\n\\end{array}\nwt+1â€‹=wtâ€‹âˆ’Î·âˆ‡L(wtâ€‹)â€‹\nÎ·\\etaÎ· æ˜¯å­¦ä¹ ç‡ï¼Œä¸€èˆ¬å– 0.01ã€‚\nSGD æœ‰ä»¥ä¸‹é—®é¢˜ï¼š\n\nå±€éƒ¨æœ€ä¼˜è§£ï¼šé™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå°¤å…¶åœ¨éå‡¸å‡½æ•°ä¸­ï¼Œéš¾ä»¥æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚\néç‚¹ï¼šé™·å…¥éç‚¹ï¼Œæ¢¯åº¦ä¸º 0ï¼Œå¯¼è‡´è®­ç»ƒåœæ»ã€‚\næ”¶æ•›é€Ÿåº¦æ…¢ï¼šé«˜ç»´æˆ–éå‡¸å‡½æ•°ä¸­ï¼Œæ”¶æ•›é€Ÿåº¦è¾ƒæ…¢ã€‚\nå­¦ä¹ ç‡é€‰æ‹©ï¼šå­¦ä¹ ç‡è¿‡å¤§å¯¼è‡´éœ‡è¡æˆ–ä¸æ”¶æ•›ï¼Œè¿‡å°åˆ™æ”¶æ•›é€Ÿåº¦æ…¢ã€‚\n\n# è‡ªé€‚åº”æ¢¯åº¦ AdaGrad\nAdaGrad\nwt+1=wtâˆ’Î·1âˆ‘i=1n(wt,i)2+Ïµâˆ‡L(wt)\\begin {array}{c}\nw_{t+1}=w_{t}-\\eta \\frac{1}{\\sqrt{\\sum_{i=1}^{n}\\left(w_{t, i}\\right)^{2}+\\epsilon}} \\nabla L(w_{t})\n\\end{array}\nwt+1â€‹=wtâ€‹âˆ’Î·âˆ‘i=1nâ€‹(wt,iâ€‹)2+Ïµâ€‹1â€‹âˆ‡L(wtâ€‹)â€‹\nAdaGrad çš„ä¼˜ç‚¹æ˜¯ï¼š\n\nå¿«é€Ÿæ”¶æ•›ï¼šåœ¨éå‡¸å‡½æ•°ä¸­ï¼ŒAdaGrad èƒ½å¤Ÿå¿«é€Ÿæ”¶æ•›åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚\næ¢¯åº¦åŠ é€Ÿï¼šåœ¨å‡¸å‡½æ•°ä¸­ï¼ŒAdaGrad èƒ½å¤ŸåŠ é€Ÿæ¢¯åº¦ä¸‹é™ï¼Œä½¿å¾—è®­ç»ƒé€Ÿåº¦æ›´å¿«ã€‚\n\n# åŠ¨é‡æ³• Momentum\nMomentum\nwt+1=wt+Î·mt\\begin {array}{c}\nw_{t+1}=w_{t}+\\eta m_{t}\n\\end{array}\nwt+1â€‹=wtâ€‹+Î·mtâ€‹â€‹\nmt=Î²mtâˆ’1+(1âˆ’Î²)âˆ‡L(wt)\\begin {array}{c}\nm_{t}=\\beta m_{t-1}+\\left(1-\\beta\\right) \\nabla L(w_{t})\n\\end{array}\nmtâ€‹=Î²mtâˆ’1â€‹+(1âˆ’Î²)âˆ‡L(wtâ€‹)â€‹\nÎ²\\betaÎ² æ˜¯åŠ¨é‡çš„è¶…å‚æ•°ï¼Œä¸€èˆ¬å– 0.9ã€‚\nåŠ¨é‡çš„ä½œç”¨æ˜¯åŠ é€Ÿæ¢¯åº¦ä¸‹é™ï¼Œä¼šä¿å­˜å†å²æ¢¯åº¦å¹¶ç»™äºˆä¸€å®šçš„æƒé‡ï¼Œä½¿å…¶ä¹Ÿå‚ä¸åˆ°å‚æ•°æ›´æ–°ä¸­ï¼Œä½¿å¾—æ¢¯åº¦ä¸‹é™é€Ÿåº¦æ›´å¿«ã€‚\nå…¶ä¸­ï¼Œmt-1 æ˜¯å†å²æ¢¯åº¦ï¼Œmt æ˜¯å½“å‰æ¢¯åº¦ã€‚\nåœ¨å½“å‰æ¢¯åº¦ä¸­ï¼Œä¹ŸåŒ…å«äº†å†å²æ¢¯åº¦ï¼Œå› æ­¤ï¼Œmt-1 ä¸­çš„å†å²æ¢¯åº¦ä¹Ÿä¼šè¢«åŠ å…¥åˆ°å½“å‰æ¢¯åº¦ä¸­ï¼Œä»è€Œå®ç°æ¢¯åº¦åŠ é€Ÿã€‚\n# Adam\nAdam\nmt=Î²1mtâˆ’1+(1âˆ’Î²1)âˆ‡L(wt)\\begin {array}{c}\nm_{t}=\\beta_{1} m_{t-1}+(1-\\beta_{1}) \\nabla L(w_{t})\n\\end{array}\nmtâ€‹=Î²1â€‹mtâˆ’1â€‹+(1âˆ’Î²1â€‹)âˆ‡L(wtâ€‹)â€‹\nvt=Î²2vtâˆ’1+(1âˆ’Î²2)âˆ‡L(wt)2\\begin {array}{c}\nv_{t}=\\beta_{2} v_{t-1}+(1-\\beta_{2}) \\nabla L(w_{t})^{2}\n\\end{array}\nvtâ€‹=Î²2â€‹vtâˆ’1â€‹+(1âˆ’Î²2â€‹)âˆ‡L(wtâ€‹)2â€‹\nwt+1=wtâˆ’Î·v^t+Ïµm^t\\begin {array}{c}\nw_{t+1}=w_{t}-\\frac{\\eta}{\\sqrt{\\hat{v}_{t}}+\\epsilon} \\hat{m}_{t}\n\\end{array}\nwt+1â€‹=wtâ€‹âˆ’v^tâ€‹â€‹+ÏµÎ·â€‹m^tâ€‹â€‹\nÎ²1\\beta_{1}Î²1â€‹ å’ŒÎ²2\\beta_{2}Î²2â€‹ æ˜¯ Adam ç®—æ³•ä¸­çš„ä¸¤ä¸ªè¶…å‚æ•°ï¼Œä¸€èˆ¬å– 0.9 å’Œ 0.999ã€‚\nÏµ\\epsilonÏµ æ˜¯ Adam ç®—æ³•ä¸­çš„è¶…å‚æ•°ï¼Œä¸€èˆ¬å– 1e-8ã€‚\nm^t\\hat{m}_{t}m^tâ€‹ å’Œv^t\\hat{v}_{t}v^tâ€‹ æ˜¯ Adam ç®—æ³•ä¸­çš„ä¸¤ä¸ªä¸­é—´å˜é‡ï¼Œåˆ†åˆ«è¡¨ç¤ºmtm_{t}mtâ€‹ å’Œvtv_{t}vtâ€‹ çš„ä¼°è®¡å€¼ã€‚\nm^t\\hat{m}_{t}m^tâ€‹ å’Œv^t\\hat{v}_{t}v^tâ€‹ çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\nm^t=mt1âˆ’Î²1t\\begin {array}{c}\n\\hat{m}_{t}=\\frac{m_{t}}{1-\\beta_{1}^{t}}\n\\end{array}\nm^tâ€‹=1âˆ’Î²1tâ€‹mtâ€‹â€‹â€‹\nv^t=vt1âˆ’Î²2t\\begin {array}{c}\n\\hat{v}_{t}=\\frac{v_{t}}{1-\\beta_{2}^{t}}\n\\end{array}\nv^tâ€‹=1âˆ’Î²2tâ€‹vtâ€‹â€‹â€‹\n# AdamW\nAdamW\nwt+1=wtâˆ’Î·v^t+Ïµm^t+Î»wt\\begin {array}{c}\nw_{t+1}=w_{t}-\\frac{\\eta}{\\sqrt{\\hat{v}_{t}}+\\epsilon} \\hat{m}_{t}+\\lambda w_{t}\n\\end{array}\nwt+1â€‹=wtâ€‹âˆ’v^tâ€‹â€‹+ÏµÎ·â€‹m^tâ€‹+Î»wtâ€‹â€‹\nÎ»\\lambdaÎ» æ˜¯ AdamW ç®—æ³•ä¸­çš„è¶…å‚æ•°ï¼Œä¸€èˆ¬å– 0.01ã€‚\nm^t\\hat{m}_{t}m^tâ€‹ å’Œv^t\\hat{v}_{t}v^tâ€‹ çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\nm^t=mt1âˆ’Î²1t\\begin {array}{c}\n\\hat{m}_{t}=\\frac{m_{t}}{1-\\beta_{1}^{t}}\n\\end{array}\nm^tâ€‹=1âˆ’Î²1tâ€‹mtâ€‹â€‹â€‹\nv^t=vt1âˆ’Î²2t\\begin {array}{c}\n\\hat{v}_{t}=\\frac{v_{t}}{1-\\beta_{2}^{t}}\n\\end{array}\nv^tâ€‹=1âˆ’Î²2tâ€‹vtâ€‹â€‹â€‹\n# å­¦ä¹ ç‡è¡°å‡æœºåˆ¶\n# ç­‰é—´éš”è¡°å‡\nÎ·t=Î·0(1âˆ’tT)p\\begin {array}{c}\n\\eta_{t}=\\eta_{0}\\left(1-\\frac{t}{T}\\right)^{p}\n\\end{array}\nÎ·tâ€‹=Î·0â€‹(1âˆ’Ttâ€‹)pâ€‹\nÎ·0\\eta_{0}Î·0â€‹ æ˜¯åˆå§‹å­¦ä¹ ç‡ï¼ŒTTT æ˜¯æ€»è¿­ä»£æ¬¡æ•°ï¼Œppp æ˜¯è¡°å‡å› å­ï¼Œä¸€èˆ¬å– 0.5ã€‚\nç­‰é—´éš”è¡°å‡çš„ç¼ºç‚¹æ˜¯ï¼Œå­¦ä¹ ç‡è¡°å‡è¿‡å¿«ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœå˜å·®ã€‚\n# æŒ‡å®šé—´éš”è¡°å‡\nåœ¨æŒ‡å®šçš„ epochï¼Œè®©å­¦ä¹ ç‡æŒ‰ç…§ä¸€å®šçš„ç³»æ•°è¡°å‡ï¼Œç›´åˆ°æŒ‡å®š epoch ç»“æŸï¼Œå†æŒ‰ç…§åˆå§‹å­¦ä¹ ç‡ç»§ç»­è®­ç»ƒã€‚\n# æŒ‡æ•°è¡°å‡\nÎ·t=Î·0Ã—(0.99)t/T\\begin {array}{c}\n\\eta_{t}=\\eta_{0} \\times \\left(0.99\\right)^{t / T}\n\\end{array}\nÎ·tâ€‹=Î·0â€‹Ã—(0.99)t/Tâ€‹\nÎ·0\\eta_{0}Î·0â€‹ æ˜¯åˆå§‹å­¦ä¹ ç‡ï¼ŒTTT æ˜¯æ€»è¿­ä»£æ¬¡æ•°ã€‚\næŒ‡æ•°è¡°å‡çš„ç¼ºç‚¹æ˜¯ï¼Œå­¦ä¹ ç‡è¡°å‡è¿‡æ…¢ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœå˜å·®ã€‚\n# ä½™å¼¦é€€ç«\nÎ·t=Î·0Ã—(0.5(1+cosâ¡(Ï€tT)))\\begin {array}{c}\n\\eta_{t}=\\eta_{0} \\times \\left(0.5\\left(1+\\cos\\left(\\frac{\\pi t}{T}\\right)\\right)\\right)\n\\end{array}\nÎ·tâ€‹=Î·0â€‹Ã—(0.5(1+cos(TÏ€tâ€‹)))â€‹\nÎ·0\\eta_{0}Î·0â€‹ æ˜¯åˆå§‹å­¦ä¹ ç‡ï¼ŒTTT æ˜¯æ€»è¿­ä»£æ¬¡æ•°ã€‚\nä½™å¼¦é€€ç«ç®—æ³•çš„ä¼˜ç‚¹æ˜¯ï¼Œå­¦ä¹ ç‡è¡°å‡é€Ÿåº¦é€‚ä¸­ï¼Œè®­ç»ƒæ•ˆæœè¾ƒå¥½ã€‚\n# åˆå§‹åŒ–\n# He åˆå§‹åŒ–ï¼ˆKaiming åˆå§‹åŒ–ï¼‰\nHe åˆå§‹åŒ–çš„ä¼˜ç‚¹æ˜¯ï¼Œåˆå§‹åŒ–åçš„æƒé‡åˆ†å¸ƒæ›´æ¥è¿‘äºæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œä»è€ŒåŠ é€Ÿè®­ç»ƒã€‚\nimport torch.nn as nnlinear = nn.Linear(5, 2)# Kaiming æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–nn.init.kaiming_normal_(linear.weight)print(linear.weight)# Kaiming å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–nn.init.kaiming_uniform_(linear.weight)print(linear.weight)# æ­£åˆ™åŒ–\næœºå™¨å­¦ä¹ çš„é—®é¢˜ä¸­è¿‡æ‹Ÿåˆæ˜¯ä¸€ä¸ªå¾ˆå¸¸è§çš„é—®é¢˜ã€‚\nè¿‡æ‹ŸåˆæŒ‡çš„æ˜¯èƒ½è¾ƒå¥½æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œä½†ä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆä¸åŒ…å«åœ¨è®­ç»ƒæ•°æ®ä¸­çš„å…¶ä»–æ•°æ®ã€‚æœºå™¨å­¦ä¹ çš„ç›®æ ‡æ˜¯æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå¸Œæœ›å³ä¾¿æ˜¯ä¸åŒ…å«åœ¨è®­ç»ƒæ•°æ®é‡Œçš„æœªè§‚æµ‹æ•°æ®ï¼Œæ¨¡å‹ä¹Ÿå¯ä»¥è¿›è¡Œæ­£ç¡®çš„é¢„æµ‹ã€‚å› æ­¤å¯ä»¥é€šè¿‡\næ­£åˆ™åŒ–æ–¹æ³•æ¥æŠ‘åˆ¶è¿‡æ‹Ÿåˆã€‚\nå¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•æœ‰ Batch Normalizationã€æƒå€¼è¡°å‡ã€Dropoutã€æ—©åœæ³•ç­‰ã€‚\n# Batch Normalization æ‰¹é‡æ ‡å‡†åŒ–\nBatch Normalization\ny=xâˆ’Î¼Ïƒ2+Ïµ\\begin {array}{c}\ny=\\frac{x-\\mu}{\\sqrt{\\sigma^{2}+\\epsilon}}\n\\end{array}\ny=Ïƒ2+Ïµâ€‹xâˆ’Î¼â€‹â€‹\nå…¶ä¸­ï¼ŒÎ¼\\muÎ¼ æ˜¯å‡å€¼ï¼ŒÏƒ2\\sigma^{2}Ïƒ2 æ˜¯æ–¹å·®ï¼ŒÏµ\\epsilonÏµ æ˜¯ä¸€ä¸ªå¾ˆå°çš„æ•°ï¼Œä¸€èˆ¬å– 0.001ã€‚\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","RNN","LSTM"]},{"title":"Harriså…´è¶£ç‚¹æ£€æµ‹","url":"/python/Harris/","content":"# Harris å…´è¶£ç‚¹æ£€æµ‹\n# ä»€ä¹ˆæ˜¯ â€œå…´è¶£ç‚¹â€\nåœ¨ Harris å…´è¶£ç‚¹æ£€æµ‹ä¸­ï¼Œâ€œå…´è¶£ç‚¹â€ é€šå¸¸æŒ‡å›¾åƒä¸­é‚£äº›åœ¨æ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªæ–¹å‘ä¸Šéƒ½å…·æœ‰æ˜¾è‘—ç°åº¦å˜åŒ–çš„åƒç´ ç‚¹ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨å±€éƒ¨çª—å£åœ¨ä»»æ„æ–¹å‘åšå°å¹…å¹³ç§»éƒ½ä¼šå¼•èµ·è¾ƒå¤§åƒç´ å·®å¼‚çš„ç‚¹ã€‚è¿™ç±»ç‚¹å¾€å¾€å¯¹åº”äºå›¾åƒä¸­çš„è§’ç‚¹æˆ–å±€éƒ¨çº¹ç†æ˜¾è‘—çš„åŒºåŸŸï¼Œå› æ­¤è¢«è®¤ä¸ºæ˜¯å…·æœ‰åˆ¤åˆ«æ€§å’Œç¨³å®šæ€§çš„ç‰¹å¾ç‚¹ã€‚\n\nä¸€å¤§ç‰‡å¹³å¦åŒºåŸŸï¼Œæ‰€æœ‰æ–¹å‘éƒ½å˜åŒ–å°ï¼Œä¸æ˜¯å…´è¶£ç‚¹\né«˜æ¥¼é¡¶éƒ¨çš„è½¬è§’å¤„ã€åå­—è·¯å£çš„äº¤å‰ç‚¹ï¼Œåœ¨æ‰€æœ‰æ–¹å‘éƒ½å˜åŒ–å¤§è¿™æ˜¯å…´è¶£ç‚¹\n\n\nè§’ç‚¹ä¼šåœ¨ä¸¤ä¸ªæ–¹å‘åŒæ—¶äº§ç”Ÿå‰§çƒˆå˜åŒ–ï¼Œè¾¹ç•Œåªä¼šåœ¨ä¸€ä¸ªæ–¹å‘ä¸Šäº§ç”Ÿå‰§çƒˆå˜åŒ–ï¼Œå¹³å¦åŒºåˆ™éƒ½ä¸ä¼šã€‚\n# æ•°å­¦åŸç†\n# ä»ä¸Šå¸è§†è§’ç†è§£\nå¦‚ä½•æ£€æµ‹æœ¬è´¨åœ¨äºè®¡ç®—çª—å£æ»‘åŠ¨å‰åï¼Œå…¶åƒç´ çš„å˜åŒ–æƒ…å†µã€‚\n\nå‡è®¾ä¸€ä¸ªçª—å£åŒ…å«å››ä¸ªåƒç´ ï¼Œé‚£ä¹ˆè¿™é‡Œä¼šé‡‡é›†åˆ°è¿™å››ä¸ªå€¼ï¼š\nx1,x2,x3,x4x_1,x_2,x_3,x_4\nx1â€‹,x2â€‹,x3â€‹,x4â€‹\nå†æ¬¡å‡è®¾ï¼Œç™½è‰²éƒ¨åˆ†æ•°å€¼ä¸º 0ï¼Œè“è‰²éƒ¨åˆ†æ•°å€¼ä¸º 1ï¼Œé‚£ä¹ˆæœ‰ï¼š\nx1=0,x2=1,x3=0,x4=1x_1=0,x_2=1,x_3=0,x_4=1\nx1â€‹=0,x2â€‹=1,x3â€‹=0,x4â€‹=1\næ°´å¹³æ–¹å‘ç§»åŠ¨ï¼š\n\næ­¤æ—¶æœ‰ï¼š\nx1=0,x2=0,x3=0,x4=0x_1=0,x_2=0,x_3=0,x_4=0\nx1â€‹=0,x2â€‹=0,x3â€‹=0,x4â€‹=0\næ•°å€¼äº§ç”Ÿå‰§çƒˆå˜åŒ–ã€‚\nå‚ç›´æ–¹å‘ç§»åŠ¨ï¼š\n\n$$\nx_1=0,x_2=1,x_3=0,x_4=1\n$$\næ•°å€¼ä¸å˜ã€‚\nå™¢ï½è¿™æ˜¯è¾¹ç•Œï¼\nå¦‚æœæŠŠè¿™ä¸ªæ”¾åœ¨è“è‰²çŸ©å½¢çš„å·¦ä¸Šè§’å‘¢ï¼Ÿå¯ä»¥å¾ˆè½»æ¾çš„æƒ³è±¡åˆ°ï¼Œæ— è®ºæ˜¯åœ¨æ°´å¹³æ–¹å‘è¿˜æ˜¯å‚ç›´æ–¹å‘ï¼Œæ•°å€¼éƒ½ä¼šäº§ç”Ÿå‰§çƒˆå˜åŒ–ã€‚å™¢ï½è¿™æ˜¯è§’ç‚¹ï¼\nå¦‚æœæŠŠè¿™ä¸ªæ”¾åœ¨è“è‰²çŸ©å½¢çš„ä¸­é—´å‘¢ï¼Ÿå¯ä»¥æ›´å¾ˆè½»æ¾çš„æƒ³è±¡åˆ°ï¼Œæ— è®ºæ˜¯åœ¨æ°´å¹³æ–¹å‘è¿˜æ˜¯å‚ç›´æ–¹å‘ï¼Œæ•°å€¼éƒ½ä¸ä¼šäº§ç”Ÿå‰§çƒˆå˜åŒ–ã€‚å™¢ï½è¿™æ˜¯å¹³å¦åŒºï¼\næˆ‘ä»¬ä¸€çœ‹å°±çŸ¥é“ï¼Œå™¢ï¼Œæ•°å€¼äº§ç”Ÿå‰§çƒˆå˜åŒ–äº†ï¼Œå†æ€è€ƒä¸€ä¸‹æˆ‘ä»¬å°±çŸ¥é“è¿™æ˜¯è§’ç‚¹è¿˜æ˜¯è¾¹ç•Œäº†ï¼Œé‚£æœ‰æ²¡æœ‰ä¸€ç§æ•°å­¦æ–¹æ³•è®©è®¡ç®—æœºä¹ŸçŸ¥é“è¿™æ˜¯è§’ç‚¹è¿˜æ˜¯è¾¹ç•Œäº¦æˆ–æ˜¯å¹³å¦åŒºå‘¢ï¼Ÿ\næœ‰çš„å…„å¼Ÿæœ‰çš„ï¼Œè¿™å°±æ˜¯ Harris å…´è¶£ç‚¹æ£€æµ‹æ³•ã€‚\n# Harris æ£€æµ‹æ–¹æ³•\nå¯¹äºå›¾åƒI(x,y)I(x,y)I(x,y)ï¼Œæˆ‘ä»¬å¯ä»¥åˆ¤æ–­åœ¨ç‚¹(x,y)(x,y)(x,y) å¤„å¹³ç§»(Î”x,Î”y)(\\Delta x,\\Delta y)(Î”x,Î”y) åçš„è‡ªç›¸ä¼¼æ€§ã€‚æ­¤å¤„I(x,y)I(x,y)I(x,y) æ˜¯ä¸€ä¸ªç°åº¦å›¾åƒã€‚\næœ‰è‡ªç›¸ä¼¼æ€§å…¬å¼ï¼š\nc(x,y,Î”x,Î”y)=âˆ‘(u,v)âˆˆW(x,y)W(u,v)(I(u,v)âˆ’I(u+Î”x,v+Î”y))2c(x,y,\\Delta x,\\Delta y)=\\sum_{(u,v)\\in W(x,y)}W(u,v)(I(u,v)-I(u+\\Delta x,v+\\Delta y))^2\nc(x,y,Î”x,Î”y)=(u,v)âˆˆW(x,y)âˆ‘â€‹W(u,v)(I(u,v)âˆ’I(u+Î”x,v+Î”y))2\nå…¶ä¸­I(u,v)I(u,v)I(u,v) æ˜¯åŸæ¥çš„ç°åº¦å€¼ï¼ŒI(u+Î”x,v+Î”y)I(u+\\Delta x,v+\\Delta y)I(u+Î”x,v+Î”y) æ˜¯ç»è¿‡å¹³ç§»å˜æ¢åçš„ç°åº¦å€¼ï¼Œåšå‡æ³•æ˜¯ä¸ºäº†çœ‹çœ‹å¹³ç§»æ“ä½œåå…¶ä¸ä¹‹å‰çš„å·®å¼‚æ˜¯å¤šå¤§çš„ï¼Œæœ‰æ—¶å€™æˆ‘ä»¬çš„ç°åº¦å˜åŒ–æ˜¯ä¸Šå‡çš„ï¼Œè€Œæœ‰æ—¶å€™æˆ‘ä»¬çš„ç°åº¦å˜åŒ–æ˜¯ä¸‹é™çš„ï¼Œæˆ‘ä»¬åªå…³å¿ƒä»–å˜åŒ–äº†å¤šå°‘ï¼Œå› æ­¤è¿™é‡Œåšäº†å¹³æ–¹æ“ä½œï¼Œç»è¿‡å¹³æ–¹åä¸ä»…åŒ–è´Ÿä¸ºæ­£ï¼Œè¿˜è¿›ä¸€æ­¥å¼ºåŒ–äº†å‰åçš„å·®å¼‚ã€‚\nè€ŒW(u,v)W(u,v)W(u,v) æ˜¯ä¸€ä¸ªæƒé‡è®¾è®¡ï¼Œåœ¨æ•´ä¸ªçª—å£ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰å¿…è¦å¹³ç­‰çš„çœ‹å¾…æ¯ä¸€ä¸ªåƒç´ ï¼ˆpsï¼šå½“ç„¶ä¹Ÿå¯ä»¥å¹³ç­‰çš„çœ‹å¾…ï¼Œæ­¤æ—¶W(u,v)W(u,v)W(u,v) æ¯ä¸€é¡¹å‡ä¸ºåŒä¸€å¸¸æ•°ï¼‰ï¼Œé€šå¸¸æˆ‘ä»¬ä½¿ç”¨é«˜æ–¯åŠ æƒå‡½æ•°ï¼Œåœ¨å›¾åƒä¸Šï¼Œæœ€å¸¸ç”¨çš„æ˜¯äºŒç»´ç‰ˆæœ¬ï¼š\nw(x,y)=12Ï€Ïƒ2expâ¡(âˆ’x2+y22Ïƒ2)w(x, y) = \\frac{1}{2\\pi \\sigma^2} \\exp\\left(-\\frac{x^2 + y^2}{2\\sigma^2}\\right)\nw(x,y)=2Ï€Ïƒ21â€‹exp(âˆ’2Ïƒ2x2+y2â€‹)\nå…¶ä¸­(x,y)(x, y)(x,y)ï¼šç›¸å¯¹äºçª—å£ä¸­å¿ƒçš„åæ ‡ï¼ŒÏƒ\\sigmaÏƒ æ§åˆ¶æ¨¡ç³Šç¨‹åº¦æˆ–è€…è¯´æ˜¯å½±å“èŒƒå›´ï¼ŒäºŒç»´æƒé‡çš„ä¸‰ç»´è¡¨ç¤ºå¦‚å›¾æ‰€ç¤ºï¼š\n\nåƒå›¾ä¸­è¡¨ç¤ºçš„ä¸€æ ·ï¼Œä»–å°†ä¼šæ›´åŠ é‡è§†çª—å£ä¸­å¿ƒçš„å…ƒç´ ï¼Œä¸€ä¸ª3Ã—33\\times 33Ã—3 çš„é«˜æ–¯çŸ©é˜µå½¢å¦‚ï¼š\n[121242121]\\begin{bmatrix}\n 1 &amp; 2 &amp; 1\\\\\n 2 &amp; 4 &amp; 2\\\\\n 1 &amp; 2 &amp; 1\n\\end{bmatrix}\nâ£â¢â¡â€‹121â€‹242â€‹121â€‹â¦â¥â¤â€‹\nå¯¹I(u+Î”x,v+Î”y)I(u+\\Delta x,v+\\Delta y)I(u+Î”x,v+Î”y) è¿›è¡Œæ³°å‹’å±•å¼€ï¼š\nI(u+Î”x,v+Î”y)=I(u,v)+Ix(u,v)Î”x+Iy(u,v)Î”y+O(Î”x2,Î”y2)I(u+\\Delta x,v+\\Delta y)=I(u,v)+I_x(u,v)\\Delta x+I_y(u,v)\\Delta y+O(\\Delta x^2,\\Delta y^2)\nI(u+Î”x,v+Î”y)=I(u,v)+Ixâ€‹(u,v)Î”x+Iyâ€‹(u,v)Î”y+O(Î”x2,Î”y2)\nå¦‚æ­¤å±•å¼€åˆ°ä¸€é˜¶å°±å¤Ÿç”¨äº†ï¼Œä¸¢å¼ƒé«˜é˜¶æ— ç©·å°åï¼ŒåŸå¼è¿‘ä¼¼ç­‰äºï¼š\nI(u+Î”x,v+Î”y)â‰ˆI(u,v)+Ix(u,v)Î”x+Iy(u,v)Î”yI(u+\\Delta x,v+\\Delta y)\\approx I(u,v)+I_x(u,v)\\Delta x+I_y(u,v)\\Delta y\nI(u+Î”x,v+Î”y)â‰ˆI(u,v)+Ixâ€‹(u,v)Î”x+Iyâ€‹(u,v)Î”y\nå…¶ä¸­IxI_xIxâ€‹ è¡¨ç¤ºå…¶å¯¹xxx çš„åå¯¼ï¼Œå…¶ä¸­IyI_yIyâ€‹ è¡¨ç¤ºå…¶å¯¹yyy çš„åå¯¼ã€‚\nå¯¹äºåŸå¼I(u,v)âˆ’I(u+Î”x,v+Î”y)I(u,v)-I(u+\\Delta x,v+\\Delta y)I(u,v)âˆ’I(u+Î”x,v+Î”y) æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œå…¶åŒ…å«äº†I(u,v)I(u,v)I(u,v)ï¼Œå› æ­¤å¯ä»¥ç›´æ¥è¢«æ¶ˆæ‰ï¼Œäºæ˜¯æˆ‘ä»¬é‡å†™c(x,y,Î”x,Î”y)c(x,y,\\Delta x,\\Delta y)c(x,y,Î”x,Î”y)ï¼Œè¿‘ä¼¼å¾—åˆ°ï¼š\nc(x,y,Î”x,Î”y)â‰ˆâˆ‘(u,v)âˆˆW(x,y)W(u,v)(Ix(u,v)Î”x+Iy(u,v)Î”y)2c(x,y,\\Delta x,\\Delta y)\\approx \\sum_{(u,v)\\in W(x,y)}W(u,v)(I_x(u,v)\\Delta x+I_y(u,v)\\Delta y)^2\nc(x,y,Î”x,Î”y)â‰ˆ(u,v)âˆˆW(x,y)âˆ‘â€‹W(u,v)(Ixâ€‹(u,v)Î”x+Iyâ€‹(u,v)Î”y)2\nç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†âˆ‘(u,v)âˆˆW(x,y)W(u,v)\\sum_{(u,v)\\in W(x,y)}W(u,v)âˆ‘(u,v)âˆˆW(x,y)â€‹W(u,v)ï¼Œæ”¶ç¼©è‡³æ±‚å’Œç¬¦å·ä¸­è®°ä½œï¼š\\sum_\nè¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠä¸Šå¼æ”¹å†™æˆçŸ©é˜µçš„å½¢å¼ï¼Œè®¾çŸ©é˜µM(x,y)M(x,y)M(x,y) ä¸ºï¼š\nM(x,y)=âˆ‘w[Ix(x,y)2Ix(x,y)Iy(x,y)Ix(x,y)Iy(x,y)Iy(x,y)2]=[âˆ‘wIx(x,y)2âˆ‘wIx(x,y)Iy(x,y)âˆ‘wIx(x,y)Iy(x,y)âˆ‘wIy(x,y)2]M(x,y)=\\sum_{w}\\begin{bmatrix}\n I_x(x,y)^2 &amp; I_x(x,y)I_y(x,y)\\\\\n I_x(x,y)I_y(x,y) &amp; I_y(x,y)^2\n\\end{bmatrix}=\\begin{bmatrix}\n\\sum_{w} I_x(x,y)^2 &amp; \\sum_{w} I_x(x,y)I_y(x,y)\\\\\n\\sum_{w} I_x(x,y)I_y(x,y) &amp;\\sum_{w} I_y(x,y)^2\n\\end{bmatrix}\nM(x,y)=wâˆ‘â€‹[Ixâ€‹(x,y)2Ixâ€‹(x,y)Iyâ€‹(x,y)â€‹Ixâ€‹(x,y)Iyâ€‹(x,y)Iyâ€‹(x,y)2â€‹]=[âˆ‘wâ€‹Ixâ€‹(x,y)2âˆ‘wâ€‹Ixâ€‹(x,y)Iyâ€‹(x,y)â€‹âˆ‘wâ€‹Ixâ€‹(x,y)Iyâ€‹(x,y)âˆ‘wâ€‹Iyâ€‹(x,y)2â€‹]\nè§‚å¯Ÿåˆ°çŸ©é˜µçš„å‰¯å¯¹è§’çº¿å®Œå…¨ä¸€æ ·ï¼Œä¸ºè¿›ä¸€æ­¥ç®€åŒ–M(x,y)M(x,y)M(x,y)ï¼Œè®¾A=Ix(x,y)2A=I_x(x,y)^2A=Ixâ€‹(x,y)2ã€B=Ix(x,y)2B=I_x(x,y)^2B=Ixâ€‹(x,y)2ã€C=Ix(x,y)Iy(x,y)C=I_x(x,y)I_y(x,y)C=Ixâ€‹(x,y)Iyâ€‹(x,y)ï¼Œäºæ˜¯å¾—åˆ°ï¼š\nM(x,y)=[ACCB]M(x,y)=\\begin{bmatrix}\nA &amp; C\\\\\nC &amp; B\n\\end{bmatrix}\nM(x,y)=[ACâ€‹CBâ€‹]\næ˜¾ç„¶ï¼ŒM(x,y)M(x,y)M(x,y) æ˜¯ä¸€ä¸ªå¯¹ç§°é˜µï¼Œå› æ­¤å¾—åˆ°ï¼š\nc(x,y,Î”x,Î”y)â‰ˆ[Î”x,Î”y]M(x,y)[Î”xÎ”y]=[Î”x,Î”y][ACCB][Î”xÎ”y]c(x,y,\\Delta x,\\Delta y)\\approx \\begin{bmatrix}\n\\Delta x, \n\\Delta y \n\\end{bmatrix}M(x,y)\\begin{bmatrix}\n\\Delta x \\\\\n\\Delta y \n\\end{bmatrix}=\\begin{bmatrix}\n\\Delta x, \n\\Delta y \n\\end{bmatrix}\\begin{bmatrix}\nA &amp; C\\\\\nC &amp; B\n\\end{bmatrix}\\begin{bmatrix}\n\\Delta x \\\\\n\\Delta y \n\\end{bmatrix}\nc(x,y,Î”x,Î”y)â‰ˆ[Î”x,Î”yâ€‹]M(x,y)[Î”xÎ”yâ€‹]=[Î”x,Î”yâ€‹][ACâ€‹CBâ€‹][Î”xÎ”yâ€‹]\nåŒ–ç®€å¯å¾—ï¼š\nc(x,y,Î”x,Î”y)â‰ˆAÎ”x2+2CÎ”xÎ”y+BÎ”y2c(x,y,\\Delta x,\\Delta y)\\approx A\\Delta x^2+2C\\Delta x\\Delta y+B\\Delta y^2\nc(x,y,Î”x,Î”y)â‰ˆAÎ”x2+2CÎ”xÎ”y+BÎ”y2\nå…¶ä¸­A=âˆ‘wIx2A=\\sum_{w}I_x^2A=âˆ‘wâ€‹Ix2â€‹ï¼ŒB=âˆ‘wIy2B=\\sum_{w}I_y^2B=âˆ‘wâ€‹Iy2â€‹ï¼ŒC=âˆ‘wIxIyC=\\sum_{w}I_x I_yC=âˆ‘wâ€‹Ixâ€‹Iyâ€‹ã€‚\nè¿™é‡Œçš„AÎ”x2+2CÎ”xÎ”y+BÎ”y2A\\Delta x^2+2C\\Delta x\\Delta y+B\\Delta y^2AÎ”x2+2CÎ”xÎ”y+BÎ”y2ï¼Œéå¸¸åƒæ¤­åœ†æ–¹ç¨‹ï¼Œå›å¿†æ¤­åœ†ä¸€èˆ¬äºŒæ¬¡å‹ï¼šAx2+Bxy+Cy2+Dx+Ey+F=0Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0Ax2+Bxy+Cy2+Dx+Ey+F=0ï¼Œå‡ºç°äº¤å‰é¡¹æ—¶ï¼Œå…¶å˜ä¸ºéæ ‡å‡†å½¢ï¼Œå½¢å¦‚ï¼š\n\næˆ‘ä»¬éœ€è¦æŠŠæ•´ä¸ªéæ ‡å‡†æ¤­åœ†åšæ ‡å‡†åŒ–å˜æ¢ã€‚\nä¸ºä»€ä¹ˆAÎ”x2+2CÎ”xÎ”y+BÎ”y2A\\Delta x^2+2C\\Delta x\\Delta y+B\\Delta y^2AÎ”x2+2CÎ”xÎ”y+BÎ”y2 å¹¶ä¸æ ‡å‡†ï¼Œå› ä¸ºè¿™é‡Œå­˜åœ¨äº¤å‰é¡¹2CÎ”xÎ”y2C\\Delta x\\Delta y2CÎ”xÎ”yï¼Œå¦‚æœè¿™ä¸€é¡¹èƒ½è¢«æ¶ˆæ‰é‚£å°±å˜æˆæ ‡å‡†çš„äº†ï¼Œæœ€ç›´æ¥çš„æ–¹æ³•å°±æ˜¯è®©CCC ç­‰äº000ï¼Œæ­¤å¤„çš„CCC æ˜¯ç”±M(x,y)M(x,y)M(x,y) äº§ç”Ÿçš„ï¼Œè§‚å¯Ÿåˆ°MMM çŸ©é˜µæ˜¯ä¸€ä¸ªå®å¯¹ç§°çŸ©é˜µï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥å¯¹MMM è¿›è¡Œç›¸ä¼¼å¯¹è§’åŒ–ï¼Œæ¶ˆæ‰CCCï¼Œå˜æ ‡å‡†æ¤­åœ†ã€‚\n\nä¸‹é¢å‡è®¾å·²ç»å®Œæˆäº†å¯¹çŸ©é˜µMMM çš„å½¢ä¼¼å¯¹è§’åŒ–ï¼š\nPâˆ’1MPâˆ¼[Î»1Î»2]P^{-1}MP\\sim  \\begin{bmatrix}\n\\lambda _1&amp; \\\\\n &amp; \\lambda _2\n\\end{bmatrix}\nPâˆ’1MPâˆ¼[Î»1â€‹â€‹Î»2â€‹â€‹]\nå…¶ä¸­ï¼ŒÎ»1\\lambda _1Î»1â€‹ï¼ŒÎ»2\\lambda _2Î»2â€‹ï¼Œæ˜¯çŸ©é˜µMMM çš„ç‰¹å¾å€¼ï¼Œå› æ­¤å¯è¿›ä¸€æ­¥å†™åšï¼š\nc(x,y,Î”x,Î”y)â‰ˆ[Î”x,Î”y][ACCB][Î”xÎ”y]â‰ˆ[Î”xâ€²,Î”yâ€²][Î»1Î»2][Î”xâ€²Î”yâ€²]=Î»1(Î”xâ€²)2+Î»2(Î”yâ€²)2c(x,y,\\Delta x,\\Delta y)\\approx\\begin{bmatrix}\n\\Delta x, \n\\Delta y \n\\end{bmatrix}\\begin{bmatrix}\nA &amp; C\\\\\nC &amp; B\n\\end{bmatrix}\\begin{bmatrix}\n\\Delta x \\\\\n\\Delta y \n\\end{bmatrix}\\approx\n\\begin{bmatrix}\n\\Delta x&#x27; , \n\\Delta y&#x27; \n\\end{bmatrix}\n\n\\begin{bmatrix}\n\\lambda _1&amp; \\\\\n &amp; \\lambda _2\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Delta x&#x27; \\\\\n\\Delta y&#x27;\n\\end{bmatrix}=\\lambda_1 (\\Delta x&#x27;)^2 + \\lambda_2 (\\Delta y&#x27;)^2\nc(x,y,Î”x,Î”y)â‰ˆ[Î”x,Î”yâ€‹][ACâ€‹CBâ€‹][Î”xÎ”yâ€‹]â‰ˆ[Î”xâ€²,Î”yâ€²â€‹][Î»1â€‹â€‹Î»2â€‹â€‹][Î”xâ€²Î”yâ€²â€‹]=Î»1â€‹(Î”xâ€²)2+Î»2â€‹(Î”yâ€²)2\näºæ˜¯æˆ‘ä»¬å¯ä»¥ç”¨Î»1,Î»2\\lambda_1,\\lambda_2Î»1â€‹,Î»2â€‹ çš„å¤§å°å…³ç³»åŒºåˆ†å¹³å¦ã€è¾¹ç¼˜äº¦æˆ–æ˜¯è§’ç‚¹ã€‚ç›¸ä¼¼å¯¹è§’åŒ–ä¸æ˜¯ä¸ºäº†æ–¹ä¾¿è®¡ç®—ï¼Œè€Œæ˜¯ä¸ºäº†æ–¹ä¾¿ç†è§£ ä¸åˆ†ç±»ï¼Œå®é™…å®ç° Harris çš„æ—¶å€™ï¼ŒåŸºæœ¬ä¸ä¼šæ˜¾å¼å»ç®—ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡ï¼Œå¯¹è§’åŒ–æ˜¯ä¸ºäº†çœ‹æ¸…Î»1,Î»2\\lambda_1,\\lambda_2Î»1â€‹,Î»2â€‹ çš„å‡ ä½•æ„ä¹‰ã€‚\nåƒè¿™æ ·çš„Î»1(Î”xâ€²)2+Î»2(Î”yâ€²)2\\lambda_1 (\\Delta x&#x27;)^2 + \\lambda_2 (\\Delta y&#x27;)^2Î»1â€‹(Î”xâ€²)2+Î»2â€‹(Î”yâ€²)2ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒæ”¹å˜ä¸€ä¸‹ï¼Œè®©å…¶ä¸æ ‡å‡†å¼å¯¹é½ï¼Œå¾—åˆ°ï¼š\nÎ”xâ€²2(1Î»1)2+Î”yâ€²2(1Î»2)2\\frac{\\Delta x&#x27;^2}{(\\sqrt{\\frac{1}{\\lambda _1} } )^2} +\\frac{\\Delta y&#x27;^2}{(\\sqrt{\\frac{1}{\\lambda _2} } )^2}\n(Î»1â€‹1â€‹â€‹)2Î”xâ€²2â€‹+(Î»2â€‹1â€‹â€‹)2Î”yâ€²2â€‹\nå¤ªå¤æ‚äº†ï¼Œç®€å•ç‚¹å†™åšï¼š\nÎ”xâ€²2(Î»1âˆ’12)2+Î”yâ€²2(Î»2âˆ’12)2\\frac{\\Delta x&#x27;^2}{(\\lambda_1^{-\\frac{1}{2} })^2} +\\frac{\\Delta y&#x27;^2}{(\\lambda_2^{-\\frac{1}{2} })^2}\n(Î»1âˆ’21â€‹â€‹)2Î”xâ€²2â€‹+(Î»2âˆ’21â€‹â€‹)2Î”yâ€²2â€‹\n\nç°åœ¨æœ‰ä¸‰ç§æƒ…å†µï¼š\n\nå¹³å¦åŒºåŸŸï¼šÎ»1â‰ˆ0,Â Î»2â‰ˆ0\\lambda_1 \\approx 0,\\ \\lambda_2 \\approx 0Î»1â€‹â‰ˆ0,Â Î»2â€‹â‰ˆ0ï¼ˆä¸¤ä¸ªéƒ½å¾ˆå°ï¼‰\nè¾¹ç¼˜åŒºåŸŸï¼šÎ»1â‰«0,Â Î»2â‰ˆ0\\lambda_1 \\gg 0,\\ \\lambda_2 \\approx 0Î»1â€‹â‰«0,Â Î»2â€‹â‰ˆ0 æˆ–è€…Î»2â‰«0,Â Î»1â‰ˆ0\\lambda_2 \\gg 0,\\ \\lambda_1 \\approx 0Î»2â€‹â‰«0,Â Î»1â€‹â‰ˆ0ï¼ˆä¸€å¤§ä¸€å°ï¼‰\nè§’ç‚¹ï¼šÎ»1â‰«0,Â Î»2â‰«0\\lambda_1 \\gg 0,\\ \\lambda_2 \\gg 0Î»1â€‹â‰«0,Â Î»2â€‹â‰«0ï¼ˆä¸¤ä¸ªéƒ½å¾ˆå¤§ï¼‰\n\nç„¶åï¼Œä½¿ç”¨detâ¡(M)\\det(M)det(M) å’Œtrace(M)\\text{trace}(M)trace(M) æ„é€ è§’ç‚¹å“åº”RRR å€¼ï¼š\nR=detâ¡(M)âˆ’kâ‹…trace2(M)R = \\det(M) - k \\cdot \\text{trace}^2(M)\nR=det(M)âˆ’kâ‹…trace2(M)\nå…¶ä¸­detâ¡(M)\\det(M)det(M) æ˜¯çŸ©é˜µMMM çš„è¡Œåˆ—å¼ï¼Œtrace(M)\\text{trace}(M)trace(M) æ˜¯çŸ©é˜µMMM çš„è¿¹ï¼Œdetâ¡(M)=Î»1Î»2\\det(M) = \\lambda_1\\lambda_2det(M)=Î»1â€‹Î»2â€‹ï¼Œtrace(M)=Î»1+Î»2\\text{trace}(M) = \\lambda_1 + \\lambda_2trace(M)=Î»1â€‹+Î»2â€‹ï¼Œè¿™å°±æ˜¯ Harris è®¾è®¡å‡ºæ¥çš„ä¸€ä¸ªè§’ç‚¹è¯„åˆ†å…¬å¼ã€‚\nè¿›ä¸€æ­¥é‡è¿°ä¸Šè¿°ä¸‰ç§æƒ…å†µï¼š\n\nå¹³å¦åŒºåŸŸï¼šÎ»1â‰ˆ0,Â Î»2â‰ˆ0\\lambda_1 \\approx 0,\\ \\lambda_2 \\approx 0Î»1â€‹â‰ˆ0,Â Î»2â€‹â‰ˆ0ï¼ˆä¸¤ä¸ªéƒ½å¾ˆå°ï¼‰ï¼Œdetâ¡=Î»1Î»2â‰ˆ0\\det = \\lambda_1\\lambda_2 \\approx 0det=Î»1â€‹Î»2â€‹â‰ˆ0ï¼Œtrace2â‰ˆ0â‡’(Râ‰ˆ0)\\text{trace}^2 \\approx 0 â‡’ (R \\approx 0)trace2â‰ˆ0â‡’(Râ‰ˆ0)\nè¾¹ç¼˜åŒºåŸŸï¼šÎ»1â‰«0,Â Î»2â‰ˆ0\\lambda_1 \\gg 0,\\ \\lambda_2 \\approx 0Î»1â€‹â‰«0,Â Î»2â€‹â‰ˆ0 æˆ–è€…Î»2â‰«0,Â Î»1â‰ˆ0\\lambda_2 \\gg 0,\\ \\lambda_1 \\approx 0Î»2â€‹â‰«0,Â Î»1â€‹â‰ˆ0ï¼ˆä¸€å¤§ä¸€å°ï¼‰ï¼Œdetâ¡=Î»1Î»2\\det = \\lambda_1\\lambda_2det=Î»1â€‹Î»2â€‹ ä¸ç®—å¤§ï¼Œtrace2=(Î»1+Î»2)2â‰ˆÎ»12\\text{trace}^2 = (\\lambda_1+\\lambda_2)^2 \\approx \\lambda_1^2trace2=(Î»1â€‹+Î»2â€‹)2â‰ˆÎ»12â€‹ å¾ˆå¤§ï¼Œ$â‡’ R $ å¾€å¾€æ˜¯è´Ÿçš„ï¼ˆè¿™é‡Œ Harris æ•…æ„ç”¨ $-k \\cdot \\text {trace}^2 $ æŠŠè¾¹ç¼˜å‹ä¸‹å»ï¼‰\nè§’ç‚¹ï¼šÎ»1â‰«0,Â Î»2â‰«0\\lambda_1 \\gg 0,\\ \\lambda_2 \\gg 0Î»1â€‹â‰«0,Â Î»2â€‹â‰«0ï¼ˆä¸¤ä¸ªéƒ½å¾ˆå¤§ï¼‰ï¼Œdetâ¡=Î»1Î»2\\det = \\lambda_1\\lambda_2det=Î»1â€‹Î»2â€‹ å¾ˆå¤§ï¼Œå³ä¾¿å‡å»äº†k(Î»1+Î»2)2k(\\lambda_1+\\lambda_2)^2k(Î»1â€‹+Î»2â€‹)2ï¼Œä½†æ•´ä½“è¿˜æ˜¯ä¼šæ˜¯ä¸ªæ¯”è¾ƒå¤§çš„æ­£æ•°\n\n\nç»¼ä¸Šæ‰€è¿°ï¼ŒRRR æœ‰å¦‚ä¸‹ç‰¹æ€§ï¼š\n\nRâ‰ˆ0R \\approx 0Râ‰ˆ0 â‡’ å¹³å¦åŒº\nR&lt;0R &lt; 0R&lt;0 â‡’ æ›´åƒè¾¹ç¼˜\nRâ‰«0R \\gg 0Râ‰«0 â‡’ å¾ˆåƒè§’ç‚¹ï¼ˆå…´è¶£ç‚¹ï¼‰\n\ndetâ¡(M)\\det(M)det(M) å¤§ï¼Œå°±è¯´æ˜ä¸¤ä¸ªæ–¹å‘ä¸Šå˜åŒ–éƒ½å¤§ï¼Œtrace(M)2\\text{trace}(M)^2trace(M)2 å¤§ï¼Œå¯èƒ½åªæ˜¯æœ‰ä¸€ä¸ªæ–¹å‘ç‰¹åˆ«å¤§ï¼Œæ¯”å¦‚è¾¹ç¼˜ï¼ŒR=detâ¡âˆ’kâ‹…trace2R = \\det - k \\cdot \\text{trace}^2R=detâˆ’kâ‹…trace2ï¼Œç”¨ detâ¡\\detdet å¥–åŠ±ä¸¤ä¸ªæ–¹å‘éƒ½å¤§çš„æƒ…å†µï¼Œç”¨ âˆ’ktrace2-k\\text{trace}^2âˆ’ktrace2 æƒ©ç½šåªæœ‰ä¸€ä¸ªæ–¹å‘å¤§ã€å¦ä¸€ä¸ªæ–¹å‘å°çš„æƒ…å†µã€‚\n# åœ¨ OpenCV ä¸­çš„ä½¿ç”¨\nimport cv2img = cv2.imread('1.jpg')gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)dst = cv2.cornerHarris(gray, 2, 3, 0.04)img[dst > 0.1 * dst.max()]=[0, 0, 255]cv2.imshow('dst', img)cv2.imwrite('1_corner.png', img)cv2.waitKey(0)cv2.destroyAllWindows()\nblockSize=2 æ˜¯çª—å£å¤§å°\nksize =3 æ˜¯ Sobel æ±‚å¯¼ç®—å­æ ¸å¤§å°ï¼ŒHarris éœ€è¦å…ˆç®—å›¾åƒåœ¨ xï¼Œy æ–¹å‘çš„æ¢¯åº¦ Ix,IyI_x, I_yIxâ€‹,Iyâ€‹ï¼ŒOpenCV ç”¨çš„æ˜¯ Sobel ç®—å­ã€‚\nk = 0.04 æ˜¯ Harris å…¬å¼é‡Œçš„ç»éªŒå‚æ•° kï¼ŒR=detâ¡(M)âˆ’kâ‹…trace2(M)R = \\det(M) - k \\cdot \\text{trace}^2(M)R=det(M)âˆ’kâ‹…trace2(M)\n\n# å¯¹æ¯”\n# ç®€å•åœºæ™¯\n\n\n# å¤æ‚åœºæ™¯\n\n# å‚è€ƒ\n[1]  Harris C G, Stephens M. A combined corner and edge detector[C] Alvey vision conference. 1988, 15(50): 10-5244.\n[2]  Harris è§’ç‚¹æ£€æµ‹ä¸ SIFT ç‰¹å¾åŒ¹é…å…¨è§£æ https://www.bilibili.com/video/BV1Zi1eYLEiR\n[3]  Harris Corner Detection https://docs.opencv.org/4.x/dc/d0d/tutorial_py_features_harris.html\n[4]  Harris corner detector https://en.wikipedia.org/wiki/Harris_corner_detector?utm_source=chatgpt.com\n","categories":["å›¾åƒå¤„ç†"],"tags":["python","Harris"]},{"title":"NLPè‡ªç„¶è¯­è¨€å¤„ç†","url":"/python/NLP/","content":"# NLP è‡ªç„¶è¯­è¨€å¤„ç†\n\nå­¦ä¹ ç¬”è®°\n\n# å¸¸è§ä»»åŠ¡\n\næ–‡æœ¬åˆ†ç±»ï¼šæƒ…æ„Ÿåˆ†æï¼ˆç§¯æ / æ¶ˆæï¼‰ã€åƒåœ¾é‚®ä»¶è¯†åˆ«ã€æ–°é—»ä¸»é¢˜åˆ†ç±»ã€å¥å­çº§åˆ«ã€‘\nåºåˆ—æ ‡æ³¨ï¼šå‘½åå®ä½“è¯†åˆ«ï¼ˆæ‰¾äººåã€åœ°åã€æ‰‹æœºå·ï¼‰ã€æ–‡æœ¬ç”Ÿæˆã€ä¿¡æ¯æŠ½å–ã€æ–‡æœ¬è½¬åŒ–ã€Token çº§åˆ«ã€‘\n\n# æ–‡æœ¬è¡¨ç¤º\n# åˆ†è¯\n\nè¯çº§åˆ†è¯ï¼šå°†æ–‡æœ¬æŒ‰ç…§è¯åˆ‡åˆ†åœ¨è‹±è¯­ä¸­ç©ºæ ¼å¾€å¾€æ˜¯å¤©ç„¶çš„åˆ‡è¯æ ‡å¿—ï¼Œä½†æ˜¯å®¹æ˜“å‡ºç° OOV é—®é¢˜ï¼ˆæœªç™»å½•è¯é—®é¢˜ï¼‰\nå­—ç¬¦çº§åˆ†è¯ï¼šä¸€ä¸ªå­—æ¯ã€æ•°å­—ã€æ ‡ç‚¹ç”šè‡³ç©ºæ ¼ï¼Œéƒ½ä¼šè¢«è§†ä½œä¸€ä¸ªç‹¬ç«‹çš„ tokenï¼Œä¸ä¼šæœ‰ OOV é—®é¢˜ï¼Œä½†æ¨¡å‹å¿…é¡»ä¾èµ–æ›´é•¿çš„ä¸Šä¸‹æ–‡æ¥æ¨æ–­è¯ä¹‰å’Œç»“æ„ï¼Œè¿™æ˜¾è‘—å¢åŠ äº†å»ºæ¨¡éš¾åº¦å’Œè®­ç»ƒæˆæœ¬ã€‚\nå­è¯çº§åˆ†è¯ï¼šå°†è¯è¯­åˆ‡åˆ†ä¸ºæ›´å°çš„å•å…ƒ â€”â€” å­è¯ï¼ˆsubwordï¼‰ï¼Œä¾‹å¦‚è¯æ ¹ã€å‰ç¼€ã€åç¼€æˆ–å¸¸è§è¯ç‰‡æ®µã€‚\n\nä»¥ä¸Šæ˜¯è‹±æ–‡é€‚ç”¨çš„åˆ†è¯æ–¹æ³•ï¼Œä¸‹é¢æ˜¯ä¸­æ–‡é€‚ç”¨çš„åˆ†è¯æ–¹æ³•ã€‚\n\nå­—ç¬¦çº§åˆ†è¯ï¼šä¸€ä¸ªå­—å°±è¿›è¡Œä¸€æ¬¡åˆ‡åˆ†ï¼Œæ¯”è‹±æ–‡ä¸­çš„å­—ç¬¦åˆ†è¯ï¼Œä¸­æ–‡çš„å­—ç¬¦åˆ†è¯æ›´åŠ  â€œè¯­ä¹‰å‹å¥½â€ã€‚\nè¯çº§åˆ†è¯ï¼šç”±äºä¸­æ–‡æ²¡æœ‰ç©ºæ ¼ç­‰å¤©ç„¶è¯è¾¹ç•Œï¼Œè¯çº§åˆ†è¯é€šå¸¸ä¾èµ–è¯å…¸ã€è§„åˆ™æˆ–æ¨¡å‹æ¥è¯†åˆ«è¯è¯­è¾¹ç•Œã€‚\nå­è¯çº§åˆ†è¯ï¼šå®ƒä»¬ä»¥æ±‰å­—ä¸ºåŸºæœ¬å•ä½ï¼Œé€šè¿‡å­¦ä¹ è¯­æ–™ä¸­é«˜é¢‘çš„å­—ç»„åˆï¼ˆå¦‚ â€œè‡ªç„¶â€ã€â€œè¯­è¨€â€ã€â€œå¤„ç†â€ï¼‰ï¼Œè‡ªåŠ¨æ„å»ºå­è¯è¯è¡¨ã€‚åœ¨å½“å‰ä¸»æµçš„ä¸­æ–‡å¤§æ¨¡å‹ï¼ˆå¦‚é€šä¹‰åƒé—®ã€DeepSeekï¼‰ä¸­ï¼Œå­è¯åˆ†è¯å·²æˆä¸ºå¹¿æ³›é‡‡ç”¨çš„æ–‡æœ¬åˆ‡åˆ†ç­–ç•¥ã€‚\n\n# JiebBa åˆ†è¯ç»„ä»¶\nword_gen = jieba.cut(\"æˆ‘çš„åå­—å«Karryï¼Œæ¥è‡ªè®¡ç®—æœºç§‘å­¦æŠ€æœ¯å­¦é™¢\")for word in word_gen:    print(word)\næˆ‘\nçš„\nåå­—\nå«\n Karry\nï¼Œ\næ¥è‡ª\nè®¡ç®—æœº\nç§‘å­¦æŠ€æœ¯\nå­¦é™¢\n\n# è¯è¡¨ç¤º\n\nOne-hot ç¼–ç ï¼ˆç‹¬çƒ­ç¼–ç ï¼‰ï¼šå®ƒå°†è¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªè¯æ˜ å°„ä¸ºä¸€ä¸ªç¨€ç–å‘é‡ï¼Œå‘é‡çš„é•¿åº¦ç­‰äºæ•´ä¸ªè¯è¡¨çš„å¤§å°ã€‚è¯¥è¯åœ¨å¯¹åº”çš„ä½ç½®ä¸º 1ï¼Œå…¶ä»–ä½ç½®ä¸º 0ã€‚åœ¨å®é™…è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œone-hot è¡¨ç¤ºå·²ç»å¾ˆå°‘è¢«ç›´æ¥ä½¿ç”¨ã€‚\nè¯­ä¹‰åŒ–è¯å‘é‡ï¼šå®ƒé€šè¿‡å¯¹å¤§è§„æ¨¡è¯­æ–™çš„å­¦ä¹ ï¼Œä¸ºæ¯ä¸ªè¯ç”Ÿæˆä¸€ä¸ªå…·æœ‰è¯­ä¹‰æ„ä¹‰çš„ç¨ å¯†å‘é‡è¡¨ç¤ºã€‚æ¯”å¦‚ â€œå¥³äººâ€ å’Œ â€œå¥³å­©â€ï¼Œè¿™ä¸¤ä¸ªè¯å‘é‡å°±å¾ˆæ¥è¿‘ã€‚Word2Vecã€‚\n\n# Word2Vec\n\nå·¦ä¾§æ˜¯ CBOWï¼Œä¸­é—´è¯æ˜¯æ•™å¸ˆï¼Œä»¥æ­¤æ¥å­¦ä¹ ä¸Šä¸‹æ–‡ã€‚\nå³ä¾§æ˜¯ Skip-gramï¼Œä¸Šä¸‹æ–‡æ˜¯æ•™å¸ˆï¼Œä»¥æ­¤æ¥å­¦ä¹ ä¸­é—´è¯ã€‚\n# GENSIM è¯å‘é‡ç»„ä»¶\n# åŠ è½½ä¸ä½¿ç”¨å…¬å¼€è¯å‘é‡\nfrom gensim.models import KeyedVectorsmodel_path = 'sgns.weibo.word.bz2'model = KeyedVectors.load_word2vec_format(model_path)similarity = model.similarity('å…¬äº¤', 'åœ°é“')print('å…¬äº¤å’Œåœ°é“çš„ç›¸ä¼¼åº¦', similarity)\nå…¬äº¤å’Œåœ°é“çš„ç›¸ä¼¼åº¦ 0.65458214\n\nmodel.most_similar(positive=['ç”·äºº', 'å¥³å­©'], negative=['ç”·å­©'], topn=10)ç”·äºº + å¥³å­© - ç”·å­© = å¥³äºº\n\n[(â€˜å¥³äººâ€™, 0.6578881740570068),\n(â€˜å¥³å­©å­â€™, 0.515068531036377),\n(â€˜å¥³ç”Ÿâ€™, 0.4519447982311249),\n(â€˜å¥³äººçœŸâ€™, 0.44206273555755615),\n(â€˜å¥³äººä»¬â€™, 0.4369858503341675),\n(â€˜å¥³äººçˆ±â€™, 0.435453325510025),\n(â€˜å¯¡è¨€å°‘è¯­â€™, 0.42479249835014343),\n(â€˜ç”·å­©å­â€™, 0.42177465558052063),\n(â€˜çœ‹å¥³äººâ€™, 0.41949161887168884),\n(â€˜ç¬¨å¥³äººâ€™, 0.4182003140449524)]\n\n# è®­ç»ƒè‡ªå·±çš„è¯å‘é‡\nimport pandas as pdimport jiebafrom gensim.models import Word2Veccomments = pd.read_csv('./data/online_shopping_10_cats.csv', encoding='utf-8')reviews = comments['review']reviews = reviews.dropna()sentences = [[token for token in jieba.__lcut(review) if token.strip() != ''] for review in reviews]model = Word2Vec(    sentences,            # å·²åˆ†è¯çš„å¥å­åºåˆ—    vector_size=100,      # è¯å‘é‡ç»´åº¦    window=5,             # ä¸Šä¸‹æ–‡çª—å£å¤§å°    min_count=2,          # æœ€å°è¯é¢‘ï¼ˆä½äºå°†è¢«å¿½ç•¥ï¼‰    sg=1,                 # 1:Skip-Gramï¼Œ0:CBOW    workers=4             # å¹¶è¡Œè®­ç»ƒçº¿ç¨‹æ•°)model.wv.save_word2vec_format('./data/word2vec.txt')# è¯å‘é‡çš„åº”ç”¨\nimport torchfrom torch import nnfrom gensim.models import KeyedVectors# åŠ è½½è¯å‘é‡wv = KeyedVectors.load_word2vec_format('./data/word2vec.txt')# æ„å»ºè¯å‘é‡çŸ©é˜µnum_embedding = len(wv.key_to_index)embedding_dim = wv.vector_sizeembedding_matrix = torch.randn(num_embedding, embedding_dim)for word, index in wv.key_to_index.items():    embedding_matrix[index] = torch.from_numpy(wv[word])print(embedding_matrix.shape)# åˆ›å»º Embeddingembedding = nn.Embedding.from_pretrained(embedding_matrix)text = 'æˆ‘å–œæ¬¢ä¹˜ååœ°é“'tokens= jieba.lcut(text)input_ids = [wv.key_to_index[token] for token in tokens if token in wv.key_to_index]input_tensor = torch.LongTensor(input_ids)embedding(input_tensor)# ELMo æ¨¡å‹ â€”â€” ä¸€è¯å¤šä¹‰é—®é¢˜\nNNLM æ¨¡å‹æ˜¯åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè€Œè¯å‘é‡æ˜¯å‰¯äº§å“ã€‚\nWord2Vec æ¨¡å‹æ˜¯åœ¨ä¸“é—¨åšè¯å‘é‡ï¼Œæœ‰ CBOW å’Œ Skip-gramã€‚\nELMo æ¨¡å‹è§£å†³çš„æ˜¯ä¸€è¯å¤šä¹‰çš„é—®é¢˜ã€‚\n\nELMo ä¸ä»…ä»…æ˜¯è®­ç»ƒäº†ä¸€ä¸ª Q çŸ©é˜µï¼Œè¿˜æŠŠè¿™ä¸ªè¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯èå…¥åˆ°è¿™ä¸ª Q çŸ©é˜µä¸­ï¼Œå·¦è¾¹çš„ LSTM è·å– E2 çš„ä¸Šæ–‡ä¿¡æ¯ï¼Œå³ä¾§çš„ LSTM è·å–ä¸‹æ–‡ä¿¡æ¯ã€‚\nT1 åŒ…å«äº†ç¬¬ä¸€ä¸ªè¯çš„ç‰¹å¾ï¼Œä¸æ­¤åŒæ—¶ä¹ŸåŒ…å«äº†è¯­æ³•ç‰¹å¾å’Œè¯­ä¹‰ç‰¹å¾ã€‚\nç„¶è€Œ LSTM æ— æ³•å¹¶è¡Œè®¡ç®—ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶ã€‚\n# RNN åŸºæœ¬ç»“æ„\nRNN ä»¥æ—¶é—´æ­¥ä¸ºåŸºæœ¬å•ä½ï¼Œé€ä¸ªå¤„ç†æ¯ä¸€ä¸ª Tokenï¼Œæ–°çš„éšè—çŠ¶æ€æ˜¯ç”±ï¼Œä¸Šä¸€ä¸ªéšè—çŠ¶æ€ä¸å½“å‰æ­¥å…±åŒå†³å®šçš„ã€‚\n\nx1ï¼Œx2ï¼Œx3â€¦xt è¿™æ˜¯ä¸€ç»„ç‰¹å¾ï¼Œä½†æ˜¯è¿™æ˜¯ä¸æ—¶é—´æœ‰å…³çš„ç‰¹å¾ï¼Œhâ‚œæ˜¯æ¯æ—¶æ¯åˆ»çš„é¢„æµ‹ã€‚\næ¯”å¦‚ä¸€å¥è¯ï¼šâ€œæˆ‘å‡ºç”Ÿåœ¨ä¸­å›½ï¼Œæˆ‘ä¼šè¯´ä¸­æ–‡â€\næˆ‘ä»¬å¯ä»¥æŒ‰æ—¶é—´æ­¥å±•å¼€ï¼š\n\n\n\næ—¶é—´æ­¥\nè¾“å…¥ xâ‚œï¼ˆè¯å‘é‡ï¼‰\néšè—çŠ¶æ€ hâ‚œï¼ˆç¼–ç äº†å‰é¢çš„ä¸Šä¸‹æ–‡ï¼‰\nå¯èƒ½çš„é¢„æµ‹ yâ‚œï¼ˆä¸‹ä¸€ä¸ªè¯ï¼‰\n\n\n\n\nt=1\nâ€œæˆ‘â€\nhâ‚ï¼ˆç¼–ç äº† â€œæˆ‘â€ï¼‰\nâ€œå‡ºç”Ÿâ€\n\n\nt=2\nâ€œå‡ºç”Ÿâ€\nhâ‚‚ï¼ˆç¼–ç äº† â€œæˆ‘ å‡ºç”Ÿâ€ï¼‰\nâ€œåœ¨â€\n\n\nt=3\nâ€œåœ¨â€\nhâ‚ƒï¼ˆç¼–ç äº† â€œæˆ‘ å‡ºç”Ÿ åœ¨â€ï¼‰\nâ€œä¸­å›½â€\n\n\nt=4\nâ€œä¸­å›½â€\nhâ‚„ï¼ˆç¼–ç äº† â€œæˆ‘ å‡ºç”Ÿ åœ¨ ä¸­å›½â€ï¼‰\nâ€œï¼Œâ€\n\n\nt=5\nâ€œï¼Œâ€\nhâ‚…ï¼ˆç¼–ç äº† â€œæˆ‘ å‡ºç”Ÿ åœ¨ä¸­å›½ ï¼Œâ€ï¼‰\nâ€œæˆ‘â€\n\n\nt=6\nâ€œæˆ‘â€\nhâ‚†ï¼ˆç¼–ç äº†å‰åŠå¥ +â€œæˆ‘â€ï¼‰\nâ€œä¼šâ€\n\n\nt=7\nâ€œä¼šâ€\nhâ‚‡ï¼ˆç¼–ç äº†å‰åŠå¥ +â€œæˆ‘ ä¼šâ€ï¼‰\nâ€œè¯´â€\n\n\nt=8\nâ€œè¯´â€\nhâ‚ˆï¼ˆç¼–ç äº†å‰åŠå¥ +â€œæˆ‘ ä¼š è¯´â€ï¼‰\nâ€œä¸­æ–‡â€\n\n\n\nRNN çš„éšè—çŠ¶æ€ hâ‚œ èµ·åˆ°äº† **â€œè®°å¿†â€** çš„ä½œç”¨ï¼š\n\nå½“æ¨¡å‹çœ‹åˆ° â€œä¸­å›½â€ æ—¶ï¼Œhâ‚„ å·²ç»ç¼–ç äº† â€œæˆ‘å‡ºç”Ÿåœ¨ä¸­å›½â€ è¿™ä¸ªä¿¡æ¯ã€‚\nå½“æ¨¡å‹çœ‹åˆ°ååŠå¥ â€œæˆ‘ä¼šè¯´ä¸­æ–‡â€ æ—¶ï¼Œhâ‚ˆ å·²ç»ç¼–ç äº†æ•´å¥è¯çš„ä¸Šä¸‹æ–‡ï¼Œå› æ­¤å®ƒå¯ä»¥æ¨æ–­å‡º â€œä¸­æ–‡â€ æ˜¯åˆç†çš„ä¸‹ä¸€ä¸ªè¯ï¼Œå› ä¸º â€œå‡ºç”Ÿåœ¨ä¸­å›½â€ å’Œ â€œä¼šè¯´ä¸­æ–‡â€ ä¹‹é—´æœ‰è¯­ä¹‰å…³è”ã€‚\n\nåœ¨ RNN ä¸­ï¼Œæ¯ä¸ªè¯ xâ‚œ æ˜¯éšæ—¶é—´è¾“å…¥çš„ç‰¹å¾ï¼Œéšè—çŠ¶æ€ hâ‚œ æ˜¯æ¨¡å‹å¯¹ â€œåˆ°ç›®å‰ä¸ºæ­¢æ‰€æœ‰è¯â€ çš„ç†è§£ï¼Œè€Œé¢„æµ‹ yâ‚œ æ˜¯åŸºäºè¿™ç§ç†è§£åšå‡ºçš„ä¸‹ä¸€æ­¥åˆ¤æ–­ã€‚\n# RNN ä¸ FCNNï¼ˆå…¨è¿æ¥ç¥ç»ç½‘ç»œï¼‰çš„åŒºåˆ«\n\nå·¦ä¾§æ˜¯ RNNï¼Œå³ä¾§æ˜¯å…¨è¿æ¥ç¥ç»ç½‘ç»œã€‚å…¨è¿æ¥ç¥ç»ç½‘ç»œæ˜¯ä¸€ä¸ªç›´ç­’çš„ç»“æ„ï¼ŒRNN æ˜¯ä¸€ä¸ªä¸æ—¶é—´æœ‰å…³çš„å¾ªç¯ç»“æ„ã€‚\n# FCNN çš„å±•å¼€\n\n# RNN çš„å±•å¼€\n\n# ä¸ºä»€ä¹ˆï¼Ÿ\nFCNN æŠŠæ¯ä¸ªè¾“å…¥å½“ä½œç‹¬ç«‹é™æ€å‘é‡\nRNN æŠŠè¾“å…¥çœ‹æˆéšæ—¶é—´å±•å¼€çš„åºåˆ—ï¼Œç”¨å…±äº«å‚æ•° + å¾ªç¯éšçŠ¶æ€æ¥æ˜¾å¼å»ºæ¨¡ â€œè¿‡å»â€ å¯¹ â€œç°åœ¨â€ çš„å½±å“ã€‚\n# æ•°å­¦è¡¨è¾¾\nht=tanhâ¡(xtWx+htâˆ’1Wh+b),\\begin {array}{c}\nh_t = \\tanh(x_t W_x + h_{t-1} W_h + b),\n\\end{array}\nhtâ€‹=tanh(xtâ€‹Wxâ€‹+htâˆ’1â€‹Whâ€‹+b),â€‹\n[ht1ht2ht3ht4]=tanhâ¡([htâˆ’11htâˆ’12htâˆ’13htâˆ’14][wh11wh12wh13wh14wh21wh22wh23wh24wh31wh32wh33wh34wh41wh42wh43wh44]+[xt1xt2xt3xt4][wx11wx12wx13wx14wx21wx22wx23wx24wx31wx32wx33wx34]+[b1b2b3b4])\\begin {array}{c}\n\\begin{bmatrix}\nh_t^1 &amp; h_t^2 &amp; h_t^3 &amp; h_t^4\n\\end{bmatrix}\n=\n\\tanh(\n\\begin{bmatrix}\nh_{t-1}^1 &amp; h_{t-1}^2 &amp; h_{t-1}^3 &amp; h_{t-1}^4\n\\end{bmatrix}\n\\begin{bmatrix}\nw_h^{11} &amp; w_h^{12} &amp; w_h^{13} &amp; w_h^{14} \\\\\nw_h^{21} &amp; w_h^{22} &amp; w_h^{23} &amp; w_h^{24} \\\\\nw_h^{31} &amp; w_h^{32} &amp; w_h^{33} &amp; w_h^{34} \\\\\nw_h^{41} &amp; w_h^{42} &amp; w_h^{43} &amp; w_h^{44}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nx_t^1 &amp; x_t^2 &amp; x_t^3 &amp; x_t^4\n\\end{bmatrix}\n\\begin{bmatrix}\nw_x^{11} &amp; w_x^{12} &amp; w_x^{13} &amp; w_x^{14} \\\\\nw_x^{21} &amp; w_x^{22} &amp; w_x^{23} &amp; w_x^{24} \\\\\nw_x^{31} &amp; w_x^{32} &amp; w_x^{33} &amp; w_x^{34}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_1 &amp; b_2 &amp; b_3 &amp; b_4\n\\end{bmatrix}\n)\n\\end{array}\n[ht1â€‹â€‹ht2â€‹â€‹ht3â€‹â€‹ht4â€‹â€‹]=tanh([htâˆ’11â€‹â€‹htâˆ’12â€‹â€‹htâˆ’13â€‹â€‹htâˆ’14â€‹â€‹]â£â¢â¢â¢â¡â€‹wh11â€‹wh21â€‹wh31â€‹wh41â€‹â€‹wh12â€‹wh22â€‹wh32â€‹wh42â€‹â€‹wh13â€‹wh23â€‹wh33â€‹wh43â€‹â€‹wh14â€‹wh24â€‹wh34â€‹wh44â€‹â€‹â¦â¥â¥â¥â¤â€‹+[xt1â€‹â€‹xt2â€‹â€‹xt3â€‹â€‹xt4â€‹â€‹]â£â¢â¡â€‹wx11â€‹wx21â€‹wx31â€‹â€‹wx12â€‹wx22â€‹wx32â€‹â€‹wx13â€‹wx23â€‹wx33â€‹â€‹wx14â€‹wx24â€‹wx34â€‹â€‹â¦â¥â¤â€‹+[b1â€‹â€‹b2â€‹â€‹b3â€‹â€‹b4â€‹â€‹])â€‹\n# æƒé‡å…±äº«\næƒé‡å…±äº«â€ æ˜¯ RNN ä¸ CNN é‡Œæœ€å¸¸è¢«æåˆ°çš„ä¸€ä¸ªæ ¸å¿ƒè®¾è®¡ï¼Œä½†å®ƒä¸æ˜¯ â€œæ‰€æœ‰ç¥ç»å…ƒå…±ç”¨åŒä¸€ä¸ªæ•°â€ï¼Œè€Œæ˜¯åŒä¸€ç»„å‚æ•°ï¼ˆçŸ©é˜µ / å‘é‡ï¼‰åœ¨å¤šä¸ªä½ç½®ã€å¤šä¸ªæ—¶é—´æ­¥æˆ–ç©ºé—´ä½ç½®åå¤ä½¿ç”¨ã€‚\n# åŒå‘ RNN\nåŒå‘é€’å½’ç¥ç»ç½‘ç»œï¼ˆBidirectional Recurrent Neural Networkï¼Œç®€ç§° Bi-RNNï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼Œå®ƒåœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶ï¼Œä¸ä»…è€ƒè™‘äº†è¿‡å»çš„ä¿¡æ¯ï¼Œè¿˜è€ƒè™‘äº†æœªæ¥çš„ä¿¡æ¯ã€‚è¿™ä½¿å¾— Bi-RNN åœ¨å¤„ç†è¯¸å¦‚è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºå®ƒèƒ½å¤ŸåŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\n# åœ¨ PyTorch ä½¿ç”¨ RNN\nimport torch.nn as nn# åŒå±‚åŒå‘ RNNrnn = nn.RNN(input_size=3, hidden_size=4, num_layers=2, batch_first=True, bidirectional=True)# shape: (batch, seq_len, input_size)input = torch.randn(2, 4, 3)output, hn = rnn(input)print(output.shape)print(hn.shape)\ntorch.Size([2, 4, 8])\ntorch.Size([4, 2, 4])\n\n# è¯åµŒå…¥å±‚ API åº”ç”¨\n# ä½œç”¨\næŠŠè¯æˆ–è¯å¯¹åº”çš„ç´¢å¼•è½¬ä¸ºè¯å‘é‡\n# ä½¿ç”¨æ¡†æ¶å®ç°\nimport torchimport jiebaimport torch.nn as nndef dm01():    text = \"å½“æ‚¨ç™»å½•å¹³å°å³è¡¨ç¤ºæ‚¨æ¥å—æœ¬éšç§æ”¿ç­–çš„å…¨éƒ¨å†…å®¹ï¼Œå¹¶åŒæ„å¹³å°æŒ‰æœ¬æ”¿ç­–æ”¶é›†ã€ä½¿ç”¨å’Œä¿æŠ¤æ‚¨çš„ç›¸å…³ä¸ªäººä¿¡æ¯ã€‚\"    words = jieba.lcut(text)    print(words)    '''    len(words) : è¯è¡¨å¤§å°    embedding_dim : è¯å‘é‡ç»´åº¦    '''    embed = nn.Embedding(len(words), embedding_dim=4)    for i, word in enumerate(words):        # è¯ç´¢å¼•ï¼ˆå¼ é‡ï¼‰è½¬å˜ä¸ºè¯å‘é‡        word2Vec = embed(torch.tensor([i]))        print(word, word2Vec)if __name__ == '__main__':    dm01()# RNN çš„ API ä½¿ç”¨\nRNN å°±åƒæ˜¯ä½ çš„å¤§è„‘ï¼Œåœ¨çœ‹ç”µå½±çš„è¿‡ç¨‹ä¸­è®°ä½å‰§æƒ…ã€‚\nimport torchimport torch.nn as nn'''input_sizeï¼šè¯å‘é‡çš„ç»´åº¦hidden_sizeï¼šéšè—çŠ¶æ€çš„ç»´åº¦num_layersï¼šéšè—å±‚æ•°batch_firstï¼šæ‰¹æ¬¡ä¼˜å…ˆ'''rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=1)'''5ï¼šæœ‰5ä¸ªè¯3ï¼š3ä¸ªæ‰¹æ¬¡10ï¼šæ¯ä¸ªè¯çš„ç»†èŠ‚æ˜¯10ç»´åº¦'''x = torch.rand(5, 3, 10)'''1ï¼šéšè—å±‚å±‚æ•°3ï¼šå¥å­æ•°é‡20ï¼šæœ‰20ä¸ªå¾ªç¯ç»´åº¦ï¼Œä¹Ÿå°±æ˜¯éšè—çŠ¶æ€çš„ç»´åº¦'''h0 = torch.zeros(1, 3, 20)'''RNNå¤„ç†xï¼šæœ¬æ¬¡çš„è¾“å…¥h0ï¼šä¸Šä¸€æ¬¡çš„éšè—çŠ¶æ€è¾“å‡ºoutputï¼šæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼ŒåŒ…å«äº†æ‰€æœ‰æ—¶é—´æ­¥éª¤çš„éšè—çŠ¶æ€h1ï¼šæœ€åä¸€æ¬¡éšè—çŠ¶æ€ï¼Œå¤§è„‘é‡Œæœ€æ–°çš„å‰§æƒ…'''output, h1 = rnn(x, h0)print(f'output_shape:&#123;output.shape&#125;')print(f'h1_shape:&#123;h1.shape&#125;')# RNN çš„æ–‡æœ¬ç”Ÿæˆ\n# _*_ coding : utf-8 _*_# @Time : 2025/10/31 10:02# @Author : KarryLiu# File : æ­Œè¯ç”Ÿæˆ# @Project : pytorchSTUimport mathimport torchimport jiebafrom torch.utils.data import DataLoader, Datasetimport torch.nn as nnimport torch.optim as optimimport timefrom tqdm import tqdm\"\"\"å®ç°æ­¥éª¤ï¼š    1. è·å–æ•°æ®ï¼Œè¿›è¡Œåˆ†è¯    2. è·å–è¯è¡¨ï¼Œæ„å»ºæ•°æ®é›†    3. æ­å»ºRNNç¥ç»ç½‘ç»œæ¨¡å‹    4. è®­ç»ƒæ¨¡å‹    5. æ¨¡å‹é¢„æµ‹    6. æµ‹è¯•\"\"\"def build_vocab():    unique_words, all_words = [], []    with open('data/jaychou_lyrics.txt', 'r', encoding='utf-8') as f:        for line in tqdm(f, desc='æ­£åœ¨å¤„ç†æ•°æ®', total=5819):            words = jieba.lcut(line)            all_words.append(words)            for word in words:                if word not in unique_words:                    unique_words.append(word)    word2index = &#123;word: index for index, word in enumerate(unique_words)&#125;    index2word = &#123;index: word for index, word in enumerate(unique_words)&#125;    # å°†è¯è¡¨è½¬ä¸ºç´¢å¼•ï¼Œã€0ï¼Œ1ï¼Œ2ï¼Œ3ã€‘ï¼Œè¿™ä¸ªæ˜¯ä¸€å¥æ­Œè¯    corpus_idx = []    for all_word in all_words:        tmp = []        for word in all_word:            tmp.append(word2index[word])        tmp.append(word2index[' '])        corpus_idx.extend(tmp)    word_count = len(unique_words)    return unique_words, word2index, word_count, corpus_idxclass LyricsDataset(Dataset):    def __init__(self, corpus_idx, num_chars):        super().__init__()        self.corpus_idx = corpus_idx        self.num_chars = num_chars        self.word_count = len(corpus_idx)        self.sentence_len = self.word_count // num_chars    def __len__(self):        return self.sentence_len    def __getitem__(self, index):        start = min(max(index, 0), self.word_count - self.num_chars - 1)        end = start + self.num_chars        sentence_x = self.corpus_idx[start:end]        sentence_y = self.corpus_idx[start + 1:end + 1]        sentence_x = torch.tensor(sentence_x, dtype=torch.long)        sentence_y = torch.tensor(sentence_y, dtype=torch.long)        return sentence_x, sentence_yclass TextGenerator(nn.Module):    def __init__(self, unique_words_count, ):        super().__init__()        self.embedding = nn.Embedding(unique_words_count, 128)        self.rnn = nn.RNN(128, 256, 1)        self.linear = nn.Linear(256, unique_words_count)    def forward(self, input, hidden):        embed = self.embedding(input)        output, hidden = self.rnn(embed.transpose(0, 1), hidden)        output = self.linear(output.reshape(shape=(-1, output.shape[-1])))        return output, hidden    def init_hidden(self, batch_size):        return torch.zeros(1, batch_size, 256)def train():    unique_words, word2index, unique_word_count, corpus_idx = build_vocab()    dataset = LyricsDataset(corpus_idx, 32)    dataloader = DataLoader(dataset, batch_size=5, shuffle=True)    model = TextGenerator(unique_word_count)    optimizer = optim.Adam(model.parameters(), lr=0.01)    loss_fn = nn.CrossEntropyLoss()    min_loss = math.inf    loss = 0    total_loss = 0    iter_times = 0    for epoch in range(50):        for i, (x, y) in enumerate(tqdm(dataloader, desc=f'æ­£åœ¨è®­ç»ƒç¬¬&#123;epoch + 1&#125;è½®', total=len(dataset) // 5)):            hidden = model.init_hidden(5)            output, hidden = model(x, hidden)            y = torch.transpose(y, 0, 1).reshape(shape=(-1,))            loss = loss_fn(output, y)            optimizer.zero_grad()            loss.backward()            optimizer.step()            iter_times += 1            total_loss += loss.item()        print(f'ç¬¬&#123;epoch + 1&#125;è½®ï¼Œæ€»æŸå¤±ï¼š&#123;total_loss / iter_times&#125;')        if loss &lt; min_loss:            min_loss = loss            torch.save(model.state_dict(), 'model.pth')def eval(start_word, seq_len):    unique_words, word2index, unique_word_count, corpus_idx = build_vocab()    model = TextGenerator(unique_word_count)    model.load_state_dict(torch.load('model.pth'))    hidden = model.init_hidden(1)    word_index = word2index[start_word]    generate_sentence = [word_index]    for i in range(seq_len):        output, hidden = model(torch.tensor([[word_index]]), hidden)        output = output.reshape(shape=(-1,))        word_index = torch.argmax(output).item()        generate_sentence.append(word_index)    for e in [unique_words[index] for index in generate_sentence]:        print(e, end='')if __name__ == '__main__':    train()    eval('åˆ†æ‰‹', 100)\nåˆ†æ‰‹çš„è¯åƒè¯­è¨€æš´åŠ›ä½ è€Œé¦™ ç‰§è‰æœ‰æ²¡æœ‰ æˆ‘é©¬å„¿æœ‰äº›ç˜¦\nå¤©æ¶¯å°½å¤´ æ»¡è„¸é£éœœè½å¯ è¿‘ä¹¡æƒ…æ€¯çš„æˆ‘\næˆ‘è¯´åº—å°äºŒ ä¸‰ä¸¤é“¶å¤Ÿä¸å¤Ÿ\næ™¯è‰²å…¥ç§‹ æ¼«å¤©é»„æ²™å‡‰è¿‡\nå¡åŒ—çš„å®¢æ ˆäººå¤š ç‰§è‰æœ‰æ²¡æœ‰ æˆ‘é©¬å„¿æœ‰äº›ç˜¦\nä¸–äº‹çœ‹é€ æ±Ÿæ¹–ä¸Šæ½®èµ·æ½®è½ ä»€ä¹ˆæ©æ€¨è¿‡é”™\nåœ¨å¤šå¹´ä»¥å è¿˜æ˜¯è®©äººéš¾è¿‡ å¿ƒä¼¤é€\nå¨˜å­å¥¹äººåœ¨æ±Ÿå—ç­‰æˆ‘ æ³ªä¸ä¼‘ è¯­æ²‰é»˜\n\n# æ™ºèƒ½æç¤ºè¾“å…¥æ³•çš„å®ç°\n# æœ€ä½³å®è·µ\nprint(__file__)__ file __ æ˜¯å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œpy åœ¨å¤„ç†ç›¸å¯¹è·¯å¾„æ—¶å¯èƒ½ä¼šé‡åˆ°é—®é¢˜ï¼Œæœ€å¥½ä½¿ç”¨ç»å¯¹è·¯å¾„ã€‚\nfrom pathlib import Pathprint(Path(__file__).parent.parent / \"data/raw/synthesized_.jsonl\")æ‰€ä»¥æˆ‘ä»¬é€šå¸¸ä¼šè¿™æ ·å†™ï¼š\nRAW_DATA_DIR = Path(__file__).parent.parent / \"data/raw\"def process():    print(\"å¼€å§‹å¤„ç†æ•°æ®\")    # è¯»å–åŸå§‹æ–‡ä»¶    df = pd.read_json(RAW_DATA_DIR / \"synthesized_.jsonl\", lines=True, orient='records',                      encoding='utf-8')    print(df.head())    print(\"æ•°æ®å¤„ç†å®Œæˆ\")# æ•°æ®é¢„å¤„ç†\nimport jiebafrom sklearn.model_selection import train_test_splitimport pandas as pdfrom tqdm import tqdmimport configdef build_dataset(sentences, word2index, desc=\"æ„å»ºæ•°æ®é›†\"):    indexed_sentences = [[word2index.get(token, 0) for token in jieba.lcut(sentences)] for sentences in                         sentences]    dataset = []    for index, sentence in tqdm(enumerate(indexed_sentences), desc=desc):        for i in range(len(sentence) - config.SWQ_LEN):            input = sentence[i:i + config.SWQ_LEN]            target = sentence[i + config.SWQ_LEN]            dataset.append(&#123;                'input': input,                'target': target,            &#125;)    return datasetdef process():    print(\"å¼€å§‹å¤„ç†æ•°æ®\")    # è¯»å–åŸå§‹æ–‡ä»¶    df = pd.read_json(config.RAW_DATA_DIR / \"synthesized_.jsonl\", lines=True, orient='records',                      encoding='utf-8').sample(frac=0.1)    # æå–å¥å­    sentences = []    for sentencesX in df['dialog']:        for sentencesXs in sentencesX:            sentences.append(sentencesXs.split('ï¼š')[1])    print(f\"å¥å­çš„æ•°é‡ä¸ºï¼š&#123;len(sentences)&#125;\")    # åˆ’åˆ†æ•°æ®é›†    train_sentences, valid_sentences = train_test_split(sentences, test_size=0.2)    # æ„å»ºè¯è¡¨    vocab_set = set()    for sentence in tqdm(train_sentences, desc='æ„å»ºè¯è¡¨'):        vocab_set.update(jieba.lcut(sentence))    vocab_list = ['&lt;unk>'] + list(vocab_set)    print(f\"è¯è¡¨çš„æ•°é‡ä¸ºï¼š&#123;len(vocab_list)&#125;\")    # ä¿å­˜æ­¤è¡¨    with open(config.MODELS_DIR / \"vocab.txt\", 'w', encoding='utf-8') as f:        f.write('\\n'.join(vocab_list))    # æ„å»ºè®­ç»ƒé›†    word2index = &#123;word: index for index, word in enumerate(vocab_list)&#125;    train_dataset = build_dataset(train_sentences, word2index)    # ä¿å­˜è®­ç»ƒé›†    pd.DataFrame(train_dataset).to_json(config.PROCESSED_DATA_DIR / \"train.jsonl\", orient='records', lines=True)    # æ„å»ºéªŒè¯é›†    valid_dataset = build_dataset(valid_sentences, word2index)    # ä¿å­˜éªŒè¯é›†    pd.DataFrame(valid_dataset).to_json(config.PROCESSED_DATA_DIR / \"valid.jsonl\", orient='records', lines=True)    print(\"æ•°æ®å¤„ç†å®Œæˆ\")if __name__ == '__main__':    process()# æ•°æ®é›†\nimport pandas as pdimport torchfrom torch.utils.data import DataLoader, Datasetfrom torch.utils.data.dataset import _T_cofrom src.NLP.SmartPrompt.src import config# å®šä¹‰ Datasetclass InputMethodDataset(Dataset):    def __init__(self, path):        super().__init__()        self.data = pd.read_json(path, lines=True, orient='records').to_dict('records')    def __getitem__(self, index) -> _T_co:        input_tensor = torch.tensor(self.data[index]['input'], dtype=torch.long)        target_tensor = torch.tensor(self.data[index]['target'], dtype=torch.long)        return input_tensor, target_tensor    def __len__(self) -> int:        return len(self.data)# æä¾›ä¸€ä¸ªè·å– DATALoader çš„æ–¹æ³•def get_dataloader(train=True):    path = config.PROCESSED_DATA_DIR / (\"train.jsonl\" if train else \"valid.jsonl\")    dataset = InputMethodDataset(path)    return DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=True)if __name__ == '__main__':    train_loader = get_dataloader(train=True)    valid_loader = get_dataloader(train=False)    print(len(train_loader))    print(len(valid_loader))    for input_tensor, target_tensor in train_loader:        print(input_tensor.shape)        print(target_tensor.shape)        break# è®­ç»ƒ\nimport timeimport torchfrom torch import nnfrom torch.utils.tensorboard import SummaryWriterfrom tqdm import tqdmfrom src.NLP.SmartPrompt.src import configfrom src.NLP.SmartPrompt.src.dataset import get_dataloaderfrom src.NLP.SmartPrompt.src.model import InputMethodModeldef train_onr_epoch(model, dataloader, loss_fn, optimizer, device):    \"\"\"    :param model: æ¨¡å‹    :param dataloader: æ•°æ®é›†    :param loss_fn: æŸå¤±å‡½æ•°    :param optimizer: ä¼˜åŒ–å™¨    :param device: è®¾å¤‡    :return: æŸå¤±å€¼    \"\"\"    model.train()    total_loss = 0    for batch in tqdm(dataloader, desc=\"è®­ç»ƒä¸­\"):        features, targets = batch        features = features.to(device)        targets = targets.to(device)        outputs = model(features)        loss = loss_fn(outputs, targets)        total_loss += loss.item()        optimizer.zero_grad()        loss.backward()        optimizer.step()    return total_loss / len(dataloader)def train():    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    dataloader = get_dataloader(train=True)    with open(config.MODELS_DIR / 'vocab.txt', 'r', encoding='utf-8') as f:        vocab_list = f.readlines()        vocab_list = [vocab.strip() for vocab in vocab_list]    model = InputMethodModel(len(vocab_list)).to(device)    loss_fn = nn.CrossEntropyLoss()    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)    writer = SummaryWriter(log_dir=config.LOGS_DIR/time.strftime('%Y-%m-%d_%H-%M-%S'))    bestLoss = float('inf')    for epoch in range(1, 1 + config.EPOCHS):        print(\"-\" * 5, f\"Epoch &#123;epoch&#125;/&#123;config.EPOCHS&#125;\", \"-\" * 5)        loss = train_onr_epoch(model, dataloader, loss_fn, optimizer, device)        print(f\"loss:&#123;loss&#125;\")        writer.add_scalar('loss', loss, epoch)        if loss &lt; bestLoss:            bestLoss = loss            torch.save(model.state_dict(), config.MODELS_DIR / 'model.pt')    writer.close()if __name__ == '__main__':    train()# æ¨¡å‹\nfrom torch import nnimport configclass InputMethodModel(nn.Module):    def __init__(self, vocab_size, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=config.EMBEDDING_DIM)        self.rnn = nn.RNN(            input_size=config.EMBEDDING_DIM,            hidden_size=config.HIDDEN_SIZE,            batch_first=True,        )        self.linear = nn.Linear(in_features=config.HIDDEN_SIZE, out_features=vocab_size)    def forward(self, x, *args, **kwargs):        embedding = self.embedding(x)        output, hidden = self.rnn(embedding)        last_hidden_state = output[:,-1,:]        output = self.linear(last_hidden_state)        return output# é¢„æµ‹\nimport jiebaimport torchfrom src.NLP.SmartPrompt.src import configfrom src.NLP.SmartPrompt.src.model import InputMethodModeldevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')with open(config.MODELS_DIR / 'vocab.txt', 'r', encoding='utf-8') as f:    vocab_list = f.readlines()    vocab_list = [vocab.strip() for vocab in vocab_list]word2index = &#123;word: index for index, word in enumerate(vocab_list)&#125;index2word = &#123;index: word for index, word in enumerate(vocab_list)&#125;model = InputMethodModel(len(vocab_list)).to(device)model.load_state_dict(torch.load(config.MODELS_DIR / 'model.pt'))def predict(text):    tokens = jieba.lcut(text)    input = [word2index.get(token, 0) for token in tokens]    input_tenosr = torch.tensor([input], dtype=torch.long).to(device)    model.eval()    with torch.no_grad():        output = model(input_tenosr)    topk = torch.topk(output, k=5).indices.tolist()    return [index2word[index] for index in topk[0]]if __name__ == '__main__':    user_str = ''    while user_str != 'q':        now_str = input(\"è¯·è¾“å…¥ï¼š\")        user_str += now_str        if now_str.strip() == 'q':            break        top5_tokens = predict(user_str)        print(top5_tokens)        print(\"å½“å‰è¾“å…¥ï¼š\", user_str)# LSTM\nLSTM çµæ„Ÿæ¥åŸä¸è®¡ç®—æœºé€»è¾‘é—¨ã€‚\n\nå›¾ç‰‡æ¥æºäºï¼šLSTM - é•¿çŸ­æœŸè®°å¿†é€’å½’ç¥ç»ç½‘ç»œ - çŸ¥ä¹\né—å¿˜é—¨ï¼šä¸»è¦è´Ÿè´£é—å¿˜è¿‡å»çš„è®°å¿†ä¿¡æ¯ï¼Œæœ€é‡è¦çš„æ˜¯è¦å»ç»“åˆå½“ä¸‹çš„çŠ¶æ€ä¿¡æ¯å»å¤„ç†ã€‚\nè¾“å…¥é—¨ï¼šè¾“å…¥é—¨ä¸»è¦è´Ÿè´£ç°åœ¨è¦è®°ä¸‹ä»€ä¹ˆï¼Œå¯ä»¥çœ‹åˆ°åœ¨è¾“å…¥é—¨çš„å³ä¾§è¿˜æœ‰ä¸€ä¸ª tanh çš„æ¿€æ´»å‡½æ•°ï¼Œ\nè¾“å‡ºé—¨ï¼š\n\n# åŒå‘ç»“æ„\n\n# æ³¨æ„åŠ›æœºåˆ¶\næ³¨æ„åŠ›æœºåˆ¶çš„èµ·æºï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬å¾€å¾€ä¼šèšç„¦äºé‡è¦çš„ä¿¡æ¯ã€‚\næ€ä¹ˆåšï¼Ÿ\næˆ‘ï¼ˆæŸ¥è¯¢å¯¹è±¡ Qï¼‰ï¼Œè¿™å¼ å›¾ï¼ˆè¢«æŸ¥è¯¢å¯¹è±¡ Vï¼‰\næˆ‘çœ‹ä¸€çœ¼è¿™å¼ å›¾ï¼Œæˆ‘å°±ä¼šå»åˆ¤æ–­å“ªäº›ä¸œè¥¿å¯¹æˆ‘è€Œè¨€æ˜¯é‡è¦çš„ï¼Œé‚£äº›ä¸œè¥¿å¯¹æˆ‘æ¥è¯´æ˜¯æ˜¯ä¸é‡è¦çš„ï¼ˆå»è®¡ç®— Q å’Œ V é‡Œçš„äº‹ç‰©é‡è¦ç¨‹åº¦ï¼‰ã€‚\nå›¾ç‰‡æ¥è‡ªï¼šhttps://www.cnblogs.com/nickchen121/p/16470710.html\n\nè§£ç å™¨åœ¨ç”Ÿæˆç›®æ ‡åºåˆ—çš„æ¯ä¸€æ­¥æ—¶ï¼Œä¸å†ä¾èµ–äºä¸€ä¸ªé™æ€çš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œè€Œæ˜¯æ ¹æ®å½“å‰çš„è§£ç çŠ¶æ€ï¼ŒåŠ¨æ€åœ°ä»ç¼–ç å™¨å„ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä¸­é€‰å–æœ€ç›¸å…³çš„ä¿¡æ¯ï¼Œä»¥è¾…åŠ©å½“å‰æ­¥ç”Ÿæˆã€‚\nè¿™ç§æœºåˆ¶è¯­æ³•èµ‹äºˆæ¨¡å‹å¯¹é½çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªåŠ¨åˆ¤æ–­æºå¥å­ä¸­é‚£äº›ä½ç½®å¯¹å½“å‰ç›®æ ‡è¯æ›´ä¸ºé‡è¦ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£ä¿¡æ¯ç“¶é¢ˆé—®é¢˜ï¼Œæå‡ç”Ÿæˆè´¨é‡ä¸è¡¨è¾¾èƒ½åŠ›ã€‚\n\næ³¨æ„åŠ›æœºåˆ¶å®é™…ä¸Šæ˜¯åœ¨åŠ¨æ€çš„æå–å½“å…ˆæœ€éœ€è¦å…³å¿ƒçš„æ•°æ®ã€‚\nè¿™ä¸€æœºåˆ¶é€šå¸¸ä»¥ä¸‹å››ä¸ªæ­¥éª¤æ¥å®Œæˆã€‚\n\nç›¸å…³æ€§è®¡ç®—\næ³¨æ„åŠ›æƒé‡è®¡ç®—\nä¸Šä¸‹æ–‡å‘é‡è®¡ç®—\nè§£ç ä¿¡æ¯èåˆ\n\n# ç›¸å…³æ€§è®¡ç®—\nç›¸å…³æ€§çš„è®¡ç®—ä¾èµ–äºç‰¹å®šçš„å‡½æ•°ï¼Œé€šå¸¸è¢«ç§°ä¸ºæ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ã€‚\n\n# æ³¨æ„åŠ›æƒé‡è®¡ç®—\nå¾—åˆ°æ‰€æœ‰æºä½ç½®çš„æ³¨æ„åŠ›è¯„åˆ†åï¼Œä½¿ç”¨ Softmax å‡½æ•°å°†å…¶å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œä½œä¸ºæ³¨æ„åŠ›æƒé‡ã€‚å¾—åˆ†è¶Šé«˜çš„ä½ç½®ï¼Œå…¶å¯¹åº”çš„æƒé‡è¶Šå¤§ï¼Œä»£è¡¨æ¨¡å‹åœ¨å½“å‰ç”Ÿæˆä¸­æ›´å…³æ³¨è¯¥ä½ç½®çš„ä¿¡æ¯ã€‚\n\n# ä¸Šä¸‹æ–‡å‘é‡è®¡ç®—\nå°†æ‰€æœ‰ç¼–ç å™¨è¾“å‡ºæŒ‰ç…§æ³¨æ„åŠ›æƒé‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°ä¸€ä¸ªä¸Šä¸‹æ–‡å‘é‡ã€‚è¿™ä¸ªå‘é‡å°±è¡¨ç¤ºå½“å‰æ—¶é—´æ­¥ï¼Œæ¨¡å‹ä»æºå¥ä¸­æå–å‡ºçš„å…³é”®ä¿¡æ¯ã€‚\n\n# è§£ç ä¿¡æ¯èåˆ\nåœ¨å¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡åï¼Œè§£ç å™¨å°†å…¶ä¸å½“å‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€è¿›è¡Œæ‹¼æ¥ï¼Œä»¥èåˆä¸¤è€…ä¿¡æ¯ï¼Œæœ€ç»ˆé€šè¿‡çº¿æ€§å˜æ¢å’Œ Softmaxï¼Œç”Ÿæˆå½“å‰æ—¶é—´æ­¥ç›®æ ‡è¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n\n# æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°\n# ç‚¹ç§¯è¯„åˆ†\nå®ƒé€šè¿‡è®¡ç®—è§£ç å™¨å½“å‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä¸ç¼–ç å™¨æ¯ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€çš„ç‚¹ç§¯ï¼Œæ¥è¡¡é‡äºŒè€…ä¹‹é—´çš„ç›¸å…³æ€§ã€‚\n# é€šç”¨ç‚¹ç§¯è¯„åˆ†\né€šç”¨ç‚¹ç§¯è¯„åˆ†åœ¨ç‚¹ç§¯çš„åŸºç¡€ä¸Šå¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„æƒé‡çŸ©é˜µ W, ç”¨äºå…ˆå¯¹ç¼–ç å™¨éšè—çŠ¶æ€è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œå†ä¸è§£ç å™¨éšè—çŠ¶æ€è¿›è¡Œç‚¹ç§¯ã€‚\n# æ‹¼æ¥è¯„åˆ†\næ‹¼æ¥è¯„åˆ†æ˜¯ä¸€ç§è¡¨è¾¾èƒ½åŠ›æ›´å¼ºçš„ç›¸å…³æ€§è¯„åˆ†æ–¹æ³•ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šå°†è§£ç å™¨å½“å‰éšè—çŠ¶æ€ä¸ç¼–ç å™¨æ¯ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€æ‹¼æ¥ä¸ºä¸€ä¸ªé•¿å‘é‡ï¼Œç»è¿‡çº¿æ€§å˜æ¢å’Œéçº¿æ€§æ¿€æ´»ï¼Œæœ€åç”¨ä¸€ä¸ªå‘é‡è¿›è¡ŒæŠ•å½±ï¼Œå¾—åˆ°æœ€ç»ˆæ‰“åˆ†å€¼ã€‚\n\n# Transformer\n\nTransformer å…¶å®å°±æ˜¯ Attention çš„ä¸€ä¸ªå †å ã€‚\n# Transformer ä¸»è¦æ˜¯åœ¨åšä»€ä¹ˆ\næŠŠä¸€ä¸ªè¾“å…¥åºåˆ—ï¼ˆå¦‚ä¸€æ®µæ–‡å­—ã€ä¸€æ®µè¯­éŸ³ã€æˆ–ä¸€å¼ å›¾ç‰‡çš„ç‰¹å¾åºåˆ—ï¼‰â€”â€” ç¼–ç æˆè¡¨ç¤ºè¯­ä¹‰çš„å‘é‡åºåˆ—ï¼Œç„¶åï¼ˆå¯é€‰ï¼‰å†è§£ç å‡ºå¦ä¸€ä¸ªåºåˆ—ã€‚Transformer ä¸æ˜¯ä¸€ä¸ªå•çº¯çš„ â€œç®—æ³•â€ï¼Œè€Œæ˜¯ä¸€ä¸ªåºåˆ—å»ºæ¨¡æ¡†æ¶ã€‚ å®ƒæœ€æ“…é•¿çš„äº‹æ˜¯ï¼šç†è§£ä¸Šä¸‹æ–‡ä¸­çš„å…³ç³»ï¼Œå¹¶åŸºäºæ­¤ç”Ÿæˆè¾“å‡ºã€‚\n\n# Transformer çš„ Encoder\nTransformer çš„ Encoder ç”± N å±‚å †å çš„ç»“æ„ï¼ˆé€šå¸¸æ˜¯ 6 å±‚ï¼‰ ç»„æˆï¼Œæ¯ä¸€å±‚çš„ç»“æ„å‡ ä¹ä¸€æ ·ï¼Œæ¯å±‚åŒ…å«ä¸¤ä¸ªä¸»è¦å­å±‚ï¼š\nè¾“å…¥ â†’ [å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶] â†’ [å‰é¦ˆç¥ç»ç½‘ç»œ] â†’ è¾“å‡º\n\nå¹¶ä¸”æ¯ä¸ªå­å±‚åéƒ½æœ‰ï¼š\n\næ®‹å·®è¿æ¥ï¼ˆResidual Connectionï¼‰\nå±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰\n\nRNNï¼šé€ä¸ªæ—¶é—´æ­¥å¤„ç†åºåˆ—ï¼Œæœ‰è®°å¿†ä½†æ…¢ã€‚\nTransformer Encoderï¼šä¸€æ¬¡æ€§å¤„ç†å…¨åºåˆ—ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ â€œå¹¶è¡Œæ„ŸçŸ¥â€ æ‰€æœ‰è¯ä¹‹é—´çš„å…³ç³»ï¼Œé€Ÿåº¦å¿«ã€æ•ˆæœå¥½ã€‚\nè¯´ç™½äº†è¿˜æ˜¯åœ¨å¼„ä¸€ä¸ªè¯å‘é‡ï¼Œåªä¸è¿‡è¿™ä¸ªè¯å‘é‡æ›´åŠ ä¼˜ç§€ï¼ï¼\næ¯ä¸ª Encoder Layer éƒ½åŒ…å«ä¸¤ä¸ªå­å±‚ï¼ˆsublayerï¼‰ï¼Œåˆ†åˆ«æ˜¯è‡ªæ³¨æ„åŠ›å­å±‚ï¼ˆSelf-Attention Sublayerï¼‰å’Œå‰é¦ˆç¥ç»ç½‘ç»œå­å±‚ï¼ˆFeed-Forward Sublayerï¼‰ã€‚\n\n# è‡ªæ³¨æ„åŠ›å±‚\nè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ç¬¬ä¸€æ­¥ï¼Œæ˜¯å°†è¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®è¡¨ç¤ºæ˜ å°„ä¸ºä¸‰ä¸ªä¸åŒçš„å‘é‡ï¼Œåˆ†åˆ«æ˜¯ æŸ¥è¯¢ï¼ˆQueryï¼‰ã€é”®ï¼ˆKeyï¼‰ å’Œ å€¼ï¼ˆValueï¼‰ã€‚\n\nQueryï¼šè¡¨ç¤ºå½“å‰è¯çš„ç”¨äºå‘èµ·æ³¨æ„åŠ›åŒ¹é…çš„å‘é‡ï¼›\nKeyï¼šè¡¨ç¤ºåºåˆ—ä¸­æ¯ä¸ªä½ç½®çš„å†…å®¹æ ‡è¯†ï¼Œç”¨äºä¸ Query è¿›è¡ŒåŒ¹é…ï¼›\nValueï¼šè¡¨ç¤ºè¯¥ä½ç½®æºå¸¦çš„ä¿¡æ¯ï¼Œç”¨äºåŠ æƒæ±‡æ€»å¾—åˆ°æ–°çš„è¡¨ç¤ºã€‚\nè‡ªæ³¨æ„åŠ›çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šæ¯ä¸ªä½ç½®ç”¨è‡ªèº«çš„ Query å‘é‡ï¼Œä¸æ•´ä¸ªåºåˆ—ä¸­æ‰€æœ‰ä½ç½®çš„ Key å‘é‡è¿›è¡Œç›¸å…³æ€§è®¡ç®—ï¼Œä»è€Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡ï¼Œå¹¶æ®æ­¤å¯¹å¯¹åº”çš„ Value å‘é‡åŠ æƒæ±‡æ€»ï¼Œå½¢æˆæ–°çš„è¡¨ç¤ºã€‚\nå®Œæˆ Queryã€Keyã€Value å‘é‡çš„ç”Ÿæˆåï¼Œæ¨¡å‹ä¼šä½¿ç”¨æ¯ä¸ªä½ç½®çš„ Query å‘é‡ä¸æ‰€æœ‰ä½ç½®çš„ Key å‘é‡è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ã€‚\nåœ¨å¾—åˆ°æ¯ä¸ªä½ç½®ä¸æ‰€æœ‰ä½ç½®ä¹‹é—´çš„ç›¸å…³æ€§è¯„åˆ†åï¼Œæ¨¡å‹ä¼šä½¿ç”¨ softmax å‡½æ•°è¿›è¡Œå½’ä¸€åŒ–ï¼Œç¡®ä¿æ¯ä¸ªä½ç½®å¯¹æ‰€æœ‰ä½ç½®çš„å…³æ³¨ç¨‹åº¦ä¹‹å’Œä¸º 1ï¼Œä»è€Œå½¢æˆä¸€ä¸ªæœ‰æ•ˆçš„åŠ æƒåˆ†å¸ƒã€‚å¯¹äºæ•´ä¸ªåºåˆ—ï¼Œæ¨¡å‹è¦åšçš„æ˜¯å¯¹ä¹‹å‰å¾—åˆ°çš„æ³¨æ„åŠ›è¯„åˆ†çŸ©é˜µçš„æ¯ä¸€è¡Œè¿›è¡Œ softmax å½’ä¸€åŒ–ã€‚\n\n\nç»¼ä¸Šï¼š\n\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n$$\n# å‰é¦ˆç¥ç»ç½‘ç»œå±‚\n\n# Transformer çš„ Decoder\nè§£ç å™¨æ¥æ”¶ç¼–ç å™¨ç”Ÿæˆçš„è¯å‘é‡ï¼Œç„¶åé€šè¿‡è¿™ä¸ªè¯å‘é‡ç”Ÿæˆç¿»è¯‘çš„ç»“æœã€‚\n# æ³¨æ„åŠ›ä¸å¤šå¤´æ³¨æ„åŠ›\nimport torchimport torch.nn as nnimport mathclass SelfAttention(nn.Module):    def __init__(self, dropout=0.1) -> None:        super().__init__()        self.dropout = nn.Dropout(dropout)  # å¯¹ 10% çš„æ•°æ®è¿›è¡Œ dropoutï¼Œé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆ        self.softmax = nn.Softmax(dim=-1)  # å¯¹æœ€åä¸€ç»´è¿›è¡Œ softmaxï¼Œä¸ºä»€ä¹ˆæ˜¯æœ€åä¸€ä¸ªç»´åº¦ï¼Ÿ        # å› ä¸ºæ˜¯å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ‰€ä»¥æ˜¯å¤šä¸ªå¤´ï¼Œæ¯ä¸ªå¤´å¯¹è¾“å…¥è¿›è¡Œ softmax    def forward(self, Q, K, V, mask=None):        # X: [batch_size, seq_len, d_model]        # batch_size: æ‰¹æ¬¡å¤§å°ï¼Œä¸€æ¬¡é€å‡ ä¸ªå¥å­        # seq_len: åºåˆ—é•¿åº¦ï¼Œä¸€ä¸ªå¥å­ä¸­çš„ Token æ•°é‡        # d_model: æ¨¡å‹ç»´åº¦ï¼Œè¿™æ˜¯ä¸ª Embedding å‘é‡çš„ç»´åº¦        # Qï¼šquery å‘é‡     [batch_size, heads, seq_len_q, d_k]        # Kï¼škey å‘é‡       [batch_size, heads, seq_len_k, d_k]        # Vï¼švalues å‘é‡    [batch_size, heads, seq_len) v, d_v]        # maskï¼šæ©ç å‘é‡    [batch_size, seq_len, seq_len]   mask çš„æ„ä¹‰æ˜¯é‚£äº›éœ€è¦å¿½ç•¥ï¼Œä¸è¦çœ‹è§æœªæ¥çš„ä¿¡æ¯        d_k = Q.size(-1)        # Qï¼š                [batch_size, heads, seq_len_q, d_k]       seq_len_q, d_k        # K.T:               [batch_size, heads, d_k, seq_len_k]      d_k, seq_len_k        # attention_scoresï¼š [batch_size, heads, seq_len_q, seq_len_k]        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)  # (QÂ·K.T)/sqrt(d_k)        # å¦‚æœæä¾›äº† maskï¼Œmasked_fill åˆ™å°† mask ä¸­çš„å€¼ä¸º 0 çš„å…ƒç´ æ›¿æ¢ä¸ºè´Ÿæ— ç©·å¤§        if mask is not None:            attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))        # è·å–æ³¨æ„åŠ›æƒé‡ï¼Œå¯¹æœ€åä¸€ä½è¿›è¡Œ softmax        attn = self.softmax(attention_scores)        attn = self.dropout(attn)        # è·å–æ³¨æ„åŠ›ç»“æœï¼Œå¯¹ V è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œ[batch_size, heads, seq_len_q, d_v]        output = torch.matmul(attn, V)        return output, attnclass MultiHeadAttention(nn.Module):    def __init__(self, d_model, n_heads, dropout=0.1) -> None:        super().__init__()        # d_model: æ¨¡å‹ç»´åº¦ï¼Œè¿™æ˜¯ä¸ª Embedding å‘é‡çš„ç»´åº¦ï¼Œä¸€èˆ¬æ˜¯ 512        # n_heads: å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„ä¸ªæ•°ï¼Œä¸€èˆ¬æ˜¯ 8        assert d_model % n_heads == 0        self.d_k = d_model // n_heads        self.n_heads = n_heads        self.W_q = nn.Linear(d_model, d_model)        self.W_k = nn.Linear(d_model, d_model)        self.W_v = nn.Linear(d_model, d_model)        self.fc = nn.Linear(d_model, d_model)        self.attention = SelfAttention(dropout)        self.layer_norm = nn.LayerNorm(d_model)        self.dropout = nn.Dropout(dropout)    def forward(self, q, k, v, mask=None):        batch_size = q.size(0)        # Q: [batch_size, seq_len, d_model] -> [batch_size, n_heads, seq_len, d_k]        # ä¸ºäº†è·å–å¤šå¤´æ³¨æ„åŠ›ï¼Œéœ€è¦å°†è¾“å…¥è¿›è¡Œåˆ†å‰²ï¼Œåˆ†å‰²æˆå¤šä¸ªå¤´ï¼Œæ¯ä¸ªå¤´å¯¹è¾“å…¥è¿›è¡Œè®¡ç®—ï¼Œç„¶åè¿›è¡Œæ‹¼æ¥        Q = self.W_q(q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)        K = self.W_k(k).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)        V = self.W_v(v).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)        output, attn = self.attention(Q, K, V, mask)        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_k)        output = self.fc(output)        output = self.layer_norm(q + self.dropout(output))        return output, attn# Torch ä¸­ä½¿ç”¨ TransformerAPI\ntorch.nn.Transformer(d_model=512,                      nhead=8,                      num_encoder_layers=6,                      num_decoder_layers=6,                      dim_feedforward=2048,                      dropout=0.1,                      activation='relu',                      custom_encoder=None,                      custom_decoder=None,                      layer_norm_eps=1e-05,                      batch_first=False,                      norm_first=False,                      bias=True,                      device=None,                      dtype=None)# transformer\nfrom torch import nn# åˆå§‹åŒ– Transformertransformer = nn.Transformer(  d_model=512,   nhead=8,   num_encoder_layers=6,   num_decoder_layers=6,   batch_first=True)# forward\noutput = transformer(    src=src_emb,    tgt=tgt_emb,    src_key_padding_mask=src_pad_mask,    tgt_key_padding_mask=tgt_pad_mask,    tgt_mask=tgt_mask,    memory_key_padding_mask=src_pad_mask)# encoder\nfrom torch import nn# åˆå§‹åŒ– Transformertransformer = nn.Transformer(    d_model=512, nhead=8,    num_encoder_layers=6, num_decoder_layers=6,    batch_first=True)# è°ƒç”¨ç¼–ç å™¨memory = transformer.encoder(    src=src_emb,     src_key_padding_mask=src_pad_mask)# decoder\nfrom torch import nn# åˆå§‹åŒ– Transformertransformer = nn.Transformer(    d_model=512, nhead=8,    num_encoder_layers=6, num_decoder_layers=6,    batch_first=True)# è°ƒç”¨ç¼–ç å™¨memory = transformer.encoder(    src=src_emb,     src_key_padding_mask=src_pad_mask)# è°ƒç”¨è§£ç å™¨ï¼ˆé€æ­¥ç”Ÿæˆï¼‰output = transformer.decoder(    tgt=tgt_emb,    memory=memory,    tgt_mask=tgt_mask,    tgt_key_padding_mask=tgt_pad_mask,    memory_key_padding_mask=src_pad_mask)# å‚è€ƒæ–‡çŒ®\n\nã€[æ‰‹æŠŠæ‰‹æ•™å­¦] åŸºäº RNNã€LSTM ç¥ç»ç½‘ç»œå•ç‰¹å¾ç”¨ç”µè´Ÿè·é¢„æµ‹ã€‘https://www.bilibili.com/video/BV1HN4y1Y7Lt\nã€å°šç¡…è°· NLP æ•™ç¨‹ï¼Œnlp è‡ªç„¶è¯­è¨€å¤„ç†ï¼ŒTransformerã€LSTMã€BERT ç­‰å¤§æ¨¡å‹æŠ€æœ¯å…¨è¦†ç›–ã€‘https://www.bilibili.com/video/BV1k44LzPEhU\nã€Word2Vec æ¨¡å‹ã€Attentionã€Transformer ã€‘https://space.bilibili.com/383551518\nã€Transformer æ¨¡å‹è¯¦è§£ï¼ˆå›¾è§£æœ€å®Œæ•´ç‰ˆï¼‰ã€‘https://zhuanlan.zhihu.com/p/338817680\nã€é»‘é©¬ç¨‹åºå‘˜ AI å¤§æ¨¡å‹ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹ã€‘https://www.bilibili.com/video/BV1c5yrBcEEX\n\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","æ·±åº¦å­¦ä¹ ","RNN","LSTM","NLP","GRU","Transformer"]},{"title":"Transformerå®æˆ˜","url":"/python/Transformer/","content":"# Transformer å®æˆ˜\n# èƒŒæ™¯\nä¸ºäº†è§£å†³åœ¨åºåˆ—å»ºæ¨¡ä¸­æå‡å¹¶è¡Œä¸é•¿è·ç¦»ä¾èµ–å»ºæ¨¡èƒ½åŠ›ï¼Œæ‘†è„±å¯¹å¾ªç¯ä¸å·ç§¯çš„ä¾èµ–ã€‚å…¶æ ¸å¿ƒæ˜¯ç¼–ç å™¨ä¸è§£ç å™¨ç»“æ„ã€‚\nå…¶ä¸­æœ‰ä¸‰ç§æ³¨æ„åŠ›æœºåˆ¶ï¼šç¼–ç å™¨å¤šå¤´æ³¨æ„åŠ›ã€äº¤å‰æ³¨æ„åŠ›ã€è§£ç å™¨å¤šå¤´æ³¨æ„åŠ›ï¼ˆå«å› æœç¼–ç ï¼‰\n\n# è¾“å…¥æ•°æ®\nTransformer é‡Œè®¡ç®—çš„å…¨æ˜¯æ•°å€¼ï¼Œåœ¨è¾“å‡ºä¹‹åå’Œè¾“å‡ºä¹‹å‰ï¼Œéƒ½è¦æŠŠè¯è½¬æ¢ä¸ºè¯å‘é‡ï¼Œæˆ–è€…å°†è¯è¯å‘é‡è½¬åŒ–ä¸ºè¯ã€‚\n# è¯åµŒå…¥ï¼ˆWord Embeddingï¼‰\n\nè¿™ä¸ªè¯åµŒå…¥çŸ©é˜µçš„ d ç›¸å½“äºå‹ç¼©åè¯å‘é‡çš„å¤§å°ï¼ˆç»´åº¦ï¼‰ã€‚\n\n# ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰\n\n# è‡ªæ³¨æ„åŠ›æœºåˆ¶\nè‡ªæ³¨æ„åŠ›æœºåˆ¶è®©æ¯ä¸ªè¾“å…¥ä½ç½®éƒ½èƒ½åŠ¨æ€åœ°æ ¹æ®ä¸å…¶ä»–ä½ç½®çš„ç›¸å…³æ€§é‡æ–°è¡¨ç¤ºè‡ªå·±ï¼Œä»è€Œå®ç°äº†ä¿¡æ¯çš„å…¨å±€å»ºæ¨¡ä¸åŠ¨æ€åŠ æƒèåˆã€‚\n\n# å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶\n\n# æ©ç æ³¨æ„åŠ›ï¼ˆæ¨ç†ï¼‰\n\n# äº¤å‰æ³¨æ„åŠ›\n\n# å‚è€ƒæ–‡çŒ®\n\nã€Transformer ç®—æ³•åŸç†ä¸å®æˆ˜ã€‘https://www.bilibili.com/video/BV1ej1EBWEWu\n\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","Transformer"]},{"title":"Methods and datasets on semantic segmentation for Unmanned Aerial Vehicle remote sensing imagesï¼šA review","url":"/paper/review_remote_sensing_m_d/","content":"# Methods and datasets on semantic segmentation for Unmanned Aerial Vehicle remote sensing images: A review\n\n\nã€Original Linkã€‘ Methods and datasets on semantic segmentation for Unmanned Aerial Vehicle remote sensing imagesï¼šA review\nDepartment of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, 611731, Sichuan, PR China\nVolume 211, May 2024, Pages 1-34\nAuthors\n\nJian Cheng\nChangjian Deng\nYanzhou Su\nZeyu An\nQi Wang\n\n\n\n\n# Abstract\nUnmanned Aerial Vehicle (UAV) has seen a dramatic rise in popularity for remote-sensing image acquisition and analysis in recent years.\nè¿‘å¹´æ¥ï¼Œæ— äººæœºï¼ˆUAVï¼‰åœ¨é¥æ„Ÿå›¾åƒé‡‡é›†å’Œåˆ†æé¢†åŸŸçš„æµè¡Œåº¦å¤§å¹…ä¸Šå‡ã€‚\nIt has brought promising results in low-altitude monitoring tasks that require detailed visual inspections.\nå®ƒåœ¨éœ€è¦è¯¦ç»†ç›®è§†æ£€æŸ¥çš„ä½ç©ºç›‘æµ‹ä»»åŠ¡ä¸­å–å¾—äº†ä»¤äººé¼“èˆçš„æˆæœã€‚\nSemantic segmentation is one of the hot topics in UAV remote sensing image analysis, as its capability to mine contextual semantic information from UAV images is crucial for achieving a fine-grained understanding of scenes.\nè¯­ä¹‰åˆ†å‰²æ˜¯æ— äººæœºé¥æ„Ÿå›¾åƒåˆ†æä¸­çš„çƒ­é—¨è¯é¢˜ä¹‹ä¸€ï¼Œå…¶ä»æ— äººæœºå›¾åƒä¸­æŒ–æ˜ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯çš„èƒ½åŠ›å¯¹äºå®ç°å¯¹åœºæ™¯çš„ç»†è‡´ç†è§£è‡³å…³é‡è¦ã€‚\nHowever, in the remote sensing field, recent reviews have not focused on combining â€˜â€˜UAV remote sensingâ€™â€™ and â€˜â€˜semantic segmentationâ€™â€™ to summarize the advanced works and future trends.\nç„¶è€Œï¼Œåœ¨é¥æ„Ÿé¢†åŸŸï¼Œè¿‘æœŸç»¼è¿°å¹¶æœªå°† â€œæ— äººæœºé¥æ„Ÿâ€ ä¸ â€œè¯­ä¹‰åˆ†å‰²â€ ç»“åˆèµ·æ¥ï¼Œä»¥æ€»ç»“å…ˆè¿›çš„å·¥ä½œæˆæœå’Œæœªæ¥è¶‹åŠ¿ã€‚\nIn this study, we focus primarily on describing various recent semantic segmentation methods applied in UAV remote sensing images and summarizing their advantages and limitations. According to the distinction in modeling contextual semantic information, we have categorized and outlined the methods based on graph-based contextual models and deep-learning-based models.\næœ¬ç ”ç©¶ä¸»è¦ä»‹ç»äº†æ— äººæœºé¥æ„Ÿå›¾åƒä¸­åº”ç”¨çš„å„ç§è¿‘æœŸè¯­ä¹‰åˆ†å‰²æ–¹æ³•ï¼Œå¹¶æ€»ç»“å…¶ä¼˜ç¼ºç‚¹ã€‚æ ¹æ®å¯¹ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯å»ºæ¨¡çš„åŒºåˆ†ï¼Œæˆ‘ä»¬åŸºäºåŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹å¯¹æ–¹æ³•è¿›è¡Œäº†åˆ†ç±»å’Œæ¦‚è¿°ã€‚\nPublicly available UAV-based image datasets are also gathered to encourage systematic research on advanced semantic segmentation methods. We provide quantitative results of representative methods on two high-resolution UAV-based image datasets for fair comparisons and discussions in terms of semantic segmentation accuracy and model inference efficiency.\nè¿˜æ”¶é›†äº†å…¬å¼€å¯ç”¨çš„æ— äººæœºå›¾åƒæ•°æ®é›†ï¼Œä»¥é¼“åŠ±ç³»ç»Ÿæ€§ç ”ç©¶é«˜çº§è¯­ä¹‰åˆ†å‰²æ–¹æ³•ã€‚æˆ‘ä»¬æä¾›äº†ä¸¤ç§é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒæ•°æ®é›†ä¸­ä»£è¡¨æ€§æ–¹æ³•çš„å®šé‡ç»“æœï¼Œä»¥ä¾¿å…¬å¹³æ¯”è¾ƒå’Œè®¨è®ºè¯­ä¹‰åˆ†å‰²å‡†ç¡®æ€§å’Œæ¨¡å‹æ¨æ–­æ•ˆç‡ã€‚\nBesides, this paper concludes some remaining challenges and future directions in semantic segmentation for UAV remote sensing images and points out that methods based on deep learning will become the future research trend.\næ­¤å¤–ï¼Œæœ¬æ–‡æ€»ç»“äº†æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²ä¸­å‰©ä½™çš„ä¸€äº›æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ï¼Œå¹¶æŒ‡å‡ºåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•å°†æˆä¸ºæœªæ¥ç ”ç©¶è¶‹åŠ¿ã€‚\n# Introduction\nSemantic segmentation is the process of dividing an image into disjoint regions of the same class or semantics and labeling these regions with pixel-level annotations, where each pixel of the given image requires a label of the desired object class (Yu et al., 2018b; Mo et al., 2022).\nè¯­ä¹‰åˆ†å‰²æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºåŒä¸€ç±»æˆ–è¯­ä¹‰çš„ä¸ç›¸äº¤åŒºåŸŸï¼Œå¹¶ç”¨åƒç´ çº§æ³¨é‡Šæ ‡è®°è¿™äº›åŒºåŸŸçš„è¿‡ç¨‹ï¼Œå…¶ä¸­ç»™å®šå›¾åƒçš„æ¯ä¸ªåƒç´ éƒ½éœ€è¦å¯¹ç›®æ ‡å¯¹è±¡ç±»åˆ«è¿›è¡Œæ ‡ç­¾ï¼ˆYu ç­‰ï¼Œ2018b;Mo ç­‰ï¼Œ2022ï¼‰ã€‚\nUnlike image classification, which identifies the primary content of an entire image and categorizes it into a specific class, semantic segmentation provides detailed delineations of multiple classes and their respective regions in the image (Yuan et al., 2021)\nä¸å›¾åƒåˆ†ç±»ä¸åŒï¼Œåè€…æ˜¯è¯†åˆ«æ•´å¼ å›¾åƒçš„ä¸»è¦å†…å®¹å¹¶å°†å…¶å½’ç±»åˆ°ç‰¹å®šç±»åˆ«ï¼Œè¯­ä¹‰åˆ†å‰²åˆ™æä¾›äº†å›¾åƒä¸­å¤šä¸ªç±»åˆ«åŠå…¶ç›¸åº”åŒºåŸŸçš„è¯¦ç»†åˆ’åˆ†ï¼ˆYuan ç­‰ï¼Œ2021ï¼‰\nIn fact, image semantic segmentation is derived from image segmentation (Ohta et al., 1978), but puts more emphasis on capturing the semantic information of spatial context, so that the segmented areas have semantic meaning.\näº‹å®ä¸Šï¼Œå›¾åƒè¯­ä¹‰åˆ†å‰²æºè‡ªå›¾åƒåˆ†å‰²ï¼ˆOhta ç­‰ï¼Œ1978ï¼‰ï¼Œä½†æ›´å¼ºè°ƒæ•æ‰ç©ºé—´ä¸Šä¸‹æ–‡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½¿åˆ†å‰²åŒºåŸŸå…·æœ‰è¯­ä¹‰æ„ä¹‰ã€‚\nIt is the perceptual basis of many computer vision tasks and has been widely employed in diverse image analysis applications, such as the natural and medical image parsing (Yu et al., 2018b; Guo et al., 2018; Asgari Taghanaki et al., 2021), automatic driving systems (Siam et al., 2017; Feng et al., 2020), road extraction (Abdollahi et al., 2020), perception of urban features (Neupane et al., 2021), landuse mapping (Zang et al., 2021), and many others.\nå®ƒæ˜¯è®¸å¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„æ„ŸçŸ¥åŸºç¡€ï¼Œå¹¶è¢«å¹¿æ³›åº”ç”¨äºå¤šç§å›¾åƒåˆ†æé¢†åŸŸï¼Œå¦‚è‡ªç„¶å’ŒåŒ»å­¦å›¾åƒè§£æï¼ˆYu ç­‰ï¼Œ2018b;Guo ç­‰ï¼Œ2018;Asgari Taghanaki ç­‰ï¼Œ2021ï¼‰ï¼Œè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼ˆSiam ç­‰ï¼Œ2017;Feng ç­‰ï¼Œ2020ï¼‰ã€é“è·¯æå–ï¼ˆAbdollahi ç­‰ï¼Œ2020ï¼‰ã€åŸå¸‚ç‰¹å¾æ„ŸçŸ¥ï¼ˆNeupane ç­‰ï¼Œ2021ï¼‰ã€åœŸåœ°åˆ©ç”¨åœ°å›¾ç»˜åˆ¶ï¼ˆZang ç­‰ï¼Œ2021ï¼‰ç­‰ã€‚\nRemote sensing images collected by various platforms, such as satellites, aircraft, and UAVs (Toth and JÃ³zÌkÃ³w, 2016; Bhardwaj et al., 2016), provide the data basis for semantic segmentation.\né¥æ„Ÿå›¾åƒç”±å«æ˜Ÿã€é£æœºå’Œæ— äººæœºç­‰å¤šç§å¹³å°æ”¶é›†çš„å›¾åƒï¼ˆToth å’Œ JÃ³ÅºkÃ³wï¼Œ2016;Bhardwaj ç­‰ï¼Œ2016ï¼‰ï¼Œä¸ºè¯­ä¹‰åˆ†å‰²æä¾›äº†æ•°æ®åŸºç¡€ã€‚\nThe continuously evolving semantic segmentation technology not only demonstrates superior performance in diverse and data-rich remote sensing problems (Ball et al., 2017; Yuan et al., 2021), but its integration with UAVs also offers a feasible solution for the fine-grained scene analysis of low-altitude remote sensing (Toth and JÃ³zÌkÃ³w, 2016; Bhardwaj et al., 2016; Yao et al., 2019; Nex et al., 2022; Zhang and Zhu, 2023).\næŒç»­æ¼”è¿›çš„è¯­ä¹‰åˆ†å‰²æŠ€æœ¯ä¸ä»…åœ¨å¤šæ ·ä¸”æ•°æ®ä¸°å¯Œçš„é¥æ„Ÿé—®é¢˜ä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼ˆBall ç­‰ï¼Œ2017;Yuan ç­‰ï¼Œ2021ï¼‰ï¼Œå…¶ä¸æ— äººæœºçš„é›†æˆä¹Ÿä¸ºä½ç©ºé¥æ„Ÿçš„ç»†ç²’åº¦åœºæ™¯åˆ†ææä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼ˆToth å’Œ JÃ³ÅºkÃ³wï¼Œ2016;Bhardwaj ç­‰ï¼Œ2016;Yao ç­‰ï¼Œ2019;Nex ç­‰ï¼Œ2022;Zhang å’Œ Zhuï¼Œ2023ï¼‰ã€‚\nThe UAV platforms, also known as aerial robots or drones, have demonstrated many unique advantages compared with satellite remote sensing platforms, such as lower flight altitude close to the ground surface, well-controlled path planning without the restriction of revisit intervals, flexible flight schedules to access specific areas, flexible optical sensor integration, and especially, lower developing and operational costs for commercial and academic purposes (Yao et al., 2019; Osco et al., 2021; Zhang and Zhu, 2023).\næ— äººæœºå¹³å°ï¼Œä¹Ÿç§°ä¸ºç©ºä¸­æœºå™¨äººæˆ–æ— äººæœºï¼Œç›¸æ¯”å«æ˜Ÿé¥æ„Ÿå¹³å°å±•ç°å‡ºè®¸å¤šç‹¬ç‰¹ä¼˜åŠ¿ï¼Œå¦‚é è¿‘åœ°é¢çš„è¾ƒä½é£è¡Œé«˜åº¦ã€æ— é‡è®¿é—´éš”é™åˆ¶çš„è‰¯å¥½è·¯å¾„è§„åˆ’ã€çµæ´»çš„é£è¡Œè®¡åˆ’ä»¥è¿›å…¥ç‰¹å®šåŒºåŸŸã€çµæ´»çš„å…‰å­¦ä¼ æ„Ÿå™¨é›†æˆï¼Œå°¤å…¶æ˜¯åœ¨å•†ä¸šå’Œå­¦æœ¯ç”¨é€”ä¸Šæ›´ä½çš„å¼€å‘å’Œè¿è¥æˆæœ¬ï¼ˆYao ç­‰ï¼Œ2019;Osco ç­‰ï¼Œ2021;Zhang å’Œ Zhuï¼Œ2023ï¼‰ã€‚\n\nThanks to the flexibility of flying altitudes and sensor integration, UAVs are suitable for resource management and visual inspection tasks that require high labor costs or may affect personal safety, such as bridge condition assessment (Liang et al., 2023), insulator inspections (Ma et al., 2021), early wildfire detection (Bouguettaya et al., 2022c), and bridge damage detection (Feroz and Abu Dabous, 2021).\nå¾—ç›Šäºé£è¡Œé«˜åº¦çš„çµæ´»æ€§å’Œä¼ æ„Ÿå™¨é›†æˆï¼Œæ— äººæœºé€‚åˆèµ„æºç®¡ç†å’Œç›®è§†æ£€æŸ¥ä»»ï¼Œè¿™äº›éœ€è¦é«˜äººå·¥æˆæœ¬æˆ–å¯èƒ½å½±å“ä¸ªäººå®‰å…¨çš„ä»»åŠ¡ï¼Œå¦‚æ¡¥æ¢çŠ¶å†µè¯„ä¼°ï¼ˆLiang ç­‰ï¼Œ2023ï¼‰ã€ç»ç¼˜ä½“æ£€æŸ¥ï¼ˆé©¬ç­‰ï¼Œ2021ï¼‰ã€æ—©æœŸé‡ç«æ£€æµ‹ï¼ˆå¸ƒç›–å¡”äºšç­‰ï¼Œ2022cï¼‰ä»¥åŠæ¡¥æ¢æŸåæ£€æµ‹ï¼ˆè´¹ç½—å…¹å’Œé˜¿å¸ƒè¾¾å¸ƒæ–¯ï¼Œ2021ï¼‰ã€‚\nThe hopeful prospect of UAV applications has been well demonstrated and tested in the current literature.\næ— äººæœºåº”ç”¨çš„å‰æ™¯åœ¨ç°æœ‰æ–‡çŒ®ä¸­å·²è¢«å……åˆ†éªŒè¯å’ŒéªŒè¯ã€‚\nFor instance, in forestry applications (Torresan et al., 2017; GuimaraÌƒes et al., 2020; Diez et al., 2021), some efforts apply UAVs to pest infestation monitoring (Lehmann et al., 2015), forest fire detection (Yuan et al., 2015), individual tree detection (Chadwick et al., 2020; Gibril et al., 2021), tree species classification (Fujimoto et al., 2019; Kentsch et al., 2020; Egli and HÃ¶pke, 2020), among others.\nä¾‹å¦‚ï¼Œåœ¨æ—ä¸šåº”ç”¨ä¸­ï¼ˆTorresan ç­‰ï¼Œ2017;GuimarÃ£es ç­‰ï¼Œ2020;Diez ç­‰ï¼Œ2021ï¼‰ï¼Œéƒ¨åˆ†ç ”ç©¶å°†æ— äººæœºåº”ç”¨äºå®³è™«ä¾µæ‰°ç›‘æµ‹ï¼ˆLehmann ç­‰ï¼Œ2015ï¼‰ã€æ£®æ—ç«ç¾æ£€æµ‹ï¼ˆYuan ç­‰ï¼Œ2015ï¼‰ã€å•æ£µæ ‘æœ¨æ£€æµ‹ï¼ˆChadwick ç­‰ï¼Œ2020;Gibril ç­‰ï¼Œ2021ï¼‰ï¼Œæ ‘ç§åˆ†ç±»ï¼ˆFujimoto ç­‰ï¼Œ2019;Kentsch ç­‰ï¼Œ2020;Egli å’Œ HÃ¶pkeï¼Œ2020ï¼‰ï¼Œç­‰ã€‚\nIn damage assessment tasks, relevant literature has demonstrated the efficiency and adaptability of analyzing structure cracks (Zhong et al., 2018; Han et al., 2022), bridge inspection and management (Ayele et al., 2020; Feroz and Abu Dabous, 2021), and disaster damage mapping (Kerle et al., 2019).\nåœ¨æŸä¼¤è¯„ä¼°ä»»åŠ¡ä¸­ï¼Œç›¸å…³æ–‡çŒ®å·²è¯æ˜ç»“æ„è£‚çº¹åˆ†æçš„æ•ˆç‡å’Œé€‚åº”æ€§ï¼ˆZhong ç­‰ï¼Œ2018;Han ç­‰ï¼Œ2022ï¼‰ï¼Œæ¡¥æ¢æ£€æŸ¥ä¸ç®¡ç†ï¼ˆAyele ç­‰ï¼Œ2020;Feroz å’Œ Abu Dabousï¼Œ2021ï¼‰ï¼Œä»¥åŠç¾å®³æŸå®³æµ‹ç»˜ï¼ˆKerle ç­‰ï¼Œ2019ï¼‰ã€‚\nIn precision agriculture (AdaÌƒo et al., 2017; Tsouros et al., 2019), many advanced works have focused on weed mapping (Huang et al., 2018a; Sa et al., 2018; Deng et al., 2020), crop lodging detection (Song et al., 2020; Yang et al., 2020; Su et al., 2022), vegetation growth and health monitoring (Jung et al., 2018; Han et al., 2018; Kerkech et al., 2018, 2020), and many others.\nåœ¨ç²¾å‡†å†œä¸šä¸­ï¼ˆAdÃ£o ç­‰ï¼Œ2017;Tsouros ç­‰ï¼Œ2019ï¼‰ï¼Œè®¸å¤šå…ˆè¿›ç ”ç©¶èšç„¦äºæ‚è‰æµ‹ç»˜ï¼ˆHuang ç­‰ï¼Œ2018a;Sa ç­‰ï¼Œ2018; é‚“ç­‰ï¼Œ2020ï¼‰ï¼Œä½œç‰©å€’ä¼æ£€æµ‹ï¼ˆå®‹ç­‰ï¼Œ2020;Yang ç­‰ï¼Œ2020;Su ç­‰ï¼Œ2022ï¼‰ï¼Œæ¤è¢«ç”Ÿé•¿ä¸å¥åº·ç›‘æµ‹ï¼ˆJung ç­‰ï¼Œ2018;Han ç­‰ï¼Œ2018;Kerkech ç­‰ï¼Œ2018,2020ï¼‰ï¼Œä»¥åŠè®¸å¤šå…¶ä»–ç ”ç©¶ã€‚\nMoreover, other literature in which the use of UAV delivered promising results in monitoring and counting wildlife (Chamoso et al., 2014; Sundaram and Loganathan, 2020), land use and land cover (LULC) (Zhang et al., 2017; Al-Najjar et al., 2019), urban mapping (Chen et al., 2018c; Lyu et al., 2020), and 3D mapping applications (Nex and Remondino, 2014; KÃ¶lle et al., 2021).\næ­¤å¤–ï¼Œå…¶ä»–æ–‡çŒ®ä¸­æ— äººæœºåœ¨ç›‘æµ‹å’Œè®¡æ•°é‡ç”ŸåŠ¨ç‰©æ–¹é¢å–å¾—äº†æœ‰å¸Œæœ›çš„æˆæœï¼ˆChamoso ç­‰ï¼Œ2014;Sundaram å’Œ Loganathanï¼Œ2020ï¼‰ï¼ŒåœŸåœ°åˆ©ç”¨ä¸åœŸåœ°è¦†ç›–ï¼ˆLULCï¼‰ï¼ˆZhang ç­‰ï¼Œ2017;Al-Najjar ç­‰ï¼Œ2019ï¼‰ï¼ŒåŸå¸‚åˆ¶å›¾ï¼ˆChen ç­‰ï¼Œ2018c;Lyu ç­‰ï¼Œ2020ï¼‰ï¼Œä»¥åŠä¸‰ç»´æ˜ å°„åº”ç”¨ï¼ˆNex å’Œ Remondinoï¼Œ2014;KÃ¶lle ç­‰ï¼Œ2021ï¼‰ã€‚\nAmong these applications, the combination of UAV remote sensing and image semantic segmentation exhibits several distinctive advantages compared with satellite remote sensing.\nåœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œæ— äººæœºé¥æ„Ÿä¸å›¾åƒè¯­ä¹‰åˆ†å‰²çš„ç»“åˆç›¸æ¯”å«æ˜Ÿé¥æ„Ÿå±•ç°å‡ºå¤šé¡¹ç‹¬ç‰¹ä¼˜åŠ¿ã€‚\nFirstly, UAV-based semantic segmentation is more suitable for practical application scenarios requiring higher temporal and spatial resolution, such as environmental and agricultural monitoring (AdaÌƒo et al., 2017; Tsouros et al., 2019), emergency response (Shamsoshoara et al., 2021), and disaster assessment (Rahnemoonfar et al., 2021; Chowdhury et al., 2022, 2020).\né¦–å…ˆï¼ŒåŸºäºæ— äººæœºçš„è¯­ä¹‰åˆ†å‰²æ›´é€‚åˆéœ€è¦æ›´é«˜æ—¶é—´å’Œç©ºé—´åˆ†è¾¨ç‡çš„å®é™…åº”ç”¨åœºæ™¯ï¼Œå¦‚ç¯å¢ƒå’Œå†œä¸šç›‘æµ‹ï¼ˆAdÃ£o ç­‰ï¼Œ2017;Tsouros ç­‰ï¼Œ2019ï¼‰ã€åº”æ€¥å“åº”ï¼ˆShamsoshoara ç­‰ï¼Œ2021ï¼‰å’Œç¾éš¾è¯„ä¼°ï¼ˆRahnemoonfar ç­‰ï¼Œ2021;Chowdhury ç­‰ï¼Œ2022,2020ï¼‰ã€‚\nBesides, semantic segmentation models can extract diverse and finegrained semantic feature representations from high-resolution remote sensing images captured at different altitudes and angles by UAVs, contributing to the comprehensive understanding of complex scenes from multi-view directions.\næ­¤å¤–ï¼Œè¯­ä¹‰åˆ‡å‰²æ¨¡å‹è¿˜èƒ½ä»æ— äººæœºåœ¨ä¸åŒé«˜åº¦å’Œè§’åº¦æ‹æ‘„çš„é«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒä¸­æå–å¤šæ ·ä¸”ç»†ç²’åº¦çš„è¯­ä¹‰ç‰¹å¾è¡¨ç¤ºï¼Œæœ‰åŠ©äºä»å¤šè§†è§’æ–¹å‘å…¨é¢ç†è§£å¤æ‚åœºæ™¯ã€‚\nHence, UAV-based image semantic segmentation plays a crucial role in image analysis tasks with fine semantic objects and complex backgrounds, such as urban scene perception (Chen et al., 2018c; Nigam et al., 2018; Lyu et al., 2020) and crack detection (Zhong et al., 2018; Feroz and Abu Dabous, 2021; Han et al., 2022; Liang et al., 2023).\nå› æ­¤ï¼ŒåŸºäº UAV çš„å›¾åƒè¯­ä¹‰åˆ†å‰²åœ¨æ¶‰åŠç²¾ç»†è¯­ä¹‰å¯¹è±¡å’Œå¤æ‚èƒŒæ™¯çš„å›¾åƒåˆ†æä»»åŠ¡ä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œå¦‚åŸå¸‚åœºæ™¯æ„ŸçŸ¥ï¼ˆChen ç­‰ï¼Œ2018c;Nigam ç­‰ï¼Œ2018;Lyu ç­‰ï¼Œ2020ï¼‰å’Œè£‚çº¹æ£€æµ‹ï¼ˆZhong ç­‰ï¼Œ2018;Feroz å’Œ Abu Dabousï¼Œ2021;Han ç­‰ï¼Œ2022;Liang ç­‰ï¼Œ2023ï¼‰ã€‚\nAdditionally, autonomous UAVs without human intervention have been the research focus in recent years, which requires UAVs to possess independent capabilities for scene perception, data processing, and decision-making (Nex et al., 2022).\næ­¤å¤–ï¼Œè¿‘å¹´æ¥ç ”ç©¶é‡ç‚¹å…³æ³¨æ— äººæœºè‡ªä¸»æ— äººæœºï¼Œè¦æ±‚æ— äººæœºå…·å¤‡ç‹¬ç«‹çš„åœºæ™¯æ„ŸçŸ¥ã€æ•°æ®å¤„ç†å’Œå†³ç­–èƒ½åŠ›ï¼ˆNex ç­‰ï¼Œ2022ï¼‰ã€‚\nThe development and application of UAV platforms have contributed to the emergence of comprehensive reviews.\næ— äººæœºå¹³å°çš„å‘å±•å’Œåº”ç”¨ä¿ƒè¿›äº†ç»¼åˆè¯„å®¡çš„å‡ºç°ã€‚\nGreat efforts had been made to summarize the research status and specific applications of UAVs in various fields, such as 3D mapping for geomatics applications (Nex and Remondino, 2014), urban land cover classification (Yan et al., 2015), glaciological research and applications (Bhardwaj et al., 2016), automatic cadastral mapping (Crommelinck et al., 2016), agriculture and forestry (AdaÌƒo et al., 2017; GuimaraÌƒes et al., 2020), structural damage mapping (Kerle et al., 2019), monitoring in mining areas (Ren et al., 2019), and cultural heritage and archaeology (Themistocleous, 2020).\nåœ¨æ€»ç»“æ— äººæœºåœ¨å¤šä¸ªé¢†åŸŸçš„ç ”ç©¶ç°çŠ¶å’Œå…·ä½“åº”ç”¨æ–¹é¢ï¼Œå·²ä»˜å‡ºäº†å¤§é‡åŠªåŠ›ï¼Œå¦‚åœ°ç†ä¿¡æ¯æŠ€æœ¯åº”ç”¨çš„ä¸‰ç»´åˆ¶å›¾ï¼ˆNex å’Œ Remondinoï¼Œ2014ï¼‰ã€åŸå¸‚åœŸåœ°è¦†ç›–åˆ†ç±»ï¼ˆYan ç­‰ï¼Œ2015ï¼‰ã€å†°å·å­¦ç ”ç©¶ä¸åº”ç”¨ï¼ˆBhardwaj ç­‰ï¼Œ2016ï¼‰ã€è‡ªåŠ¨åœ°ç±æµ‹ç»˜ï¼ˆCrommelinck ç­‰ï¼Œ2016ï¼‰ã€å†œä¸šå’Œæ—ä¸šï¼ˆAdÃ£o ç­‰ï¼Œ 2017;GuimarÃ£es ç­‰ï¼Œ2020 å¹´ï¼‰ã€ç»“æ„æŸä¼¤æµ‹ç»˜ï¼ˆKerle ç­‰ï¼Œ2019 å¹´ï¼‰ã€çŸ¿åŒºç›‘æµ‹ï¼ˆä»»ç­‰ï¼Œ2019 å¹´ï¼‰ä»¥åŠæ–‡åŒ–é—äº§ä¸è€ƒå¤å­¦ï¼ˆThemistocleousï¼Œ2020 å¹´ï¼‰ã€‚\nThese reviews provided an overview of data acquisition sensors, data processing and data analysis techniques, and practical applications in their respective research fields.\nè¿™äº›ç»¼è¿°æ¦‚è¿°äº†æ•°æ®é‡‡é›†ä¼ æ„Ÿå™¨ã€æ•°æ®å¤„ç†å’Œåˆ†ææŠ€æœ¯åŠå…¶åœ¨å„è‡ªç ”ç©¶é¢†åŸŸçš„å®é™…åº”ç”¨ã€‚\nMoreover, some other reviews were not limited to specific research fields  and comprehensively summarized the advanced technologies, broad applications, and future trends from the UAV-based remote sensing perspective.\næ­¤å¤–ï¼Œä¸€äº›ç»¼è¿°ä¸ä»…é™äºç‰¹å®šç ”ç©¶é¢†åŸŸï¼Œå…¨é¢æ€»ç»“äº†åŸºäºæ— äººæœºçš„é¥æ„ŸæŠ€æœ¯ã€å¹¿æ³›åº”ç”¨å’Œæœªæ¥è¶‹åŠ¿ã€‚\nColomina and Molina (2014) presented a discussion about the evolution and advanced technology of Unmanned Aerial Systems (UAS) in the field of photogrammetry and remote sensing.\nColomina å’Œ Molinaï¼ˆ2014ï¼‰å°±æ— äººæœºç³»ç»Ÿï¼ˆUASï¼‰åœ¨æ‘„å½±æµ‹é‡å’Œé¥æ„Ÿé¢†åŸŸçš„æ¼”å˜ä¸å…ˆè¿›æŠ€æœ¯è¿›è¡Œäº†è®¨è®ºã€‚\nYao et al. (2019) provided a comprehensive review of recent advanced studies involving UAV sensors, data analysis, and their remote sensing applications.\nYao ç­‰äººï¼ˆ2019ï¼‰å¯¹è¿‘æœŸæ¶‰åŠæ— äººæœºä¼ æ„Ÿå™¨ã€æ•°æ®åˆ†æåŠå…¶é¥æ„Ÿåº”ç”¨çš„å…ˆè¿›ç ”ç©¶è¿›è¡Œäº†å…¨é¢ç»¼è¿°ã€‚\nNex et al. (2022) investigated the best practices of remote sensing and mapping applications by UAVs and discussed the future trend and impact. Unfortunately, only a few of these reviews briefly mentioned high-level scene understanding and semantic analysis methods that related to pixel-accurate semantic segmentation for UAV-based images.\nNex ç­‰äººï¼ˆ2022ï¼‰ç ”ç©¶äº†æ— äººæœºé¥æ„Ÿå’Œåˆ¶å›¾åº”ç”¨çš„æœ€ä½³å®è·µï¼Œå¹¶è®¨è®ºäº†æœªæ¥è¶‹åŠ¿å’Œå½±å“ã€‚é—æ†¾çš„æ˜¯ï¼Œåªæœ‰å°‘æ•°ç»¼è¿°ç®€è¦æåŠä¸æ— äººæœºå›¾åƒåƒç´ ç²¾ç¡®è¯­ä¹‰åˆ†å‰²ç›¸å…³çš„é«˜çº§åœºæ™¯ç†è§£å’Œè¯­ä¹‰åˆ†ææ–¹æ³•ã€‚\nFor instance, Crommelinck et al. (2016) and Kerle et al. (2019) had mentioned the applications of random fields and convolutional neural networks for UAV image analysis, but the summary of the characteristics of different data analysis methods is still lacking.\nä¾‹å¦‚ï¼ŒCrommelinck ç­‰ï¼ˆ2016ï¼‰å’Œ Kerle ç­‰ï¼ˆ2019ï¼‰æåˆ°äº†éšæœºåœºå’Œå·ç§¯ç¥ç»ç½‘ç»œåœ¨æ— äººæœºå›¾åƒåˆ†æä¸­çš„åº”ç”¨ï¼Œä½†ä¸åŒæ•°æ®åˆ†ææ–¹æ³•çš„ç‰¹æ€§æ€»ç»“ä»ç„¶ä¸è¶³ã€‚\nNex et al. (2022) briefly summarized commonly used semantic segmentation methods and best practices, but did not analyze the advantages and disadvantages of semantic segmentation methods in detail.\nNex ç­‰äººï¼ˆ2022ï¼‰ç®€è¦æ€»ç»“äº†å¸¸ç”¨çš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•åŠå…¶æœ€ä½³å®è·µï¼Œä½†æœªè¯¦ç»†åˆ†æè¯­ä¹‰åˆ†å‰²æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚\nMore recently, Deep Learning (DL) has a profound impact on remote sensing image semantic segmentation (Kotaridis and Lazaridou, 2021; Neupane et al., 2021; Yuan et al., 2021).\nè¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰å¯¹é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²äº§ç”Ÿäº†æ·±è¿œå½±å“ï¼ˆKotaridis å’Œ Lazaridouï¼Œ2021;Neupane ç­‰ï¼Œ2021;Yuan ç­‰ï¼Œ2021ï¼‰ã€‚\nAs of recently, some literature reviews combining DL and UAV image parsing tasks focus on various approaches within different task-oriented applications.\næœ€è¿‘ï¼Œä¸€äº›ç»“åˆæ·±åº¦å­¦ä¹ å’Œæ— äººæœºå›¾åƒè§£æä»»åŠ¡çš„æ–‡çŒ®ç»¼è¿°èšç„¦äºä¸åŒé¢å‘ä»»åŠ¡çš„åº”ç”¨ä¸­çš„ä¸åŒæ–¹æ³•ã€‚\nFor instance, Bouguettaya et al. (2022c) briefly introduced DL-based algorithms applied to early wildfire detection, such as image classification, object detection, and semantic segmentation.\nä¾‹å¦‚ï¼ŒBouguettaya ç­‰äººï¼ˆ2022cï¼‰ç®€è¦ä»‹ç»äº†åº”ç”¨äºæ—©æœŸé‡ç«æ£€æµ‹çš„åŸºäº DL çš„ç®—æ³•ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ã€‚\nBouguettaya et al. (2022a) reported object-based and pixel-based crop classification methods combining DL-based algorithms.\nBouguettaya ç­‰äººï¼ˆ2022aï¼‰æŠ¥å‘Šäº†ç»“åˆ DL ç®—æ³•çš„åŸºäºå¯¹è±¡å’Œåƒç´ çš„ä½œç‰©åˆ†ç±»æ–¹æ³•ã€‚\nBouguettaya et al. (2022b) summarized various types of DL-based architectures for vehicle detection in UAV images.\nBouguettaya ç­‰äººï¼ˆ2022bï¼‰æ€»ç»“äº†æ— äººæœºå›¾åƒä¸­åŸºäº DL çš„å„ç§è½¦è¾†æ£€æµ‹æ¶æ„ã€‚\nShahi et al. (2023) reviewed the recent advances in crop disease detection of UAV remote sensing based on machine learning and deep learning technologies.\nShahi ç­‰äººï¼ˆ2023ï¼‰å›é¡¾äº†åŸºäºæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„æ— äººæœºé¥æ„Ÿä½œç‰©ç—…å®³æ£€æµ‹çš„æœ€æ–°è¿›å±•ã€‚\nOsco et al. (2021) and Nex et al. (2022) are more concerned with DL-based methods as a future trend for the field of UAV remote sensing.\nOsco ç­‰ï¼ˆ2021ï¼‰å’Œ Nex ç­‰ï¼ˆ2022ï¼‰æ›´å…³æ³¨åŸºäº DL çš„æ–¹æ³•ï¼Œè§†å…¶ä¸ºæ— äººæœºé¥æ„Ÿé¢†åŸŸçš„æœªæ¥è¶‹åŠ¿ã€‚\nAlthough, from these recent reviews, various DL-based methods have been validated in many UAV image analysis tasks, such as image classification, object detection, and semantic segmentation, a comprehensive summary and comparison of the characteristics, advantages, and limitations of semantic segmentation methods combined with UAV remote sensing images is currently absent.\nå°½ç®¡è¿™äº›æœ€æ–°ç»¼è¿°å·²éªŒè¯å¤šç§åŸºäº DL çš„æ–¹æ³•åœ¨è®¸å¤šæ— äººæœºå›¾åƒåˆ†æä»»åŠ¡ä¸­ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ï¼Œä½†ç›®å‰å°šç¼ºä¹å¯¹è¯­ä¹‰åˆ†å‰²æ–¹æ³•ä¸æ— äººæœºé¥æ„Ÿå›¾åƒç»“åˆçš„ç‰¹æ€§ã€ä¼˜åŠ¿å’Œå±€é™æ€§çš„å…¨é¢æ€»ç»“ä¸æ¯”è¾ƒã€‚\nTherefore, it is necessary to summarize the characteristics and development of specific semantic segmentation algorithms, provide scholars and practitioners with the quantitative comparison of representative models, as well as identify remaining challenges and future research directions in the image semantic segmentation of UAV remote sensing.\nå› æ­¤ï¼Œæœ‰å¿…è¦æ€»ç»“ç‰¹å®šè¯­ä¹‰åˆ†å‰²ç®—æ³•çš„ç‰¹æ€§å’Œå‘å±•ï¼Œå‘å­¦è€…å’Œå®è·µè€…æä¾›ä»£è¡¨æ€§æ¨¡å‹çš„å®šé‡æ¯”è¾ƒï¼Œå¹¶è¯†åˆ«æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„å‰©ä½™æŒ‘æˆ˜å’Œæœªæ¥ç ”ç©¶æ–¹å‘ã€‚\nDifferent from orbital and other aerial sensing methods of acquisition, the remote sensing images captured from UAVs have the characteristics of higher resolution, complex scenes, and appearance variations caused by multi-direction angles of view (Nigam et al., 2018; Chen et al., 2018c; Lyu et al., 2020).\nä¸è½¨é“åŠå…¶ä»–ç©ºä¸­æ„Ÿæµ‹é‡‡é›†æ–¹æ³•ä¸åŒï¼Œä»æ— äººæœºæ•è·çš„é¥æ„Ÿå›¾åƒå…·æœ‰æ›´é«˜åˆ†è¾¨ç‡ã€å¤æ‚åœºæ™¯ä»¥åŠå¤šæ–¹å‘è§†è§’å¼•èµ·çš„å¤–è§‚å˜åŒ–ï¼ˆNigam ç­‰ï¼Œ2018;Chen ç­‰ï¼Œ2018c;Lyu ç­‰ï¼Œ2020ï¼‰ã€‚\nTypically, semantic segmentation methods designed for natural images or remote sensing images require single-channel or multi-channel images of a fixed size as the data input (Yu et al., 2018b; Dias et al., 2020; Asgari Taghanaki et al., 2021; Kotaridis and Lazaridou, 2021; Yuan et al., 2021).\né€šå¸¸ï¼Œä¸ºè‡ªç„¶å›¾åƒæˆ–é¥æ„Ÿå›¾åƒè®¾è®¡çš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•éœ€è¦ä»¥å›ºå®šå¤§å°çš„å•é€šé“æˆ–å¤šé€šé“å›¾åƒä½œä¸ºæ•°æ®è¾“å…¥ï¼ˆYu ç­‰ï¼Œ2018b;Dias ç­‰ï¼Œ2020;Asgari Taghanaki ç­‰ï¼Œ2021;Kotaridis å’Œ Lazaridouï¼Œ2021 å¹´ï¼›Yuan ç­‰ï¼Œ2021ï¼‰ã€‚\nBy slightly changing the input image scale and the number of input image channels of the model structure, these methods can also be applied to process UAV-acquired remote sensing images (Huang et al., 2018b, 2021a; Osco et al., 2021).\né€šè¿‡ç¨å¾®æ”¹å˜è¾“å…¥å›¾åƒæ¯”ä¾‹å’Œæ¨¡å‹ç»“æ„çš„è¾“å…¥å›¾åƒé€šé“æ•°ï¼Œè¿™äº›æ–¹æ³•ä¹Ÿå¯ä»¥åº”ç”¨äºå¤„ç†æ— äººæœºé‡‡é›†çš„é¥æ„Ÿå›¾åƒï¼ˆHuang ç­‰ï¼Œ2018bï¼Œ2021a;Osco ç­‰ï¼Œ2021ï¼‰ã€‚\nBesides, we found that back-end users also prefer to make minor modifications to the internal architecture of models, which have been thoroughly validated for semantic segmentation tasks in natural or remote sensing images, to accomplish semantic segmentation for UAV-based images (Sui et al., 2020; Barmpoutis et al., 2020; Huang et al., 2021a).\næ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°åç«¯ç”¨æˆ·ä¹Ÿæ›´å€¾å‘äºå¯¹æ¨¡å‹å†…éƒ¨æ¶æ„åšå°å¹…ä¿®æ”¹ï¼Œè¿™äº›æ¨¡å‹å·²ç»è¿‡å……åˆ†éªŒè¯ï¼Œé€‚ç”¨äºè‡ªç„¶æˆ–é¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼Œä»¥å®ç°åŸºäºæ— äººæœºçš„å›¾åƒè¯­ä¹‰åˆ†å‰²ï¼ˆSui ç­‰ï¼Œ2020;Barmpoutis ç­‰ï¼Œ2020;Huang ç­‰ï¼Œ2021aï¼‰ã€‚\nAlthough performance-proven image semantic segmentation models have been shown to be applicable to UAV-based images, the off-the-shelf models may not always offer the optimal solution for UAV-based image semantic segmentation (Nex et al., 2022).\nå°½ç®¡ç»è¿‡æ€§èƒ½éªŒè¯çš„å›¾åƒè¯­ä¹‰åˆ†å‰²æ¨¡å‹å·²è¢«è¯æ˜å¯åº”ç”¨äºæ— äººæœºå›¾åƒï¼Œä½†ç°æˆçš„æ¨¡å‹å¯èƒ½å¹¶ä¸æ€»æ˜¯ä¸ºæ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æä¾›æœ€ä½³è§£å†³æ–¹æ¡ˆï¼ˆNex ç­‰ï¼Œ2022ï¼‰ã€‚\nThere remains a need to explore unique spatial, spectral, geometric, and multi-modal patterns (Beleznai et al., 2018; Maimaitijiang et al., 2020; Song et al., 2020) in UAV remote sensing images to design effective feature representations of semantic objects for accurate image semantic segmentation.\nä»ç„¶éœ€è¦æ¢ç´¢ç‹¬ç‰¹çš„ç©ºé—´ã€å…‰è°±ã€å‡ ä½•å’Œå¤šæ¨¡æ€æ¨¡å¼ï¼ˆBeleznai ç­‰ï¼Œ2018;Maimaitijiang ç­‰ï¼Œ2020;Song ç­‰ï¼Œ2020ï¼‰åœ¨æ— äººæœºé¥æ„Ÿå›¾åƒä¸­ç”¨äºè®¾è®¡æœ‰æ•ˆçš„è¯­ä¹‰å¯¹è±¡ç‰¹å¾è¡¨ç¤ºï¼Œå®ç°å‡†ç¡®çš„å›¾åƒè¯­ä¹‰åˆ†å‰²ã€‚\nBased on the differences in modeling semantic contextual information, semantic segmentation methods for UAV remote sensing images can be divided into two categories: graphbased contextual models and DL-based models.\nåŸºäºå¯¹è¯­ä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯å»ºæ¨¡çš„å·®å¼‚ï¼Œæ— äººæœºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•å¯åˆ†ä¸ºä¸¤ç±»ï¼šåŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹å’ŒåŸºäº DL çš„æ¨¡å‹ã€‚\nThe former explicitly establishes stochastic dependencies between pixels or regions by probabilistic undirected graphs (Jordan, 2004; Drton and Maathuis, 2017) to integrate local or global spatial context information, while the latter adaptively extracts high-level semantic features of semantic objects in images (LeCun et al., 2015).\nå‰è€…é€šè¿‡æ¦‚ç‡æ— å‘å›¾æ˜ç¡®å»ºç«‹äº†åƒç´ æˆ–åŒºåŸŸä¹‹é—´çš„éšæœºä¾èµ–å…³ç³»ï¼ˆJordanï¼Œ2004;Drton å’Œ Maathuisï¼Œ2017ï¼‰ä»¥æ•´åˆå±€éƒ¨æˆ–å…¨å±€çš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè€Œåè€…åˆ™è‡ªé€‚åº”åœ°æå–å›¾åƒä¸­è¯­ä¹‰å¯¹è±¡çš„é«˜å±‚æ¬¡è¯­ä¹‰ç‰¹å¾ï¼ˆLeCun ç­‰ï¼Œ2015ï¼‰ã€‚\nBesides, most advanced semantic segmentation works applied to UAV-based images did not open-source their datasets due to flight rules and potential confidentiality.\næ­¤å¤–ï¼Œå¤§å¤šæ•°ç”¨äºæ— äººæœºå›¾åƒçš„é«˜çº§è¯­ä¹‰åˆ†å‰²ç ”ç©¶å› é£è¡Œè§„åˆ™å’Œæ½œåœ¨ä¿å¯†æ€§é—®é¢˜ï¼Œæœªå°†æ•°æ®é›†å¼€æºã€‚\nTo reduce the labor cost for investigating relevant open-source UAV remote sensing image datasets, another motivation for this review is to summarize publicly available datasets and list the corresponding parameters, such as applications, spatial resolution, classes, and modalities.\nä¸ºäº†é™ä½ç ”ç©¶ç›¸å…³å¼€æºæ— äººæœºé¥æ„Ÿå›¾åƒæ•°æ®é›†çš„äººå·¥æˆæœ¬ï¼Œæœ¬ç»¼è¿°çš„å¦ä¸€ä¸ªåŠ¨æœºæ˜¯æ€»ç»“å…¬å¼€æ•°æ®é›†å¹¶åˆ—å‡ºç›¸åº”å‚æ•°ï¼Œå¦‚åº”ç”¨ã€ç©ºé—´åˆ†è¾¨ç‡ã€ç±»åˆ«å’Œæ¨¡æ€ã€‚\nWe concentrate our review on advanced methods and available datasets for semantic segmentation applied to UAV optical imagery, rather than onboard instrumentation, payload, flight autonomy, data acquisition techniques, or specific applications.\næˆ‘ä»¬é‡ç‚¹å›é¡¾åº”ç”¨äºæ— äººæœºå…‰å­¦å½±åƒçš„è¯­ä¹‰åˆ†å‰²çš„å…ˆè¿›æ–¹æ³•å’Œå¯ç”¨æ•°æ®é›†ï¼Œè€Œéæœºè½½ä»ªå™¨ã€æœ‰æ•ˆè½½è·ã€é£è¡Œè‡ªä¸»æ€§ã€æ•°æ®é‡‡é›†æŠ€æœ¯æˆ–å…·ä½“åº”ç”¨ã€‚\nThe remainder of the paper is organized as follows.\nè®ºæ–‡å…¶ä½™éƒ¨åˆ†çš„ç»„ç»‡å¦‚ä¸‹ã€‚\nSection 2 presents the graph-based contextual models for semantic segmentation and analyzes the advantages and limitations of the individual models according to the model characteristics.\nç¬¬äºŒéƒ¨åˆ†ä»‹ç»äº†åŸºäºå›¾çš„è¯­ä¹‰åˆ†å‰²ä¸Šä¸‹æ–‡æ¨¡å‹ï¼Œå¹¶æ ¹æ®æ¨¡å‹ç‰¹æ€§åˆ†æå„æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ã€‚\nSection 3 reviews the popular semantic segmentation methods built on the DL framework, including encoderâ€“decoder architectures, multi-scale and feature fusion strategies, relationship modeling methods, vision transformer architectures, and light-weight methods.\nç¬¬ä¸‰éƒ¨åˆ†å›é¡¾åŸºäº DL æ¡†æ¶çš„æµè¡Œè¯­ä¹‰åˆ†å‰²æ–¹æ³•ï¼ŒåŒ…æ‹¬ç¼–ç å™¨ - è§£ç å™¨æ¶æ„ã€å¤šå°ºåº¦å’Œç‰¹å¾èåˆç­–ç•¥ã€å…³ç³»å»ºæ¨¡æ–¹æ³•ã€è§†è§‰å˜æ¢å™¨æ¶æ„ä»¥åŠè½»é‡çº§æ–¹æ³•ã€‚\nSection 4 summarizes the available datasets for UAV-based image semantic segmentation.\nç¬¬å››èŠ‚æ€»ç»“äº†åŸºäºæ— äººæœºçš„å›¾åƒè¯­ä¹‰åˆ†å‰²å¯ç”¨çš„æ•°æ®é›†ã€‚\nSection 5 provides an experimental evaluation of representative semantic segmentation models on two highresolution UAV-based datasets.\nç¬¬äº”èŠ‚å¯¹ä¸¤ä¸ªé«˜åˆ†è¾¨ç‡æ— äººæœºæ•°æ®é›†ä¸Šçš„ä»£è¡¨æ€§è¯­ä¹‰åˆ†å‰²æ¨¡å‹è¿›è¡Œäº†å®éªŒè¯„ä¼°ã€‚\nSemantic segmentation accuracy and model inference efficiency are the main aspects to be analyzed and discussed in our experimental assessments.\nè¯­ä¹‰åˆ†å‰²çš„å‡†ç¡®æ€§å’Œæ¨¡å‹æ¨æ–­æ•ˆç‡æ˜¯æˆ‘ä»¬å®éªŒè¯„ä¼°ä¸­ä¸»è¦éœ€è¦åˆ†æå’Œè®¨è®ºçš„æ–¹é¢ã€‚\nSection 6 provides a general summary of semantic segmentation models for UAV-based images as well as describes the remaining challenges and future research directions.\nç¬¬å…­èŠ‚æ¦‚è¿°äº†åŸºäºæ— äººæœºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼Œå¹¶æè¿°äº†å‰©ä½™æŒ‘æˆ˜å’Œæœªæ¥ç ”ç©¶æ–¹å‘ã€‚\nSection 7 concludes the paper with a brief discussion of future trends and prospects.\nç¬¬ 7 èŠ‚ä»¥å¯¹æœªæ¥è¶‹åŠ¿å’Œå‰æ™¯çš„ç®€è¦è®¨è®ºç»“æŸäº†æœ¬æ–‡ã€‚\n# Methods based on graph-based contextual models\nåŸºäºåŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹æ–¹æ³•\nIndividual pixels in a UAV image are insufficient to convey specific semantic meanings, but the image containing all pixels exhibits spatial contextual semantic information, such as scene details, semantic objects, and spatial relationships, among others.\næ— äººæœºå›¾åƒä¸­çš„å•ä¸ªåƒç´ ä¸è¶³ä»¥ä¼ è¾¾ç‰¹å®šçš„è¯­ä¹‰æ„ä¹‰ï¼Œä½†åŒ…å«æ‰€æœ‰åƒç´ çš„å›¾åƒå±•ç°äº†ç©ºé—´ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯ï¼Œå¦‚åœºæ™¯ç»†èŠ‚ã€è¯­ä¹‰å¯¹è±¡å’Œç©ºé—´å…³ç³»ç­‰ã€‚\nHence, one feasible approach for semantic feature extraction is to establish dependencies between pixels or homogeneous regions within the image.\nå› æ­¤ï¼Œä¸€ç§å¯è¡Œçš„è¯­ä¹‰ç‰¹å¾æå–æ–¹æ³•æ˜¯å»ºç«‹å›¾åƒä¸­åƒç´ æˆ–åŒè´¨åŒºåŸŸä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚\nGraphbased contextual models (Jordan, 2004; Drton and Maathuis, 2017) are practical methods that explicitly establish stochastic dependencies between pixels or regions using probabilistic theories to capture spatial contextual semantic information (Yu et al., 2018b).\nåŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ˆJordanï¼Œ2004;Drton å’Œ Maathuisï¼Œ 2017ï¼‰æ˜¯ä¸€ç§å®ç”¨æ–¹æ³•ï¼Œé€šè¿‡æ¦‚ç‡ç†è®ºæ˜ç¡®å»ºç«‹åƒç´ æˆ–åŒºåŸŸä¹‹é—´çš„éšæœºä¾èµ–å…³ç³»ï¼Œä»¥æ•æ‰ç©ºé—´ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯ï¼ˆYu ç­‰ï¼Œ2018bï¼‰ã€‚\nFurthermore, the considerable amount of complex semantic information within the UAV images can vary with changes in the scene, camera view, and flight altitude.\næ­¤å¤–ï¼Œæ— äººæœºå›¾åƒä¸­å¤§é‡çš„å¤æ‚è¯­ä¹‰ä¿¡æ¯ä¼šéšç€åœºæ™¯ã€æ‘„åƒæœºè§†è§’å’Œé£è¡Œé«˜åº¦çš„å˜åŒ–è€Œå˜åŒ–ã€‚\nGraph-based contextual models can reduce the mis-classification caused by this complexity by integrating semantic information from the neighborhoods when assigning class labels to each pixel or region in a given image (Solberg et al., 1996; Tso and Mather, 1999; Zheng and Wang, 2015; Yao et al., 2015; Gu et al., 2017; Yang et al., 2018).\nåŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹å¯ä»¥é€šè¿‡åœ¨ç»™å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ æˆ–åŒºåŸŸåˆ†é…ç±»åˆ«æ ‡ç­¾æ—¶æ•´åˆé‚»åŸŸçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå‡å°‘å› å¤æ‚æ€§å¯¼è‡´çš„é”™è¯¯åˆ†ç±»ï¼ˆSolberg ç­‰ï¼Œ1996;Tso å’Œ Matherï¼Œ1999; éƒ‘å’Œç‹ï¼Œ2015;Yao ç­‰ï¼Œ2015;Gu ç­‰ï¼Œ2017;Yang ç­‰ï¼Œ2018ï¼‰ã€‚\nGraph-based probabilistic models attribute the feature learning task to computing the probability distribution of variables.\nåŸºäºå›¾çš„æ¦‚ç‡æ¨¡å‹å°†ç‰¹å¾å­¦ä¹ ä»»åŠ¡å½’å› äºè®¡ç®—å˜é‡çš„æ¦‚ç‡åˆ†å¸ƒã€‚\nThe Markov Random Field (MRF) and the Conditional Random Field (CRF) are the most popular graph-based contextual semantic algorithms.\né©¬å°”å¯å¤«éšæœºåœºï¼ˆMRFï¼‰å’Œæ¡ä»¶éšæœºåœºï¼ˆCRFï¼‰æ˜¯æœ€æµè¡Œçš„åŸºäºå›¾çš„ä¸Šä¸‹æ–‡è¯­ä¹‰ç®—æ³•ã€‚\nBoth approaches map images onto an undirected graph model, where each vertex in the graph represents a pixel or feature vector of the image, and the edges between the vertices represent contextual dependencies.\nè¿™ä¸¤ç§æ–¹æ³•éƒ½å°†å›¾åƒæ˜ å°„åˆ°æ— å‘å›¾æ¨¡å‹ä¸Šï¼Œå›¾ä¸­çš„æ¯ä¸ªé¡¶ç‚¹ä»£è¡¨å›¾åƒçš„ä¸€ä¸ªåƒç´ æˆ–ç‰¹å¾å‘é‡ï¼Œé¡¶ç‚¹ä¹‹é—´çš„è¾¹ä»£è¡¨ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»ã€‚\n# MRF\nMRF is essentially a probabilistic generative model that predicts each class of images based on the joint probability distribution (Solberg et al., 1996; Tso and Mather, 1999; Kasetkasem and Varshney, 2002; Zheng et al., 2017; Yu et al., 2018b).\nMRF æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ¦‚ç‡ç”Ÿæˆæ¨¡å‹ï¼ŒåŸºäºè”åˆæ¦‚ç‡åˆ†å¸ƒé¢„æµ‹æ¯ç±»å›¾åƒï¼ˆSolberg ç­‰ï¼Œ1996;Tso å’Œ Matherï¼Œ1999;Kasetkasem å’Œ Varshneyï¼Œ2002 å¹´ï¼›Zheng ç­‰ï¼Œ2017;Yu ç­‰ï¼Œ2018bï¼‰ã€‚\nThe pixel distribution in an image can be viewed as the MRF since each pixel is related to its corresponding neighborhood.\nå›¾åƒä¸­çš„åƒç´ åˆ†å¸ƒå¯ä»¥çœ‹ä½œ MRFï¼Œå› ä¸ºæ¯ä¸ªåƒç´ éƒ½ä¸å…¶å¯¹åº”çš„é‚»åŸŸç›¸å…³ã€‚\nIt has been regarded as the practical model for describing spatial patterns and image characteristics.\nå®ƒè¢«è§†ä¸ºæè¿°ç©ºé—´æ¨¡å¼å’Œå›¾åƒç‰¹å¾çš„å®ç”¨æ¨¡å‹ã€‚\nLet Y denote the label field with L semantic classes, i.e. Y=y1,y2,...,yLY = {y_1, y_2, ... , y_L  }Y=y1â€‹,y2â€‹,...,yLâ€‹, and the x is the observed image.\nè®¾ Y è¡¨ç¤ºå…·æœ‰ L è¯­ä¹‰ç±»çš„æ ‡ç­¾åŸŸï¼Œå³Y=y1,y2,...,yLY = {y_1, y_2, ... , y_L  }Y=y1â€‹,y2â€‹,...,yLâ€‹ï¼ŒX æ˜¯è§‚æµ‹åˆ°çš„å›¾åƒã€‚\nAccording to the Bayesian formula, the posterior distribution should be\næ ¹æ®è´å¶æ–¯å…¬å¼ï¼ŒåéªŒåˆ†å¸ƒåº”ä¸º\nP(yâˆ£x)=P(xâˆ£y)P(y)P(x)âˆP(xâˆ£y)P(y)P(y|x)=\\frac{P(x|y)P(y)}{P(x)}âˆP(x|y)P(y)\nP(yâˆ£x)=P(x)P(xâˆ£y)P(y)â€‹âˆP(xâˆ£y)P(y)\nwhere P(xâˆ£y)P(x|y)P(xâˆ£y) is the likelihood function and P(y)P(y)P(y)is the part that describes the joint probability distribution of the label field.\nå…¶ä¸­P(xâˆ£y)P(x|y)P(xâˆ£y)  æ˜¯ä¼¼ç„¶å‡½æ•°ï¼ŒPï¼ˆyï¼‰Pï¼ˆyï¼‰Pï¼ˆyï¼‰æ˜¯æè¿°æ ‡ç­¾åœºè”åˆæ¦‚ç‡åˆ†å¸ƒçš„éƒ¨åˆ†ã€‚\nBased on the assumption that the label field is independent and identically distributed, then the segmentation problem is equivalent to maximum a posterior (MAP)\nåŸºäºæ ‡ç­¾åœºç‹¬ç«‹ä¸”åˆ†å¸ƒå‡åŒ€çš„å‡è®¾ï¼Œåˆ™åˆ†å‰²é—®é¢˜ç­‰ä»·äºæœ€å¤§åéªŒï¼ˆMAPï¼‰\ny^=argâ¡maxâ¡yâˆˆYP(yâˆ£x)\\hat{y} = \\arg\\max_{y \\in Y} P(y \\mid x)\ny^â€‹=argyâˆˆYmaxâ€‹P(yâˆ£x)\nMRF has been adopted to model interactions of image features or contextual information of UAV photogrammetry and remote sensing tasks, such as target detection and tracking (Yu et al., 2006; Wan et al., 2019), image despeckling (Alparone et al., 2010), individual tree crown delineation (Harikumar et al., 2020), image classification (Fang et al., 2018b), and image segmentation (Zhang et al., 2013).\nMRF å·²è¢«ç”¨äºå»ºæ¨¡æ— äººæœºæ‘„å½±æµ‹é‡å’Œé¥æ„Ÿä»»åŠ¡ï¼ˆå¦‚ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªï¼‰ä¸­å›¾åƒç‰¹å¾æˆ–ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç›¸äº’ä½œç”¨ï¼ˆYu ç­‰ï¼Œ2006;Wan ç­‰ï¼Œ2019ï¼‰ã€å›¾åƒå»æ–‘ç‚¹ï¼ˆAlparone ç­‰ï¼Œ2010ï¼‰ã€å•ä¸ªæ ‘å† çš„åˆ’åˆ†ï¼ˆHarikumar ç­‰ï¼Œ2020ï¼‰ã€å›¾åƒåˆ†ç±»ï¼ˆFang ç­‰ï¼Œ2018bï¼‰ä»¥åŠå›¾åƒåˆ†å‰²ï¼ˆZhang ç­‰ï¼Œ2013ï¼‰ã€‚\nHowever, the original pixel-based MRF is difficult to model the spatial pattern of the entire high-resolution image, it is more effective in tasks that only need to model a small number of pixels (Wan et al., 2019).\nç„¶è€Œï¼ŒåŸå§‹åŸºäºåƒç´ çš„ MRF éš¾ä»¥å»ºæ¨¡æ•´ä¸ªé«˜åˆ†è¾¨ç‡å›¾åƒçš„ç©ºé—´æ¨¡å¼ï¼Œåœ¨åªéœ€å»ºæ¨¡å°‘é‡åƒç´ çš„ä»»åŠ¡ä¸­æ•ˆæœæ›´ä½³ï¼ˆWan ç­‰ï¼Œ2019ï¼‰ã€‚\n\nåƒç´ çº§ MRF ä¸é€‚åˆç”¨äºå»ºæ¨¡æ•´ä¸ªé«˜åˆ†è¾¨ç‡å›¾åƒçš„å…¨å±€ç©ºé—´ç»“æ„ï¼Œä½†åœ¨åªæ¶‰åŠå°‘é‡åƒç´ æˆ–å±€éƒ¨åŒºåŸŸçš„ä»»åŠ¡ä¸­ä»ç„¶å…·æœ‰è¾ƒå¥½çš„æ•ˆæœã€‚\n\nBesides, the local Markovian property of the pixel-based MRF may not be preserved due to image transformations such as subsampling, block averaging, and subtraction of two images (Kasetkasem and Varshney, 2002; Gu et al., 2017).\næ­¤å¤–ï¼ŒåŸºäºåƒç´ çš„ MRF çš„å±€éƒ¨é©¬å°”å¯å¤«æ€§è´¨å¯èƒ½æ— æ³•ä¿æŒï¼Œå› ä¸ºå›¾åƒå˜æ¢å¦‚å­é‡‡æ ·ã€å—å¹³å‡å’Œä¸¤å¼ å›¾åƒçš„ç›¸å‡ï¼ˆKasetkasem å’Œ Varshneyï¼Œ2002;Gu ç­‰ï¼Œ2017ï¼‰ã€‚\nA multi-layer MRF can be established to achieve stable image point classification by constructing various features describing image points, such as color and texture, to model the feature interaction between layers (Kato et al., 2002; Benedek et al., 2007).\nå¯ä»¥é€šè¿‡æ„å»ºæè¿°å›¾åƒç‚¹çš„å„ç§ç‰¹å¾ï¼ˆå¦‚é¢œè‰²å’Œçº¹ç†ï¼‰æ¥å»ºç«‹å¤šå±‚ MRFï¼Œä»¥å®ç°ç¨³å®šçš„å›¾åƒç‚¹åˆ†ç±»ï¼Œä»¥æ¨¡æ‹Ÿå±‚é—´ç‰¹å¾çš„ç›¸äº’ä½œç”¨ï¼ˆKato ç­‰ï¼Œ2002;Benedek ç­‰ï¼Œ2007ï¼‰ã€‚\nHowever, this approach can introduce more computational overhead proportional to the number of layers.\nç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¼šå¸¦æ¥ä¸å±‚æ•°æˆæ­£æ¯”çš„è®¡ç®—å¼€é”€ã€‚\nTo improve the image segmentation efficiency, Alparone et al. (2010) adopted the constrained MRF based on a binary tree structure (Dâ€™Elia et al., 2003) to recursively divide the image into smaller regions.\nä¸ºäº†æé«˜å›¾åƒåˆ†å‰²æ•ˆç‡ï¼ŒAlparone ç­‰äººï¼ˆ2010ï¼‰é‡‡ç”¨äº†åŸºäºäºŒå‰æ ‘ç»“æ„çš„çº¦æŸ MRFï¼ˆDâ€™Elia ç­‰ï¼Œ2003ï¼‰ï¼Œé€’å½’åœ°å°†å›¾åƒåˆ’åˆ†ä¸ºæ›´å°çš„åŒºåŸŸã€‚\nBut this approach is still pixel-oriented and unsuitable for high-resolution UAV images with extensive texture details.\nä½†è¿™ç§æ–¹æ³•ä»ç„¶æ˜¯åƒç´ å¯¼å‘çš„ï¼Œä¸é€‚åˆå…·æœ‰å¤§é‡çº¹ç†ç»†èŠ‚çš„é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒã€‚\nA set of similar and connected pixels in an image can be grouped as an object with meaningful representation according to specific properties such as shape, color, and spectral information (Levinshtein et al., 2009; Achanta et al., 2012; Crommelinck et al., 2017; He et al., 2019). The object-based image analysis (OBIA) (Castilla and Hay, 2008; Lang, 2008; Blaschke, 2010; Chen et al., 2018a; Hossain and Chen, 2019) can serve as an alternative to the per-pixel analysis method, since it cannot only reduce the computational overhead by decreasing the number of vertex of MRF but also reduce the impact of complex texture details within the pixel-set object on the semantic representation of the target to be segmented.\nå›¾åƒä¸­ä¸€ç»„ç›¸ä¼¼ä¸”ç›¸è¿çš„åƒç´ å¯ä»¥æ ¹æ®å½¢çŠ¶ã€é¢œè‰²å’Œå…‰è°±ä¿¡æ¯ç­‰ç‰¹å®šå±æ€§è¢«å½’ä¸ºå…·æœ‰æœ‰æ„ä¹‰è¡¨ç¤ºçš„å¯¹è±¡ï¼ˆLevinshtein ç­‰ï¼Œ2009;Achanta ç­‰ï¼Œ2012;Crommelinck ç­‰ï¼Œ2017; ä»–ç­‰ï¼Œ2019ï¼‰ã€‚åŸºäºå¯¹è±¡çš„å›¾åƒåˆ†æï¼ˆOBIAï¼‰ï¼ˆCastilla å’Œ Hayï¼Œ2008;Langï¼Œ2008;Blaschkeï¼Œ2010 å¹´ï¼›Chen ç­‰ï¼Œ2018a;Hossain å’Œ Chenï¼Œ2019ï¼‰å¯ä»¥ä½œä¸ºæ¯åƒç´ åˆ†ææ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒä¸ä»…é€šè¿‡å‡å°‘ MRF é¡¶ç‚¹æ•°æ¥é™ä½è®¡ç®—å¼€é”€ï¼Œè¿˜èƒ½å‡å°‘åƒç´ é›†å¯¹è±¡ä¸­å¤æ‚çº¹ç†ç»†èŠ‚å¯¹å¾…åˆ†å‰²ç›®æ ‡è¯­ä¹‰è¡¨ç¤ºçš„å½±å“ã€‚\nThe MRF model can also be extended to object-based MRF (OMRF) for semantic segmentation, in which each vertex of the adjacency graph represents a region over-segmented by object-based methods instead of pixels (Zheng and Wang, 2014; Zheng et al., 2017).\nMRF æ¨¡å‹ä¹Ÿå¯ä»¥æ‰©å±•åˆ°åŸºäºå¯¹è±¡çš„ MRFï¼ˆOMRFï¼‰è¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œå…¶ä¸­é‚»æ¥å›¾çš„æ¯ä¸ªé¡¶ç‚¹ä»£è¡¨ä¸€ä¸ªè¢«åŸºäºå¯¹è±¡çš„æ–¹æ³•è€Œéåƒç´ è¿‡åº¦åˆ†å‰²çš„åŒºåŸŸï¼ˆZheng å’Œ Wangï¼Œ2014;Zheng ç­‰ï¼Œ2017ï¼‰ã€‚\nFor instance, Zhao et al. (2022) utilized the multi-scale line segment detector to obtain power line region proposals, then combined the Gaussian mixture model (GMM) and the weighted region adjacency graph (WRAG) to construct an OMRF-based power line detection model.\nä¾‹å¦‚ï¼Œèµµç­‰äººï¼ˆ2022ï¼‰åˆ©ç”¨å¤šå°ºåº¦çº¿æ®µæ¢æµ‹å™¨è·å¾—äº†ç”µåŠ›çº¿åŒºåŸŸçš„å»ºè®®ï¼Œéšåç»“åˆé«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰å’ŒåŠ æƒåŒºåŸŸé‚»æ¥å›¾ï¼ˆWRAGï¼‰æ„å»ºåŸºäº OMRF çš„ç”µåŠ›çº¿æ£€æµ‹æ¨¡å‹ã€‚\nGMM constructed the likelihood function to describe the conditional probability, and the WRGA utilized the spatial contextual information and interactions between objects.\nGMM æ„å»ºäº†ä¼¼ç„¶å‡½æ•°æ¥æè¿°æ¡ä»¶æ¦‚ç‡ï¼ŒWRGA åˆ©ç”¨äº†ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œç‰©ä½“é—´çš„äº¤äº’ã€‚\nadopted an improved watershed algorithm to avoid over-segmentation and combined with edge-based coupled MRF to reduce false positives caused by speckles in PolSAR images.\né‡‡ç”¨æ”¹è¿›çš„æµåŸŸç®—æ³•ä»¥é¿å…è¿‡åº¦åˆ†å‰²ï¼Œå¹¶ç»“åˆåŸºäºè¾¹ç¼˜çš„è€¦åˆ MRFï¼Œå‡å°‘ PolSAR å›¾åƒä¸­æ–‘ç‚¹å¼•èµ·çš„è¯¯æŠ¥ã€‚\nIt enhanced the accuracy of change detection between two UAVSAR images while also improving the weak missing discontinuous boundaries between the image objects.\nå®ƒæé«˜äº†ä¸¤å¹… UAVSAR å›¾åƒä¹‹é—´å˜åŒ–æ£€æµ‹çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¹Ÿæ”¹å–„äº†å›¾åƒå¯¹è±¡ä¹‹é—´ç¼ºå¤±çš„å¼±ä¸è¿ç»­è¾¹ç•Œã€‚\nBoth utilized the MRF to model the interaction between pixel groups generated from UAV-based images and assign the pixels belonging to a certain pixel group to have the same label.\nä¸¤è€…éƒ½åˆ©ç”¨ MRF æ¨¡æ‹Ÿç”±æ— äººæœºå›¾åƒç”Ÿæˆçš„åƒç´ ç»„ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶å°†å±äºæŸä¸ªåƒç´ ç»„çš„åƒç´ èµ‹äºˆç›¸åŒæ ‡ç­¾ã€‚\nHowever, improper modeling of spatial relationships of OMRF might lead to misclassification or over-smoothing for high-resolution remote sensing images.\nç„¶è€Œï¼ŒOMRF ç©ºé—´å…³ç³»å»ºæ¨¡ä¸å½“å¯èƒ½å¯¼è‡´é«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒçš„è¯¯åˆ†ç±»æˆ–è¿‡åº¦å¹³æ»‘ã€‚\nBesides, most MRF-based semantic segmentation methods did not fully consider hierarchical semantic information or interlayer relationships between pyramid multi-resolution images.\næ­¤å¤–ï¼Œå¤§å¤šæ•°åŸºäº MRF çš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•å¹¶æœªå……åˆ†è€ƒè™‘å±‚çº§è¯­ä¹‰ä¿¡æ¯æˆ–é‡‘å­—å¡”å¤šåˆ†è¾¨ç‡å›¾åƒä¹‹é—´çš„å±‚é—´å…³ç³»ã€‚\nYao et al. (2021) proposed pyramid OMRF with dual-track information transmission (POMRF-DIT) to mine and transfer pyramid multilayer information.\nYao ç­‰äººï¼ˆ2021ï¼‰æå‡ºäº†å¸¦æœ‰åŒè½¨ä¿¡æ¯ä¼ è¾“ï¼ˆPOMRF-DITï¼‰çš„é‡‘å­—å¡” OMRFï¼Œç”¨äºæŒ–æ˜å’Œä¼ è¾“é‡‘å­—å¡”å¤šå±‚ä¿¡æ¯ã€‚\nClose-loop dual-track paths were also adopted to optimize the segmentation of each layer and achieve more physically meaningful structure modeling and interlayer information transfer mechanism.\nè¿˜é‡‡ç”¨äº†é—­ç¯åŒè½¨è·¯å¾„ï¼Œä»¥ä¼˜åŒ–æ¯å±‚çš„åˆ†æ®µï¼Œå®ç°æ›´å…·ç‰©ç†æ„ä¹‰çš„ç»“æ„å»ºæ¨¡å’Œå±‚é—´ä¿¡æ¯ä¼ é€’æœºåˆ¶ã€‚\nMRF provides a solution for the semantic segmentation of UAV-based images, which constructs the interactions between pixels or groups of pixels with joint probability distribution to capture the semantic context information so that the segmentation results can be given semantic meanings.\nMRF ä¸ºæ— äººæœºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²æä¾›äº†è§£å†³æ–¹æ¡ˆï¼Œè¯¥æ–¹æ³•é€šè¿‡æ„å»ºåƒç´ æˆ–åƒç´ ç»„ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œå¹¶ä»¥è”åˆæ¦‚ç‡åˆ†å¸ƒæ•æ‰è¯­ä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œèµ‹äºˆåˆ†å‰²ç»“æœè¯­ä¹‰æ„ä¹‰ã€‚\nNevertheless, there are still many difficulties in applying MRF to high-resolution UAV remote sensing images. For instance, the updating and inference process of the joint probability distribution in MRF is complicated and time-costing (Zheng et al., 2017).\nç„¶è€Œï¼Œå°† MRF åº”ç”¨äºé«˜åˆ†è¾¨ç‡æ— äººæœºé¥æ„Ÿå›¾åƒä»å­˜åœ¨è®¸å¤šå›°éš¾ã€‚ä¾‹å¦‚ï¼ŒMRF ä¸­è”åˆæ¦‚ç‡åˆ†å¸ƒçš„æ›´æ–°å’Œæ¨æ–­è¿‡ç¨‹å¤æ‚ä¸”è€—æ—¶ï¼ˆZheng ç­‰ï¼Œ2017ï¼‰ã€‚\nIn addition, the object scale variation and complex texture of UAV images make it difficult to design reasonable semantic rules.\næ­¤å¤–ï¼Œæ— äººæœºå›¾åƒçš„ç‰©ä½“å°ºåº¦å˜åŒ–å’Œå¤æ‚çš„çº¹ç†ä½¿å¾—è®¾è®¡åˆç†çš„è¯­ä¹‰è§„åˆ™å˜å¾—å›°éš¾ã€‚\nOnly a few works are found in the literature where MRF is utilized for the semantic segmentation of UAV images.\næ–‡çŒ®ä¸­åªæœ‰å°‘æ•°æ–‡çŒ®å°† MRF ç”¨äºæ— äººæœºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ã€‚\nIn many scenarios, CRF is a more commonly used graph-based contextual model, which will be described in the next section.\nåœ¨è®¸å¤šåœºæ™¯ä¸­ï¼ŒCRF æ˜¯ä¸€ç§æ›´å¸¸ç”¨çš„åŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹ï¼Œå°†åœ¨ä¸‹ä¸€èŠ‚ä¸­è¯¦ç»†è¯´æ˜ã€‚\n# CRF\nConditional Random Field\n æ¡ä»¶éšæœºåœº\nUnlike MRF, CRF for semantic segmentation is a probabilistic discriminant model that specifies the conditional probability distribution of the semantic labels given the observation data (Lafferty et al., 2001).\nä¸ MRF ä¸åŒï¼ŒCRF ç”¨äºè¯­ä¹‰åˆ†å‰²æ˜¯ä¸€ç§æ¦‚ç‡åˆ¤åˆ«æ¨¡å‹ï¼ŒæŒ‡å®šäº†åœ¨ç»™å®šè§‚å¯Ÿæ•°æ®åè¯­ä¹‰æ ‡ç­¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒï¼ˆLafferty ç­‰ï¼Œ2001ï¼‰ã€‚\nIt had cast a bright light on many aspects of the graph-based context tasks and profoundly impacted the semantic segmentation of UAV remote sensing images.\nå®ƒä¸ºåŸºäºå›¾è¡¨çš„ä¸Šä¸‹æ–‡ä»»åŠ¡çš„è®¸å¤šæ–¹é¢å¸¦æ¥äº†äº®ç‚¹ï¼Œå¹¶æ·±åˆ»å½±å“äº†æ— äººæœºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ã€‚\nThe inference process in CRF usually consists of association potential and interaction potential.\nCRF ä¸­çš„æ¨æ–­è¿‡ç¨‹é€šå¸¸åŒ…æ‹¬å…³è”åŠ¿å’Œç›¸äº’ä½œç”¨åŠ¿ã€‚\nLet S denotes all nodes that reflect the pixels or regions in an image, the index i âˆˆ S indicates the node site while the j represents the node site in a neighborhood Ni âˆˆ S.\nè®¾ S è¡¨ç¤ºæ‰€æœ‰åæ˜ å›¾åƒåƒç´ æˆ–åŒºåŸŸçš„èŠ‚ç‚¹ï¼Œç´¢å¼• iâˆˆS è¡¨ç¤ºèŠ‚ç‚¹ç«™ç‚¹ï¼Œj è¡¨ç¤ºé‚»åŸŸ NiâˆˆS ä¸­çš„èŠ‚ç‚¹ç«™ç‚¹ã€‚\nThe posterior probability distribution P (y|x) directly modeled by the CRF can be described as (Kumar and Hebert, 2006; Hoberg et al., 2014)\nCRF ç›´æ¥å»ºæ¨¡çš„åéªŒæ¦‚ç‡åˆ†å¸ƒ Pï¼ˆy|xï¼‰å¯ä»¥æè¿°ä¸ºï¼ˆKumar å’Œ Hebertï¼Œ2006;Hoberg ç­‰ï¼Œ2014ï¼‰\nP(yâˆ£x)=1Zexpâ¡[âˆ‘iâˆˆSAi(yi,x)+âˆ‘iâˆˆSâˆ‘jâˆˆNiIij(yi,yj,x)]P(y \\mid x) = \\frac{1}{Z} \\exp\\left[\n\\sum_{i \\in S} A_i(y_i, x)\n+ \\sum_{i \\in S} \\sum_{j \\in N_i} I_{ij}(y_i, y_j, x)\n\\right]\nP(yâˆ£x)=Z1â€‹expâ£â¢â¡â€‹iâˆˆSâˆ‘â€‹Aiâ€‹(yiâ€‹,x)+iâˆˆSâˆ‘â€‹jâˆˆNiâ€‹âˆ‘â€‹Iijâ€‹(yiâ€‹,yjâ€‹,x)â¦â¥â¤â€‹\n\nZZZï¼šé…åˆ†å‡½æ•°ï¼ˆpartition function /normalization constantï¼‰\nAi(yi,x)A_i(y_i, x)Aiâ€‹(yiâ€‹,x)ï¼šä¸€å…ƒåŠ¿å‡½æ•°ï¼ˆunary potentialï¼‰\nIij(yi,yj,x)I_{ij}(y_i, y_j, x)Iijâ€‹(yiâ€‹,yjâ€‹,x)ï¼šäºŒå…ƒåŠ¿å‡½æ•°ï¼ˆpairwise potentialï¼‰\nSSSï¼šèŠ‚ç‚¹ï¼ˆåƒç´ ï¼‰é›†åˆ\nNiN_iNiâ€‹ï¼šèŠ‚ç‚¹ iii çš„é‚»åŸŸ\n\nwhere the term Ai(yi,x)A_i (y_i, x)Aiâ€‹(yiâ€‹,x) is the association (or unary) potential and the term Iij(yi,yj,x)I_{ij} (y_i, y_j , x)Iijâ€‹(yiâ€‹,yjâ€‹,x) is the interaction (or pair-wise) potential. The association potential reflects the applicability to a pixel or region xi given a label yiy_iyiâ€‹, while the interaction potential models the relationship between label yiy_iyiâ€‹ and yjy_jyjâ€‹ , which can be regarded as a constraint to ensure the consistency of semantic label predictions. ZZZ is the partition function that normalized the sum of potentials. ZZZ is defined as\nå…¶ä¸­é¡¹Ai(yi,x)A_i (y_i, x)Aiâ€‹(yiâ€‹,x) æ˜¯å…³è”åŠ¿ï¼ˆæˆ–ä¸€å…ƒåŠ¿ï¼‰ï¼Œé¡¹ Iij(yi,yj,x)I_{ij} (y_i, y_j , x)Iijâ€‹(yiâ€‹,yjâ€‹,x) æ˜¯ç›¸äº’ä½œç”¨ï¼ˆæˆ–ä¸¤å¯¹åŠ¿ï¼‰ã€‚å…³è”åŠ¿åæ˜ äº†ç»™å®šæ ‡ç­¾ yiy_iyiâ€‹ æ—¶ï¼Œåƒç´ æˆ–åŒºåŸŸä¹ é€‚ç”¨æ€§ï¼Œè€Œäº¤äº’åŠ¿èƒ½åˆ™æ¨¡æ‹Ÿæ ‡ç­¾  yiy_iyiâ€‹ ä¸  yiy_iyiâ€‹ ä¹‹é—´çš„å…³ç³»ï¼Œè¿™å¯è¢«è§†ä¸ºç¡®ä¿è¯­ä¹‰æ ‡ç­¾é¢„æµ‹ä¸€è‡´æ€§çš„çº¦æŸã€‚ ZZZ  æ˜¯å½’ä¸€åŒ–åŠ¿å’Œçš„é…åˆ†å‡½æ•°ã€‚ ZZZ  å®šä¹‰ä¸º\nZ=âˆ‘yiâˆˆYexpâ¡[âˆ‘iâˆˆSAi(yi,x)+âˆ‘iâˆˆSâˆ‘jâˆˆNiIij(yi,yj,x)]Z = \\sum_{y_i \\in Y}\n\\exp\\left[\n\\sum_{i \\in S} A_i(y_i, x)\n+ \\sum_{i \\in S} \\sum_{j \\in N_i} I_{ij}(y_i, y_j, x)\n\\right]\nZ=yiâ€‹âˆˆYâˆ‘â€‹expâ£â¢â¡â€‹iâˆˆSâˆ‘â€‹Aiâ€‹(yiâ€‹,x)+iâˆˆSâˆ‘â€‹jâˆˆNiâ€‹âˆ‘â€‹Iijâ€‹(yiâ€‹,yjâ€‹,x)â¦â¥â¤â€‹\nThe unary potential of CRF for semantic segmentation is generally defined by the label assignment probability at pixels.\nCRF åœ¨è¯­ä¹‰åˆ†å‰²ä¸­çš„ä¸€å…ƒåŠ¿èƒ½é€šå¸¸ç”±åƒç´ å¤„çš„æ ‡ç­¾åˆ†é…æ¦‚ç‡å®šä¹‰ã€‚\nIn the early UAV semantic segmentation tasks, Random Forest (Quang et al., 2015), Support Vector Machine (Zhang et al., 2018), or boosted classifiers (Girisha et al., 2019; Shotton et al., 2009) have been adopted to obtain the unary potential.\nåœ¨æ—©æœŸçš„æ— äººæœºè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œéšæœºæ£®æ—ï¼ˆQuang ç­‰ï¼Œ2015ï¼‰ã€æ”¯æŒå‘é‡æœºï¼ˆZhang ç­‰ï¼Œ2018ï¼‰æˆ–å¢å¼ºåˆ†ç±»å™¨ï¼ˆGirisha ç­‰ï¼Œ2019;Shotton ç­‰ï¼Œ2009ï¼‰å·²è¢«é‡‡ç”¨æ¥è·å¾—ä¸€å…ƒåŠ¿ã€‚\nHowever, constructing unary potential through traditional  classifiers lacks the integration of spatial context information, which may lead to misclassifications of pixel labels in high-resolution UAV images (Zhang et al., 2018).\nç„¶è€Œï¼Œé€šè¿‡ä¼ ç»Ÿåˆ†ç±»å™¨æ„å»ºä¸€å…ƒåŠ¿ç¼ºä¹ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•´åˆï¼Œå¯èƒ½å¯¼è‡´é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­åƒç´ æ ‡ç­¾çš„é”™è¯¯åˆ†ç±»ï¼ˆZhang ç­‰ï¼Œ2018ï¼‰ã€‚\nZeggada et al. (2018), in another way, subdivided UAV images into a grid of tiles of equal size, then combined the Bag of Words, Autoencoder, and Multi-Layer Perceptron to construct the unary potential of CRF.\nZeggada ç­‰äººï¼ˆ2018ï¼‰åˆ™ä»¥å¦ä¸€ç§æ–¹å¼å°†æ— äººæœºå›¾åƒç»†åˆ†ä¸ºå¤§å°ç›¸ç­‰çš„ç½‘æ ¼ï¼Œç„¶åç»“åˆè¯è¢‹ã€è‡ªç¼–ç å™¨å’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼Œæ„å»ºäº† CRF çš„ä¸€å…ƒåŠ¿èƒ½ã€‚\nIt independently integrated the local spatial context of each grid in UAV imagery to extract compact signatures that effectively describe the corresponding tiles.\nå®ƒç‹¬ç«‹æ•´åˆäº†æ— äººæœºå›¾åƒä¸­æ¯ä¸ªç½‘æ ¼çš„å±€éƒ¨ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œæå–å‡ºæœ‰æ•ˆæè¿°å¯¹åº”ç“¦ç‰‡çš„ç´§å‡‘ç­¾åã€‚\nIn the subsequent practices (Zhang et al., 2019b; Chiu et al., 2020; Huang et al., 2020; Lobo Torres et al., 2020; Girisha et al., 2020; Song et al., 2020; Zhong et al., 2020; Girisha et al., 2021a; Zhang et al., 2022a) of semantic segmentation for UAV images, Deep Convolutional Neural Networks (DCNNs) have gradually replaced the unary potential construction methods that require hand-crafted feature extraction.\nåœ¨åç»­å®è·µä¸­ï¼ˆZhang ç­‰ï¼Œ2019b;Chiu ç­‰ï¼Œ2020;Huang ç­‰ï¼Œ2020;Lobo Torres ç­‰ï¼Œ2020;Girisha ç­‰ï¼Œ2020;Song ç­‰ï¼Œ2020;Zhong ç­‰ï¼Œ2020;Girisha ç­‰ï¼Œ2021a;Zhang ç­‰äººï¼Œ2022aï¼‰å…³äºæ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²çš„åº”ç”¨ï¼Œæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆDCNNsï¼‰é€æ¸å–ä»£äº†éœ€è¦æ‰‹å·¥ç‰¹å¾æå–çš„ä¸€å…ƒåŠ¿æ„å»ºæ–¹æ³•ã€‚\nThe stacked convolutional layers of DCNNs expand the receptive field (Krizhevsky et al., 2012) layer by layer, making it possible to automatically capture rich spatial contextual feature information of UAV images.\nå †å å·ç§¯çš„ DCNN å±‚æ‰©å±•æ„Ÿå—åœºï¼ˆKrizhevsky ç­‰ï¼Œ2012ï¼‰ï¼Œä½¿å¾—èƒ½å¤Ÿè‡ªåŠ¨æ•æ‰æ— äººæœºå›¾åƒä¸°å¯Œçš„ç©ºé—´ä¸Šä¸‹æ–‡ç‰¹å¾ä¿¡æ¯ã€‚\nThe last feature layer with softmax activation function (Krizhevsky et al., 2012; Long et al., 2015; Badrinarayanan et al., 2017) can be utilized as the label assignment probability required by the unary potential. Thus, researchers can focus on designing pair-wise potential functions applied to different UAV images and scenarios to capture the dependencies between pixels or objects.\n== æœ€åä¸€ä¸ªå¸¦æœ‰ softmax æ¿€æ´»å‡½æ•°çš„ç‰¹å¾å±‚ï¼ˆKrizhevsky ç­‰ï¼Œ2012;Long ç­‰ï¼Œ2015;Badrinarayanan ç­‰ï¼Œ2017ï¼‰å¯ä»¥ä½œä¸ºä¸€å…ƒåŠ¿æ‰€éœ€çš„æ ‡ç­¾èµ‹å€¼æ¦‚ç‡ã€‚== å› æ­¤ï¼Œç ”ç©¶äººå‘˜å¯ä»¥ä¸“æ³¨äºè®¾è®¡åº”ç”¨äºä¸åŒæ— äººæœºå›¾åƒå’Œåœºæ™¯çš„æˆå¯¹åŠ¿å‡½æ•°ï¼Œä»¥æ•æ‰åƒç´ æˆ–ç‰©ä½“ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚\nThe pair-wise potential of the most commonly used plain CRF is usually defined by the Potts model or its variants (Yu et al., 2018b; Girisha et al., 2019).\næœ€å¸¸ç”¨çš„çº¯ CRF çš„ä¸¤å¯¹åŠ¿èƒ½é€šå¸¸ç”± Potts æ¨¡å‹æˆ–å…¶å˜ä½“å®šä¹‰ï¼ˆYu ç­‰ï¼Œ2018b;Girisha ç­‰ï¼Œ2019ï¼‰ã€‚\nHowever, the plain CRF is limited to capturing long-range contextual semantic information due to the improper penalizing function.\nç„¶è€Œï¼Œç”±äºæƒ©ç½šå‡½æ•°ä¸å½“ï¼Œçº¯ CRF ä»…é™äºæ•æ‰é•¿è·ç¦»è¯­ä¹‰ä¿¡æ¯ã€‚\nKong et al. (2020) argued that the part of UAV images where complex textures exist might result in label misclassification, and it was not convincible to penalize all inconsistent labels equally using the Potts model.\nKong ç­‰äººï¼ˆ2020ï¼‰è®¤ä¸ºï¼Œå­˜åœ¨å¤æ‚çº¹ç†çš„æ— äººæœºå›¾åƒéƒ¨åˆ†å¯èƒ½å¯¼è‡´æ ‡ç­¾é”™è¯¯åˆ†ç±»ï¼Œä¸”ç”¨ Potts æ¨¡å‹å¯¹æ‰€æœ‰ä¸ä¸€è‡´æ ‡ç­¾å‡ç­‰æƒ©ç½šæ˜¯ä¸å¯ä¿¡çš„ã€‚\nThe pair-wise potentials applied to the semantic segmentation of UAV images can vary according to the specific tasks. For instance, Kong et al. (2020) considered that pixels with similar positions, similar colors, and small height differences should have a higher probability of assigning the same label for urban semantic segmentation.\nåº”ç”¨äºæ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ä¸¤å¯¹åŠ¿èƒ½ä¼šæ ¹æ®å…·ä½“ä»»åŠ¡è€Œå¼‚ã€‚ä¾‹å¦‚ï¼ŒKong ç­‰äººï¼ˆ2020ï¼‰è®¤ä¸ºä½ç½®ç›¸ä¼¼ã€é¢œè‰²ç›¸ä¼¼ä¸”é«˜åº¦å·®å¼‚è¾ƒå°çš„åƒç´ ï¼Œåœ¨åŸå¸‚è¯­ä¹‰åˆ†å‰²ä¸­åº”æœ‰æ›´é«˜çš„æ¦‚ç‡è¢«èµ‹äºˆç›¸åŒæ ‡ç­¾ã€‚\nThe pair-wise potential they designed had considered features such as color, position, height, and scale. It achieved a more reasonable penalty for inconsistent label predictions of the semantic segmentation for UAV images.\nä»–ä»¬è®¾è®¡çš„é…å¯¹æ½œåŠ›è€ƒè™‘äº†é¢œè‰²ã€ä½ç½®ã€é«˜åº¦å’Œæ¯”ä¾‹ç­‰ç‰¹å¾ã€‚å®ƒå¯¹æ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æ ‡ç­¾é¢„æµ‹ä¸ä¸€è‡´çš„æƒ©ç½šæ›´ä¸ºåˆç†ã€‚\nFurthermore, the long-range and shortrange dependencies between pixels are also essential for capturing the global contextual information needed for the semantic segmentation of UAV images.\næ­¤å¤–ï¼Œåƒç´ ä¹‹é—´çš„é•¿è·ç¦»å’ŒçŸ­è·ç¦»ä¾èµ–å…³ç³»å¯¹äºæ•æ‰æ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æ‰€éœ€çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ä¹Ÿè‡³å…³é‡è¦ã€‚\nFully connected CRF (FC-CRF) (KrÃ¤henbÃ¼hl and Koltun, 2011) contains pair-wise potentials of all individual pixels in an image.\nå…¨è¿é€š CRFï¼ˆFC-CRFï¼‰ï¼ˆKrÃ¤henbÃ¼hl å’Œ Koltunï¼Œ2011ï¼‰åŒ…å«å›¾åƒä¸­æ‰€æœ‰å•ä¸ªåƒç´ çš„ä¸¤ä¸¤åŠ¿ã€‚\nThe spatial dependency between pixels established by FC-CRF is more effective in reducing the cluttered pixel-level misclassification in the semantic segmentation map and improving the smoothness of the segmentation boundaries of semantic objects (Quang et al., 2015; Zhang et al., 2018; Zhuo et al., 2018a; Girisha et al., 2019; Zhang et al., 2019b; Zhuo et al., 2019; Chiu et al., 2020; Huang et al., 2020; Lyu et al., 2020; Zhang et al., 2022a).\nFC-CRF ç¡®ç«‹çš„åƒç´ é—´ç©ºé—´ä¾èµ–æ€§åœ¨å‡å°‘è¯­ä¹‰åˆ†å‰²å›¾ä¸­åƒç´ å±‚çº§çš„æ‚ä¹±é”™è¯¯åˆ†ç±»å’Œæ”¹å–„è¯­ä¹‰å¯¹è±¡åˆ†å‰²è¾¹ç•Œçš„å¹³æ»‘æ€§æ–¹é¢æ›´ä¸ºæœ‰æ•ˆï¼ˆQuang ç­‰ï¼Œ2015;Zhang ç­‰äººï¼Œ2018;Zhuo ç­‰ï¼Œ2018a;Girisha ç­‰ï¼Œ2019;Zhang ç­‰äººï¼Œ2019b;Zhuo ç­‰ï¼Œ2019;Chiu ç­‰ï¼Œ2020;Huang ç­‰ï¼Œ2020;Lyu ç­‰ï¼Œ2020;Zhang ç­‰ï¼Œ2022aï¼‰ã€‚\nIn addition, FC-CRF can also be extended from the spatial dimension to the spatio-temporal dimension for comprehensive context integration and accurate scene understanding of UAV-based videos (Cao et al., 2019; Lyu et al., 2020).\næ­¤å¤–ï¼ŒFC-CRF è¿˜å¯ä»¥ä»ç©ºé—´ç»´åº¦æ‰©å±•åˆ°æ—¶ç©ºç»´åº¦ï¼Œå®ç°æ— äººæœºè§†é¢‘çš„å…¨é¢ä¸Šä¸‹æ–‡æ•´åˆå’Œå‡†ç¡®çš„åœºæ™¯ç†è§£ï¼ˆCao ç­‰ï¼Œ2019;Lyu ç­‰ï¼Œ2020ï¼‰ã€‚\nHowever, the FC-CRF was no longer popular in recent remote sensing image parsing tasks due to the expensive computational overhead. To solve the abovementioned shortcomings of dense CRFs, Teichmann and Cipolla (2018) proposed Convolutional CRF (ConvCRF) based on the conditional independence assumption between two pixels.\nç„¶è€Œï¼Œç”±äºè®¡ç®—å¼€é”€è¾ƒé«˜ï¼ŒFC-CRF åœ¨è¿‘æœŸé¥æ„Ÿå›¾åƒè§£æä»»åŠ¡ä¸­å·²ä¸å†æµè¡Œã€‚ä¸ºäº†è§£å†³ä¸Šè¿°å¯†é›† CRF çš„ä¸è¶³ï¼ŒTeichmann å’Œ Cipollaï¼ˆ2018ï¼‰æå‡ºäº†åŸºäºä¸¤ä¸ªåƒç´ ä¹‹é—´æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾çš„å·ç§¯ CRFï¼ˆConvCRFï¼‰ã€‚\nThe model utilized a convolutional neural network to construct unary potentials and set the interaction potentials to zero as the Manhattan distance between pixels exceeded the threshold. Based on the locality assumption, the processing speed of segmentation increased by two orders of magnitude while improving segmentation accuracy.\nè¯¥æ¨¡å‹åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ„é€ ä¸€å…ƒåŠ¿ï¼Œå¹¶åœ¨åƒç´ é—´æ›¼å“ˆé¡¿è·ç¦»è¶…è¿‡é˜ˆå€¼æ—¶å°†äº¤äº’åŠ¿è®¾ä¸ºé›¶ã€‚åŸºäºå±€éƒ¨æ€§å‡è®¾ï¼Œåˆ†å‰²çš„å¤„ç†é€Ÿåº¦æé«˜äº†ä¸¤ä¸ªæ•°é‡çº§ï¼ŒåŒæ—¶æé«˜äº†åˆ‡å‰²å‡†ç¡®æ€§ã€‚\nSong et al. (2020) used ConvCRF as the post-processing of SegNet for sunflower lodging detection.\nSong ç­‰äººï¼ˆ2020ï¼‰ä½¿ç”¨ ConvCRF ä½œä¸ºå‘æ—¥è‘µå€’ä¼æ£€æµ‹çš„ SegNet åå¤„ç†ã€‚\nThis algorithm combination corrected the wrong prediction of the lodging area in UAV images and further optimized the segmentation boundaries, achieving the balance between segmentation accuracy and computational overhead.\nè¯¥ç®—æ³•ç»„åˆçº æ­£äº†æ— äººæœºå›¾åƒä¸­å€’ä¼åŒºåŸŸçš„é”™è¯¯é¢„æµ‹ï¼Œå¹¶è¿›ä¸€æ­¥ä¼˜åŒ–äº†åˆ†å‰²è¾¹ç•Œï¼Œå®ç°äº†åˆ†å‰²ç²¾åº¦ä¸è®¡ç®—å¼€é”€ä¹‹é—´çš„å¹³è¡¡ã€‚\nHere we introduce several public graph-based models and highlight their advantages and shortcomings, shown in Table 1. Although only a few works can be found where the graph-based models are utilized in recent research on semantic segmentation for UAV remote sensing images, the ideas of integrating semantic information by interaction terms between pixels or regions have encouraged the relationship modeling methods in deep feature-learned methods. We refer readers to Section 3.3 for more details.\nè¿™é‡Œæˆ‘ä»¬ä»‹ç»äº†å‡ ä¸ªåŸºäºå…¬å¼€çš„åŸºäºå›¾çš„æ¨¡å‹ï¼Œå¹¶é‡ç‚¹ä»‹ç»å®ƒä»¬çš„ä¼˜ç¼ºç‚¹ï¼Œè§è¡¨ 1ã€‚å°½ç®¡ç›®å‰åœ¨æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²ç ”ç©¶ä¸­åº”ç”¨åŸºäºå›¾çš„æ¨¡å‹çš„ä½œå“å¾ˆå°‘ï¼Œä½†é€šè¿‡åƒç´ æˆ–åŒºåŸŸé—´äº¤äº’é¡¹æ•´åˆè¯­ä¹‰ä¿¡æ¯çš„ç†å¿µï¼Œæ¨åŠ¨äº†æ·±åº¦ç‰¹å¾å­¦ä¹ æ–¹æ³•ä¸­å…³ç³»å»ºæ¨¡æ–¹æ³•çš„å‘å±•ã€‚æ›´å¤šè¯¦æƒ…è¯·é˜…è¯»ç¬¬ 3.3 èŠ‚ã€‚\nSummary of graph-based contextual models for UAV semantic segmentation.\næ— äººæœºè¯­ä¹‰åˆ†å‰²çš„åŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹æ€»ç»“ã€‚\n\n\n\nç±»åˆ«\næ¨¡å‹\nåº”ç”¨\nå›¾åƒæ¨¡æ€\nç‰¹ç‚¹\næ€§èƒ½ä¸ä¼˜åŠ¿\nå±€é™æ€§\n\n\n\n\nMRF\nOMRF\nè¾“ç”µçº¿æ£€æµ‹ï¼ˆZhao et al., 2022ï¼‰\nRGB\nä½¿ç”¨ GMM å’Œ WRAG æ¥å®šä¹‰ç›®æ ‡ä¹‹é—´çš„å…³ç³»\nãƒ»å…·æœ‰æ›´å¥½çš„æŠ—å¹²æ‰°èƒ½åŠ›ãƒ»æä¾›äº†è¾ƒé«˜çš„æ£€æµ‹ç²¾åº¦å¹¶å‡å°‘äº†è¯¯æ£€çº¿æ¡\nãƒ»å¯¹å¤æ‚å›¾åƒéœ€è¦é¢å¤–çš„è®¡ç®—æ—¶é—´ãƒ»å‚æ•°é€‰æ‹©è¾ƒä¸ºå¤æ‚\n\n\nMRF\nPOMRF-DIT\nèˆªç©ºåœºæ™¯ï¼ˆYao et al., 2021ï¼‰\nRGB\nåŸºäºé‡‘å­—å¡”çš„ç›®æ ‡çº§ MRFï¼Œå¼•å…¥åŒé€šé“ä¿¡æ¯ä¼ è¾“ä»¥æŒ–æ˜å’Œä¼ é€’é‡‘å­—å¡”å¤šå±‚ä¿¡æ¯\nãƒ»èƒ½å¤Ÿä»é‡‘å­—å¡”ç»“æ„ä¸­æŒ–æ˜å¹¶ä¼ é€’å›¾åƒä¿¡æ¯ãƒ»åˆ†å‰²æ”¶æ•›é€Ÿåº¦æ›´å¿«\nãƒ»å¯¹å…‰è°±ç‰¹å¾ç›¸ä¼¼çš„ç›®æ ‡å®¹æ˜“äº§ç”Ÿè¯¯åˆ†ç±»\n\n\nCRF\nTextonBoost\nèˆªç©ºåœºæ™¯ï¼ˆGirisha et al., 2019ï¼‰\nRGB\nåˆ©ç”¨çº¹ç†å¸ƒå±€å’Œä½å±‚å›¾åƒç‰¹å¾ï¼Œå¼•å…¥åƒç´ é—´ç›¸å…³æ€§ä»¥å®ç°è¯­ä¹‰åˆ†å‰²\nãƒ»å­¦ä¹ çº¹ç†ç‰¹å¾ä»¥æ•è·å›¾åƒä¸­çš„çº¹ç†å¸ƒå±€ä¸Šä¸‹æ–‡ãƒ»èƒ½å¤Ÿæ•è·æ›´å¤šå›¾åƒç»†èŠ‚\nãƒ»åŸºäºåƒç´ çš„ CRFãƒ»å¤„ç†æ—¶é—´è¾ƒé•¿\n\n\nCRF\nAF-CRF\nåŸå¸‚åœºæ™¯ï¼ˆKong et al., 2020ï¼‰\nRGBã€DSM\nå°†å¤šå°ºåº¦å’Œæ³¨æ„åŠ›åˆ†æå¼•å…¥åˆ†å‰²è¿‡ç¨‹\nãƒ»é‡‡ç”¨å‡å€¼åœºè¿‘ä¼¼çš„å¿«é€Ÿæ±‚è§£ç®—æ³•ä»¥åŠ é€Ÿè®¡ç®—ãƒ»æä¾›æ›´é«˜çš„ç²¾åº¦å’Œåˆ†å‰²ç½®ä¿¡åº¦\nãƒ»è¿‡åº¦è€ƒè™‘é•¿ç¨‹ä¾èµ–å¯èƒ½å¯¼è‡´è¯¯åˆ†ç±»\n\n\nCRF\nDCNN + DenseCRF\nåŸå¸‚ / èˆªç©ºåœºæ™¯ï¼ˆZhang et al., 2019bï¼›Chiu et al., 2020ï¼›Huang et al., 2020ï¼›Lobo Torres et al., 2020ï¼›Girisha et al., 2020ï¼›Zhong et al., 2020ï¼›Girisha et al., 2021aï¼›Zhang et al., 2022aï¼‰\nRGBã€çº¢å¤–\nä½¿ç”¨ç¨ å¯† CRF ä½œä¸ºåå¤„ç†ï¼Œå¯¹å·ç§¯ç¥ç»ç½‘ç»œè¾“å‡ºè¿›è¡Œç»†åŒ–\nãƒ»èƒ½ç”Ÿæˆæ›´åŠ ç²¾ç»†çš„åˆ†å‰²ç»“æœãƒ»ä¿®æ­£äº† CNN ä¸­çš„ä¸€äº›è¯¯åˆ†ç±»\nãƒ»ç¨ å¯† CRF ä¸­æˆå¯¹åŠ¿å‡½æ•°çš„è®¡ç®—å¤æ‚åº¦è¾ƒé«˜\n\n\nCRF\nDCNN + ConvCRF\nå†œä½œç‰©å€’ä¼æ£€æµ‹ï¼ˆSong et al., 2020ï¼‰\nRGBã€çº¢è¾¹ã€è¿‘çº¢å¤–ï¼ˆNIRï¼‰\næ¯å¹…å›¾åƒçš„å•åŠ¿ç”± CNN çš„ softmax è¾“å‡ºè®¾å®šï¼Œå¹¶é‡‡ç”¨å±€éƒ¨æ€§å‡è®¾è®¾è®¡æˆå¯¹åŠ¿\nãƒ»é™ä½äº†æˆå¯¹åŠ¿çš„è®¡ç®—å¤æ‚åº¦ãƒ»æ›´å¿«ä¸”æ›´å…·å®ç”¨æ€§\nãƒ»ConvCRF åœ¨è®¡ç®—æ•ˆç‡ä¸åƒç´ é—´é•¿ç¨‹ä¾èµ–ä¹‹é—´å­˜åœ¨æŠ˜ä¸­\n\n\n\n# Methods based on deep-learning models\nåŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ–¹æ³•\nUAV-based images with higher resolution typically contain semantic objects or regions that hold intricate and detailed semantic representations.\nåŸºäºæ— äººæœºçš„æ›´é«˜åˆ†è¾¨ç‡å›¾åƒé€šå¸¸åŒ…å«åŒ…å«å¤æ‚ä¸”è¯¦ç»†è¯­ä¹‰è¡¨ç¤ºçš„è¯­ä¹‰å¯¹è±¡æˆ–åŒºåŸŸã€‚\nHand-engineered graph-based contextual models struggle to cope with these intricate semantic representations, and these techniques of image semantic segmentation are gradually being overtaken by DL-based architectures in UAV remote sensing (Osco et al., 2021).\næ‰‹å·¥è®¾è®¡çš„åŸºäºå›¾çš„ä¸Šä¸‹æ–‡æ¨¡å‹éš¾ä»¥åº”å¯¹è¿™äº›å¤æ‚çš„è¯­ä¹‰è¡¨ç¤ºï¼Œè¿™äº›å›¾åƒè¯­ä¹‰åˆ†å‰²æŠ€æœ¯æ­£é€æ¸è¢«æ— äººæœºé¥æ„Ÿä¸­çš„åŸºäº DL æ¶æ„æ‰€å–ä»£ï¼ˆOsco ç­‰ï¼Œ2021ï¼‰ã€‚\nDLbased semantic segmentation not only eliminates the tedious process of hand-crafted feature extraction with the well-designed combinations of various trainable operators, such as convolution layers, linear layers, and activation layers (Yu et al., 2018b; Yuan et al., 2021), but also presents better segmentation performance to the complex semantic representations of high-resolution images in UAV remote sensing.\nåŸºäº DL çš„è¯­ä¹‰åˆ†å‰²ä¸ä»…æ¶ˆé™¤äº†æ‰‹å·¥åˆ¶ä½œç‰¹å¾æå–çš„ç¹çè¿‡ç¨‹ï¼Œé‡‡ç”¨äº†å¤šç§å¯è®­ç»ƒç®—ç¬¦çš„è‰¯å¥½ç»„åˆï¼Œå¦‚å·ç§¯å±‚ã€çº¿æ€§å±‚å’Œæ¿€æ´»å±‚ï¼ˆYu ç­‰ï¼Œ2018b;Yuan ç­‰ï¼Œ2021ï¼‰ï¼ŒåŒæ—¶ä¹Ÿåœ¨æ— äººæœºé¥æ„Ÿä¸­å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒçš„å¤æ‚è¯­ä¹‰è¡¨ç¤ºæä¾›äº†æ›´å¥½çš„åˆ†å‰²æ€§èƒ½ã€‚\nOur literature review in this section focuses on five aspects of DL-based advances for image semantic segmentation in UAV remote sensing: (1) Encoderâ€“decoder architectures; (2) Multi-scale and feature fusion strategies; (3) Relationship modeling methods; (4) Vision transformer architectures; (5) Light-weight methods.\næœ¬èŠ‚æ–‡çŒ®ç»¼è¿°èšç„¦äºæ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²åŸºäº DL çš„äº”ä¸ªæ–¹é¢ï¼š\n\nç¼–ç  - è§£ç å™¨æ¶æ„\nå¤šå°ºåº¦å’Œç‰¹å¾èåˆç­–ç•¥\nå…³ç³»å»ºæ¨¡æ–¹æ³•\nè§†è§‰å˜æ¢å™¨æ¶æ„\nè½»é‡åŒ–æ–¹æ³•ã€‚\n\n# Encoderâ€“decoder architectures\nIn previous studies, the encoderâ€“decoder architecture had been widely adopted to achieve pixel-wise labeling when designing DCNN for semantic segmentation tasks.\nåœ¨ä»¥å¾€çš„ç ”ç©¶ä¸­ï¼Œç¼–ç å™¨ - è§£ç å™¨æ¶æ„å·²è¢«å¹¿æ³›é‡‡ç”¨ï¼Œä»¥å®ç°é’ˆå¯¹è¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„ DCNN å®ç°åƒç´ æ ‡è®°ã€‚\nThe encoderâ€“decoder architectures usually consist of two primary components.\nç¼–ç å™¨ - è§£ç å™¨æ¶æ„é€šå¸¸ç”±ä¸¤ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ç»„æˆã€‚\nThe first component is the encoder structure, which is generally composed of an efficient backbone of a pre-trained classification network.\nç¬¬ä¸€ä¸ªç»„æˆéƒ¨åˆ†æ˜¯ç¼–ç å™¨ç»“æ„ï¼Œé€šå¸¸ç”±é¢„è®­ç»ƒåˆ†ç±»ç½‘ç»œçš„é«˜æ•ˆéª¨å¹²ç»„æˆã€‚\nIt aims to reduce the spatial scale of the input image and extract feature maps with context semantic information.\nå…¶ç›®æ ‡æ˜¯é™ä½è¾“å…¥å›¾åƒçš„ç©ºé—´å°ºåº¦ï¼Œå¹¶æå–å¸¦æœ‰ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯çš„ç‰¹å¾å›¾ã€‚\nBesides, pooling-based and convolution-based down-sampling strategies have been wildly adopted as the standard techniques in the encoder process for increasing the local prospective field and reducing computation costs.\næ­¤å¤–ï¼ŒåŸºäºæ± å’Œå·ç§¯çš„ä¸‹é‡‡æ ·ç­–ç•¥å·²è¢«å¹¿æ³›é‡‡ç”¨ä¸ºç¼–ç å™¨è¿‡ç¨‹ä¸­çš„æ ‡å‡†æŠ€æœ¯ï¼Œç”¨äºå¢åŠ å±€éƒ¨å‰æ™¯åœºå¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚\nAnother component is the decoder structure, which typically utilizes bilinear interpolation or deconvolution (Dumoulin and Visin, 2016) up-sample strategies.\nå¦ä¸€ä¸ªç»„æˆéƒ¨åˆ†æ˜¯è§£ç å™¨ç»“æ„ï¼Œé€šå¸¸é‡‡ç”¨åŒçº¿æ€§æ’å€¼æˆ–åå·ç§¯ï¼ˆDumoulin å’Œ Visinï¼Œ2016ï¼‰ä¸Šé‡‡æ ·ç­–ç•¥ã€‚\nIt maps the low-resolution feature blocks of the encoder structure back to feature blocks or prediction outputs with higher spatial resolution.\nå®ƒå°†ç¼–ç å™¨ç»“æ„ä¸­çš„ä½åˆ†è¾¨ç‡ç‰¹å¾å—æ˜ å°„å›å…·æœ‰æ›´é«˜ç©ºé—´åˆ†è¾¨ç‡çš„ç‰¹å¾å—æˆ–é¢„æµ‹è¾“å‡ºã€‚\nIt maps the low-resolution feature blocks of the encoder structure back to feature blocks or prediction outputs with higher spatial resolution.\nå®ƒå°†ç¼–ç å™¨ç»“æ„ä¸­çš„ä½åˆ†è¾¨ç‡ç‰¹å¾å—æ˜ å°„å›å…·æœ‰æ›´é«˜ç©ºé—´åˆ†è¾¨ç‡çš„ç‰¹å¾å—æˆ–é¢„æµ‹è¾“å‡ºã€‚\n# FCN\nThe pioneering end-to-end encoderâ€“decoder structure for the pixelwise semantic segmentation tasks is fully convolutional neural network (FCN) proposed by Long et al. (2015).\nåƒç´ è¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„å¼€åˆ›æ€§ç«¯åˆ°ç«¯ç¼–ç  - è§£ç ç»“æ„æ˜¯ Long ç­‰äººï¼ˆ2015ï¼‰æå‡ºçš„å…¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆFCNï¼‰ã€‚\nFCN adopted the performanceproven convolutional classification network, such as VGG16 (Simonyan and Zisserman, 2015), as the feature encoder to integrate contextual and location information.\nFCN é‡‡ç”¨äº†æ€§èƒ½éªŒè¯çš„å·ç§¯åˆ†ç±»ç½‘ç»œï¼Œå¦‚ VGG16ï¼ˆSimonyan å’Œ Zissermanï¼Œ2015ï¼‰ï¼Œä½œä¸ºæ•´åˆä¸Šä¸‹æ–‡å’Œä½ç½®ä¿¡æ¯çš„ç‰¹å¾ç¼–ç å™¨ã€‚\nAs shown in Fig. 1, FCN replaced the fully connected layers of CNN with only convolutional layers, making it possible to predict the class labels of all pixels with different spatial resolutions.\nå¦‚å›¾ 1 æ‰€ç¤ºï¼ŒFCN ç”¨å·ç§¯å±‚æ›¿ä»£äº† CNN çš„å…¨è¿é€šå±‚ï¼Œä½¿å¾—é¢„æµ‹æ‰€æœ‰å…·æœ‰ä¸åŒç©ºé—´åˆ†è¾¨ç‡åƒç´ çš„ç±»æ ‡ç­¾æˆä¸ºå¯èƒ½ã€‚\nThe structures of three types of FCNs followed the principle of combining coarse to fine layers to make the local predictions consistent with the global context information. For instance, the prediction result of FCN32s was computed by up-sampling the last max-pooling layer of VGG16 by a factor of 32, while that of FCN8s could be obtained by up-sampling the combination of the last three max-pooling layers by a factor of 8.\nä¸‰ç§ç±»å‹çš„å…¨å·ç§¯ç½‘ç»œï¼ˆFCNï¼‰çš„ç»“æ„éµå¾ªä»ç²—åˆ°ç»†å±‚ç»“åˆçš„åŸåˆ™ï¼Œä»¥ä½¿å±€éƒ¨é¢„æµ‹ä¸å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ä¿æŒä¸€è‡´ã€‚ä¾‹å¦‚ï¼ŒFCN32s çš„é¢„æµ‹ç»“æœæ˜¯é€šè¿‡å¯¹ VGG16 çš„æœ€åä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚è¿›è¡Œ 32 å€ä¸Šé‡‡æ ·è®¡ç®—å¾—åˆ°çš„ï¼Œè€Œ FCN8s çš„é¢„æµ‹ç»“æœåˆ™å¯ä»¥é€šè¿‡å¯¹æœ€åä¸‰ä¸ªæœ€å¤§æ± åŒ–å±‚çš„ç»„åˆè¿›è¡Œ 8 å€ä¸Šé‡‡æ ·å¾—åˆ°ã€‚\nFig. 1. Upsampling and fusion step of the FCN. Three upsampling and fusion strategies correspond to the network structure of FCN32s, FCN16s, and FCN8s. The fully connected layers of the feature backbone are replaced by the convolutional layers.\nå›¾ 1ã€‚FCN çš„ä¸Šé‡‡æ ·å’Œèåˆæ­¥éª¤ã€‚ä¸‰ç§ä¸Šé‡‡æ ·å’Œèåˆç­–ç•¥å¯¹åº” FCN32ã€FCN16 å’Œ FCN8 çš„ç½‘ç»œç»“æ„ã€‚ç‰¹å¾éª¨å¹²çš„å…¨è¿é€šå±‚è¢«å·ç§¯å±‚å–ä»£ã€‚\n\nFig. 2. Graphical visualization of the original SegNet architecture. SegNet adopts a symmetric encoderâ€“decoder structure without fully connected layers.\nå›¾ 2ã€‚åŸå§‹ SegNet æ¶æ„çš„å›¾å½¢å¯è§†åŒ–ã€‚SegNet é‡‡ç”¨å¯¹ç§°ç¼–ç  - è§£ç ç»“æ„ï¼Œæ²¡æœ‰å®Œå…¨è¿æ¥çš„å±‚ã€‚\nAs far as we know, FCN had been widely used for weed mapping (Huang et al., 2018a; Deng et al., 2020), crop lodging detection (Yang et al., 2020), road extraction (Kestur et al., 2018; Varia et al., 2018; Senthilnath et al., 2020), cadastral boundary extraction (Xia et al., 2019a,b), building footprint detection (Zhuo et al., 2018b), and many others. Comparative experiments (Huang et al., 2018c; Xia et al., 2019b; Yang et al., 2020) also demonstrated that the FCN had more excellent semantic aggregation ability and outstanding image processing efficiency than traditional image segmentation methods, such as CRF, Maximum Likelihood Classification (MLC), and Multi-Resolution Segmentation (MRS).\næ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒFCN å·²è¢«å¹¿æ³›ç”¨äºæ‚è‰æµ‹ç»˜ï¼ˆHuang ç­‰ï¼Œ2018a; é‚“ç­‰ï¼Œ2020ï¼‰ã€ä½œç‰©æ²‰ä¼æ£€æµ‹ï¼ˆYang ç­‰ï¼Œ2020ï¼‰ã€é“è·¯å¼€é‡‡ï¼ˆKestur ç­‰ï¼Œ2018;Varia ç­‰ï¼Œ2018;Senthilnath ç­‰ï¼Œ2020ï¼‰ã€åœ°ç±è¾¹ç•Œæå–ï¼ˆXia ç­‰ï¼Œ2019aï¼Œbï¼‰ã€å»ºç­‘åŸºå‡†æ£€æµ‹ï¼ˆZhuo ç­‰ï¼Œ2018bï¼‰ä»¥åŠå…¶ä»–è®¸å¤šæ–¹æ³•ã€‚æ¯”è¾ƒå®éªŒï¼ˆHuang ç­‰ï¼Œ2018c;Xia ç­‰ï¼Œ2019b;Yang ç­‰ï¼Œ2020ï¼‰è¿˜è¯æ˜ï¼ŒFCN æ¯”ä¼ ç»Ÿå›¾åƒåˆ†å‰²æ–¹æ³•ï¼ˆå¦‚ CRFã€æœ€å¤§ä¼¼ç„¶åˆ†ç±»ï¼ˆMLCï¼‰å’Œå¤šåˆ†è¾¨ç‡åˆ†å‰²ï¼ˆMRSï¼‰ï¼‰å…·æœ‰æ›´ä¼˜å¼‚çš„è¯­ä¹‰èšåˆèƒ½åŠ›å’Œå“è¶Šçš„å›¾åƒå¤„ç†æ•ˆç‡ã€‚\nHowever, there were still some drawbacks of FCN in handling high-resolution UAV-based images.\nç„¶è€Œï¼ŒFCN åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒæ—¶ä»å­˜åœ¨ä¸€äº›ç¼ºç‚¹ã€‚\nHuang et al. (2018b) had proven the efficiency of FCN on semantic segmentation of weed maps by transfer learning strategy, but their subsequent work (Huang et al., 2018a) found that the last pooling operation of FCN8s might result in losing spatial information and reduced accuracy.\nHuang ç­‰äººï¼ˆ2018bï¼‰å·²è¯æ˜ FCN é€šè¿‡è¿ç§»å­¦ä¹ ç­–ç•¥åœ¨æ‚è‰å›¾è¯­ä¹‰åˆ†å‰²ä¸­çš„é«˜æ•ˆæ€§ï¼Œä½†ä»–ä»¬åç»­çš„ç ”ç©¶ï¼ˆHuang ç­‰ï¼Œ2018aï¼‰å‘ç° FCN8 çš„æœ€åä¸€æ¬¡æ± åŒ–ä½œå¯èƒ½å¯¼è‡´ç©ºé—´ä¿¡æ¯ä¸¢å¤±å’Œå‡†ç¡®æ€§ä¸‹é™ã€‚\nXia et al. (2019a) also utilized FCN to obtain the fragmented cadastral boundaries from UAV remote sensing images and then applied the OWT-UCM algorithm to produce connected boundaries.\nXia ç­‰äººï¼ˆ2019aï¼‰è¿˜åˆ©ç”¨ FCN ä»æ— äººæœºé¥æ„Ÿå›¾åƒä¸­è·å–ç¢ç‰‡åŒ–åœ°å±‚è¾¹ç•Œï¼Œéšååº”ç”¨ OWT-UCM ç®—æ³•ç”Ÿæˆè¿é€šè¾¹ç•Œã€‚\nUnfortunately, the smoothing effect caused by max-pooling layers of FCN resulted in discontinuous boundaries. Therefore, their subsequent work (Xia et al., 2019b) on FCN discarded the max-pooling layers to avoid fuzzy boundary predictions.\nä¸å¹¸çš„æ˜¯ï¼Œæœ€å¤§æ± åŒ–å±‚é€ æˆçš„å¹³æ»‘æ•ˆæœå¯¼è‡´è¾¹ç•Œä¸è¿ç»­ã€‚å› æ­¤ï¼Œä»–ä»¬åç»­å…³äº FCN çš„ç ”ç©¶ï¼ˆXia ç­‰ï¼Œ2019bï¼‰ä¸ºé¿å…æ¨¡ç³Šè¾¹ç•Œé¢„æµ‹ï¼Œèˆå¼ƒäº†æœ€å¤§æ± å±‚ã€‚\nThe literature abovementioned exemplifies the suitability of FCN for UAV remote sensing image parsing tasks. But it is worth noting that the max pooling layers make the FCN insensitive to the details in high-resolution images, which leads to fuzzy pixel-level semantic predictions.\nä¸Šè¿°æ–‡çŒ®å±•ç¤ºäº† FCN åœ¨æ— äººæœºé¥æ„Ÿå›¾åƒè§£æä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ã€‚ä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ€å¤§æ± åŒ–å±‚ä½¿å¾— FCN å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒçš„ç»†èŠ‚ä¸æ•æ„Ÿï¼Œå¯¼è‡´åƒç´ çº§è¯­ä¹‰é¢„æµ‹æ¨¡ç³Šã€‚\nSome attention has focused on custom improvements to FCN, such as skip connections (Kestur et al., 2018), to exploit rich spatial patterns and semantic representations of UAV images.\nä¸€äº›å…³æ³¨ç‚¹é›†ä¸­åœ¨å¯¹ FCN çš„è‡ªå®šä¹‰æ”¹è¿›ä¸Šï¼Œå¦‚è·³è·ƒè¿æ¥ï¼ˆKestur ç­‰ï¼Œ2018ï¼‰ï¼Œä»¥åˆ©ç”¨æ— äººæœºå›¾åƒä¸°å¯Œçš„ç©ºé—´æ¨¡å¼å’Œè¯­ä¹‰è¡¨ç¤ºã€‚\nComparative experiments (Song et al., 2020; Lobo Torres et al., 2020) also illustrated that skip connection and discarding the max-pooling layers allowed FCN to preserve fine-grained spatial information and object overall consistency.\næ¯”è¾ƒå®éªŒï¼ˆSong ç­‰ï¼Œ2020;Lobo Torres ç­‰ï¼Œ2020ï¼‰è¿˜æŒ‡å‡ºï¼Œè·³è·ƒè¿æ¥å’Œä¸¢å¼ƒæœ€å¤§æ± å±‚ä½¿ FCN èƒ½å¤Ÿä¿æŒç»†ç²’åº¦çš„ç©ºé—´ä¿¡æ¯å’Œæ•´ä½“å¯¹è±¡çš„ä¸€è‡´æ€§ã€‚\n# SegNet\nThe down-sampling strategy of FCN did not take the pixel-to-pixel contextual relationship and object overall consistency into consideration, resulting in the segmentation predictions with insufficient refinement.\nFCN çš„ä¸‹é‡‡æ ·ç­–ç•¥æœªè€ƒè™‘åƒç´ å¯¹åƒç´ çš„ä¸Šä¸‹æ–‡å…³ç³»å’Œå¯¹è±¡æ•´ä½“ä¸€è‡´æ€§ï¼Œå¯¼è‡´åˆ†å‰²é¢„æµ‹ç»†åŒ–ä¸è¶³ã€‚\nTo address these drawbacks of lacking a reasonable mapping mechanism from feature map to input image spatial resolution, SegNet (Badrinarayanan et al., 2017) adopted a structurally symmetrical encoderâ€“decoder network with skip connections.\nä¸ºè§£å†³ç‰¹å¾æ˜ å°„åˆ°è¾“å…¥å›¾åƒç©ºé—´åˆ†è¾¨ç‡ç¼ºä¹åˆç†æ˜ å°„æœºåˆ¶çš„ä¸è¶³ï¼ŒSegNetï¼ˆBadrinarayanan ç­‰ï¼Œ2017ï¼‰é‡‡ç”¨äº†ç»“æ„å¯¹ç§°çš„ç¼–ç  - è§£ç å™¨ç½‘ç»œï¼Œé‡‡ç”¨è·³è·ƒè¿æ¥ã€‚\nSpecifically, SegNet decoded multi-scale encoded feature maps layer by layer to enhance the capacity of global contextual information.\nå…·ä½“æ¥è¯´ï¼ŒSegNet é€å±‚è§£ç å¤šå°ºåº¦ç¼–ç ç‰¹å¾å›¾ï¼Œä»¥å¢å¼ºå…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å®¹é‡ã€‚\nMeanwhile, it utilized the max-pooling indices of encoder layers to maintain the overall consistency of semantic information and avoid ambiguous predictions. The illustration of the SegNet architecture is shown in Fig. 2.\nåŒæ—¶ï¼Œå®ƒåˆ©ç”¨ç¼–ç å™¨å±‚çš„æœ€å¤§æ± åŒ–ç´¢å¼•æ¥ä¿æŒè¯­ä¹‰ä¿¡æ¯çš„æ•´ä½“ä¸€è‡´æ€§ï¼Œå¹¶é¿å…æ¨¡ç³Šçš„é¢„æµ‹ã€‚SegNet æ¶æ„çš„ç¤ºæ„å›¾å¦‚å›¾ 2 æ‰€ç¤ºã€‚\n\nSegNet çš„æƒ³æ³•ï¼šæ—¢ç„¶ä¸‹é‡‡æ ·æ—¶æˆ‘ä¸¢äº†ä½ç½®ï¼Œé‚£æˆ‘å°±é¡ºæ‰‹æŠŠä½ç½®è®°ä¸‹æ¥\n\n\n\nå¯¹æ¯”é¡¹\næ± åŒ–ç´¢å¼•\nåå·ç§¯\n\n\n\n\næ˜¯å¦å­¦ä¹ \nâŒ\nâœ…\n\n\nä¿å­˜å†…å®¹\nä½ç½®\nå·ç§¯æ ¸\n\n\nä¸Šé‡‡æ ·æ–¹å¼\næ”¾å›åŸä½\nå­¦ä¹ æ’å€¼\n\n\næ˜¯å¦ä¼šäº§ç”Ÿä¼ªå½±\nå‡ ä¹ä¸ä¼š\nå¯èƒ½æœ‰æ£‹ç›˜æ•ˆåº”\n\n\n\n\nBased on the improvements, a significant amount of research had been devoted to segmenting crops (Fawakherji et al., 2019; Song et al., 2020), trees (Lobo Torres et al., 2020), wetlands (Fu et al., 2021a), buildings (Boonpook et al., 2018), and roads (Boonpook et al., 2021) from high-resolution images.\nåŸºäºè¿™äº›æ”¹è¿›ï¼Œå¤§é‡ç ”ç©¶è‡´åŠ›äºä½œç‰©åˆ†æ®µï¼ˆFawakherji ç­‰ï¼Œ2019;Song ç­‰ï¼Œ2020ï¼‰ã€æ ‘æœ¨ï¼ˆLobo Torres ç­‰ï¼Œ2020ï¼‰ã€æ¹¿åœ°ï¼ˆFu ç­‰ï¼Œ2021aï¼‰ã€å»ºç­‘ç‰©ï¼ˆBoonpook ç­‰ï¼Œ2018ï¼‰å’Œé“è·¯ï¼ˆBoonpook ç­‰ï¼Œ2021ï¼‰ï¼Œå‡æ¥è‡ªé«˜åˆ†è¾¨ç‡å›¾åƒã€‚\nThe modifications on SegNet for segmenting different objects can vary substantially due to the physical and spatial characteristics of UAV remote sensing images.\nSegNet åœ¨åˆ†å‰²ä¸åŒç‰©ä½“æ—¶çš„ä¿®æ”¹å¯èƒ½å› æ— äººæœºé¥æ„Ÿå›¾åƒçš„ç‰©ç†å’Œç©ºé—´ç‰¹æ€§è€Œæœ‰å¾ˆå¤§å·®å¼‚ã€‚\nFor instance, Li et al. (2022a) reduced the number of convolutional blocks in the encoding and decoding block to improve segmentation efficiency.\nä¾‹å¦‚ï¼ŒLi ç­‰äººï¼ˆ2022aï¼‰å‡å°‘äº†ç¼–ç å’Œè§£ç å—ä¸­çš„å·ç§¯å—æ•°é‡ï¼Œä»¥æé«˜åˆ†å‰²æ•ˆç‡ã€‚\nThen they adopted the dilated convolution to expand the lost receptive field.\nç„¶åä»–ä»¬é‡‡ç”¨æ‰©å¼ å·ç§¯æ³•æ¥æ‰©å±•å¤±å»çš„æ„Ÿå—é‡ã€‚\nZhong et al. (2022) proposed W-SegNet, the two encoderâ€“decoder structure built on top of SegNet, to achieve hierarchical, multi-scale, and multi-level feature fusion. In addition, benefiting from excellent feature extraction and overall consistency predictions, SegNet has also received great attention for multi-modal UAV image segmentation tasks.\nZhong ç­‰äººï¼ˆ2022ï¼‰æå‡ºäº†åŸºäº SegNet æ„å»ºçš„åŒç¼–ç  - è§£ç å™¨ç»“æ„ W-SegNetï¼Œä»¥å®ç°å±‚çº§ã€å¤šå°ºåº¦å’Œå¤šå±‚æ¬¡çš„ç‰¹å¾èåˆã€‚æ­¤å¤–ï¼Œå‡­å€Ÿå‡ºè‰²çš„ç‰¹å¾æå–å’Œæ•´ä½“ä¸€è‡´æ€§é¢„æµ‹ï¼ŒSegNet åœ¨å¤šæ¨¡æ€æ— äººæœºå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ä¹Ÿå¤‡å—å…³æ³¨ã€‚\nSong et al. (2020) combined SegNet with ConvCRF to refine sunflower lodging prediction on high-resolution multispectral images collected by UAVs.\nSong ç­‰äººï¼ˆ2020ï¼‰ç»“åˆ SegNet ä¸ ConvCRFï¼Œä¼˜åŒ–äº†æ— äººæœºé‡‡é›†çš„é«˜åˆ†è¾¨ç‡å¤šå…‰è°±å›¾åƒå‘æ—¥è‘µå€’ä¼é¢„æµ‹ã€‚\nYang et al. (2020) achieved the highest mapping accuracy of plastic mulched farmland and the smoothest mapping boundary based on 6-band image data.\nYang ç­‰äººï¼ˆ2020ï¼‰åŸºäº 6 æ³¢æ®µå›¾åƒæ•°æ®ï¼Œå®ç°äº†å¡‘æ–™è¦†ç›–å†œç”°çš„æœ€é«˜æµ‹ç»˜ç²¾åº¦å’Œæœ€å¹³æ»‘çš„æµ‹ç»˜è¾¹ç•Œã€‚\nKerkech et al. (2020) proposed a fusion of multi-modal segmentation based on dual SegNets to obtain robust vine disease maps after image registration between the visible and infrared ranges.\nKerkech ç­‰äººï¼ˆ2020ï¼‰æå‡ºäº†åŸºäºåŒé‡ SegNet çš„å¤šæ¨¡æ€åˆ†å‰²èåˆï¼Œä»¥è·å¾—å¯è§å…‰ä¸çº¢å¤–èŒƒå›´å›¾åƒé…çº¿åçš„ç¨³å¥è—¤è”“ç—…å®³å›¾è°±ã€‚\nLi et al. (2021b) concluded that combining NIR and RGB images could improve the accuracy of sunflower lodging, while the red-edge data acted as a side effect.\nLi ç­‰äººï¼ˆ2021bï¼‰å¾—å‡ºç»“è®ºï¼Œç»“åˆè¿‘çº¢å¤–å’Œ RGB å›¾åƒå¯ä»¥æé«˜å‘æ—¥è‘µå€’ä¼çš„å‡†ç¡®æ€§ï¼Œè€Œçº¢è¾¹æ•°æ®åˆ™æ˜¯å‰¯ä½œç”¨ã€‚\n\nåœ¨å®é™…æ•°æ®ä¸­ï¼Œâ€œçº¢è¾¹æ•°æ®â€ é€šå¸¸æ˜¯ï¼š\n\næ— äººæœº / å«æ˜Ÿçš„ çº¢è¾¹æ³¢æ®µå½±åƒ\nå¸¸è§æ³¢æ®µä¸­å¿ƒï¼š705 nm 717 nm 740 nm\n\nçº¢è¾¹æ›´æ“…é•¿ â€œå¥åº·è¯„ä¼°â€ï¼Œè€Œä¸æ˜¯ â€œå½¢æ€ / å€’ä¼æ£€æµ‹â€\n\nBoonpook et al. (2018) also demonstrated that different combinations of modalities (RGB, visible-band difference vegetation index (VDVI), and DSM) of UAV sensors allowed SegNet to distinguish building and ground features more accurately.\nBoonpook ç­‰äººï¼ˆ2018ï¼‰è¿˜è¯æ˜ï¼Œä¸åŒæ— äººæœºä¼ æ„Ÿå™¨çš„æ¨¡æ€ç»„åˆï¼ˆRGBã€å¯è§æ³¢æ®µå·®æ¤è¢«æŒ‡æ•°ï¼ˆVDVIï¼‰å’Œ DSMï¼‰ä½¿ SegNet èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åŒºåˆ†å»ºç­‘ç‰©å’Œåœ°é¢ç‰¹å¾ã€‚\nThe wildly adopted SegNet selected VGG (Simonyan and Zisserman, 2015) as the feature extraction backbone and utilized max-pooling layers in the encoding process.\nå¹¿å—æ¬¢è¿çš„ SegNet é€‰æ‹©äº† VGGï¼ˆSimonyan å’Œ Zissermanï¼Œ2015ï¼‰ä½œä¸ºç‰¹å¾æå–éª¨å¹²ï¼Œå¹¶åœ¨ç¼–ç è¿‡ç¨‹ä¸­ä½¿ç”¨äº†æœ€å¤§æ± åŒ–å±‚ã€‚\nSuch network architecture offered the unique advantages of maintaining overall semantic consistency for large-scale scenes such as buildings and geographical areas.\nè¿™ç§ç½‘ç»œæ¶æ„æä¾›äº†ä¿æŒå¤§å‹åœºæ™¯ï¼ˆå¦‚å»ºç­‘ç‰©å’Œåœ°ç†åŒºåŸŸï¼‰æ•´ä½“è¯­ä¹‰ä¸€è‡´æ€§çš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚\nBut the significant limitation was that those scenes with apparent edge features and texture information, such as vegetation and crops, suffered poor segmentation accuracy as max-pooling layers lost detailed spatial contents.\nä½†ä¸»è¦å±€é™æ˜¯é‚£äº›å¸¦æœ‰æ˜æ˜¾è¾¹ç¼˜ç‰¹å¾å’Œçº¹ç†ä¿¡æ¯çš„åœºæ™¯ï¼Œå¦‚æ¤è¢«å’Œä½œç‰©ï¼Œç”±äºæœ€å¤§å±‚å ä¼šä¸¢å¤±è¯¦ç»†çš„ç©ºé—´å†…å®¹ï¼Œåˆ†å‰²ç²¾åº¦è¾ƒä½ã€‚\nFu et al. (2021a) conducted comparative experiments with optimized objects-based Random Forest-Decision Tree (RF-DT) and SegNet on the UAV dataset of digital orthophoto map (DOM) and digital surface model (DSM) imagery for Karst wetland vegetation communities.\nFu ç­‰äººï¼ˆ2021aï¼‰åœ¨æ— äººæœºæ•°å­—æ­£å°„ç…§ç‰‡åœ°å›¾ï¼ˆDOMï¼‰å’Œæ•°å­—åœ°è¡¨æ¨¡å‹ï¼ˆDSMï¼‰æ•°æ®é›†ä¸Šï¼Œé’ˆå¯¹å–€æ–¯ç‰¹æ¹¿åœ°æ¤è¢«ç¾¤è½è¿›è¡Œäº†åŸºäºä¼˜åŒ–å¯¹è±¡çš„éšæœºæ£®æ—å†³ç­–æ ‘ï¼ˆRF-DTï¼‰å’Œ SegNet çš„æ¯”è¾ƒå®éªŒã€‚\nSurprisingly, the optimized RF-DT algorithm achieved better overall accuracy than SegNet. After further analysis of the contribution of the four multi-source features, they found that the geometric feature describing the boundaries and shapes of vegetations as well as the texture feature presenting the surface properties of the scene played an important role in vegetation classification.\n== ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä¼˜åŒ–åçš„å°„é¢‘ - DT ç®—æ³•æ•´ä½“ç²¾åº¦ä¼˜äº SegNetã€‚== ç»è¿‡å¯¹å››å¤§å¤šæºç‰¹å¾è´¡çŒ®çš„è¿›ä¸€æ­¥åˆ†æï¼Œä»–ä»¬å‘ç°æè¿°æ¤è¢«è¾¹ç•Œå’Œå½¢çŠ¶çš„å‡ ä½•ç‰¹å¾ï¼Œä»¥åŠå‘ˆç°åœºæ™¯è¡¨é¢å±æ€§çš„çº¹ç†ç‰¹å¾ï¼Œåœ¨æ¤è¢«åˆ†ç±»ä¸­èµ·åˆ°äº†é‡è¦ä½œç”¨ã€‚\nSubsequent work, a fusion of multiple SegNet, conducted by Deng et al. (2022) further demonstrated that texture features could provide the visible intensity complement for karst wetland vegetation mapping.\néšåï¼Œé‚“ç­‰äººï¼ˆ2022 å¹´ï¼‰å¯¹å¤šé‡ SegNet çš„èåˆè¿›ä¸€æ­¥è¯æ˜ï¼Œçº¹ç†ç‰¹å¾å¯ä»¥ä¸ºå–€æ–¯ç‰¹æ¹¿åœ°æ¤è¢«ç»˜åˆ¶æä¾›å¯è§å¼ºåº¦çš„è¡¥å……ã€‚\nBoth verified that fine-scale information could enhance the spectral separability of vegetation in wetlands (Szantoi et al., 2013; Hu et al., 2020).\nä¸¤è€…éƒ½è¯å®äº†ç»†å¾®å°ºåº¦ä¿¡æ¯èƒ½å¤Ÿå¢å¼ºæ¹¿åœ°æ¤è¢«çš„å…‰è°±åˆ†ç¦»æ€§ï¼ˆSzantoi ç­‰ï¼Œ2013; èƒ¡ç­‰ï¼Œ2020ï¼‰ã€‚\nUnfortunately, SegNet was still deficient in extracting and handling these detailed features.\né—æ†¾çš„æ˜¯ï¼ŒSegNet åœ¨æå–å’Œç®¡ç†è¿™äº›è¯¦ç»†åŠŸèƒ½æ–¹é¢ä»ç„¶ä¸è¶³ã€‚\n# DeconvNet\nImproper down-sampling operations may lead to loss of spatial features, and thus decoding or mapping low-resolution feature maps to pixel-level predictions is the primary concern in encoderâ€“decoder architectures.\nä¸å½“çš„ä¸‹é‡‡æ ·ä½œå¯èƒ½å¯¼è‡´ç©ºé—´ç‰¹å¾ä¸¢å¤±ï¼Œå› æ­¤è§£ç æˆ–æ˜ å°„ä½åˆ†è¾¨ç‡ç‰¹å¾æ˜ å°„åˆ°åƒç´ çº§é¢„æµ‹æ˜¯ç¼–ç å™¨ - è§£ç å™¨æ¶æ„ä¸­çš„ä¸»è¦å…³æ³¨ç‚¹ã€‚\nFCN adopted deconvolution to produce nonlinear pixel-level predictions, while SegNet utilized max-pooling indices to upsample feature maps from the corresponding encoder layers.\nFCN é‡‡ç”¨äº†åå·ç§¯æŠ€æœ¯æ¥ç”Ÿæˆéçº¿æ€§åƒç´ çº§é¢„æµ‹ï¼Œè€Œ SegNet åˆ™åˆ©ç”¨æœ€å¤§æ± åŒ–æŒ‡æ ‡ä»ç›¸åº”ç¼–ç å™¨å±‚å¯¹ç‰¹å¾å›¾è¿›è¡Œä¸Šé‡‡æ ·ã€‚\nAnother effective encoderâ€“decoder structure, DeconvNet proposed by Noh et al. (2015), aimed to accurately reconstruct the high-dimensional nonlinear structural information with deep deconvolution up-sample mechanism.\nå¦ä¸€ç§æœ‰æ•ˆçš„ç¼–ç å™¨ - è§£ç å™¨ç»“æ„ï¼Œç”± Noh ç­‰äººï¼ˆ2015 å¹´ï¼‰æå‡ºçš„ DeconvNetï¼Œæ—¨åœ¨é€šè¿‡æ·±åº¦åå·ç§¯ä¸Šé‡‡æ ·æœºåˆ¶ï¼Œå‡†ç¡®é‡å»ºé«˜ç»´éçº¿æ€§ç»“æ„ä¿¡æ¯ã€‚\nHuang et al. (2016) constructed two isolated DeconvNet for optical images and NRG data, respectively.\nHuang ç­‰äººï¼ˆ2016ï¼‰åˆ†åˆ«æ„å»ºäº†ä¸¤ä¸ªç‹¬ç«‹çš„å»æ•´åˆç½‘ï¼Œåˆ†åˆ«ç”¨äºå…‰å­¦å›¾åƒå’Œ NRG æ•°æ®ã€‚\nThe quantitative evaluation proved the efficiency of DeconvNet in extracting buildings with rich topological appearances.\nå®šé‡è¯„ä¼°è¯æ˜äº† DeconvNet åœ¨æå–å…·æœ‰ä¸°å¯Œæ‹“æ‰‘å¤–è§‚å»ºç­‘æ–¹é¢çš„é«˜æ•ˆæ€§ã€‚\nTo handle the complex texture information and visual intensity change of remote sensing images, Cheng et al. (2016) designed a structured edge network (SeNet) with skip connections based on DeconvNet.\nä¸ºäº†å¤„ç†é¥æ„Ÿå›¾åƒçš„å¤æ‚çº¹ç†ä¿¡æ¯å’Œè§†è§‰å¼ºåº¦å˜åŒ–ï¼ŒCheng ç­‰äººï¼ˆ2016ï¼‰è®¾è®¡äº†ä¸€ä¸ªåŸºäº DeconvNet çš„ç»“æ„åŒ–è¾¹ç¼˜ç½‘ç»œï¼ˆSeNetï¼‰ï¼Œå¸¦æœ‰è·³è·ƒè¿æ¥ã€‚\nThe SeNet that combined local regularization with structured edge supervision achieved better spatial consistency and edge accuracy.\nå°†å±€éƒ¨æ­£åˆ™åŒ–ä¸ç»“æ„åŒ–è¾¹ç¼˜ç›‘ç£ç»“åˆçš„ SeNet å®ç°äº†æ›´å¥½çš„ç©ºé—´ä¸€è‡´æ€§å’Œè¾¹ç¼˜ç²¾åº¦ã€‚\nHowever, due to the larger number of parameters of the trainable deconvolution, DeconvNet requires longer training and inference time than FCN and SegNet (Yi et al., 2019). It curbed the application of DeconvNet and there are few papers can be found where DeconvNet was adopted for the semantic segmentation of UAV remote sensing images.\nç„¶è€Œï¼Œç”±äºå¯è®­ç»ƒåå·ç§¯çš„å‚æ•°æ•°é‡æ›´å¤šï¼ŒDeconvNet éœ€è¦æ¯” FCN å’Œ SegNet æ›´é•¿çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼ˆYi ç­‰ï¼Œ2019ï¼‰ã€‚å®ƒé™åˆ¶äº† DeconvNet çš„åº”ç”¨ï¼Œç›®å‰å¾ˆå°‘æœ‰è®ºæ–‡å°† DeconvNet ç”¨äºæ— äººæœºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ã€‚\n\nIn this section, we introduced three types of encoderâ€“decoder models for semantic segmentation of high-resolution remote sensing images, including FCN, SegNet, and DeconvNet.\næœ¬èŠ‚ä»‹ç»äº†ä¸‰ç§ç”¨äºé«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ç¼–ç å™¨ - è§£ç å™¨æ¨¡å‹ï¼ŒåŒ…æ‹¬ FCNã€SegNet å’Œ DeconvNetã€‚\nThe network structure of FCN and SegNet is simple yet efficient, and it is feasible to perform rapid evaluation and deployment based on these models for various tasks.\nFCN å’Œ SegNet çš„ç½‘ç»œç»“æ„ç®€å•é«˜æ•ˆï¼ŒåŸºäºè¿™äº›æ¨¡å‹å¯ä»¥å¿«é€Ÿè¯„ä¼°å’Œéƒ¨ç½²å„ç§ä»»åŠ¡ã€‚\nThey have been the most popular DL-based methods in the recent advances of semantic segmentation for UAV remote sensing images.\nå®ƒä»¬æ˜¯è¿‘å¹´æ¥æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²è¿›å±•ä¸­æœ€å—æ¬¢è¿çš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ã€‚\nHowever, the compressed latent representation of encoders makes the decoders difficult to recover spatial details and leads to ambiguity in the segmentation results, such as inconsistent intra-class predictions and fuzzy boundaries.\nç„¶è€Œï¼Œç¼–ç å™¨çš„å‹ç¼©æ½œåœ¨è¡¨ç¤ºä½¿å¾—è§£ç å™¨éš¾ä»¥æ¢å¤ç©ºé—´ç»†èŠ‚ï¼Œå¹¶å¯¼è‡´åˆ†å‰²ç»“æœå­˜åœ¨æ­§ä¹‰ï¼Œå¦‚ç±»å†…é¢„æµ‹ä¸ä¸€è‡´å’Œè¾¹ç•Œæ¨¡ç³Šã€‚\n# Multi-scale and feature fusion strategies\nå¤šå°ºåº¦å’Œç‰¹å¾èåˆç­–ç•¥\nThe rapid increment in the resolution of UAV remote sensing images leads to more complex intra-class variations of pixels within semantic objects or regions (Aplin, 2006; Torres-SÃ¡nchez et al., 2015).\næ— äººæœºé¥æ„Ÿå›¾åƒåˆ†è¾¨ç‡çš„å¿«é€Ÿæå‡å¯¼è‡´è¯­ä¹‰å¯¹è±¡æˆ–åŒºåŸŸå†…åƒç´ çš„ç±»åˆ«å†…å˜å¼‚æ›´åŠ å¤æ‚ï¼ˆAplinï¼Œ2006;Torres-SÃ¡nchez ç­‰ï¼Œ2015ï¼‰ã€‚\nThe rich spatial details provided by high-resolution images may result in variation within semantic features (Aplin, 2006), which will also weaken the modelsâ€™ capacity to maintain intra-class consistency and inter-class variance for semantic segmentation (Torres-SÃ¡nchez et al., 2015; Tamouridou et al., 2017).\né«˜åˆ†è¾¨ç‡å›¾åƒæä¾›çš„ä¸°å¯Œç©ºé—´ç»†èŠ‚å¯èƒ½å¯¼è‡´è¯­ä¹‰ç‰¹å¾çš„å˜å¼‚ï¼ˆAplinï¼Œ2006ï¼‰ï¼Œè¿™ä¹Ÿä¼šå‰Šå¼±æ¨¡å‹ç»´æŒç±»å†…ä¸€è‡´æ€§å’Œç±»é—´è¯­ä¹‰åˆ†å‰²å˜å¼‚çš„èƒ½åŠ›ï¼ˆTorres-SÃ¡nchez ç­‰ï¼Œ2015;Tamouridou ç­‰ï¼Œ2017ï¼‰ã€‚\nBesides, due to the unfixed perspective and varying flight altitudes of UAV platforms, semantic representations extracted at different spatial resolutions in high-resolution images may yield different semantic segmentation accuracies (Aplin, 2006; Woodcock and Strahler, 1987), which can be one of the primary challenges for image semantic segmentation in UAV remote sensing.\næ­¤å¤–ï¼Œç”±äºæ— äººæœºå¹³å°çš„è§†è§’ä¸å›ºå®šä¸”é£è¡Œé«˜åº¦ä¸åŒï¼Œåœ¨é«˜åˆ†è¾¨ç‡å›¾åƒä¸­ä»¥ä¸åŒç©ºé—´åˆ†è¾¨ç‡æå–çš„è¯­ä¹‰è¡¨ç¤ºå¯èƒ½äº§ç”Ÿä¸åŒçš„è¯­ä¹‰åˆ†å‰²ç²¾åº¦ï¼ˆAplinï¼Œ2006;Woodcock å’Œ Strahlerï¼Œ1987ï¼‰ï¼Œè¿™å¯èƒ½æ˜¯æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ã€‚\nEarly studies (Baatz and Schape, 2000; Hay et al., 2003; DrË‡agutÌ§ et al., 2010) on high-resolution remote sensing image parsing demonstrated that multiresolution techniques were able to address these problems.\næ—©æœŸç ”ç©¶ï¼ˆBaatz å’Œ Schapeï¼Œ2000;Hay ç­‰ï¼Œ2003;DrË‡aguÅ£ ç­‰ï¼Œ2010ï¼‰å…³äºé«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒè§£æçš„ç ”ç©¶è¡¨æ˜ï¼Œå¤šåˆ†è¾¨ç‡æŠ€æœ¯èƒ½å¤Ÿè§£å†³è¿™äº›é—®é¢˜ã€‚\nSimilarly, in the field of DL, the strategy based on multi-scale feature extraction and feature fusion has been developed to extract effective feature representations at different spatial scales.\nåŒæ ·ï¼Œåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼ŒåŸºäºå¤šå°ºåº¦ç‰¹å¾æå–å’Œç‰¹å¾èåˆçš„ç­–ç•¥å·²è¢«å¼€å‘å‡ºæ¥ï¼Œä»¥åœ¨ä¸åŒç©ºé—´å°ºåº¦ä¸‹æå–æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤ºã€‚\nIntuitively, this strategy extracts coarse to fine feature maps at multiple spatial scales from high-resolution UAV images simultaneously, then integrates these into a fused feature map at a particular spatial scale after feature  alignment (Chen et al., 2017a; Ronneberger et al., 2015; Chen et al., 2017a,b, 2018b; Wang et al., 2020c).\nç›´è§‚ä¸Šï¼Œè¯¥ç­–ç•¥ä»é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­åŒæ—¶æå–å¤šä¸ªç©ºé—´å°ºåº¦çš„ç²—åˆ°ç»†ç‰¹å¾å›¾ï¼Œç„¶ååœ¨ç‰¹å¾å¯¹é½åå°†å…¶æ•´åˆåˆ°ç‰¹å®šç©ºé—´å°ºåº¦çš„èåˆç‰¹å¾å›¾ä¸­ï¼ˆChen ç­‰ï¼Œ2017a;Ronneberger ç­‰ï¼Œ2015;Chen ç­‰ï¼Œ2017aï¼Œbï¼Œ2018b;Wang ç­‰ï¼Œ2020cï¼‰ã€‚\nIt not only allows for adaptive selection of feature maps with optimal spatial scales based on the size of semantic objects in high-resolution UAV images, but also compensates for the loss of spatial details caused by the down-sampling operators in the feature encoder structure.\nå®ƒä¸ä»…å…è®¸åŸºäºé«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­è¯­ä¹‰å¯¹è±¡å¤§å°ï¼Œè‡ªé€‚åº”é€‰æ‹©å…·æœ‰æœ€ä½³ç©ºé—´å°ºåº¦çš„ç‰¹å¾å›¾ï¼Œè¿˜èƒ½è¡¥å¿ç‰¹å¾ç¼–ç ç»“æ„ä¸­ä¸‹é‡‡æ ·ç®—å­å¯¼è‡´çš„ç©ºé—´ç»†èŠ‚æŸå¤±ã€‚\n# DeepLab series\nThe pioneering encoderâ€“decoder architectures, such as SegNet and FCN, integrate multi-scale features from the last encoder layers to simultaneously handle large-scale and fine-scale objects.\nå¼€åˆ›æ€§çš„ç¼–ç å™¨ - è§£ç å™¨æ¶æ„ï¼Œå¦‚ SegNet å’Œ FCNï¼Œæ•´åˆäº†ä¸Šä¸€ä»£ç¼–ç å™¨å±‚çš„å¤šå°ºåº¦ç‰¹å¾ï¼Œä»¥åŒæ—¶å¤„ç†å¤§å°ºåº¦å’Œç»†å°ºåº¦å¯¹è±¡ã€‚\nBut it is still deficient in achieving accurate segmentation of fine-structure objects, such as reliable edge prediction and texture refinement.\nä½†åœ¨å®ç°ç²¾ç»†ç»“æ„å¯¹è±¡çš„å‡†ç¡®åˆ†å‰²æ–¹é¢ï¼Œå¦‚å¯é çš„è¾¹ç¼˜é¢„æµ‹å’Œçº¹ç†ç»†åŒ–æ–¹é¢ï¼Œä»ç„¶å­˜åœ¨ä¸è¶³ã€‚\nTo avoid the shortcomings of losing detailed information in max-pooling layers, the atrous convolution (Yu and Koltun, 2016), also called dilated convolution, has been explored to expand the receptive field and integrate uncontiguous elements with discontinuous convolution kernels.\nä¸ºé¿å…æœ€å¤§æ± åŒ–å±‚ä¸­ä¸¢å¤±è¯¦ç»†ä¿¡æ¯çš„ç¼ºé™·ï¼Œé‡‡ç”¨äº†æå…¶å¤æ‚çš„å·ç§¯ï¼ˆYu å’Œ Koltunï¼Œ2016ï¼‰ï¼Œä¹Ÿç§°ä¸ºè†¨èƒ€å·ç§¯ï¼Œç”¨äºæ‰©å±•æ„Ÿå—åœºå¹¶ç§¯åˆ†å…·æœ‰ä¸è¿ç»­å·ç§¯æ ¸çš„éè¿ç»­å…ƒç´ ã€‚\nDeepLabV1 (Chen et al., 2017a) and DeepLabV2 (Chen et al., 2017a) were among the most instructive image segmentation models designed to solve three crucial challenges in DCNN: the loss of detailed information in the down-sampling process, multi-scale objects in images, and fuzzy boundary predictions.\nDeepLabV1ï¼ˆChen ç­‰ï¼Œ2017aï¼‰å’Œ DeepLabV2ï¼ˆChen ç­‰ï¼Œ2017aï¼‰æ˜¯æœ€å…·å¯å‘æ€§çš„å›¾åƒåˆ†å‰²æ¨¡å‹ä¹‹ä¸€ï¼Œæ—¨åœ¨è§£å†³ DCNN ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä¸‹é‡‡æ ·è¿‡ç¨‹ä¸­ç»†èŠ‚ä¿¡æ¯çš„ä¸¢å¤±ã€å›¾åƒä¸­å¤šå°ºåº¦ç‰©ä½“çš„å‡ºç°ä»¥åŠæ¨¡ç³Šçš„è¾¹ç•Œé¢„æµ‹ã€‚\nThe latter introduced two essential improvements to the DCNN structure of semantic segmentation. One was to adopt the Atrous Spatial Pyramid Pooling (ASPP) that applied atrous convolution with the same kernel but different atrous sample rates to generate multi-scale feature maps in parallel.\nåè€…ä¸º DCNN è¯­ä¹‰åˆ†å‰²ç»“æ„å¼•å…¥äº†ä¸¤é¡¹é‡è¦æ”¹è¿›ã€‚å…¶ä¸­ä¸€ç§æ˜¯é‡‡ç”¨ Atrous ç©ºé—´é‡‘å­—å¡”æ± åŒ–ï¼ˆASPPï¼‰ï¼Œè¯¥æ–¹æ³•åœ¨ç›¸åŒæ ¸ä½†ä¸åŒ atrous é‡‡æ ·ç‡ä¸‹åº”ç”¨ atrous å·ç§¯ï¼Œå¹¶è¡Œç”Ÿæˆå¤šå°ºåº¦ç‰¹å¾å›¾ã€‚\nAnother was to refine of segmentation boundary with the probability graph model.\nå¦ä¸€ä¸ªæ–¹æ³•æ˜¯ç”¨æ¦‚ç‡å›¾æ¨¡å‹ç»†åŒ–åˆ†å‰²è¾¹ç•Œã€‚\nHowever, it failed to consider the balance between model complexity and prediction accuracy, resulting in inefficient processing efficiency for large-scale remote sensing images (Xia et al., 2021b). Subsequently, they revisited the structure of the previous semantic segmentation networks and proposed DeepLabV3 (Chen et al., 2017b) and DeepLabV3+ (Chen et al., 2018b).\nç„¶è€Œï¼Œå®ƒæœªèƒ½è€ƒè™‘æ¨¡å‹å¤æ‚åº¦ä¸é¢„æµ‹å‡†ç¡®æ€§ä¹‹é—´çš„å¹³è¡¡ï¼Œå¯¼è‡´å¤§è§„æ¨¡é¥æ„Ÿå›¾åƒçš„å¤„ç†æ•ˆç‡ä½ä¸‹ï¼ˆXia ç­‰ï¼Œ2021bï¼‰ã€‚éšåï¼Œä»–ä»¬é‡æ–°å®¡è§†äº†ä¹‹å‰è¯­ä¹‰åˆ†å‰²ç½‘ç»œçš„ç»“æ„ï¼Œæå‡ºäº† DeepLabV3ï¼ˆChen ç­‰ï¼Œ2017bï¼‰å’Œ DeepLabV3+ï¼ˆChen ç­‰ï¼Œ2018bï¼‰ã€‚\nDeepLabV3 applied the multigrid to create a deeper network and added a global pooling layer to ASPP to address the degradation of the atrous convolution when the atrous rate was excessive. DeepLabV3+ adopted the encoder structure of the DeepLabV3, combining shallow and deeper features by feature concatenation in the decoder network to refine the boundary details. Besides, DeeplabV3+ utilized pointwise-wise and depth-wise convolutions (Chollet, 2017) to design the encoderâ€“decoder structure, which achieved a significant balance between semantic feature extraction and computation overhead.\nDeepLabV3 åº”ç”¨å¤šç½‘æ ¼åˆ›å»ºæ›´æ·±å±‚çš„ç½‘ç»œï¼Œå¹¶åœ¨ ASPP ä¸­å¢åŠ äº†å…¨å±€æ± å±‚ï¼Œä»¥è§£å†³å½“è¡°è´¥ç‡è¿‡é«˜æ—¶å·ç§¯è¡°å‡çš„é—®é¢˜ã€‚DeepLabV3 + é‡‡ç”¨äº† DeepLabV3 çš„ç¼–ç ç»“æ„ï¼Œå°†æµ…å±‚å’Œæ·±å±‚ç‰¹å¾é€šè¿‡ç‰¹å¾é“¾è¿æ¥åœ¨è§£ç å™¨ç½‘ç»œä¸­ç»†åŒ–è¾¹ç•Œç»†èŠ‚ã€‚æ­¤å¤–ï¼ŒDeeplabV3+ åˆ©ç”¨äº†ç‚¹å‘å’Œæ·±åº¦å‘çš„å·ç§¯è®¾è®¡ç¼–ç å™¨ - è§£ç å™¨ç»“æ„ï¼Œå®ç°äº†è¯­ä¹‰ç‰¹å¾æå–å’Œè®¡ç®—å¼€é”€ä¹‹é—´çš„æ˜¾è‘—å¹³è¡¡ã€‚\nThe multi-scale feature map generated by the ASPP module can expand the receptive field of the convolution kernel without adding additional parameters, thereby capturing more spatial context information. In offshore aquaculture area monitoring tasks, the background water in the high-resolution UAV images can confuse the extraction of floating raft aquaculture areas due to excessive suspended impurities in the seawater.\nASPP æ¨¡å—ç”Ÿæˆçš„å¤šå°ºåº¦ç‰¹å¾æ˜ å°„å¯ä»¥åœ¨ä¸å¢åŠ é¢å¤–å‚æ•°çš„æƒ…å†µä¸‹æ‰©å±•å·ç§¯æ ¸çš„æ„Ÿå—åœºï¼Œä»è€Œæ•æ‰æ›´å¤šç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åœ¨è¿‘æµ·æ°´äº§å…»æ®–åŒºç›‘æµ‹ä»»åŠ¡ä¸­ï¼Œé«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­çš„èƒŒæ™¯æ°´å¯èƒ½å› æµ·æ°´ä¸­è¿‡å¤šæ‚¬æµ®æ‚è´¨è€Œå¹²æ‰°æµ®ç­å…»æ®–åŒºçš„æå–ã€‚\nHowever, Sui et al. (2020) proposed OAE-V3 based on DeepLabV3, which achieved smoother boundaries with less noise prediction compared with FCN, even in some floating raft areas without significant spectral information. In addition, multi-scale feature maps also contribute to segmenting semantic objects at different spatial scales. For instance, in UAV-based images, DeepLabV3 accurately segmented eelgrass from meadow-scale to small-scale patches less than one meter in size (Tallam et al., 2023). Further analysis of the segmentation results found that DeepLabV3 was able to identify thousands of smaller eelgrass patches that human annotators ignored.\nç„¶è€Œï¼ŒSui ç­‰äººï¼ˆ2020ï¼‰æå‡ºäº†åŸºäº DeepLabV3 çš„ OAE-V3ï¼Œè¯¥æ–¹æ³•åœ¨æŸäº›æµ®ç­åŒºåŸŸä¸­ä¹Ÿå®ç°äº†æ›´å¹³æ»‘çš„è¾¹ç•Œå’Œæ›´å°‘çš„å™ªå£°é¢„æµ‹ï¼Œç›¸è¾ƒäº FCNï¼Œä¸”æ²¡æœ‰æ˜¾è‘—çš„é¢‘è°±ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œå¤šå°ºåº¦ç‰¹å¾å›¾è¿˜æœ‰åŠ©äºåœ¨ä¸åŒç©ºé—´å°ºåº¦ä¸‹å¯¹è¯­ä¹‰å¯¹è±¡è¿›è¡Œåˆ‡æ®µã€‚ä¾‹å¦‚ï¼Œåœ¨åŸºäºæ— äººæœºçš„å›¾åƒä¸­ï¼ŒDeepLabV3 èƒ½å¤Ÿå‡†ç¡®åœ°å°†é³—è‰ä»è‰åœ°å¤§å°åˆ°å°äºä¸€ç±³çš„æ–‘å—è¿›è¡Œç»†åˆ†ï¼ˆTallam ç­‰ï¼Œ2023ï¼‰ã€‚å¯¹åˆ†å‰²ç»“æœçš„è¿›ä¸€æ­¥åˆ†æå‘ç°ï¼ŒDeepLabV3 èƒ½å¤Ÿè¯†åˆ«å‡ºæ•°åƒä¸ªäººå·¥æ³¨é‡Šè€…å¿½è§†çš„è¾ƒå°é³—è‰æ–‘å—ã€‚\nThe application of DeepLabV3+ in semantic segmentation for UAV remote sensing is even more extensive.\nDeepLabV3 + åœ¨æ— äººæœºé¥æ„Ÿè¯­ä¹‰åˆ†å‰²ä¸­çš„åº”ç”¨æ›´ä¸ºå¹¿æ³›ã€‚\nFor example, with different image resolutions, white balance settings, lighting conditions, and other defects in UAV-based images, the DeepLabV3+, adopted by Morales et al. (2018), still yielded 98.03% segmentation accuracy for the automatic segmentation of Mauritania flexuosa.\nä¾‹å¦‚ï¼Œåœ¨æ— äººæœºå›¾åƒä¸­å­˜åœ¨ä¸åŒçš„å›¾åƒåˆ†è¾¨ç‡ã€ç™½å¹³è¡¡è®¾ç½®ã€å…‰ç…§æ¡ä»¶åŠå…¶ä»–ç¼ºé™·æ—¶ï¼ŒMorales ç­‰äººï¼ˆ2018ï¼‰é‡‡ç”¨çš„ DeepLabV3 + åœ¨æ¯›é‡Œå¡”å°¼äºšæŸ”æ€§é¸Ÿçš„è‡ªåŠ¨åˆ†å‰²ä¸­ä»èƒ½å®ç° 98.03% çš„åˆ†å‰²å‡†ç¡®ç‡ã€‚\nIn road extraction, Mahmud et al. (2021) considered that the heterogeneity of roads in terms of location, size, shape, and color complicates the implementation of semantic segmentation algorithms.\nåœ¨é“è·¯æå–ä¸­ï¼ŒMahmud ç­‰äººï¼ˆ2021ï¼‰è®¤ä¸ºï¼Œé“è·¯åœ¨ä½ç½®ã€å¤§å°ã€å½¢çŠ¶å’Œé¢œè‰²ä¸Šçš„å¼‚è´¨æ€§ä½¿è¯­ä¹‰åˆ†å‰²ç®—æ³•çš„å®ç°å˜å¾—å¤æ‚ã€‚\nBut DeepLabV3+ with ResNet50 (He et al., 2016) as the feature backbone effectively reduces the negative impact of the complex noise background in UAV images on semantic segmentation.\nä½† DeepLabV3 + æ­é… ResNet50ï¼ˆHe ç­‰ï¼Œ2016ï¼‰ä½œä¸ºç‰¹å¾éª¨å¹²ï¼Œæœ‰æ•ˆå‡å°‘äº†æ— äººæœºå›¾åƒä¸­å¤æ‚å™ªå£°èƒŒæ™¯å¯¹è¯­ä¹‰åˆ†å‰²çš„è´Ÿé¢å½±å“ã€‚\nThe crack scale on the surface of steel structures in UAV images is relatively small, which presents insufficient detailed information.\næ— äººæœºå›¾åƒä¸­é’¢ç»“æ„è¡¨é¢çš„è£‚çº¹å°ºåº¦ç›¸å¯¹è¾ƒå°ï¼Œè¿™å¯¼è‡´ä¿¡æ¯çš„è¯¦ç»†ä¿¡æ¯ä¸è¶³ã€‚\nHan et al. (2022) utilized the pixel-level crack segmentation results of DeepLabV3+ as a secondary determination for crack detection.\nHan ç­‰äººï¼ˆ2022ï¼‰åˆ©ç”¨ DeepLabV3 + çš„åƒç´ çº§è£‚çº¹åˆ†å‰²ç»“æœä½œä¸ºè£‚çº¹æ£€æµ‹çš„äºŒæ¬¡åˆ¤å®šã€‚\nThe authors claimed that UAVs about 5 m away from steel surfaces could identify cracks about 5 cm long and 0.5 cm width.\nä½œè€…å£°ç§°ï¼Œè·ç¦»é’¢åˆ¶è¡¨é¢çº¦ 5 ç±³çš„æ— äººæœºå¯ä»¥è¯†åˆ«çº¦ 5 å˜ç±³é•¿ã€0.5 å˜ç±³å®½çš„è£‚ç¼ã€‚\nA system established by Njane et al. (2023) for automatically evaluating the phenotypic properties of potatoes adopted DeepLabV3+ to initially segment crop parameters from the bare soil in UAV images. Compared to segmentation methods based on thresholding, DeepLabV3+ could adapt to sunny conditions or crops completely covering the image. Moreover, the deep features generated by DeepLabV3+ can be used as effective feature representations of salient objects in UAV images. Specifically, Megir et al. (2021) employed a pre-trained DeepLabV3+ model as a salient object detector and clustered the deep features with K-means.\nNjane ç­‰äººï¼ˆ2023 å¹´ï¼‰å»ºç«‹çš„è‡ªåŠ¨è¯„ä¼°åœŸè±†è¡¨å‹ç‰¹æ€§çš„ç³»ç»Ÿé‡‡ç”¨äº† DeepLabV3+ï¼Œæœ€åˆåœ¨æ— äººæœºå›¾åƒä¸­ä»è£¸åœŸä¸­åˆ‡å‰²ä½œç‰©å‚æ•°ã€‚ä¸åŸºäºé˜ˆå€¼çš„åˆ†å‰²æ–¹æ³•ç›¸æ¯”ï¼ŒDeepLabV3 + èƒ½å¤Ÿé€‚åº”é˜³å…‰æ¡ä»¶æˆ–å®Œå…¨è¦†ç›–å›¾åƒçš„ä½œç‰©ã€‚æ­¤å¤–ï¼ŒDeepLabV3 + ç”Ÿæˆçš„æ·±åº¦ç‰¹å¾è¿˜å¯ä½œä¸ºæ— äººæœºå›¾åƒä¸­æ˜¾è‘—ç‰©ä½“çš„æœ‰æ•ˆç‰¹å¾è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼ŒMegir ç­‰äººï¼ˆ2021ï¼‰é‡‡ç”¨é¢„è®­ç»ƒçš„ DeepLabV3+ æ¨¡å‹ä½œä¸ºæ˜¾è‘—ç‰©ä½“æ¢æµ‹å™¨ï¼Œå¹¶å°†æ·±å±‚ç‰¹å¾ä¸ K å‡å€¼èšç±»ã€‚\nIt had been demonstrated effective even though the semantic class of the object of interest is unknown and no additional training is performed. However, it should be noted that DeepLabV3+, constructed based on a complex model structure with more parameters, is more difficult to train when there are fewer semantic labels and limited training data, which ultimately results in a significant deviation in test accuracy after training (Jeon et al., 2021).\nå°½ç®¡ç›®æ ‡å¯¹è±¡çš„è¯­ä¹‰ç±»åˆ«æœªçŸ¥ä¸”æœªè¿›è¡Œé¢å¤–åŸ¹è®­ï¼Œä½†è¯¥æ–¹æ³•å·²è¢«è¯æ˜æœ‰æ•ˆã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒåŸºäºå¤æ‚æ¨¡å‹ç»“æ„å’Œæ›´å¤šå‚æ•°æ„å»ºçš„ DeepLabV3+ï¼Œå½“è¯­ä¹‰æ ‡ç­¾å‡å°‘ä¸”è®­ç»ƒæ•°æ®æœ‰é™æ—¶ï¼Œè®­ç»ƒéš¾åº¦æ›´é«˜ï¼Œæœ€ç»ˆå¯¼è‡´è®­ç»ƒåæµ‹è¯•å‡†ç¡®æ€§æ˜¾è‘—åå·®ï¼ˆJeon ç­‰ï¼Œ2021ï¼‰ã€‚\n# UNet\nUNet (Ronneberger et al., 2015) is another feature-engineered encoderâ€“decoder architecture with more multi-scale feature extraction and fusion operations. It was originally designed to solve the problem of biomedicine image segmentation with small image samples. As illustrated in Fig. 3(a), the feature backbone of UNet labeled by the dashed box was called the contracting path, which consisted of four feature blocks and the last max-pooling layer. The contracting path compressed the feature resolution and increased the feature channels. The part on the right side of the dashed box was called the expansive path, which also contained four feature blocks that up-sampled the feature map of the previous layer to twice its scale by deconvolution and fused it with the feature output of the contracting path on the left side.\nUNetï¼ˆRonneberger ç­‰ï¼Œ2015ï¼‰æ˜¯å¦ä¸€ç§ç‰¹å¾å·¥ç¨‹ç¼–ç  - è§£ç å™¨æ¶æ„ï¼Œå…·æœ‰æ›´å¤šå¤šå°ºåº¦çš„ç‰¹å¾æå–å’Œèåˆä½œã€‚å®ƒæœ€åˆè®¾è®¡ç”¨äºè§£å†³ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å°æ ·æœ¬å›¾åƒçš„é—®é¢˜ã€‚å¦‚å›¾ 3ï¼ˆaï¼‰æ‰€ç¤ºï¼ŒUNet ä¸­è™šçº¿æ¡†æ ‡è®°çš„ç‰¹å¾éª¨å¹²ç§°ä¸ºæ”¶ç¼©è·¯å¾„ï¼Œç”±å››ä¸ªç‰¹å¾å—å’Œæœ€åä¸€ä¸ªæœ€å¤§æ± å±‚ç»„æˆã€‚æ”¶ç¼©è·¯å¾„å‹ç¼©äº†ç‰¹å¾åˆ†è¾¨ç‡å¹¶å¢åŠ äº†ç‰¹å¾é€šé“ã€‚è™šçº¿æ¡†å³ä¾§çš„éƒ¨åˆ†ç§°ä¸ºæ‰©å±•è·¯å¾„ï¼ŒåŒ…å«å››ä¸ªç‰¹å¾å—ï¼Œé€šè¿‡åå·ç§¯å°†ä¸Šä¸€å±‚çš„ç‰¹å¾æ˜ å°„æ”¾å¤§åˆ°å…¶å°ºåº¦çš„ä¸¤å€ï¼Œå¹¶ä¸å·¦ä¾§æ”¶ç¼©è·¯å¾„çš„ç‰¹å¾è¾“å‡ºèåˆã€‚\nBy leveraging a contracting path to gather contextual information and a symmetric expansion path for precise positioning, UNet efficiently integrates multi-scale features across various layers from shallow to deep, facilitating accurate semantic segmentation of finestructure objects in UAV remote sensing images. Kattenborn et al. (2019) tested the fine-grained mapping of vegetation species and communities obtained from high-resolution RGB UAV image datasets based on UNet.\né€šè¿‡åˆ©ç”¨æ”¶ç¼©è·¯å¾„æ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå¯¹ç§°æ‰©å±•è·¯å¾„å®ç°ç²¾ç¡®å®šä½ï¼ŒUNet é«˜æ•ˆæ•´åˆäº†ä»æµ…å±‚åˆ°æ·±å±‚çš„å¤šå°ºåº¦ç‰¹å¾ï¼Œä¿ƒè¿›æ— äººæœºé¥æ„Ÿå›¾åƒä¸­ç²¾ç»†ç»“æ„å¯¹è±¡çš„å‡†ç¡®è¯­ä¹‰åˆ†å‰²ã€‚Kattenborn ç­‰äººï¼ˆ2019ï¼‰æµ‹è¯•äº†åŸºäº UNet çš„é«˜åˆ†è¾¨ç‡ RGB æ— äººæœºå›¾åƒæ•°æ®é›†ä¸­å¯¹æ¤è¢«ç‰©ç§å’Œç¾¤è½çš„ç»†ç²’åº¦æ˜ å°„ã€‚\nAs the resolution increased, they found that fine-structured spatial patterns, such as leaf shapes and branching patterns, played a  more important role than overall reflective features. Zhao et al. (2019) equipped the UAV with a high-resolution RGB and multispectral camera and established a dataset of lodging and un-lodging rice image samples. The dice coefficients of UNet with different modal inputs indicated that UNet provides the ability to extract spatial features and patterns of rice lodging directly from high-resolution UAV images. Both demonstrated the superiority of UNet in integrating fine-grained spatial features of optical images and aggregating semantic representations of multimodal data. To make the network more trainable, Zhang et al. (2019b) proposed Deep Res-UNet combined with the residual module of ResNet (He et al., 2016) for infrared image segmentation of photovoltaic panels. And (Zhang et al., 2021a) modified UNet by embedding an irregular encoderâ€“decoder module and content-aware channel re-weight module to address the drawback of irregular and fuzzy boundaries in wheat yellow rust disease detection. However, the classic UNet consumes a large amount of computational and memory resources due to the complex encoderâ€“decoder framework.\néšç€åˆ†è¾¨ç‡çš„æå‡ï¼Œä»–ä»¬å‘ç°ç»†ç»“æ„çš„ç©ºé—´å›¾æ¡ˆï¼Œå¦‚å¶ç‰‡å½¢çŠ¶å’Œåˆ†æ”¯å›¾æ¡ˆï¼Œæ¯”æ•´ä½“åå°„ç‰¹å¾æ›´ä¸ºé‡è¦ã€‚èµµç­‰äººï¼ˆ2019ï¼‰ä¸ºæ— äººæœºé…å¤‡äº†é«˜åˆ†è¾¨ç‡ RGB å’Œå¤šå…‰è°±ç›¸æœºï¼Œå»ºç«‹äº†ç¨»ç±³æ²‰ç§¯å’Œè„±è½æ°´ç¨»å›¾åƒæ ·æœ¬æ•°æ®é›†ã€‚UNet åœ¨ä¸åŒæ¨¡æ€è¾“å…¥ä¸‹çš„éª°å­ç³»æ•°è¡¨æ˜ï¼ŒUNet èƒ½å¤Ÿç›´æ¥ä»é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­æå–ç¨»ç±³ç€ä¼çš„ç©ºé—´ç‰¹å¾å’Œæ¨¡å¼ã€‚ä¸¤è€…éƒ½å±•ç¤ºäº† UNet åœ¨æ•´åˆå…‰å­¦å›¾åƒç»†ç²’åº¦ç©ºé—´ç‰¹å¾å’Œèšåˆå¤šæ¨¡æ€æ•°æ®è¯­ä¹‰è¡¨ç¤ºæ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚ä¸ºäº†ä½¿ç½‘ç»œæ›´æ˜“è®­ç»ƒï¼ŒZhang ç­‰äººï¼ˆ2019bï¼‰æå‡ºäº†å°† Deep Res-UNet ä¸ ResNet æ®‹å·®æ¨¡å—ç»“åˆï¼ˆHe ç­‰ï¼Œ2016ï¼‰ç”¨äºå…‰ä¼é¢æ¿çš„çº¢å¤–å›¾åƒåˆ†å‰²ã€‚æ­¤å¤–ï¼ˆZhang ç­‰ï¼Œ2021aï¼‰é€šè¿‡åµŒå…¥ä¸è§„åˆ™ç¼–ç  - è§£ç å™¨æ¨¡å—å’Œå†…å®¹æ„ŸçŸ¥é€šé“é‡æƒæ¨¡å—ï¼Œå¯¹ UNet è¿›è¡Œäº†ä¿®æ”¹ï¼Œä»¥è§£å†³å°éº¦é»„é”ˆç—…æ£€æµ‹ä¸­ä¸è§„åˆ™å’Œæ¨¡ç³Šè¾¹ç•Œçš„ä¸è¶³ã€‚ç„¶è€Œï¼Œç»å…¸çš„ UNet ç”±äºå¤æ‚çš„ç¼–ç å™¨ - è§£ç å™¨æ¡†æ¶ï¼Œä¼šæ¶ˆè€—å¤§é‡çš„è®¡ç®—å’Œå†…å­˜èµ„æºã€‚\nTo meet the demand for real-time image processing on embedding UAV platforms, Shi et al. (2022) used EfficientNet-B4 (Tan and Le, 2019), an efficient network with balanced model width and depth, as the feature backbone to speed up model convergence. Lan et al. (2021) explored MobileNetV2 (Sandler et al., 2018) as the backbone network to reduce parameters and computations of UNet and achieved a frame rate of 45.05 on the embedded platform with 16-bit floating-point weights. He et al. (2023) considered that it was necessary to combine the light-weight UNet with sub-modules, designed for local feature refinement and global receptive field enhancement, to avoid intermittent segmentation or mis-segmentation of transmission lines in UAV images with complex backgrounds. Gao et al. (2023) embedded Depth Separable Residue Block (DR-Block) and Atrous Spatial Pyramid Fusion Attention Module (ASAM) in UNet, which could adapt to the irregular topological shapes of tiny cracks, reduce the considerable interference in complex backgrounds, and ensure the integrity of fracture features in the feature extraction process. Such advanced practices illustrate that UNet provides a reliable baseline for semantic segmentation of UAV remote sensing images, as researchers can either add or modify the original network structure according to the diverse semantic representations of specific scenes to achieve higher semantic segmentation accuracy.\nä¸ºæ»¡è¶³åµŒå…¥å¼æ— äººæœºå¹³å°å¯¹å®æ—¶å›¾åƒå¤„ç†çš„éœ€æ±‚ï¼ŒShi ç­‰äººï¼ˆ2022ï¼‰é‡‡ç”¨ EfficientNet-B4ï¼ˆTan å’Œ Leï¼Œ2019ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆä¸”æ¨¡å‹å®½åº¦å’Œæ·±åº¦å¹³è¡¡çš„ç½‘ç»œï¼Œä½œä¸ºåŠ é€Ÿæ¨¡å‹èåˆçš„ç‰¹å¾éª¨å¹²ã€‚Lan ç­‰äººï¼ˆ2021ï¼‰æ¢ç´¢äº† MobileNetV2ï¼ˆSandler ç­‰ï¼Œ2018ï¼‰ä½œä¸ºå‡å°‘ UNet å‚æ•°å’Œè®¡ç®—çš„éª¨å¹²ç½‘ç»œï¼Œåœ¨åµŒå…¥å¼å¹³å°ä¸Šä»¥ 16 ä½æµ®ç‚¹æƒé‡å®ç°äº† 45.05 å¸§ç‡ã€‚ä»–ç­‰äººï¼ˆ2023ï¼‰è®¤ä¸ºï¼Œä¸ºäº†é¿å…å¤æ‚èƒŒæ™¯çš„æ— äººæœºå›¾åƒä¸­ä¼ è¾“çº¿é—´æ­‡æ€§åˆ†å‰²æˆ–è¯¯åˆ†ï¼Œæœ‰å¿…è¦å°†è½»é‡çº§ UNet ä¸è®¾è®¡ç”¨äºå±€éƒ¨ç‰¹å¾ç»†åŒ–å’Œå…¨å±€æ„Ÿå—åœºå¢å¼ºçš„å­æ¨¡å—ç»“åˆã€‚Gao ç­‰ï¼ˆ2023ï¼‰åœ¨ UNet ä¸­åµŒå…¥äº†æ·±åº¦å¯åˆ†ç¦»æ®‹ç•™å—ï¼ˆDR-Blockï¼‰å’Œ Atrous ç©ºé—´é‡‘å­—å¡”èåˆæ³¨æ„æ¨¡å—ï¼ˆASAMï¼‰ï¼Œèƒ½å¤Ÿé€‚åº”å¾®å°è£‚çº¹çš„ä¸è§„åˆ™æ‹“æ‰‘å½¢çŠ¶ï¼Œå‡å°‘å¤æ‚èƒŒæ™¯ä¸­çš„æ˜¾è‘—å¹²æ‰°ï¼Œå¹¶ç¡®ä¿ç‰¹å¾æå–è¿‡ç¨‹ä¸­æ–­è£‚ç‰¹å¾çš„å®Œæ•´æ€§ã€‚è¿™äº›å…ˆè¿›å®è·µè¡¨æ˜ UNet ä¸ºæ— äººæœºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²æä¾›äº†å¯é çš„åŸºçº¿ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ ¹æ®ç‰¹å®šåœºæ™¯çš„å¤šæ ·è¯­ä¹‰è¡¨ç¤ºæ·»åŠ æˆ–ä¿®æ”¹åŸå§‹ç½‘ç»œç»“æ„ï¼Œä»¥å®ç°æ›´é«˜çš„è¯­ä¹‰åˆ†å‰²ç²¾åº¦ã€‚\nUNet++ (Zhou et al., 2018), a variant of UNet, aimed to bridge the semantic gap via nested dense skip connections of feature maps in encoderâ€“decoder networks. As shown in Fig. 3(b), the number of features to be fused at each node of the expansive path in UNet++ depended on the corresponding pyramid level. Nested dense connections also allowed the expansive path to integrate semantic information close to the contracting path. The dense connections among feature maps in each layer of UNet++ provide a significant advantage for processing spatial details of high-resolution UAV images on a large spatial scale. Tran et al. (2020) combined UNet and UNet++ and proposed a two-stage semantic network for damaged area estimation after a forest fire. Specifically, UNet++ was the first stage to process spatial detail information in large-scale UAV image patches, while UNet was the second stage for refining the segmentation results with the output of the first stage in small-scale patches. To streamline the wetland mapping of UAV images, Hu et al. (2021a) proposed Auto-UNet++ incorporated with multi-views, unsupervised clustering, multi-scale CNN, and attention mechanism.\nUNet++ï¼ˆå‘¨ç­‰ï¼Œ2018ï¼‰æ˜¯ UNet çš„ä¸€ä¸ªå˜ä½“ï¼Œæ—¨åœ¨é€šè¿‡ç¼–ç å™¨ - è§£ç å™¨ç½‘ç»œä¸­ç‰¹å¾å›¾çš„åµŒå¥—ç¨ å¯†è·³è·ƒè¿æ¥æ¥å¼¥åˆè¯­ä¹‰å·®è·ã€‚å¦‚å›¾ 3ï¼ˆbï¼‰æ‰€ç¤ºï¼ŒUNet ä¸­æ‰©å±•è·¯å¾„æ¯ä¸ªèŠ‚ç‚¹éœ€è¦èåˆçš„ç‰¹å¾æ•°é‡å–å†³äºå¯¹åº”çš„é‡‘å­—å¡”å±‚çº§ã€‚åµŒå¥—ç¨ å¯†è¿æ¥è¿˜å…è®¸æ‰©å±•è·¯å¾„æ•´åˆæ¥è¿‘æ”¶ç¼©è·¯å¾„çš„è¯­ä¹‰ä¿¡æ¯ã€‚UNet æ¯å±‚ç‰¹å¾å›¾ä¹‹é—´çš„å¯†é›†è¿æ¥ä¸ºå¤„ç†é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒçš„ç©ºé—´ç»†èŠ‚åœ¨å¤§å°ºåº¦ä¸Šæä¾›äº†æ˜¾è‘—ä¼˜åŠ¿ã€‚Tran ç­‰äººï¼ˆ2020ï¼‰ç»“åˆäº† UNet å’Œ UNet++ï¼Œæå‡ºäº†ä¸€ä¸ªç”¨äºæ£®æ—ç«ç¾åå—æŸåŒºåŸŸä¼°è®¡çš„ä¸¤é˜¶æ®µè¯­ä¹‰ç½‘ç»œã€‚å…·ä½“æ¥è¯´ï¼ŒUNet æ˜¯å¤„ç†å¤§å°ºåº¦æ— äººæœºå›¾åƒç‰‡æ®µç©ºé—´ç»†èŠ‚ä¿¡æ¯çš„ç¬¬ä¸€é˜¶æ®µï¼Œè€Œ UNet åˆ™æ˜¯ç¬¬äºŒé˜¶æ®µï¼Œç”¨äºç»†åŒ–å°å°ºåº¦ç‰‡æ®µä¸­ç¬¬ä¸€é˜¶æ®µè¾“å‡ºçš„åˆ†å‰²ç»“æœã€‚ä¸ºäº†ç®€åŒ–æ— äººæœºå›¾åƒçš„æ¹¿åœ°æ˜ å°„ï¼Œèƒ¡ç­‰äººï¼ˆ2021aï¼‰æå‡ºäº†æ•´åˆå¤šè§†å›¾ã€æ— ç›‘ç£èšç±»ã€å¤šå°ºåº¦å·ç§¯ç¥ç»ç½‘ç»œå’Œæ³¨æ„åŠ›æœºåˆ¶çš„ Auto-UNetã€‚\n\nFig. 3. Graphical visualization of the network structure of UNet (a) and UNet++ (b). Both UNet and UNet++ start with an encoder of feature backbone followed by a decoder network. The main difference between these two networks is that UNet++ has nested dense skip connections at the same feature resolution to bridge the semantic gap between the encoder and decoder, while the UNet is composed of plain skip connections.\nå›¾ 3ã€‚UNet ï¼ˆaï¼‰ å’Œ UNet++ ï¼ˆbï¼‰ ç½‘ç»œç»“æ„çš„å›¾å½¢å¯è§†åŒ–ã€‚UNet å’Œ UNet++ éƒ½ä»¥ç‰¹å¾éª¨å¹²ç¼–ç å™¨å¼€å§‹ï¼Œéšåæ˜¯è§£ç å™¨ç½‘ç»œã€‚è¿™ä¸¤ä¸ªç½‘ç»œçš„ä¸»è¦åŒºåˆ«åœ¨äºï¼ŒUNet++ é‡‡ç”¨åµŒå¥—çš„å¯†é›†è·³è·ƒè¿æ¥ï¼Œä¸”å…·æœ‰ç›¸åŒç‰¹å¾åˆ†è¾¨ç‡ï¼Œä»¥å¼¥åˆç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„è¯­ä¹‰å·®è·ï¼Œè€Œ UNet åˆ™ç”±çº¯è·³è·ƒè¿æ¥ç»„æˆã€‚\nDespite computational limitations and longer deployment cycles, sufficient experiments prove its efficiency and practicality. Cao et al. (2023) attempted to address the suboptimal segmentation for irregular cracks caused by the lack of special treatment of deep feature maps in the UNet++ by integrating a deep parallel feature fusion module, which captured higher-level semantic information and enhanced the network sensitivity to the features of road cracks. Experiments showed that the proposed model effectively eliminated the interference of complex backgrounds in high-resolution images and improved the networkâ€™s ability to identify irregular cracks.\nå°½ç®¡è®¡ç®—èƒ½åŠ›æœ‰é™ä¸”éƒ¨ç½²å‘¨æœŸè¾ƒé•¿ï¼Œä½†è¶³å¤Ÿçš„å®éªŒè¯æ˜äº†å…¶æ•ˆç‡å’Œå®ç”¨æ€§ã€‚Cao ç­‰äººï¼ˆ2023ï¼‰è¯•å›¾é€šè¿‡é›†æˆæ·±åº¦å¹¶è¡Œç‰¹å¾èåˆæ¨¡å—ï¼Œè§£å†³ UNet++ ä¸­å› ç¼ºä¹å¯¹æ·±åº¦ç‰¹å¾å›¾ç‰¹æ®Šå¤„ç†è€Œå¯¼è‡´ä¸è§„åˆ™è£‚ç¼åˆ†å‰²çš„ä¸ä¼˜é—®é¢˜ï¼Œè¯¥æ¨¡å—æ•æ‰äº†æ›´é«˜å±‚æ¬¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å¢å¼ºäº†å¯¹é“è·¯è£‚ç¼ç‰¹å¾çš„ç½‘ç»œæ•æ„Ÿæ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹æœ‰æ•ˆæ¶ˆé™¤äº†é«˜åˆ†è¾¨ç‡å›¾åƒä¸­å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œå¹¶æå‡äº†ç½‘ç»œè¯†åˆ«ä¸è§„åˆ™è£‚çº¹çš„èƒ½åŠ›ã€‚\nThe paradigm of improving and fine-tuning the models for specific scenarios in UAV remote sensing seems to become an effective solution for enhancing the ability of CNNs to extract contextual information. Nevertheless, it is worth noting that during the model inference process, UNet++ needs to consume more memory and computational resources to store the feature maps for dense connections, leading to a slower inference speed in semantic segmentation for large-scale high-resolution UAV images (Cao et al., 2023; Xiao et al., 2023b).\nåœ¨æ— äººæœºé¥æ„Ÿä¸­ï¼Œä¸ºç‰¹å®šåœºæ™¯æ”¹è¿›å’Œå¾®è°ƒæ¨¡å‹çš„èŒƒå¼ä¼¼ä¹æˆä¸ºæé«˜å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æå–ä¸Šä¸‹æ–‡ä¿¡æ¯èƒ½åŠ›çš„æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒUNet éœ€è¦æ¶ˆè€—æ›´å¤šçš„å†…å­˜å’Œè®¡ç®—èµ„æºæ¥å­˜å‚¨ç”¨äºå¯†é›†è¿æ¥çš„ç‰¹å¾å›¾ï¼Œä»è€Œå¯¼è‡´åœ¨å¤§è§„æ¨¡é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ä¸­æ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼ˆCao ç­‰ï¼Œ2023ï¼›Xiao ç­‰ï¼Œ2023bï¼‰ã€‚\n# High-resolution network\né«˜åˆ†è¾¨ç‡ç½‘ç»œ\nHigh-resolution representation learning plays a crucial role in UAV semantic segmentation due to the ultra-high resolution and varying object scale of UAV remote sensing imagery. There are two approaches to computing high-resolution representation.\nç”±äºæ— äººæœºé¥æ„Ÿå›¾åƒå…·æœ‰è¶…é«˜åˆ†è¾¨ç‡å’Œå¤šå˜ç‰©ä½“å°ºåº¦ï¼Œé«˜åˆ†è¾¨ç‡è¡¨ç¤ºå­¦ä¹ åœ¨æ— äººæœºè¯­ä¹‰åˆ†å‰²ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚è®¡ç®—é«˜åˆ†è¾¨ç‡è¡¨ç¤ºæœ‰ä¸¤ç§æ–¹æ³•ã€‚\nOne is to up-sample and recover the low-resolution feature maps of CNNs to high-resolution representations. Another one is to maintain the high-resolution information by convolution operations and strengthen semantic context by integrating parallel multi-scale low-resolution feature maps (Zhou et al., 2015; Saxena and Verbeek, 2016; Fourure et al., 2017; Sun et al., 2019). Since high-resolution representation relies on the latent semantic information of multi-scale feature maps, Wang et al. (2020c) designed a high-resolution network (HRNet) that repeatedly exchanges semantic information across adjacent multi-resolution subnetworks. As shown in Fig. 4, vertically, HRNet starts from the first high-resolution feature stream and adds high-to-low resolution subnetworks step by step to form a new multi-resolution stage. To enhance the high-resolution representation and position sensitivity, it connected high-resolution and low-resolution features in parallel and exchanged the semantic information across adjacent multi-resolution sub-networks.\nä¸€ç§æ˜¯å¯¹å·ç§¯ç½‘ç»œçš„ä½åˆ†è¾¨ç‡ç‰¹å¾æ˜ å°„è¿›è¡Œä¸Šé‡‡æ ·ï¼Œå¹¶æ¢å¤ä¸ºé«˜åˆ†è¾¨ç‡è¡¨ç¤ºã€‚å¦ä¸€ç§æ˜¯é€šè¿‡å·ç§¯ä½œä¿æŒé«˜åˆ†è¾¨ç‡ä¿¡æ¯ï¼Œå¹¶é€šè¿‡é›†æˆå¹¶è¡Œå¤šå°ºåº¦ä½åˆ†è¾¨ç‡ç‰¹å¾å›¾æ¥å¼ºåŒ–è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼ˆå‘¨ç­‰ï¼Œ2015;Saxena å’Œ Verbeekï¼Œ2016;Fourure ç­‰ï¼Œ2017;Sun ç­‰ï¼Œ2019ï¼‰ã€‚ç”±äºé«˜åˆ†è¾¨ç‡è¡¨ç¤ºä¾èµ–äºå¤šå°ºåº¦ç‰¹å¾å›¾çš„æ½œåœ¨è¯­ä¹‰ä¿¡æ¯ï¼ŒWang ç­‰äººï¼ˆ2020cï¼‰è®¾è®¡äº†ä¸€ä¸ªé«˜åˆ†è¾¨ç‡ç½‘ç»œï¼ˆHRNetï¼‰ï¼Œèƒ½å¤Ÿåå¤åœ¨ç›¸é‚»å¤šåˆ†è¾¨ç‡å­ç½‘ç»œé—´äº¤æ¢è¯­ä¹‰ä¿¡æ¯ã€‚å¦‚å›¾ 4 æ‰€ç¤ºï¼Œå‚ç›´æ–¹å‘ï¼ŒHRNet ä»ç¬¬ä¸€ä¸ªé«˜åˆ†è¾¨ç‡ç‰¹å¾æµå¼€å§‹ï¼Œé€æ­¥æ·»åŠ é«˜åˆ†è¾¨ç‡åˆ°ä½åˆ†è¾¨ç‡å­ç½‘ç»œï¼Œå½¢æˆæ–°çš„å¤šåˆ†è¾¨ç‡é˜¶æ®µã€‚ä¸ºäº†å¢å¼ºé«˜åˆ†è¾¨ç‡è¡¨ç¤ºå’Œä½ç½®çµæ•åº¦ï¼Œå®ƒå¹¶è¡Œè¿æ¥äº†é«˜åˆ†è¾¨ç‡å’Œä½åˆ†è¾¨ç‡ç‰¹å¾ï¼Œå¹¶åœ¨ç›¸é‚»çš„å¤šåˆ†è¾¨ç‡å­ç½‘ç»œä¹‹é—´äº¤æ¢è¯­ä¹‰ä¿¡æ¯ã€‚\n\nFig. 4. Illustration of the structure of HRNet that consists of four high-to-low resolution sub-networks. In the vertical direction, HRNet repeatedly exchanges semantic information across adjacent multi-resolution sub-networks with up-sampling, down-sampling, and convolutional units.\nå›¾ 4ã€‚HRNet ç»“æ„ç¤ºæ„ï¼Œç”±å››ä¸ªé«˜åˆ†è¾¨ç‡åˆ°ä½åˆ†è¾¨ç‡å­ç½‘ç»œç»„æˆã€‚åœ¨çºµå‘æ–¹å‘ä¸Šï¼ŒHRNet é€šè¿‡ä¸Šé‡‡æ ·ã€ä¸‹é‡‡æ ·å’Œå·ç§¯å•å…ƒåå¤åœ¨ç›¸é‚»çš„å¤šåˆ†è¾¨ç‡å­ç½‘ç»œé—´äº¤æ¢è¯­ä¹‰ä¿¡æ¯ã€‚\nExtracting and preserving semantic features of detailed textures and boundaries from high-resolution images presents one of the major challenges in designing semantic parsing methods applicable to highresolution remote sensing images, as the down-sampling operation during feature extraction process compresses spatially detailed features. However, high-resolution representation learning based on HRNet provides an intuitively feasible solution. It has been demonstrated in recent advances in semantic segmentation (Xu et al., 2020b; Zhang et al., 2020b; Huang et al., 2021a; Tian et al., 2022) for remote sensing images. For instance, since both semantic class imbalance and uncertain boundary information exist in remote sensing images, Xu et al. (2020b) further incorporated three vital factors, including spatial representation, contextual information, and boundary details, when applying HRNet to the semantic segmentation of high-resolution remote sensing images. In UAV remote sensing, Huang et al. (2021a) tested the performance of the object contextual representations network  (OCRNet) based on a backbone of HRNet for recognizing zucchinis intercropped with sunflowers in UAV images. Both studies demonstrated that the reasonable use of parallel features with different weights could improve the accuracy of semantic segmentation. Moreover, by extending the spatial resolution gradient and broadening the spectral band dimensions, Liu et al. (2021b) utilized multi-source data composed of satellite and UAV remote sensing images to analyze the classification capabilities of DeepLabV3+ and HRNet for marsh vegetation. Xie et al. (2021b) built a branch for land cover classification with HRNet and introduced a self-supervised generative adversarial network (GAN) to recover low-resolution images acquired by UAV sensors into corresponding high-resolution images.\nä»é«˜åˆ†è¾¨ç‡å›¾åƒä¸­æå–å’Œä¿ç•™è¯¦ç»†çº¹ç†å’Œè¾¹ç•Œçš„è¯­ä¹‰ç‰¹å¾ï¼Œæ˜¯è®¾è®¡é€‚ç”¨äºé«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒçš„è¯­ä¹‰è§£ææ–¹æ³•çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ï¼Œ== å› ä¸ºç‰¹å¾æå–è¿‡ç¨‹ä¸­çš„ä¸‹é‡‡æ ·ä½œä¼šå‹ç¼©ç©ºé—´ç»†èŠ‚ç‰¹å¾ã€‚== ç„¶è€Œï¼Œ== åŸºäº HRNet çš„é«˜åˆ†è¾¨ç‡è¡¨ç¤ºå­¦ä¹ æä¾›äº†ä¸€ä¸ªç›´è§‚å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚== è¿™ä¸€æŠ€æœ¯å·²åœ¨è¯­ä¹‰åˆ†å‰²çš„æœ€æ–°è¿›å±•ä¸­å¾—åˆ°éªŒè¯ï¼ˆXu ç­‰ï¼Œ2020b;Zhang ç­‰ï¼Œ2020b;Huang ç­‰ï¼Œ2021a;Tian ç­‰ï¼Œ2022ï¼‰ç”¨äºé¥æ„Ÿå›¾åƒã€‚ä¾‹å¦‚ï¼Œç”±äºé¥æ„Ÿå›¾åƒä¸­æ—¢å­˜åœ¨è¯­ä¹‰ç±»åˆ«å¤±è¡¡ï¼Œä¹Ÿå­˜åœ¨è¾¹ç•Œä¿¡æ¯ä¸ç¡®å®šï¼ŒXu ç­‰äººï¼ˆ2020bï¼‰åœ¨å°† HRNet åº”ç”¨äºé«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²æ—¶ï¼Œè¿›ä¸€æ­¥çº³å…¥äº†ç©ºé—´è¡¨ç°ã€ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œè¾¹ç•Œç»†èŠ‚ä¸‰ä¸ªå…³é”®å› ç´ ã€‚åœ¨æ— äººæœºé¥æ„Ÿé¢†åŸŸï¼ŒHuang ç­‰äººï¼ˆ2021aï¼‰åŸºäº HRNet éª¨å¹²æµ‹è¯•äº†å¯¹è±¡ä¸Šä¸‹æ–‡è¡¨ç¤ºç½‘ç»œï¼ˆOCRNetï¼‰åœ¨è¯†åˆ«æ— äººæœºå›¾åƒä¸­ä¸å‘æ—¥è‘µäº¤é”™çš„è¥¿è‘«èŠ¦çš„æ€§èƒ½ã€‚ä¸¤é¡¹ç ”ç©¶éƒ½è¡¨æ˜ï¼Œåˆç†ä½¿ç”¨ä¸åŒæƒé‡çš„å¹³è¡Œç‰¹å¾å¯ä»¥æé«˜è¯­ä¹‰åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ‰©å±•ç©ºé—´åˆ†è¾¨ç‡æ¢¯åº¦å’Œæ‹“å®½å…‰è°±å¸¦ç»´åº¦ï¼Œåˆ˜ç­‰äººï¼ˆ2021bï¼‰åˆ©ç”¨å«æ˜Ÿå’Œæ— äººæœºé¥æ„Ÿå›¾åƒç»„æˆçš„å¤šæºæ•°æ®ï¼Œåˆ†æäº† DeepLabV3 + å’Œ HRNet å¯¹æ²¼æ³½æ¤è¢«çš„åˆ†ç±»èƒ½åŠ›ã€‚è°¢ç­‰äººï¼ˆ2021bï¼‰åˆ©ç”¨ HRNet å»ºç«‹äº†åœŸåœ°è¦†ç›–åˆ†ç±»åˆ†æ”¯ï¼Œå¹¶å¼•å…¥äº†è‡ªç›‘ç£ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ï¼Œå°†æ— äººæœºä¼ æ„Ÿå™¨é‡‡é›†çš„ä½åˆ†è¾¨ç‡å›¾åƒæ¢å¤ä¸ºç›¸åº”çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚\nThe accuracy gains in land cover classification suggested that the generated high-resolution images compensated for the loss of information due to the feature down-sampling process of HRNet, as well as contributed to the finegrained feature extraction of edges and texture details. Ye et al. (2022) considered that the background of the post-earthquake bridge damage images collected by UAVs was cluttered, and the damage features of several components were inconspicuous. Accordingly, they constructed a multi-task HRNet for recognizing the components and damage of post-earthquake bridges by combining the loss functions of multiple single-task HRNet models. Despite such advanced practices, the native HRNet contains a large number of parameters, making it laborious to deploy in UAV devices to perform online image analysis. Hence, Huang et al. (2021b) had modified HRNet into a sparse multi-scale structure to reduce the network parameters so that it could be flexibly deployed on UAVs for multiple objects tracking.\nåœŸåœ°è¦†ç›–åˆ†ç±»çš„å‡†ç¡®æ€§æå‡è¡¨æ˜ï¼Œç”Ÿæˆçš„é«˜åˆ†è¾¨ç‡å›¾åƒå¼¥è¡¥äº† HRNet ç‰¹å¾ä¸‹é‡‡æ ·è¿‡ç¨‹å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ï¼Œå¹¶æœ‰åŠ©äºè¾¹ç¼˜å’Œçº¹ç†ç»†èŠ‚çš„ç»†ç²’åº¦ç‰¹å¾æå–ã€‚Ye ç­‰äººï¼ˆ2022ï¼‰è®¤ä¸ºï¼Œæ— äººæœºæ”¶é›†çš„åœ°éœ‡åæ¡¥æ¢æŸä¼¤å›¾åƒèƒŒæ™¯æ‚ä¹±ï¼Œå¤šä¸ªéƒ¨ä»¶çš„æŸä¼¤ç‰¹å¾ä¸æ˜æ˜¾ã€‚å› æ­¤ï¼Œä»–ä»¬æ„å»ºäº†ä¸€ä¸ªå¤šä»»åŠ¡ HRNetï¼Œé€šè¿‡ç»“åˆå¤šä¸ªå•ä»»åŠ¡ HRNet æ¨¡å‹çš„æŸè€—å‡½æ•°ï¼Œè¯†åˆ«åœ°éœ‡åæ¡¥æ¢çš„ç»„æˆéƒ¨åˆ†å’ŒæŸåæƒ…å†µã€‚å°½ç®¡é‡‡ç”¨äº†å¦‚æ­¤å…ˆè¿›çš„æŠ€æœ¯ï¼ŒHRNet æœ¬èº«åŒ…å«å¤§é‡å‚æ•°ï¼Œä½¿å¾—åœ¨æ— äººæœºè®¾å¤‡ä¸­éƒ¨ç½²è¿›è¡Œåœ¨çº¿å›¾åƒåˆ†æå˜å¾—ç¹çã€‚å› æ­¤ï¼ŒHuang ç­‰äººï¼ˆ2021bï¼‰å°† HRNet æ”¹è¿›ä¸ºç¨€ç–çš„å¤šå°ºåº¦ç»“æ„ï¼Œä»¥é™ä½ç½‘ç»œå‚æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿçµæ´»éƒ¨ç½²åœ¨æ— äººæœºä¸Šè¿›è¡Œå¤šç›®æ ‡è·Ÿè¸ªã€‚\n# Other relevant networks\nThe open-source frameworks (Abadi et al., 2016; Paszke et al., 2019) and detailed technical and coding support for DL developers allow researchers to build deeper and more complex topologies by skipping connections between latent feature layers. Hence, featurelearning models that employ multi-scale and feature fusion strategies to deal with context knowledge integration are not limited to the DeepLab series, HRNet, UNet, and their variants.\nå¼€æºæ¡†æ¶ï¼ˆAbadi ç­‰ï¼Œ2016;Paszke ç­‰ï¼Œ2019ï¼‰ä»¥åŠä¸º DL å¼€å‘è€…æä¾›çš„è¯¦ç»†æŠ€æœ¯å’Œç¼–ç æ”¯æŒï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿé€šè¿‡è·³è¿‡æ½œåœ¨ç‰¹å¾å±‚ä¹‹é—´çš„è¿æ¥æ¥æ„å»ºæ›´æ·±å±‚ã€æ›´å¤æ‚çš„æ‹“æ‰‘ã€‚å› æ­¤ï¼Œé‡‡ç”¨å¤šå°ºåº¦å’Œç‰¹å¾èåˆç­–ç•¥å¤„ç†ä¸Šä¸‹æ–‡çŸ¥è¯†é›†æˆçš„ç‰¹å¾å­¦ä¹ æ¨¡å‹ï¼Œå¹¶ä¸é™äº DeepLab ç³»åˆ—ã€HRNetã€UNet åŠå…¶å˜ä½“ã€‚\nIn CNNs, each output pixel corresponds to a fixed perceptual field. The high accuracy semantic segmentation requires the integration of multi-scale contexts to handle complicated spatial patterns. PSPNet (Zhao et al., 2017) is a representative method of multi-scale feature fusion, which proposes a pyramid pooling module based on the global prior representation that aggregates contextual information from different regions. However, the plain and simple feature aggregation in PSPNet is struggling to handle the fine-grained features of highresolution UAV images compared to networks with more efficient feature aggregation topology, such as DeepLabV3+ and UNet (Sudarshan Rao et al., 2020; Hota et al., 2020). A recent work (Zhong et al., 2022) proposed a W-shape multi-scale feature fusion network for distress segmentation via UAVs, which adopted skip connections between the encoderâ€“decoder structure to integrate low-level features and high-level semantic features. Inspired by BiSeNet, Zhang et al. (2021b) proposed dual branch-based ICENETv2 for fine-grained river ice segmentation, which integrated low-resolution semantic features from the deep branch and high-resolution finer features from the shallow branch. Lyu et al. (2020) proposed the multi-scale-dilation network, which created three model streams with different spatial scales through space-to-batch operation and batch-to-space operation. After that, they utilized skip connections to concatenate different scale features within each stream to complement the multi-scale semantic information. However, feature space optimization (FSO), a post-processing technique, was required to refine the final results.\nåœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯ä¸ªè¾“å‡ºåƒç´ å¯¹åº”ä¸€ä¸ªå›ºå®šçš„æ„ŸçŸ¥åœºã€‚é«˜ç²¾åº¦è¯­ä¹‰åˆ†å‰²éœ€è¦æ•´åˆå¤šå°ºåº¦ä¸Šä¸‹æ–‡ä»¥å¤„ç†å¤æ‚çš„ç©ºé—´æ¨¡å¼ã€‚PSPNetï¼ˆZhao ç­‰ï¼Œ2017ï¼‰æ˜¯ä¸€ç§å¤šå°ºåº¦ç‰¹å¾èåˆçš„ä»£è¡¨æ€§æ–¹æ³•ï¼Œæå‡ºäº†åŸºäºå…¨å±€å…ˆéªŒè¡¨ç¤ºçš„é‡‘å­—å¡”æ± æ¨¡å—ï¼Œæ±‡æ€»æ¥è‡ªä¸åŒåŒºåŸŸçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç„¶è€Œï¼ŒPSPNet ä¸­ç®€å•çš„ç‰¹å¾èšåˆåœ¨å¤„ç†é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒçš„ç»†ç²’åº¦ç‰¹å¾æ—¶ï¼Œä¸å…·æœ‰æ›´é«˜æ•ˆç‰¹å¾èšåˆæ‹“æ‰‘çš„ç½‘ç»œï¼ˆå¦‚ DeepLabV3 + å’Œ UNetï¼‰ç›¸æ¯”ï¼Œä»ç„¶éš¾ä»¥åº”å¯¹ï¼ˆSudarshan Rao ç­‰ï¼Œ2020;Hota ç­‰ï¼Œ2020ï¼‰ã€‚ä¸€é¡¹æœ€æ–°å·¥ä½œï¼ˆZhong ç­‰ï¼Œ2022ï¼‰æå‡ºäº†ä¸€ç§ W å½¢å¤šå°ºåº¦ç‰¹å¾èåˆç½‘ç»œï¼Œç”¨äºæ— äººæœºçš„é‡é™©åˆ†å‰²ï¼Œé‡‡ç”¨ç¼–ç å™¨ - è§£ç å™¨ç»“æ„ä¹‹é—´çš„è·³è·ƒè¿æ¥ï¼Œæ•´åˆä½å±‚ç‰¹å¾å’Œé«˜å±‚è¯­ä¹‰ç‰¹å¾ã€‚å— BiSeNet å¯å‘ï¼ŒZhang ç­‰äººï¼ˆ2021bï¼‰æå‡ºäº†åŸºäºåŒåˆ†æ”¯çš„ ICENETv2ï¼Œç”¨äºç»†ç²’åº¦æ²³æµå†°æ®µåˆ†å‰²ï¼Œæ•´åˆäº†æ·±æ”¯çš„ä½åˆ†è¾¨ç‡è¯­ä¹‰ç‰¹å¾å’Œæµ…æ”¯çš„é«˜åˆ†è¾¨ç‡ç»†è‡´ç‰¹å¾ã€‚Lyu ç­‰äººï¼ˆ2020ï¼‰æå‡ºäº†å¤šå°ºåº¦è†¨èƒ€ç½‘ç»œï¼Œé€šè¿‡ç©ºé—´åˆ°æ‰¹æ¬¡å’Œæ‰¹å¯¹ç©ºé—´ä½œåˆ›å»ºäº†ä¸‰ç§ä¸åŒç©ºé—´å°ºåº¦çš„æ¨¡å‹æµã€‚ä¹‹åï¼Œä»–ä»¬åˆ©ç”¨è·³è·ƒè¿æ¥åœ¨æ¯ä¸ªæµä¸­ä¸²æ¥ä¸åŒçš„å°ºåº¦ç‰¹å¾ï¼Œä»¥è¡¥å……å¤šå°ºåº¦è¯­ä¹‰ä¿¡æ¯ã€‚ç„¶è€Œï¼Œéœ€è¦ç‰¹å¾ç©ºé—´ä¼˜åŒ–ï¼ˆFSOï¼‰ä½œä¸ºä¸€ç§åå¤„ç†æŠ€æœ¯æ¥å®Œå–„æœ€ç»ˆç»“æœã€‚\nMost published works on multi-scale and feature fusion strategies devoted to connecting features across layers or branches. However, the multi-scale feature fusion of UAV images inevitably lead to feature redundancy. To achieve efficient multi-scale feature representation and reduce feature redundancy, He et al. (2022a) proposed a multi-scale aware-relation network (MANet) that utilized inter-class and intra-class region refinement to reduce redundancy caused by feature fusion. Then they adopted multi-scale collaborative learning to explore the relationship between different scales and to enhance the diversity of multi-scale feature representations. In addition, some recent studies (Zhang et al., 2020b, 2021b; Anand et al., 2021) had focused on combining attention mechanism to measure the importance of feature maps at different scales for adaptively aggregating multi-scale feature representations.\nå¤§å¤šæ•°å…³äºå¤šå°ºåº¦ç‰¹å¾èåˆç­–ç•¥çš„å·²å‘è¡¨ä½œå“éƒ½è‡´åŠ›äºè¿æ¥å„å±‚æˆ–å„åˆ†æ”¯çš„ç‰¹å¾ã€‚ç„¶è€Œï¼Œæ— äººæœºå›¾åƒçš„å¤šå°ºåº¦ç‰¹å¾èåˆä¸å¯é¿å…åœ°ä¼šå¯¼è‡´ç‰¹å¾å†—ä½™ã€‚ä¸ºäº†å®ç°é«˜æ•ˆçš„å¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºå¹¶å‡å°‘ç‰¹å¾å†—ä½™ï¼ŒHe ç­‰äººï¼ˆ2022aï¼‰æå‡ºäº†ä¸€ç§å¤šå°ºåº¦æ„ŸçŸ¥å…³ç³»ç½‘ç»œï¼ˆMANetï¼‰ï¼Œè¯¥ç½‘ç»œåˆ©ç”¨ç±»é—´å’Œç±»å†…åŒºåŸŸç»†åŒ–æ¥å‡å°‘ç‰¹å¾èåˆå¼•èµ·çš„å†—ä½™ã€‚ç„¶åï¼Œä»–ä»¬é‡‡ç”¨å¤šå°ºåº¦ååŒå­¦ä¹ æ¥æ¢ç´¢ä¸åŒå°ºåº¦ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶å¢å¼ºå¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºçš„å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œä¸€äº›è¿‘æœŸç ”ç©¶ï¼ˆZhang ç­‰äººï¼Œ2020bï¼Œ2021bï¼›Anand ç­‰äººï¼Œ2021ï¼‰ä¸“æ³¨äºç»“åˆæ³¨æ„åŠ›æœºåˆ¶æ¥è¡¡é‡ä¸åŒå°ºåº¦ä¸‹ç‰¹å¾å›¾çš„é‡è¦æ€§ï¼Œä»¥è‡ªé€‚åº”åœ°èšåˆå¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºã€‚\nTable 2 compiled literature on multi-scale and feature fusion methods for UAV image semantic segmentation. Despite multi-scale features providing more fine-grained contextual semantic information of UAV images, inappropriate multi-scale model designs and feature fusion strategies increased the model complexity and result in feature redundancy. Several recent models incorporated relationship modeling techniques, such as attention models, to enhance the representation of multi-scale features. Nevertheless, the deployment and optimization of the model inference require massive memory allocation and intensive computation, which poses additional challenges in balancing the computational overhead and efficient multi-scale feature aggregation.\nè¡¨ 2 æ±‡æ€»äº†å…³äºæ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²çš„å¤šå°ºåº¦ä¸ç‰¹å¾èåˆæ–¹æ³•çš„æ–‡çŒ®ã€‚å°½ç®¡å¤šå°ºåº¦ç‰¹å¾ä¸ºæ— äººæœºå›¾åƒæä¾›äº†æ›´ä¸ºç²¾ç»†çš„ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯ï¼Œä½†ä¸æ°å½“çš„å¤šå°ºåº¦æ¨¡å‹è®¾è®¡å’Œç‰¹å¾èåˆç­–ç•¥å´å¢åŠ äº†æ¨¡å‹çš„å¤æ‚æ€§ï¼Œå¹¶å¯¼è‡´äº†ç‰¹å¾å†—ä½™ã€‚è¿‘æœŸçš„ä¸€äº›æ¨¡å‹é‡‡ç”¨äº†å…³ç³»å»ºæ¨¡æŠ€æœ¯ï¼Œå¦‚æ³¨æ„åŠ›æ¨¡å‹ï¼Œä»¥å¢å¼ºå¤šå°ºåº¦ç‰¹å¾çš„è¡¨ç¤ºèƒ½åŠ›ã€‚ç„¶è€Œï¼Œæ¨¡å‹æ¨ç†çš„éƒ¨ç½²å’Œä¼˜åŒ–éœ€è¦å¤§é‡çš„å†…å­˜åˆ†é…å’Œå¯†é›†è®¡ç®—ï¼Œè¿™ä¸ºå¹³è¡¡è®¡ç®—å¼€é”€ä¸é«˜æ•ˆçš„å¤šå°ºåº¦ç‰¹å¾èšåˆå¸¦æ¥äº†é¢å¤–çš„æŒ‘æˆ˜ã€‚\n\n\n\næ¨¡å‹\nç‰¹ç‚¹\næ€§èƒ½ä¸ä¼˜åŠ¿\nå±€é™æ€§\næ–‡çŒ®\nå›¾åƒæ¨¡æ€ä¸åˆ†è¾¨ç‡\n\n\n\n\nDeepLabV3\né‡‡ç”¨å¤šç½‘æ ¼ï¼ˆmulti-gridï¼‰å’Œç©ºæ´å·ç§¯ï¼ˆatrous convolutionï¼‰ä»¥ç”Ÿæˆæ›´å¤§çš„æ„Ÿå—é‡ï¼›å¼•å…¥å…¨å±€ä¸Šä¸‹æ–‡ç‰¹å¾ä»¥ç¼“è§£ç©ºæ´å·ç§¯å¸¦æ¥çš„æ€§èƒ½é€€åŒ–é—®é¢˜ã€‚\nãƒ»æ¯ä¸ªåƒç´ å¯¹åº”æ›´å¤§çš„æ„Ÿå—é‡ãƒ»èƒ½å¤Ÿåœ¨å¤šå°ºåº¦ä¸Šè¿›è¡Œè¯­ä¹‰åˆ†å‰²\nãƒ»åœ¨å¤§è§„æ¨¡å’Œé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šåº”ç”¨æ—¶è€—æ—¶è¾ƒé•¿\nSui et al. (2020)Wang et al. (2022d)Tallam et al. (2023)\nRGB, 1.2 mRGB, ThermalRGB\n\n\nDeepLabV3+\né‡‡ç”¨ç¼–ç å™¨â€“è§£ç å™¨ç»“æ„ä¸ç©ºæ´å¯åˆ†ç¦»å·ç§¯ï¼›ä»¥ Xception ä½œä¸ºé«˜æ•ˆç‰¹å¾éª¨å¹²ç½‘ç»œã€‚\nãƒ»é«˜æ•ˆçš„ç¼–ç â€“è§£ç ç½‘ç»œï¼Œèƒ½å¤Ÿæ•è·ç»†ç²’åº¦ç›®æ ‡ãƒ»åœ¨ç‰¹å¾æå–èƒ½åŠ›ä¸è®¡ç®—å¼€é”€ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡\nãƒ»åœ¨è¯­ä¹‰æ ‡æ³¨è¾ƒå°‘ã€è®­ç»ƒæ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ï¼Œç›¸æ¯”å‚æ•°æ›´å°‘çš„ç®€å•ç»“æ„æ›´éš¾è®­ç»ƒ\nMorales et al. (2018)Barmpoutis et al. (2020)Megir et al. (2021)Gibril et al. (2021)Fu et al. (2021b)Jeon et al. (2021)Han et al. (2022)Njane et al. (2023)\nRGB, 1.4â€“2.5 cmRGBRGBRGBRGB, DEM, 30 mRGB, 4.5â€“7 cmRGBRGB, Red-edge, NIR\n\n\nUNet\nå¯¹ç§°çš„ U å½¢å…¨å·ç§¯ç½‘ç»œç»“æ„ï¼›é€šè¿‡æ”¶ç¼©è·¯å¾„ä¸æ‰©å±•è·¯å¾„è¿›è¡Œå¤šå°ºåº¦ç‰¹å¾æå–ä¸èåˆã€‚\nãƒ»ç¼–ç å™¨ä¸è§£ç å™¨ä¹‹é—´çš„å¯¹ç§°è·³è·ƒè¿æ¥æœ‰åŠ©äºç»†èŠ‚ç‰¹å¾è¡¨ç¤ºãƒ»ä¸º UAV é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²æä¾›äº†å¯é åŸºçº¿ï¼Œä¸”ç»“æ„æ˜“äºæ ¹æ®å…·ä½“åœºæ™¯è¿›è¡Œæ‰©å±•å’Œä¿®æ”¹\nãƒ»ç¼–ç å™¨ä¸è§£ç å™¨å­ç½‘ç»œä¸­ï¼Œä¸åŒåˆ†è¾¨ç‡ç‰¹å¾å›¾ä¹‹é—´å­˜åœ¨è¯­ä¹‰é¸¿æ²Ÿ\nZhang et al. (2019b)Zhao et al. (2019)Kattenborn et al. (2019)Zhang et al. (2021a)Tan et al. (2021)Shi et al. (2022)Yi et al. (2022a)Gao et al. (2023)He et al. (2023)Wang et al. (2023b)Xiao et al. (2023b)\nIRRGB, NIR, 2.2 cmRGB, 3â€“5 cmRGB, Red-edge, NIR, 1.2 cmRGB, 0.6 cmRGB, 25 cmRGBRGBRGBRGBRGB\n\n\nUNet++\nåœ¨ç›¸åŒç‰¹å¾åˆ†è¾¨ç‡ä¸‹ï¼Œå¼•å…¥ç¼–ç å™¨ä¸è§£ç å™¨ä¹‹é—´çš„å¯†é›†è·³è·ƒè¿æ¥ä»¥è¿›è¡Œç‰¹å¾æ‹¼æ¥ã€‚\nãƒ»å¤šè¯­ä¹‰è¡¨å¾çš„çµæ´»ç‰¹å¾èåˆãƒ»å¤šç©ºé—´å°ºåº¦ç‰¹å¾èåˆæå‡äº†åˆ†å‰²ç²¾åº¦\nãƒ»åœ¨å¤§è§„æ¨¡å’Œé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šåº”ç”¨æ—¶è€—æ—¶è¾ƒé•¿\nTran et al. (2020)Hu et al. (2021a)Cao et al. (2023)\nRGBRGB, 2.902 cm, Thermal: 15 cm, Red-edge &amp; NIR: 8.106 cmRGB\n\n\nHRNet\né€šè¿‡è·¨åˆ†è¾¨ç‡ç‰¹å¾é›†æˆä¸è¯­ä¹‰ä¿¡æ¯äº¤æ¢ï¼Œä¿æŒé«˜åˆ†è¾¨ç‡ç‰¹å¾è¡¨ç¤ºã€‚\nãƒ»æ›´ä¸°å¯Œã€æ›´ç²¾ç¡®çš„ç©ºé—´è¯­ä¹‰è¡¨å¾ãƒ»æ›´å¼ºçš„ç”±é«˜åˆ°ä½åˆ†è¾¨ç‡è¡¨å¾èƒ½åŠ›\nãƒ»å¤æ‚çš„æ¨¡å‹ç»“æ„éœ€è¦æ›´å¤šå†…å­˜åˆ†é…å’Œè®¡ç®—å¼€é”€\nHuang et al. (2021a)Xie et al. (2021b)Ye et al. (2022)\nRGB, 7.5 cmRGB, 15 cmRGB\n\n\nPSPNet\nä½¿ç”¨é‡‘å­—å¡”æ± åŒ–æ¨¡å—èšåˆæ¥è‡ªä¸åŒåŒºåŸŸçš„å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\nãƒ»å±€éƒ¨ä¸å…¨å±€è¯­ä¹‰èåˆä¿è¯äº†åˆ†å‰²ç»“æœçš„æ•´ä½“ä¸€è‡´æ€§\nãƒ»ç»†ç²’åº¦é¢„æµ‹æ•ˆæœä¸ç†æƒ³ãƒ»ç›®æ ‡è¾¹ç•Œæ¨¡ç³Š\nSudarshan Rao et al. (2020)Hota et al. (2020)\nRGB, Thermal, Red-edge, NIRRGB, Thermal, Red-edge, NIR\n\n\nMSDNet\nä¸‰ä¸ªç»“æ„ç›¸åŒçš„æ¨¡å‹åˆ†æ”¯ï¼Œèåˆå¤šå°ºåº¦ç‰¹å¾å›¾ä»¥å¢å¼ºé«˜åˆ†è¾¨ç‡é¢„æµ‹èƒ½åŠ›ã€‚\nãƒ»åƒç´ ã€å›¾åƒâ€“æ ‡ç­¾å¯¹åŠç‰¹å¾å›¾ä¸¥æ ¼å¯¹é½ãƒ»å¯¹å°ºåº¦å˜åŒ–è¾ƒå¤§çš„ç›®æ ‡æä¾›ä¸€è‡´é¢„æµ‹\nãƒ»éœ€è¦åå¤„ç†ä»¥å¹³æ»‘æœ€ç»ˆé¢„æµ‹ç»“æœãƒ»éç«¯åˆ°ç«¯æ–¹æ³•\nLyu et al. (2020)\nRGB\n\n\nICENetV2\næ·±å±‚åˆ†æ”¯æå–é«˜å±‚è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œæµ…å±‚åˆ†æ”¯ä¿æŒç²¾ç»†ç©ºé—´ç»†èŠ‚ã€‚\nãƒ»åŒåˆ†æ”¯çš„å¤šå°ºåº¦ç‰¹å¾èåˆå¯å¤„ç†æ›´ç»†ç²’åº¦ç‰¹å¾å¹¶è·å¾—æ›´é«˜ç²¾åº¦\nâ€”\nZhang et al. (2021b)\nRGB\n\n\nMANet\né€šè¿‡ç±»é—´ä¸ç±»å†…åŒºåŸŸç»†åŒ–åŠå¤šå°ºåº¦ååŒå­¦ä¹ ï¼Œæ„å»ºå¤šå°ºåº¦æ„ŸçŸ¥å…³ç³»ç½‘ç»œã€‚\nãƒ»åˆ¤åˆ«æ€§å¼ºä¸”å¤šæ ·åŒ–çš„å¤šå°ºåº¦è¡¨å¾ãƒ»å‡å°‘ç‰¹å¾èåˆå†—ä½™ä¿¡æ¯ï¼Œæå‡ç‰¹å¾è¡¨ç¤ºæ•ˆç‡\nâ€”\nHe et al. (2022a)\nRGB\n\n\n\n\nHRNet åœ¨æ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æ–¹é¢å±•ç°äº†æœ€å¼ºçš„æ•´ä½“èƒ½åŠ›ã€‚é€šè¿‡åœ¨æ•´ä¸ªç½‘ç»œä¸­ä¿æŒé«˜åˆ†è¾¨ç‡è¡¨ç¤ºï¼Œå¹¶åœ¨å¤šä¸ªå°ºåº¦ä¸Šåå¤äº¤æ¢ä¿¡æ¯ï¼ŒHRNet å®ç°äº†æ›´ä¸°å¯Œã€æ›´ç²¾ç¡®çš„ç©ºé—´è¯­ä¹‰è¡¨ç¤ºã€‚å°½ç®¡è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä½†å…¶è®¾è®¡ç‰¹åˆ«é€‚åˆé«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒã€‚æ€§èƒ½ä¸Šé™é«˜ï¼Œä½†å·¥ç¨‹æˆæœ¬å¤§ã€‚\n\n# Relationship modeling methods\nå…³ç³»å»ºæ¨¡æ–¹æ³•\nWeight-sharing multi-channel convolution kernels, the primary feature extraction unit of DCNNs for semantic segmentation of UAV images, enjoy remarkable spatial-agnostic and channel-specific properties (Li et al., 2021a). Spatial-agnostic property means that the convolution kernel produces similar responses to similar patterns in local space, while channel-specific property implies that the extracted feature maps may have redundancy along the feature channel dimension. Besides, the increasing resolution of UAV remote sensing images generates data redundancy that may seriously interfere with the feature-extracting and decision-making process (Xu et al., 2020b). Hence, establishing the global relationship between pixels or object regions in UAV remote sensing imagery is critical for removing data redundancy and capturing more meaningful context information. As of recently, many advanced studies for mining effective semantic representation in images based on DCNNs have focused on establishing global relationships along spatial and channel dimensions of feature maps (Hu et al., 2018; Woo et al., 2018; Fu et al., 2019; Wang et al., 2020e). According to the motivation and module structure for establishing the global contextual information, we have categorized the relationship modeling methods into non-local mappings, self-attention mechanism and hierarchical attention mechanism.\næƒé‡å…±äº«çš„å¤šé€šé“å·ç§¯æ ¸æ˜¯æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆDCNNsï¼‰ç”¨äºæ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ä¸»è¦ç‰¹å¾æå–å•å…ƒï¼Œå…·æœ‰æ˜¾è‘—çš„ç©ºé—´æ— å…³æ€§å’Œé€šé“ç‰¹å¼‚æ€§å±æ€§ï¼ˆLi ç­‰ï¼Œ2021aï¼‰ã€‚ç©ºé—´æ— å…³æ€§æ„å‘³ç€å·ç§¯æ ¸å¯¹å±€éƒ¨ç©ºé—´ä¸­çš„ç›¸ä¼¼æ¨¡å¼äº§ç”Ÿç›¸ä¼¼çš„å“åº”ï¼Œè€Œé€šé“ç‰¹å¼‚æ€§åˆ™æ„å‘³ç€æå–çš„ç‰¹å¾å›¾åœ¨ç‰¹å¾é€šé“ç»´åº¦ä¸Šå¯èƒ½å­˜åœ¨å†—ä½™ã€‚æ­¤å¤–ï¼Œæ— äººæœºé¥æ„Ÿå›¾åƒåˆ†è¾¨ç‡çš„æé«˜äº§ç”Ÿäº†æ•°æ®å†—ä½™ï¼Œå¯èƒ½ä¼šä¸¥é‡å¹²æ‰°ç‰¹å¾æå–å’Œå†³ç­–è¿‡ç¨‹ï¼ˆXu ç­‰ï¼Œ2020bï¼‰ã€‚å› æ­¤ï¼Œåœ¨æ— äººæœºé¥æ„Ÿå›¾åƒä¸­å»ºç«‹åƒç´ æˆ–ç›®æ ‡åŒºåŸŸä¹‹é—´çš„å…¨å±€å…³ç³»å¯¹äºå»é™¤æ•°æ®å†—ä½™å’Œæ•æ‰æ›´æœ‰æ„ä¹‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯è‡³å…³é‡è¦ã€‚è¿‘æœŸï¼Œè®¸å¤šåŸºäº DCNNs æŒ–æ˜å›¾åƒä¸­æœ‰æ•ˆè¯­ä¹‰è¡¨ç¤ºçš„å…ˆè¿›ç ”ç©¶éƒ½é›†ä¸­åœ¨æ²¿ç€ç‰¹å¾å›¾çš„ç©ºé—´å’Œé€šé“ç»´åº¦å»ºç«‹å…¨å±€å…³ç³»ä¸Šï¼ˆHu ç­‰ï¼Œ2018ï¼›Woo ç­‰ï¼Œ2018ï¼›Fu ç­‰ï¼Œ2019ï¼›Wang ç­‰ï¼Œ2020eï¼‰ã€‚æ ¹æ®å»ºç«‹å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„åŠ¨æœºå’Œæ¨¡å—ç»“æ„ï¼Œæˆ‘ä»¬å°†å…³ç³»å»ºæ¨¡æ–¹æ³•åˆ†ä¸ºéå±€éƒ¨æ˜ å°„ã€è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œåˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶ã€‚\n# Non-local mappings\néå±€éƒ¨æ˜ å°„\nNon-local mappings can be viewed as a contextual relationship modeling approach that adaptively recalibrates the feature response to emphasize meaningful information by explicitly establishing the spatial and channel relationships of features captured within each local receptive field, which is defined as the region size in the input image that produces the feature pixel in the feature map (Araujo et al., 2019).  Although the receptive field of the feature maps of convolutional networks with sufficient layer depth is able to cover the entire image, the local receptive field of shallow layers can only establish short-range dependencies of pixels within a limited region in images (Ramachandran et al., 2019; Khan et al., 2022). Non-local mappings not only permit the model to exploit a broader range of spatial context information but also empower accurate prediction of texture details and boundaries of high-resolution images.\néå±€éƒ¨æ˜ å°„å¯è§†ä¸ºä¸€ç§æƒ…å¢ƒå…³ç³»å»ºæ¨¡æ–¹æ³•ï¼Œé€šè¿‡æ˜¾å¼å»ºç«‹æ¯ä¸ªå±€éƒ¨æ„Ÿå—åœºå†…æ•è·ç‰¹å¾çš„ç©ºé—´å’Œé€šé“å…³ç³»ï¼Œä»¥è‡ªé€‚åº”é‡æ–°æ ¡å‡†ç‰¹å¾å“åº”ï¼Œå¼ºè°ƒæœ‰æ„ä¹‰çš„ä¿¡æ¯ï¼Œè¯¥åŒºåŸŸå®šä¹‰ä¸ºè¾“å…¥å›¾åƒä¸­äº§ç”Ÿç‰¹å¾åƒç´ çš„åŒºåŸŸå¤§å°ï¼ˆAraujo ç­‰ï¼Œ 2019 å¹´ï¼‰ã€‚å°½ç®¡å·ç§¯ç½‘ç»œå…·æœ‰è¶³å¤Ÿå±‚æ·±çš„ç‰¹å¾å›¾çš„æ„Ÿå—é‡èƒ½å¤Ÿè¦†ç›–æ•´ä¸ªå›¾åƒï¼Œä½†æµ…å±‚çš„å±€éƒ¨æ¥æ”¶é‡åªèƒ½åœ¨å›¾åƒä¸­æœ‰é™åŒºåŸŸå†…å»ºç«‹åƒç´ çš„çŸ­è·ç¦»ä¾èµ–å…³ç³»ï¼ˆRamachandran ç­‰ï¼Œ2019;Khan ç­‰ï¼Œ2022ï¼‰ã€‚éæœ¬åœ°æ˜ å°„ä¸ä»…ä½¿æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨æ›´å¹¿æ³›çš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¿˜èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹é«˜åˆ†è¾¨ç‡å›¾åƒçš„çº¹ç†ç»†èŠ‚å’Œè¾¹ç•Œã€‚\nA representative method of non-local mappings is the Convolutional Block Attention Module (CBAM) proposed by Woo et al. (2018), which focuses on extracting essential features and suppressing unnecessary ones. It consists of the Channel Attention Module (CAM) and Spatial Attention Module (SAM). Specifically, CAM used max-pooling and average-pooling operations along the spatial dimension to obtain the most significant and global channel context information, respectively. SAM recalibrated the feature maps along the channel axis with max-pooling and average-pooling operations to highlight informative regions. For image semantic segmentation of UAV remote sensing, CBAM is typically applied to enhance the modelsâ€™ ability to concentrate on spatial details and restore disconnected boundaries and cluttered false-positive predictions. For instance, Bo et al. (2022) integrated the CBAM into the burned area detection network to identify the most distinctive objects in UAV images and capture the spatial location and edge information for refining the final salient region map. Hong et al. (2021) believed that road cracks in UAV remote sensing images were very narrow since the cracks were composed of only a few pixels. Therefore, they added CBAM before the last convolutional layer of UNet to focus on the crack area, improving the segmentation accuracy of crack edge details and the connecting parts of the cracks. Bisio et al. (2023) also argued that CBAM help extract global information about road traffic density, flow patterns, and road capacity from UAV images for efficient traffic analysis. Furthermore, CBAM can be flexibly placed in convolutional networks at a negligible cost of model modification. Wang et al. (2022d) believed that the dam-surface vegetation in thermal images with low resolution and low signal-to-noise ratio was similar to dam-surface seepage, which caused the networks to generate fuzzy boundaries of the seepage area. Adding CBAM to the skip connections of the network enhanced the semantic and spatial information recognition ability for accurate seepage profiles with clear boundaries and less false-alarm rate caused by â€˜â€˜seepage-likeâ€™â€™ interference on the thermograms. Chen et al. (2023) believed small forest flame regions in high-resolution UAV images led to class imbalance issues between foreground and background. They added CBAM to the decoder of the segmentation network to extract details from the low-level semantic features, allowing the model to focus more on the flame regions and achieve a 5.43% improvement in the Intersection over Union (IoU) metric. Yan et al. (2023) embedded CBAM into the feature extraction layer of the convolutional network to suppress unnecessary feature extraction. Experimental results confirmed that CBAM promoted the model to have detailed treatments at the boundaries of rice fields and the voids in large areas.\néå±€éƒ¨æ˜ å°„çš„ä»£è¡¨æ€§æ–¹æ³•æ˜¯ Woo ç­‰äººï¼ˆ2018ï¼‰æå‡ºçš„å·ç§¯å—æ³¨æ„åŠ›æ¨¡å—ï¼ˆCBAMï¼‰ï¼Œè¯¥æ¨¡å—ä¾§é‡äºæå–å…³é”®ç‰¹å¾å¹¶æŠ‘åˆ¶ä¸å¿…è¦çš„ç‰¹å¾ã€‚å®ƒç”±é€šé“æ³¨æ„åŠ›æ¨¡å—ï¼ˆCAMï¼‰å’Œç©ºé—´æ³¨æ„åŠ›æ¨¡å—ï¼ˆSAMï¼‰ç»„æˆã€‚å…·ä½“æ¥è¯´ï¼ŒCAM æ²¿ç©ºé—´ç»´åº¦ä½¿ç”¨æœ€å¤§æ± å’Œå¹³å‡æ± ä½œï¼Œåˆ†åˆ«è·å¾—æœ€é‡è¦å’Œå…¨å±€çš„ä¿¡é“ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚SAM é€šè¿‡æœ€å¤§æ± åŒ–å’Œå¹³å‡æ± ä½œé‡æ–°æ ¡å‡†äº†é€šé“è½´çº¿çš„ç‰¹å¾å›¾ï¼Œä»¥çªå‡ºæ˜¾ç¤ºæœ‰ç”¨çš„åŒºåŸŸã€‚å¯¹äºæ— äººæœºé¥æ„Ÿçš„å›¾åƒè¯­ä¹‰åˆ†å‰²ï¼Œé€šå¸¸åº”ç”¨ CBAM ä»¥å¢å¼ºæ¨¡å‹å¯¹ç©ºé—´ç»†èŠ‚çš„èšç„¦èƒ½åŠ›ï¼Œå¹¶æ¢å¤æ–­å¼€çš„è¾¹ç•Œå’Œæ‚ä¹±çš„è¯¯æŠ¥é¢„æµ‹ã€‚ä¾‹å¦‚ï¼ŒBo ç­‰äººï¼ˆ2022ï¼‰å°† CBAM é›†æˆåˆ°çƒ§æ¯åŒºåŸŸæ£€æµ‹ç½‘ç»œä¸­ï¼Œä»¥è¯†åˆ«æ— äººæœºå›¾åƒä¸­æœ€æ˜¾è‘—çš„ç‰©ä½“ï¼Œå¹¶æ•æ‰ç©ºé—´ä½ç½®å’Œè¾¹ç¼˜ä¿¡æ¯ï¼Œä»¥ä¼˜åŒ–æœ€ç»ˆçªå‡ºåŒºåŸŸåœ°å›¾ã€‚Hong ç­‰äººï¼ˆ2021ï¼‰è®¤ä¸ºï¼Œæ— äººæœºé¥æ„Ÿå›¾åƒä¸­çš„é“è·¯è£‚ç¼éå¸¸ç‹­çª„ï¼Œå› ä¸ºè£‚ç¼ä»…ç”±å‡ ä¸ªåƒç´ ç»„æˆã€‚å› æ­¤ï¼Œä»–ä»¬åœ¨ UNet æœ€åä¸€ä¸ªå·ç§¯å±‚ä¹‹å‰åŠ å…¥äº† CBAMï¼Œä»¥èšç„¦è£‚çº¹åŒºåŸŸï¼Œæé«˜äº†è£‚çº¹è¾¹ç¼˜ç»†èŠ‚å’Œè¿æ¥éƒ¨åˆ†çš„åˆ†å‰²ç²¾åº¦ã€‚Bisio ç­‰äººï¼ˆ2023ï¼‰è¿˜è®¤ä¸ºï¼ŒCBAM æœ‰åŠ©äºä»æ— äººæœºå›¾åƒä¸­æå–å…¨çƒé“è·¯äº¤é€šå¯†åº¦ã€æµé‡æ¨¡å¼å’Œé“è·¯å®¹é‡çš„ä¿¡æ¯ï¼Œä»è€Œé«˜æ•ˆåˆ†æäº¤é€šã€‚æ­¤å¤–ï¼ŒCBAM å¯ä»¥çµæ´»åœ°åµŒå…¥å·ç§¯ç½‘ç»œä¸­ï¼Œæ¨¡å‹ä¿®æ”¹æˆæœ¬æä½ã€‚Wang ç­‰äººï¼ˆ2022dï¼‰è®¤ä¸ºï¼Œä½åˆ†è¾¨ç‡å’Œä½ä¿¡å™ªæ¯”çš„çƒ­æˆåƒä¸­å¤§åè¡¨é¢æ¤è¢«ä¸å¤§åè¡¨é¢æ¸—æ¼ç›¸ä¼¼ï¼Œå¯¼è‡´ç½‘ç»œäº§ç”Ÿäº†æ¸—æ¼åŒºæ¨¡ç³Šè¾¹ç•Œã€‚åœ¨ç½‘ç»œè·³è·ƒè¿æ¥ä¸­åŠ å…¥ CBAM æå‡äº†è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯è¯†åˆ«èƒ½åŠ›ï¼Œå®ç°äº†å‡†ç¡®çš„æ¸—æ¼å‰–é¢ï¼Œè¾¹ç•Œæ¸…æ™°ï¼Œä¸”çƒ­å›¾ä¸Š â€œæ¸—æ¼çŠ¶â€ å¹²æ‰°å¼•èµ·çš„è¯¯æŠ¥ç‡æ›´ä½ã€‚Chen ç­‰äººï¼ˆ2023ï¼‰è®¤ä¸ºï¼Œé«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­å°èŒƒå›´çš„æ£®æ—ç«ç„°åŒºåŸŸä¼šå¯¼è‡´å‰æ™¯ä¸èƒŒæ™¯ä¹‹é—´çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚ä»–ä»¬åœ¨åˆ†æ®µç½‘ç»œçš„è§£ç å™¨ä¸­æ·»åŠ äº† CBAMï¼Œä»¥æå–ä½å±‚è¯­ä¹‰ç‰¹å¾çš„ç»†èŠ‚ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´ä¸“æ³¨äºç«ç„°åŒºåŸŸï¼Œå¹¶åœ¨äº¤å‰ä¸è”åˆï¼ˆIoUï¼‰æŒ‡æ ‡ä¸Šå®ç°äº† 5.43% çš„æå‡ã€‚Yan ç­‰ï¼ˆ2023ï¼‰å°† CBAM åµŒå…¥å·ç§¯ç½‘ç»œçš„ç‰¹å¾æå–å±‚ï¼Œä»¥æŠ‘åˆ¶ä¸å¿…è¦çš„ç‰¹å¾æå–ã€‚å®éªŒç»“æœè¯å®ï¼ŒCBAM æ¨åŠ¨æ¨¡å‹åœ¨ç¨»ç”°è¾¹ç•Œå’Œå¤§é¢ç§¯ç©ºéš™å¤„è¿›è¡Œè¯¦ç»†å¤„ç†ã€‚\n\nFig. 5. Graphical visualization of the structure of the SE module and the ECA module. Both SE and ECA modules share the similar module pipeline and are channel attention modules. The nonlinear mapping function Ï†Â© in the SE module is formed by two fully connected layers, while the nonlinear mapping function Ï†Â© in the ECA module is two 1-dimensional convolutional layers.\nå›¾ 5ã€‚SE æ¨¡å—å’Œ ECA æ¨¡å—ç»“æ„çš„å›¾å½¢å¯è§†åŒ–ã€‚SE å’Œ ECA æ¨¡å—å…±äº«ç›¸ä¼¼çš„æ¨¡å—æµæ°´çº¿ï¼Œéƒ½æ˜¯é€šé“æ³¨æ„åŠ›æ¨¡å—ã€‚SE æ¨¡å—ä¸­çš„éçº¿æ€§æ˜ å°„å‡½æ•°Ï†(C)Ï†(C)Ï†(C) ç”±ä¸¤ä¸ªå…¨è¿é€šå±‚æ„æˆï¼Œè€Œ ECA æ¨¡å—ä¸­çš„éçº¿æ€§æ˜ å°„å‡½æ•°Ï†(C)Ï†(C)Ï†(C) ç”±ä¸¤ä¸ªä¸€ç»´å·ç§¯å±‚ç»„æˆã€‚\nSimilar to CAM, the Squeeze and Excitation (SE) module proposed by Hu et al. (2018) converts information along the channel dimension of a feature map into channel weight coefficients that are relevant to particular tasks. As illustrated in Fig. 5, the SE module utilizes spatial global average pooling (GAP) to obtain the average feature response of each channel. Then, it adopts two fully connected layers as the non-local mapping function Ï†Â© to integrate global information across channels. Lastly, the output of the softmax activation function serves as the weight for each feature channel. Su et al. (2022) introduced the SE module in the multi-scale feature fusion stage of UNet, and the experimental results suggested that the combination of UNet and SE provided faster training convergence and better accuracy on farmland data with small samples and fragmented information.\nç±»ä¼¼äº CAM çš„ä½œï¼Œèƒ¡ç­‰äººï¼ˆ2018ï¼‰æå‡ºçš„æŒ¤å‹ä¸æ¿€å‘ï¼ˆSEï¼‰æ¨¡å—å°†ç‰¹å¾å›¾çš„é€šé“ç»´åº¦ä¿¡æ¯è½¬æ¢ä¸ºä¸ç‰¹å®šä»»åŠ¡ç›¸å…³çš„é€šé“æƒé‡ç³»æ•°ã€‚å¦‚å›¾ 5 æ‰€ç¤ºï¼ŒSE æ¨¡å—åˆ©ç”¨ç©ºé—´å…¨å±€å¹³å‡æ± ï¼ˆGAPï¼‰æ¥è·å¾—æ¯ä¸ªé€šé“çš„å¹³å‡ç‰¹å¾å“åº”ã€‚ç„¶åï¼Œé‡‡ç”¨ä¸¤å±‚å…¨è¿é€šå›¾å±‚ä½œä¸ºéæœ¬åœ°æ˜ å°„å‡½æ•° Ï†ï¼ˆCï¼‰ï¼Œä»¥æ•´åˆè·¨ä¿¡é“çš„å…¨å±€ä¿¡æ¯ã€‚æœ€åï¼Œsoftmax æ¿€æ´»å‡½æ•°çš„è¾“å‡ºä½œä¸ºæ¯ä¸ªç‰¹å¾é€šé“çš„æƒé‡ã€‚Su ç­‰äººï¼ˆ2022ï¼‰åœ¨ UNet å¤šå°ºåº¦ç‰¹å¾èåˆé˜¶æ®µå¼•å…¥äº† SE æ¨¡å—ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒUNet å’Œ SE çš„ç»“åˆåœ¨æ ·æœ¬è¾ƒå°ä¸”ä¿¡æ¯ç¢ç‰‡åŒ–çš„å†œç”°æ•°æ®ä¸­æä¾›äº†æ›´å¿«çš„è®­ç»ƒæ”¶æ•›å’Œæ›´é«˜ç²¾åº¦ã€‚\nOn the basis of SENet, Sun et al. (2022) designed the concurrent spatial and channel squeeze and excitation (scSE) module by combining spatial and channel context information to further enhance the model capacity to extract  meaningful semantic representations for accurately segmenting trees  and roads in the orchard. However, the non-linear mapping function  of the SE module adopts two fully connected layers that are computationally intensive, and the channel dimension reduction destroys  the direct correspondence between channels and their weights.\nåœ¨ SENet çš„åŸºç¡€ä¸Šï¼ŒSun ç­‰äººï¼ˆ2022ï¼‰é€šè¿‡ç»“åˆç©ºé—´å’Œé€šé“ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè®¾è®¡äº†å¹¶è¡Œç©ºé—´å’Œé€šé“æŒ¤å‹ä¸æ¿€åŠ±ï¼ˆscSEï¼‰æ¨¡å—ï¼Œä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹æå–æœ‰æ„ä¹‰è¯­ä¹‰è¡¨å¾çš„èƒ½åŠ›ï¼Œä»è€Œå‡†ç¡®åˆ†å‰²æœå›­ä¸­çš„æ ‘æœ¨å’Œé“è·¯ã€‚ç„¶è€Œï¼ŒSE æ¨¡å—çš„éçº¿æ€§æ˜ å°„å‡½æ•°é‡‡ç”¨äº†ä¸¤ä¸ªè®¡ç®—å¯†é›†çš„å…¨è¿æ¥å±‚ï¼Œä¸”é€šé“ç»´åº¦é™ä½ç ´åäº†é€šé“ä¸å…¶æƒé‡ä¹‹é—´çš„ç›´æ¥å¯¹åº”å…³ç³»ã€‚\nWang et al. (2020e) revisited the non-linear mapping mechanism of the SE module and proposed an Efficient Channel Attention (ECA) module that adopted one-dimensional convolution as mapping function Ï†Â© to avoid dimensionality reduction and implement cross-channel interaction. As an extremely light-weight module, ECA has little impact on the number of parameters of the network regardless of where it is inserted. Han et al. (2021) embedded ECA module in the encoder stage of UNet to focus on extracting semantic features for insulators with diverse, damaged, and ambiguous appearances. Huan et al. (2022) added a parallel global maximum pooling on the top of ECA for exploring the most significant spatial information along channels to improve the accuracy of segmenting farmland edges and identifying narrow farmland ridges from UAV images. A comparative experiment conducted by Cai et al. (2023) tested three non-local mapping methods, CBAM, SE, and ECA, for identifying weeds in pineapple fields in high-resolution UAV images. The results demonstrated that ECA outperformed the other methods in terms of parameter count, computational consumption, and semantic segmentation accuracy.\nWang ç­‰äººï¼ˆ2020eï¼‰é‡æ–°å®¡è§†äº† SEï¼ˆSqueeze-and-Excitationï¼‰æ¨¡å—çš„éçº¿æ€§æ˜ å°„æœºåˆ¶ï¼Œå¹¶æå‡ºäº†ä¸€ç§é«˜æ•ˆé€šé“æ³¨æ„åŠ›ï¼ˆEfficient Channel Attentionï¼ŒECAï¼‰æ¨¡å—ã€‚è¯¥æ¨¡å—é‡‡ç”¨ä¸€ç»´å·ç§¯ä½œä¸ºæ˜ å°„å‡½æ•°Ï†(C)Ï†(C)Ï†(C)ï¼Œä»¥é¿å…é™ç»´å¹¶å®ç°è·¨é€šé“äº¤äº’ã€‚ä½œä¸ºä¸€ç§æå…¶è½»é‡çº§çš„æ¨¡å—ï¼Œæ— è®ºæ’å…¥åœ¨ç½‘ç»œçš„å“ªä¸ªä½ç½®ï¼ŒECA å¯¹ç½‘ç»œå‚æ•°æ•°é‡çš„å½±å“éƒ½å¾ˆå°ã€‚Han ç­‰äººï¼ˆ2021ï¼‰å°† ECA æ¨¡å—åµŒå…¥åˆ° UNet çš„ç¼–ç å™¨é˜¶æ®µï¼Œä¸“æ³¨äºæå–å…·æœ‰å¤šæ ·ã€å—æŸå’Œæ¨¡ç³Šå¤–è§‚çš„ç»ç¼˜ä½“çš„è¯­ä¹‰ç‰¹å¾ã€‚Huan ç­‰äººï¼ˆ2022ï¼‰åœ¨ ECA çš„é¡¶éƒ¨å¢åŠ äº†ä¸€ä¸ªå¹¶è¡Œçš„å…¨å±€æœ€å¤§æ± åŒ–æ“ä½œï¼Œä»¥æ¢ç´¢é€šé“ä¸­æœ€æ˜¾è‘—çš„ç©ºé—´ä¿¡æ¯ï¼Œä»è€Œæé«˜ä»æ— äººæœºå›¾åƒä¸­åˆ†å‰²å†œç”°è¾¹ç¼˜å’Œè¯†åˆ«ç‹­çª„å†œç”°å„åŸ‚çš„å‡†ç¡®æ€§ã€‚Cai ç­‰äººï¼ˆ2023ï¼‰è¿›è¡Œäº†ä¸€é¡¹å¯¹æ¯”å®éªŒï¼Œæµ‹è¯•äº†ä¸‰ç§éå±€éƒ¨æ˜ å°„æ–¹æ³•ï¼šCBAMã€SE å’Œ ECAï¼Œç”¨äºè¯†åˆ«é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­è èç”°çš„æ‚è‰ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å‚æ•°æ•°é‡ã€è®¡ç®—æ¶ˆè€—å’Œè¯­ä¹‰åˆ†å‰²å‡†ç¡®æ€§æ–¹é¢ï¼ŒECA å‡ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚\n# Self-attention mechanism\nè‡ªæ³¨æ„åŠ›æœºåˆ¶\nRecently, the self-attention mechanism, initially celebrated for its superior performance in sequence modeling (Vaswani et al., 2017), such as natural language processing and machine translation, has been widely adopted in the field of image processing (KosÌŒcÌŒevicÌ et al., 2019; Niu et al., 2021; Ghaffarian et al., 2021). In the context of image analysis, it aimed to compute the response matrix of one position attending to all positions and aggregate long-distance contextual dependency adaptively. Self-attention is a soft, deterministic, and differentiable attention mechanism that focuses more on regions or channels, which means that attention weights can be acquired through the learning process. It requires the input feature map from the previous layer to calculate the attention weights, reducing the dependence on external information (Wang et al., 2018). Well-known plug-and-play selfattention methods, such as Non-local Mapping Networks (Wang et al., 2018), Dual Attention Networks (DANet) (Fu et al., 2019), Criss-Cross Attention Networks (CCNet) (Huang et al., 2019b), have been developed to capture long-range contextual information in spatial and channel dimensions respectively, thus improving feature representation for accurate image segmentation. According to our investigation, DANet has received more attention for improving semantic segmentation accuracy in UAV remote sensing compared to other self-attention implementations.\nè¿‘å¹´æ¥ï¼Œè‡ªæ³¨æ„æœºåˆ¶æœ€åˆå› å…¶åœ¨åºåˆ—å»ºæ¨¡ä¸­çš„ä¼˜å¼‚è¡¨ç°è€Œå¤‡å—èµèª‰ï¼ˆVaswani ç­‰ï¼Œ2017ï¼‰ï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨ç¿»è¯‘ï¼Œå·²è¢«å¹¿æ³›åº”ç”¨äºå›¾åƒå¤„ç†é¢†åŸŸï¼ˆKoÅ¡ÄeviÄ‡ ç­‰ï¼Œ2019;Niu ç­‰ï¼Œ2021;Ghaffarian ç­‰ï¼Œ2021ï¼‰ã€‚åœ¨å›¾åƒåˆ†æçš„èƒŒæ™¯ä¸‹ï¼Œå®ƒæ—¨åœ¨è®¡ç®—ä¸€ä¸ªä½ç½®å¯¹æ‰€æœ‰ä½ç½®çš„å“åº”çŸ©é˜µï¼Œå¹¶è‡ªé€‚åº”åœ°æ±‡æ€»é•¿è·ç¦»ä¸Šä¸‹æ–‡ä¾èµ–æ€§ã€‚è‡ªæˆ‘å…³æ³¨æ˜¯ä¸€ç§è½¯æ€§ã€ç¡®å®šæ€§ä¸”å¯å¾®åˆ†çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ›´å¤šå…³æ³¨åŒºåŸŸæˆ–é€šé“ï¼Œè¿™æ„å‘³ç€æ³¨æ„åŠ›æƒé‡å¯ä»¥é€šè¿‡å­¦ä¹ è¿‡ç¨‹è·å¾—ã€‚å®ƒéœ€è¦ä¸Šä¸€å±‚çš„è¾“å…¥ç‰¹å¾å›¾æ¥è®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼Œä»è€Œå‡å°‘å¯¹å¤–éƒ¨ä¿¡æ¯çš„ä¾èµ–ï¼ˆWang ç­‰ï¼Œ2018ï¼‰ã€‚è‘—åçš„å³æ’å³ç”¨è‡ªå…³æ³¨æ–¹æ³•ï¼Œå¦‚éæœ¬åœ°æ˜ å°„ç½‘ç»œï¼ˆWang ç­‰ï¼Œ2018ï¼‰ã€åŒæ³¨æ„åŠ›ç½‘ç»œï¼ˆDANetï¼‰ï¼ˆFu ç­‰ï¼Œ2019ï¼‰ã€äº¤å‰æ³¨æ„åŠ›ç½‘ç»œï¼ˆCCNetï¼‰ï¼ˆHuang ç­‰ï¼Œ2019bï¼‰ï¼Œå·²è¢«å¼€å‘å‡ºæ¥ï¼Œåˆ†åˆ«ç”¨äºæ•æ‰ç©ºé—´ç»´åº¦å’Œé€šé“ç»´åº¦çš„é•¿è·ç¦»ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæå‡ç‰¹å¾è¡¨ç¤ºä»¥å®ç°å›¾åƒåˆ‡å‰²çš„å‡†ç¡®æ€§ã€‚æ ¹æ®æˆ‘ä»¬çš„è°ƒæŸ¥ï¼ŒDANet åœ¨æå‡æ— äººæœºé¥æ„Ÿè¯­ä¹‰åˆ†å‰²å‡†ç¡®æ€§æ–¹é¢ï¼Œç›¸è¾ƒäºå…¶ä»–è‡ªæ³¨æ„å®ç°ï¼Œå—åˆ°äº†æ›´å¤šå…³æ³¨ã€‚\nFig. 6 shows a diagram of the network topology of the Position Attention Module (PAM) and Channel Attention Module (CAM) of DANet (Fu et al., 2019) to facilitate an intuitive understanding of the self-attention mechanism. The Position Attention Module firstly convert the input feature map f âˆˆ RHÃ—W Ã—C into three tensors Î¸ âˆˆ R(HÃ—W )Ã—C , Ï† âˆˆ RCÃ—(HÃ—W ), and g âˆˆ R(HÃ—W )Ã—C . Then attention matrix Ms âˆˆ R(HÃ—W )Ã—(HÃ—W ) that captures the dependencies between any two spatial positions can be obtained by the matrix product of Î¸ and Ï†. Finally, it performs an element-wise sum operation on the original feature f and the matrix multiplication result of Ms and g to obtain the final attention-based representation. The network topology of the Channel Attention Module is similar to that of the Position Attention Module, which aims to establish channel dependencies between any two channels and adaptively update each channel map according to the weighted sum of all channel maps.\nå›¾ 6 å±•ç¤ºäº† DANetï¼ˆFu ç­‰ï¼Œ2019ï¼‰ä¸­ä½ç½®æ³¨æ„åŠ›æ¨¡å—ï¼ˆPAMï¼‰å’Œé€šé“æ³¨æ„åŠ›æ¨¡å—ï¼ˆCAMï¼‰çš„ç½‘ç»œæ‹“æ‰‘å›¾ï¼Œä¾¿äºç›´è§‚åœ°ç†è§£è‡ªæ³¨æ„æœºåˆ¶ã€‚ä½ç½®æ³¨æ„åŠ›æ¨¡å—é¦–å…ˆå°†è¾“å…¥ç‰¹å¾æ˜ å°„ f âˆˆ RHÃ—W Ã—C è½¬æ¢ä¸ºä¸‰ä¸ªå¼ é‡ Î¸ âˆˆ Rï¼ˆHÃ—W ï¼‰Ã—C ã€Ï† âˆˆ RCÃ—ï¼ˆHÃ—W ï¼‰ å’Œ g âˆˆ Rï¼ˆHÃ—W ï¼‰Ã—C ã€‚é‚£ä¹ˆï¼Œé€šè¿‡ Î¸ å’Œ Ï† çš„çŸ©é˜µç§¯ï¼Œå¯ä»¥ç”¨ Î¸ å’Œ  çš„çŸ©é˜µç§¯å¾—åˆ°æ³¨æ„åŠ›çŸ©é˜µ Ms âˆˆ Rï¼ˆHÃ—W ï¼‰Ã—ï¼ˆHÃ—W ï¼‰æ•æ‰ä»»æ„ä¸¤ä¸ªç©ºé—´ä½ç½®ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚æœ€åï¼Œå®ƒå¯¹åŸå§‹ç‰¹å¾ f å’ŒçŸ©é˜µä¹˜æ³•ç»“æœ Ms å’Œ g è¿›è¡Œé€å…ƒç´ æ±‚å’Œï¼Œå¾—åˆ°åŸºäºæ³¨æ„åŠ›çš„æœ€ç»ˆè¡¨ç¤ºã€‚ä¿¡é“æ³¨æ„åŠ›æ¨¡å—çš„ç½‘ç»œæ‹“æ‰‘ç±»ä¼¼äºä½ç½®æ³¨æ„åŠ›æ¨¡å—ï¼Œåè€…æ—¨åœ¨å»ºç«‹ä»»æ„ä¸¤ä¸ªä¿¡é“ä¹‹é—´çš„ä¿¡é“ä¾èµ–å…³ç³»ï¼Œå¹¶æ ¹æ®æ‰€æœ‰ä¿¡é“å›¾çš„åŠ æƒå’Œè‡ªé€‚åº”åœ°æ›´æ–°æ¯ä¸ªä¿¡é“æ˜ å°„ã€‚\n\nFig. 6. Graphical visualization of the Position Attention Module (a) and the Channel Attention Module (b) of DANet.\nå›¾ 6ã€‚DANet ä¸­ä½ç½®æ³¨æ„åŠ›æ¨¡å—ï¼ˆaï¼‰å’Œé€šé“æ³¨æ„åŠ›æ¨¡å—ï¼ˆbï¼‰çš„å›¾å½¢å¯è§†åŒ–ã€‚\nChowdhury and Rahnemoonfar (2021a) reported the complexities in distinguishing the similar textures of debris, sand, and buildings with total destruction damage in high-resolution natural disaster images captured by UAVs (Chowdhury et al., 2020), as the shallow layers of the semantic segmentation backbone extracted fine-grained spatial texture information with low-level meanings but poor semantic consistency. However, the combination of PAM with the shallow layers encouraged the exploration of the global autocorrelation (Chen et al., 2012) of pixels or objects between each local receptive field in high-resolution images to enhance the distinguishability of similar textures of different classes (Chowdhury and Rahnemoonfar, 2021a,b). Regarding the semantic segmentation of tree species, Huang et al. (2023) contended that significant coincidence existed among the information of various tree species growing in the same geographic location. Therefore, the author proposed a dual-attention residual module to process the strong correlation between local features and global dependence of tree species information from spatial and channel dimensions. Jiang et al. (2022) argued that the ground fissure images in coal mine areas obtained by UAVs were heavily affected by strong noise, such as different illumination and shadow, making conventional segmentation techniques, such as Canny (1986) and Adaptive Threshold (Chang et al., 2000), suffered poor generalization performance. In contrast, the proposed MFPA-Net composed of dilated residual networks and the DANet generated clear and accurate shapes of the ground fissures by utilizing plenty of valuable global features and contextual information to overcome the interference of various noises. Zhang et al. (2021b) found that the spatial patterns of the same type of river ice could vary significantly, while different types of river ice sometimes appear similar due to the complex formation and evolution processes. The authors accordingly adopted the DANet to highlight distinguishable semantic representations of drift ice and shore ice.\nChowdhury å’Œ Rahnemoonfarï¼ˆ2021aï¼‰æŠ¥å‘Šäº†åœ¨é«˜åˆ†è¾¨ç‡è‡ªç„¶ç¾å®³å›¾åƒä¸­åŒºåˆ†ç¢ç‰‡ã€æ²™åœŸå’Œå®Œå…¨æ¯åå»ºç­‘ç‰©çš„ç›¸ä¼¼çº¹ç†çš„å¤æ‚æ€§ï¼Œè¿™äº›å›¾åƒç”±æ— äººæœºï¼ˆChowdhury ç­‰äººï¼Œ2020ï¼‰æ‹æ‘„ã€‚ç”±äºè¯­ä¹‰åˆ†å‰²ä¸»å¹²ç½‘ç»œçš„æµ…å±‚æå–äº†å…·æœ‰ä½çº§å«ä¹‰ä½†è¯­ä¹‰ä¸€è‡´æ€§è¾ƒå·®çš„ç»†ç²’åº¦ç©ºé—´çº¹ç†ä¿¡æ¯ï¼Œå› æ­¤ï¼Œå°†ç‚¹è°ƒæ•´æ¨¡å—ï¼ˆPAMï¼‰ä¸æµ…å±‚ç›¸ç»“åˆï¼Œé¼“åŠ±åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒä¸­æ¢ç´¢æ¯ä¸ªå±€éƒ¨æ„Ÿå—é‡ä¹‹é—´åƒç´ æˆ–å¯¹è±¡çš„å…¨å±€è‡ªç›¸å…³æ€§ï¼ˆChen ç­‰äººï¼Œ2012ï¼‰ï¼Œä»¥æé«˜ä¸åŒç±»åˆ«ç›¸ä¼¼çº¹ç†çš„å¯åŒºåˆ†æ€§ï¼ˆChowdhury å’Œ Rahnemoonfarï¼Œ2021aï¼Œbï¼‰ã€‚å…³äºæ ‘ç§çš„è¯­ä¹‰åˆ†å‰²ï¼ŒHuang ç­‰äººï¼ˆ2023ï¼‰è®¤ä¸ºï¼Œç”Ÿé•¿åœ¨åŒä¸€åœ°ç†ä½ç½®çš„å„ç§æ ‘ç§çš„ä¿¡æ¯å­˜åœ¨æ˜¾è‘—çš„é‡åˆã€‚å› æ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªåŒæ³¨æ„åŠ›æ®‹å·®æ¨¡å—ï¼Œä»ç©ºé—´å’Œé€šé“ç»´åº¦å¤„ç†æ ‘ç§ä¿¡æ¯å±€éƒ¨ç‰¹å¾ä¸å…¨å±€ä¾èµ–ä¹‹é—´çš„å¼ºç›¸å…³æ€§ã€‚Jiang ç­‰äººï¼ˆ2022ï¼‰è®¤ä¸ºï¼Œæ— äººæœºæ‹æ‘„çš„ç…¤çŸ¿åŒºåœ°è£‚ç¼å›¾åƒå—åˆ°å¼ºçƒˆå™ªå£°ï¼ˆå¦‚ä¸åŒå…‰ç…§å’Œé˜´å½±ï¼‰çš„ä¸¥é‡å½±å“ï¼Œä½¿å¾—ä¼ ç»Ÿåˆ†å‰²æŠ€æœ¯ï¼ˆå¦‚ Cannyï¼ˆ1986ï¼‰å’Œè‡ªé€‚åº”é˜ˆå€¼ï¼ˆChang ç­‰äººï¼Œ2000ï¼‰ï¼‰çš„æ³›åŒ–æ€§èƒ½è¾ƒå·®ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ‰€æå‡ºçš„ MFPA-Net ç”±æ‰©å¼ æ®‹å·®ç½‘ç»œå’Œ DANet ç»„æˆï¼Œé€šè¿‡åˆ©ç”¨å¤§é‡æœ‰ä»·å€¼çš„å…¨å±€ç‰¹å¾å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå…‹æœäº†å„ç§å™ªå£°çš„å¹²æ‰°ï¼Œç”Ÿæˆäº†æ¸…æ™°å‡†ç¡®çš„è£‚ç¼å½¢çŠ¶ã€‚Zhang ç­‰äººï¼ˆ2021bï¼‰å‘ç°ï¼ŒåŒç§æ²³å†°çš„ç©ºé—´æ¨¡å¼å¯èƒ½å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè€Œä¸åŒç±»å‹çš„æ²³å†°æœ‰æ—¶ç”±äºå¤æ‚çš„å½¢æˆå’Œæ¼”åŒ–è¿‡ç¨‹è€Œæ˜¾å¾—ç›¸ä¼¼ã€‚å› æ­¤ï¼Œä½œè€…é‡‡ç”¨ DANet æ¥çªå‡ºæ¼‚å†°å’Œå²¸å†°çš„å¯åŒºåˆ†è¯­ä¹‰è¡¨ç¤ºã€‚\nIn summary, the self-attention mechanism represented by the DANet can be utilized to enhance the ability of semantic segmentation models to extract distinguishable features from ambiguous semantic objects in high-resolution UAV images by establishing global contextual relationships across the spatial and channel dimensions of the feature maps. However, it should be noted that the full matrix multiplication operations in both PAM and SAM are computationally intensive (Huang et al., 2019b; Khan et al., 2022). In fact, there are other light-weight yet efficient modules (Huang et al., 2019a; Zhu et al., 2019; Huang et al., 2019b) built on the top of the self-attention mechanism, but the best practices of them or similar pipelines have not been validated in semantic segmentation for UAV images.\næ€»ä¹‹ï¼ŒDANet æ‰€ä»£è¡¨çš„è‡ªæ³¨æ„æœºåˆ¶å¯ç”¨äºå¢å¼ºè¯­ä¹‰åˆ†å‰²æ¨¡å‹ä»é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­æ¨¡ç³Šè¯­ä¹‰å¯¹è±¡ä¸­æå–å¯åŒºåˆ†ç‰¹å¾çš„èƒ½åŠ›ï¼Œé€šè¿‡å»ºç«‹è·¨ç©ºé—´å’Œé€šé“ç»´åº¦çš„å…¨å±€ä¸Šä¸‹æ–‡å…³ç³»ã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒPAM å’Œ SAM ä¸­çš„å…¨çŸ©é˜µä¹˜æ³•è¿ç®—éƒ½å…·æœ‰è®¡ç®—å¯†é›†å‹ï¼ˆHuang ç­‰ï¼Œ2019b;Khan ç­‰ï¼Œ2022ï¼‰ã€‚äº‹å®ä¸Šï¼Œè¿˜æœ‰å…¶ä»–è½»é‡çº§ä½†é«˜æ•ˆçš„æ¨¡å—ï¼ˆHuang ç­‰ï¼Œ2019a;Zhu ç­‰ï¼Œ2019;Huang ç­‰ï¼Œ2019bï¼‰å»ºç«‹åœ¨è‡ªæ³¨æ„æœºåˆ¶ä¹‹ä¸Šï¼Œä½†å®ƒä»¬æˆ–ç±»ä¼¼æµç¨‹çš„æœ€ä½³å®è·µå°šæœªåœ¨æ— äººæœºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ä¸­å¾—åˆ°éªŒè¯ã€‚\n# Hierarchical attention mechanism\nå±‚çº§æ³¨æ„åŠ›æœºåˆ¶\nThe abovementioned attention models can be regarded as singleinput representation models designed to calculate the attention weights of independent branches. Another co-attention mode is the hierarchical attention mechanism (Chen et al., 2016; Tao et al., 2020) that parallelly establishes the contextual dependency on the multi-input presentations and finally merge the attentions of these parallel branches. However, only a few studies were found in literature where the hierarchical attention was used for UAV segmentation tasks in high-resolution remote sensing images. Inspired by the hierarchical attention mechanism proposed by Tao et al. (2020) for predicting relative weights between adjacent scale pairs, Anand et al. (2021) proposed AgriSegNet for IoT-assisted precision agriculture monitoring. One of the distinctive characteristics of the hierarchical attention mechanism was that the model inference with multiple image scales, such as three image scales, only required two image scales in the training phase. Lyu et al. (2021) improved it and proposed bidirectional Multi-scale Attention Network (BiMSANet) that integrated two feature-level hierarchical multi-scale attention networks corresponding to two bypasses for hierarchical feature fusion. Specifically, benefiting from attention heads with the same pipeline, these two bypasses were able to obtain the optimal scale for feature fusion from both directions. Comparative experiments on the UAVid dataset had shown that BiMSANet delivered an excellent performance on processing small targets and adaptively adjusted multiscale attention patterns for different object scales. It achieved the best segmentation performance in the Human class compared to other methods and reached a superior result with the mIoU of 70.8% for the UAVid benchmark.\nä¸Šè¿°æ³¨æ„åŠ›æ¨¡å‹å¯è§†ä¸ºå•è¾“å…¥è¡¨ç¤ºæ¨¡å‹ï¼Œæ—¨åœ¨è®¡ç®—ç‹¬ç«‹åˆ†æ”¯çš„æ³¨æ„åŠ›æƒé‡ã€‚== å¦ä¸€ç§å…±æ³¨æ„æ¨¡å¼æ˜¯å±‚çº§æ³¨æ„åŠ›æœºåˆ¶ï¼ˆChen ç­‰ï¼Œ2016;Tao ç­‰ï¼Œ2020ï¼‰ï¼Œå®ƒå¹¶è¡Œå»ºç«‹å¯¹å¤šè¾“å…¥å‘ˆç°çš„ä¸Šä¸‹æ–‡ä¾èµ–ï¼Œå¹¶æœ€ç»ˆåˆå¹¶è¿™äº›å¹¶è¡Œåˆ†æ”¯çš„æ³¨æ„åŠ›ã€‚ç„¶è€Œï¼Œæ–‡çŒ®ä¸­åªæœ‰å°‘æ•°ç ”ç©¶å°†åˆ†å±‚æ³¨æ„åŠ›ç”¨äºé«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒä¸­çš„æ— äººæœºåˆ†å‰²ä»»åŠ¡ã€‚== å— Tao ç­‰äººï¼ˆ2020ï¼‰æå‡ºçš„åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶çš„å¯å‘ï¼Œç”¨äºé¢„æµ‹ç›¸é‚»å°ºåº¦å¯¹ä¹‹é—´çš„ç›¸å¯¹æƒé‡ï¼ŒAnand ç­‰äººï¼ˆ2021ï¼‰æå‡ºäº† AgriSegNet ç”¨äºç‰©è”ç½‘è¾…åŠ©ç²¾å‡†å†œä¸šç›‘æµ‹ã€‚åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶çš„ä¸€ä¸ªæ˜¾è‘—ç‰¹ç‚¹æ˜¯ï¼Œå¤šå›¾åƒå°ºåº¦ï¼ˆå¦‚ä¸‰å›¾åƒå°ºåº¦ï¼‰çš„æ¨¡å‹æ¨æ–­åœ¨è®­ç»ƒé˜¶æ®µåªéœ€ä¸¤ä¸ªå›¾åƒå°ºåº¦ã€‚Lyu ç­‰ï¼ˆ2021ï¼‰æ”¹è¿›äº†è¯¥æœºåˆ¶ï¼Œæå‡ºäº†åŒå‘å¤šå°ºåº¦æ³¨æ„åŠ›ç½‘ç»œï¼ˆBiMSANetï¼‰ï¼Œé›†æˆäº†ä¸¤ä¸ªç‰¹å¾çº§å±‚çº§å¤šå°ºåº¦æ³¨æ„åŠ›ç½‘ç»œï¼Œå¯¹åº”äºåˆ†å±‚ç‰¹å¾èåˆçš„ä¸¤ä¸ªæ—é€šã€‚å…·ä½“æ¥è¯´ï¼Œå€ŸåŠ©åŒä¸€æµæ°´çº¿çš„æ³¨æ„åŠ›å¤´ï¼Œè¿™ä¸¤ç§æ—é€šèƒ½å¤Ÿä»ä¸¤ä¸ªæ–¹å‘è·å¾—ç‰¹å¾èåˆçš„æœ€ä¼˜å°ºåº¦ã€‚UAVid æ•°æ®é›†çš„å¯¹æ¯”å®éªŒè¡¨æ˜ï¼ŒBiMSANet åœ¨å¤„ç†å°ç›®æ ‡å’Œå¯¹ä¸åŒå¯¹è±¡å°ºåº¦çš„å¤šå°ºåº¦æ³¨æ„åŠ›æ¨¡å¼è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚å®ƒåœ¨äººç±»ç±»åˆ«ä¸­å®ç°äº†æœ€ä½³çš„åˆ†å‰²æ€§èƒ½ï¼ŒUAVid åŸºå‡†æµ‹è¯•çš„ mIoU è¾¾åˆ°äº† 70.8%ã€‚\nTable 3 provides a summary of several relevant relationship modeling methods that have been adopted in the semantic segmentation tasks for UAV-based images. The relationship modeling methods applied in the literature can be summarized as spatial-wise relationship modeling,  channel-wise relationship modeling, scale-wise relationship modeling, and hybrid methods. Developing a more effective relationship modeling mechanism for obtaining diverse and discriminative feature representation and improving the segmentation performance of UAV images are the recent trend that requires full comparisons and evaluations. As shown in Table 3, the DA modules have received significant attention in the recent literature on contextual relationship modeling. In fact, the self-attention mechanism is an essential component of Transformers (Khan et al., 2022; Jamil et al., 2023; Xiao et al., 2023a), the novel network architecture that explicitly learns the intrinsic relationships of elements or sequences. In recent years, Transformer-based semantic segmentation models have also profoundly impacted the development of semantic segmentation methods for UAV images, and we will provide details in the next section.\nè¡¨ 3 æ€»ç»“äº†å‡ ç§è¢«æ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²ä»»åŠ¡é‡‡ç”¨çš„ç›¸å…³å…³ç³»å»ºæ¨¡æ–¹æ³•ã€‚æ–‡çŒ®ä¸­åº”ç”¨çš„å…³ç³»å»ºæ¨¡æ–¹æ³•å¯å½’çº³ä¸ºç©ºé—´å…³ç³»å»ºæ¨¡ã€é€šé“å…³ç³»å»ºæ¨¡ã€å°ºåº¦å…³ç³»å»ºæ¨¡å’Œæ··åˆæ–¹æ³•ã€‚å¼€å‘æ›´æœ‰æ•ˆçš„å…³ç³»å»ºæ¨¡æœºåˆ¶ä»¥è·å¾—å¤šæ ·ä¸”åˆ¤åˆ«æ€§å¼ºçš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶æå‡æ— äººæœºå›¾åƒçš„åˆ†å‰²æ€§èƒ½ï¼Œæ˜¯è¿‘æœŸéœ€è¦å…¨é¢æ¯”è¾ƒå’Œè¯„ä¼°çš„è¶‹åŠ¿ã€‚å¦‚è¡¨ 3 æ‰€ç¤ºï¼ŒDA æ¨¡å—åœ¨è¿‘æœŸå…³äºæƒ…å¢ƒå…³ç³»å»ºæ¨¡çš„æ–‡çŒ®ä¸­è·å¾—äº†å¹¿æ³›å…³æ³¨ã€‚äº‹å®ä¸Šï¼Œè‡ªæˆ‘å…³æ³¨æœºåˆ¶æ˜¯ Transformersï¼ˆKhan ç­‰ï¼Œ2022;Jamil ç­‰ï¼Œ2023;Xiao ç­‰ï¼Œ2023aï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ç½‘ç»œæ¶æ„ï¼Œæ˜ç¡®å­¦ä¹ å…ƒç´ æˆ–åºåˆ—çš„å†…åœ¨å…³ç³»ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäº Transformer çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹ä¹Ÿæ·±åˆ»å½±å“äº†æ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æ–¹æ³•çš„å‘å±•ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚æä¾›è¯¦ç»†ä»‹ç»ã€‚\n\n\nCBAM â€”â€” æ€§ä»·æ¯”é«˜ï¼Œä½†èƒ½åŠ›æœ‰é™\nSE / ECA â€”â€” è½»é‡åŒ–æœ€ä¼˜ï¼Œä½†è¡¨è¾¾èƒ½åŠ›åå¼±\nDual Attention (DA) â€”â€” ç»¼åˆèƒ½åŠ›æœ€å¼ºï¼Œæ˜¾å¼å»ºæ¨¡é•¿ç¨‹ä¸Šä¸‹æ–‡ä¾èµ–ï¼ŒåŒæ—¶å¤„ç† ç©ºé—´æ³¨æ„åŠ› + é€šé“æ³¨æ„åŠ›å¸¦æ¥æ›´ç²¾ç¡®çš„è¯­ä¹‰åˆ†å‰²ç»“æœï¼Œä½†çŸ©é˜µè¿ç®—ï¼Œè®¡ç®—é‡å¤§\nHierarchical Attention â€”â€” æŠ˜ä¸­æ–¹æ¡ˆ\nDA &gt; Hierarchical Attention &gt; CBAM &gt; SE â‰ˆ ECA\n\n# Vision transformer architectures\nViT\nThe remarkable performance of Transformer models on natural language tasks (Vaswani et al., 2017; Ott et al., 2018) has piqued the interest of the computer vision community to explore potential applications in computer vision problems. Both Khan et al. (2022) and Jamil et al. (2023) provided a comprehensive review on transformers in computer vision. According to the review conducted by Khan et al. (2022), Transformer-based models applied to vision tasks can be broadly categorized into models with single-head attention and models with multi-head attention. The combination of DCNNs and selfattention mechanism in the previous section can be classified as the former, while this section focuses on the latter.\nTransformer æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­çš„å“è¶Šè¡¨ç°ï¼ˆVaswani ç­‰ï¼Œ2017;Ott ç­‰ï¼Œ2018ï¼‰å¼•èµ·äº†è®¡ç®—æœºè§†è§‰ç•Œå¯¹æ¢ç´¢è®¡ç®—æœºè§†è§‰é—®é¢˜æ½œåœ¨åº”ç”¨çš„å…´è¶£ã€‚Khan ç­‰äººï¼ˆ2022 å¹´ï¼‰å’Œ Jamil ç­‰äººï¼ˆ2023 å¹´ï¼‰éƒ½æä¾›äº†å…³äºè®¡ç®—æœºè§†è§‰ä¸­å˜æ¢å™¨çš„å®Œæ•´ç»¼è¿°ã€‚æ ¹æ® Khan ç­‰äººï¼ˆ2022ï¼‰çš„ç»¼è¿°ï¼ŒåŸºäº Transformer çš„æ¨¡å‹åº”ç”¨äºè§†è§‰ä»»åŠ¡ï¼Œå¤§è‡´å¯åˆ†ä¸ºå•å¤´æ³¨æ„åŠ›æ¨¡å‹å’Œå¤šå¤´æ³¨æ„åŠ›æ¨¡å‹ã€‚å‰ä¸€èŠ‚ä¸­ DCNNs ä¸è‡ªæˆ‘å…³æ³¨æœºåˆ¶çš„ç»“åˆå¯å½’ä¸ºå‰è€…ï¼Œè€Œæœ¬èŠ‚åˆ™èšç„¦åè€…ã€‚\nAs of recently, we observed that the transformer-based semantic segmentation method for UAV remote sensing images follows the encoderâ€“decoder structure, which is the same as the underlying structure of CNN-based methods. Besides, transformer models with multi-head attention can be flexibly combined with convolutional networks, thus giving rise to more diverse encoderâ€“decoder structures for UAV image semantic segmentation (Wang and Mahmoudian, 2023; Li and Hsu, 2022; Ghali and Akhloufi, 2023). In this section, we investigated and outlined the best practices of vision transformers (ViT) with multi-head attention in the semantic segmentation of UAV remote sensing images.\nè¿‘æœŸï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œç”¨äºæ— äººæœºé¥æ„Ÿå›¾åƒçš„åŸºäº Transformer çš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•éµå¾ªç¼–ç å™¨ - è§£ç å™¨ç»“æ„ï¼Œè¿™ä¸åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„æ–¹æ³•çš„åŸºç¡€ç»“æ„ç›¸åŒã€‚æ­¤å¤–ï¼Œå…·æœ‰å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„ Transformer æ¨¡å‹å¯ä»¥ä¸å·ç§¯ç½‘ç»œçµæ´»ç»“åˆï¼Œä»è€Œä¸ºæ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æä¾›äº†æ›´å¤šæ ·åŒ–çš„ç¼–ç å™¨ - è§£ç å™¨ç»“æ„ï¼ˆWang and Mahmoudian, 2023; Li and Hsu, 2022; Ghali and Akhloufi, 2023ï¼‰ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶å’Œæ¦‚è¿°äº†å…·æœ‰å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„è§†è§‰ Transformerï¼ˆViTï¼‰åœ¨æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²ä¸­çš„æœ€ä½³å®è·µã€‚\nViT, designed by Dosovitskiy et al. (2021) for image recognition tasks, first divides an image into equal-sized patches and then flattens patches into 2D-patches sequences that are fed into linear projections to obtain patch embeddings. The transformer encoder, which contributes to capturing global relationships between image pixels at shallow layers, takes these patch embeddings along with position embeddings as input (Dosovitskiy et al., 2021). However, obtaining feature representation containing global contextual information in CNN-based encoders without attention modules necessitates deeper convolutional layers. The success of ViT in image analysis contributed to promising developments and innovations applicable to image segmentation in UAV remote sensing (Li and Hsu, 2022; Ghali and Akhloufi, 2023). For instance, due to significant variations of object scale, object appearance, and background clutters in remotely captured UAV images (Lyu et al., 2020), Kumar et al. (2022, 2023) designed a ViT-based encoder with a convolution-based Token Spatial Information Fusion (TSIF) module that captured the local context details about neighboring pixels. The proposed method exhibited competitive accuracy in the semantic segmentation of small-scale objects in the UAVid dataset compared with previous CNN-based methods. Zhou et al. (2022) argued that developing a practical solution that placed greater emphasis on global contextual information and the significant variation of broccoli in terms of texture, size, and shape is crucial when utilizing UAVs for broccoli detection and characterization. They adopted TransUNet (Chen et al., 2021), the first transformer-based model (Xiao et al., 2023a) built on the top of the UNet structure (Ronneberger et al., 2015), for broccoli canopy mapping. The feature encoder of TransUNet combined transformers with convolution layers to reduce the loss of low-level semantic information in the transformer and enhance the spatial details in local space. In the decode stage, a cascaded up-sampler (CUP) with multiple up-sampling steps was leveraged to generate the final mask. Similarly, Luo et al. (2023) applied TransUNet to poppy segmentation in UAV images. Experiment results demonstrated that TransUNet obtained higher segmentation accuracy with sharper boundaries and fewer false positives than the representative CNN-based UNet (Ronneberger et al., 2015) and DeepLabV3+ (Chen et al., 2018b). Inspired by TransUNet, Niu et al. (2022) designed the HSI-TransUNet for crop mapping from UAV hyperspectral imagery. Specifically, the encoder of HSI-TransUNet adopted spectral-feature attention modules for spectral feature aggregation as well as the residual Transformer layers for global contextual feature extraction. Competitive segmentation accuracies of HSI-TransUNet on the UAV-HSI-Crop dataset against TransUNet and its variants demonstrated that it was sufficient to process the characteristics of UAV HSI data, which had both very high spatial and spectral resolutions.\nViT ç”± Dosovitskiy ç­‰äººï¼ˆ2021 å¹´ï¼‰è®¾è®¡ç”¨äºå›¾åƒè¯†åˆ«ä»»åŠ¡ï¼Œé¦–å…ˆå°†å›¾åƒåˆ†å‰²æˆç­‰å¤§å°çš„å—çŠ¶ï¼Œç„¶åå°†è¿™äº›æ–‘å—å¹³å±•æˆäºŒç»´æ–‘å—åºåˆ—ï¼Œå†è¾“å…¥çº¿æ€§æŠ•å½±ä»¥è·å¾—æ–‘å—åµŒå…¥ã€‚å˜å‹å™¨ç¼–ç å™¨è´Ÿè´£æ•æ‰æµ…å±‚å›¾åƒåƒç´ ä¹‹é—´çš„å…¨å±€å…³ç³»ï¼Œå…¶è¾“å…¥æ˜¯å°†è¿™äº›è¡¥ä¸åµŒå…¥å’Œä½ç½®åµŒå…¥ä¸€èµ·è¿›è¡Œï¼ˆDosovitskiy ç­‰ï¼Œ2021ï¼‰ã€‚ç„¶è€Œï¼Œåœ¨æ— æ³¨æ„åŠ›æ¨¡å—çš„ CNN ç¼–ç å™¨ä¸­è·å¾—åŒ…å«å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç‰¹å¾è¡¨ç¤ºï¼Œéœ€è¦æ›´æ·±å±‚çš„å·ç§¯å±‚ã€‚ViT åœ¨å›¾åƒåˆ†æä¸­çš„æˆåŠŸæ¨åŠ¨äº†æ— äººæœºé¥æ„Ÿå›¾åƒåˆ†å‰²é¢†åŸŸçš„æœ‰å‰æ™¯çš„å‘å±•å’Œåˆ›æ–°ï¼ˆLi å’Œ Hsuï¼Œ2022;Ghali å’Œ Akhloufiï¼Œ2023 å¹´ï¼‰ã€‚ä¾‹å¦‚ï¼Œç”±äºè¿œç¨‹æ•æ‰æ— äººæœºå›¾åƒä¸­ç‰©ä½“æ¯”ä¾‹ã€ç‰©ä½“å¤–è§‚å’ŒèƒŒæ™¯æ‚ä¹±å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆLyu ç­‰ï¼Œ2020ï¼‰ï¼ŒKumar ç­‰äººï¼ˆ2022,2023ï¼‰è®¾è®¡äº†ä¸€ä¸ªåŸºäº ViT çš„ç¼–ç å™¨ï¼Œé‡‡ç”¨åŸºäºå·ç§¯çš„ä»¤ç‰Œç©ºé—´ä¿¡æ¯èåˆï¼ˆTSIFï¼‰æ¨¡å—ï¼Œèƒ½å¤Ÿæ•æ‰é‚»è¿‘åƒç´ çš„å±€éƒ¨ä¸Šä¸‹æ–‡ç»†èŠ‚ã€‚ä¸ä»¥å¾€åŸºäº CNN çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨ UAVid æ•°æ®é›†ä¸­å°å°ºåº¦å¯¹è±¡çš„è¯­ä¹‰åˆ†å‰²è¡¨ç°å‡ºç«äº‰åŠ›ã€‚å‘¨ç­‰äººï¼ˆ2022ï¼‰è®¤ä¸ºï¼Œå¼€å‘ä¸€ç§å®ç”¨è§£å†³æ–¹æ¡ˆï¼Œæ›´åŠ é‡è§†å…¨çƒæƒ…å¢ƒä¿¡æ¯ä»¥åŠè¥¿å…°èŠ±åœ¨è´¨åœ°ã€å¤§å°å’Œå½¢çŠ¶ä¸Šçš„æ˜¾è‘—å˜å¼‚ï¼Œå¯¹äºåˆ©ç”¨æ— äººæœºè¿›è¡Œè¥¿å…°èŠ±æ£€æµ‹å’Œç‰¹å¾åˆ†æè‡³å…³é‡è¦ã€‚ä»–ä»¬é‡‡ç”¨äº† TransUNetï¼ˆChen ç­‰ï¼Œ2021ï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºå˜å‹å™¨çš„æ¨¡å‹ï¼ˆXiao ç­‰ï¼Œ2023aï¼‰ï¼Œæ„å»ºåœ¨ UNet ç»“æ„é¡¶éƒ¨ï¼ˆRonneberger ç­‰ï¼Œ2015ï¼‰ï¼Œç”¨äºè¥¿å…°èŠ±æ ‘å† æ˜ å°„ã€‚TransUNet çš„ç‰¹å¾ç¼–ç å™¨å°†å˜æ¢å™¨ä¸å·ç§¯å±‚ç»“åˆï¼Œä»¥å‡å°‘å˜æ¢å™¨ä¸­ä½çº§åˆ«è¯­ä¹‰ä¿¡æ¯çš„ä¸¢å¤±ï¼Œå¹¶å¢å¼ºå±€éƒ¨ç©ºé—´çš„ç©ºé—´ç»†èŠ‚ã€‚åœ¨è§£ç é˜¶æ®µï¼Œé‡‡ç”¨äº†å…·æœ‰å¤šé‡ä¸Šé‡‡æ ·æ­¥éª¤çš„çº§è”ä¸Šé‡‡æ ·å™¨ï¼ˆCUPï¼‰æ¥ç”Ÿæˆæœ€ç»ˆçš„æ©æ¨¡ã€‚åŒæ ·ï¼ŒLuo ç­‰äººï¼ˆ2023ï¼‰å°† TransUNet åº”ç”¨äºæ— äººæœºå›¾åƒä¸­çš„ç½‚ç²Ÿåˆ‡ç‰‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTransUNet åœ¨å…·æœ‰ä»£è¡¨æ€§çš„åŸºäº CNN çš„ UNetï¼ˆRonneberger ç­‰ï¼Œ2015ï¼‰å’Œ DeepLabV3+ï¼ˆChen ç­‰ï¼Œ2018bï¼‰ä¸­ï¼Œåœ¨åˆ†å‰²å‡†ç¡®æ€§ä¸Šã€è¾¹ç•Œæ›´é”åˆ©ä¸”å‡é˜³æ€§æ›´å°‘ã€‚å— TransUNet å¯å‘ï¼ŒNiu ç­‰äººï¼ˆ2022 å¹´ï¼‰è®¾è®¡äº†ç”¨äºæ— äººæœºé«˜å…‰è°±å›¾åƒè£åˆ¤æ˜ å°„çš„ HSI-TransUNetã€‚å…·ä½“æ¥è¯´ï¼ŒHSI-TransUNet çš„ç¼–ç å™¨é‡‡ç”¨äº†è°±ç‰¹å¾æ³¨æ„æ¨¡å—è¿›è¡Œè°±ç‰¹å¾èšåˆï¼Œä»¥åŠå‰©ä½™çš„ Transformer å±‚ç”¨äºå…¨å±€ä¸Šä¸‹æ–‡ç‰¹å¾æå–ã€‚HSI-TransUNet åœ¨ UAV-HSI-Crop æ•°æ®é›†ä¸Šçš„åˆ’åˆ†å‡†ç¡®åº¦ä¸ TransUNet åŠå…¶å˜ä½“çš„ç«äº‰æ€§ï¼Œè¯æ˜å¤„ç†æ— äººæœº HSI æ•°æ®çš„ç‰¹æ€§è¶³ä»¥å¤„ç†ï¼Œè¿™äº›æ•°æ®å…·æœ‰æé«˜çš„ç©ºé—´å’Œå…‰è°±åˆ†è¾¨ç‡ã€‚\nAlthough TransUNet captures global semantic information about complex objects from fine-resolution UAV images, the transformer significantly increases the computational complexity as it is quadratically related to the number of tokens (Khan et al., 2022; Xiao et al., 2023a). However, in real-time urban applications using UAV platforms, prioritizing high image processing speed with light-weight models outweighs the demand for extreme accuracy (Wang et al., 2022c). Hence, Wang et al. (2022c) adopted the light-weight ResNet18 (He et al., 2016) as the encoder of the semantic segmentation network, while the decoder utilized the Global-local Transformer Block (GLTB) and the Feature Refinement Head (FRH) to capture the global context and maintain spatial details, in which the GLTB adopted the computation-friendly cross-shaped window context interaction module to capture the crosswindow relationships. Other researchers have also demonstrated that  an excellent encoder design also benefited the acquisition of semantic feature representations composed of global context information and local details for the accurate semantic segmentation of UAV images. For instance, Ding et al. (2023) proposed the IBR-Former, which consisted of two parallel crack segmentation branches, for UAV-oriented concrete crack detection and quantification. The coarse segmentation branch leveraged the Swin-Transformer (Swin-T) (Liu et al., 2021d) as the feature encoder for effectively extracting feature representations crack with different sizes and insufficient pixels, while the other crack offset generating branch aimed to fix irregularly shaped thin crack boundaries of the coarse segmentation maps. Lu et al. (2023) and Xiang et al. (2023) coincidentally adopted a dual-encoder design composed of both Transformer-based and CNN-based encoders for semantic segmentation on UAV remote sensing imagery. Both demonstrated the heterogeneous dual-encoder structure was complementary, since the transformer-based encoder established global relationships between pixels or semantic objects of the UAV image but lost local details, while the CNN-based encoder extracted spatial local features of the UAV image, such as edge details, color, texture and shape of the land covers or crops, which compensated for the loss of local information in transformers. Inspired by CBNet (Liu et al., 2020) and CBNetv2 (Liang et al., 2022), Yi et al. (2023a,b) designed UAVformer and CCSeg for urban scene segmentation and UAV visual perception. Both networks adopted a composite structure backbone composed of a main encoder and single or multiple auxiliary encoders to satisfy the semantic segmentation requirement for UAV images, which was characterized by objects at various spatial scales, complex backgrounds, and fuzzy boundaries (Lyu et al., 2020). Besides, the decoder of both networks utilized multiple down-sampling paths and up-sampling paths to integrate multi-scaled features extracted by the encoders to retain sharper boundaries of segmented objects. In contrast, Wang et al. (2023a) straightforwardly leveraged Swin-T as an encoder for the UAV semantic segmentation model, while putting more emphasis on the decoder design, which consists of four NeW FC-CRFs (Yuan et al., 2022) in series. Compared to the state-of-the-art methods, the proposed method, Swin-T-NFC CRF, obtained 0.32% and 1.41% performance gains in OA and mIoU metrics, respectively.\nå°½ç®¡ TransUNet èƒ½å¤Ÿä»ç²¾åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­æ•æ‰å¤æ‚ç‰©ä½“çš„å…¨å±€è¯­ä¹‰ä¿¡æ¯ï¼Œä½†ç”±äºå˜æ¢å™¨ä¸ä»¤ç‰Œæ•°é‡æˆäºŒæ¬¡æ–¹ç›¸å…³ï¼Œè®¡ç®—å¤æ‚åº¦æ˜¾è‘—å¢åŠ ï¼ˆKhan ç­‰ï¼Œ2022;Xiao ç­‰ï¼Œ2023aï¼‰ã€‚ç„¶è€Œï¼Œåœ¨ä½¿ç”¨æ— äººæœºå¹³å°çš„å®æ—¶åŸå¸‚åº”ç”¨ä¸­ï¼Œä¼˜å…ˆè€ƒè™‘è½»é‡åŒ–æ¨¡å‹çš„é«˜å›¾åƒå¤„ç†é€Ÿåº¦ï¼Œè¶…è¿‡äº†å¯¹æé«˜ç²¾åº¦çš„éœ€æ±‚ï¼ˆWang ç­‰ï¼Œ2022cï¼‰ã€‚å› æ­¤ï¼ŒWang ç­‰äººï¼ˆ2022cï¼‰é‡‡ç”¨äº†è½»é‡çº§çš„ ResNet18ï¼ˆHe ç­‰ï¼Œ2016ï¼‰ä½œä¸ºè¯­ä¹‰åˆ†å‰²ç½‘ç»œçš„ç¼–ç å™¨ï¼Œè€Œè§£ç å™¨åˆ™åˆ©ç”¨å…¨å±€ - å±€éƒ¨å˜æ¢å™¨å—ï¼ˆGLTBï¼‰å’Œç‰¹å¾ç»†åŒ–å¤´ï¼ˆFRHï¼‰æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å¹¶ç»´æŠ¤ç©ºé—´ç»†èŠ‚ï¼Œè€Œ GLTB é‡‡ç”¨äº†è®¡ç®—å‹å¥½çš„äº¤å‰å½¢çŠ¶çª—å£ä¸Šä¸‹æ–‡äº¤äº’æ¨¡å—æ¥æ•æ‰è·¨çª—å£å…³ç³»ã€‚å…¶ä»–ç ”ç©¶è€…è¿˜è¯æ˜ï¼Œä¼˜ç§€çš„ç¼–ç å™¨è®¾è®¡ä¹Ÿæœ‰åŠ©äºè·å–ç”±å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå±€éƒ¨ç»†èŠ‚ç»„æˆçš„è¯­ä¹‰ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œå®ç°æ— äººæœºå›¾åƒçš„å‡†ç¡®è¯­ä¹‰åˆ†å‰²ã€‚ä¾‹å¦‚ï¼Œä¸ç­‰äººï¼ˆ2023ï¼‰æå‡ºäº† IBR-Formerï¼Œç”±ä¸¤æ¡å¹³è¡Œçš„è£‚çº¹åˆ†å‰²åˆ†æ”¯ç»„æˆï¼Œç”¨äºæ— äººæœºå¯¼å‘æ··å‡åœŸè£‚çº¹çš„æ£€æµ‹å’Œé‡åŒ–ã€‚ç²—åˆ†å‰²åˆ†æ”¯åˆ©ç”¨ Swin-Transformerï¼ˆSwin-Tï¼‰ï¼ˆLiu ç­‰ï¼Œ2021dï¼‰ä½œä¸ºç‰¹å¾ç¼–ç å™¨ï¼Œæœ‰æ•ˆæå–ä¸åŒå¤§å°å’Œåƒç´ ä¸è¶³çš„ç‰¹å¾è£‚çº¹ï¼Œè€Œå¦ä¸€åˆ†æ”¯åˆ™æ—¨åœ¨å›ºå®šç²—åˆ†å‰²å›¾ä¸­å½¢çŠ¶ä¸è§„åˆ™çš„è–„è£‚çº¹è¾¹ç•Œã€‚Lu ç­‰äººï¼ˆ2023ï¼‰å’Œ Xiang ç­‰äººï¼ˆ2023ï¼‰å·§åˆåœ°é‡‡ç”¨äº†ä¸€ç§åŒç¼–ç å™¨è®¾è®¡ï¼Œç»“åˆåŸºäº Transformer å’ŒåŸºäº CNN çš„ç¼–ç å™¨ï¼Œç”¨äºæ— äººæœºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ã€‚ä¸¤è€…éƒ½è¯æ˜äº†å¼‚æ„åŒç¼–ç å™¨ç»“æ„æ˜¯äº’è¡¥çš„ï¼Œå› ä¸ºåŸºäºå˜å‹å™¨çš„ç¼–ç å™¨å»ºç«‹äº†æ— äººæœºå›¾åƒåƒç´ æˆ–è¯­ä¹‰å¯¹è±¡ä¹‹é—´çš„å…¨å±€å…³ç³»ï¼Œä½†ä¼šä¸¢å¤±å±€éƒ¨ç»†èŠ‚ï¼›è€ŒåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„ç¼–ç å™¨åˆ™æå–æ— äººæœºå›¾åƒçš„ç©ºé—´å±€éƒ¨ç‰¹å¾ï¼Œå¦‚è¾¹ç¼˜ç»†èŠ‚ã€é¢œè‰²ã€çº¹ç†å’ŒåœŸåœ°è¦†ç›–æˆ–ä½œç‰©çš„å½¢çŠ¶ï¼Œä»è€Œè¡¥å¿å˜å‹å™¨ä¸­å±€éƒ¨ä¿¡æ¯çš„ä¸¢å¤±ã€‚å— CBNetï¼ˆLiu ç­‰ï¼Œ2020ï¼‰å’Œ CBNetv2ï¼ˆLiang ç­‰ï¼Œ2022ï¼‰å¯å‘ï¼ŒYi ç­‰ï¼ˆ2023aï¼Œbï¼‰è®¾è®¡äº† UAVformer å’Œ CCSegï¼Œç”¨äºåŸå¸‚åœºæ™¯åˆ†å‰²å’Œæ— äººæœºè§†è§‰æ„ŸçŸ¥ã€‚ä¸¤ä¸ªç½‘ç»œéƒ½é‡‡ç”¨äº†ç”±ä¸»ç¼–ç å™¨å’Œå•ä¸ªæˆ–å¤šä¸ªè¾…åŠ©ç¼–ç å™¨ç»„æˆçš„å¤åˆç»“æ„éª¨å¹²ï¼Œä»¥æ»¡è¶³æ— äººæœºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²éœ€æ±‚ï¼Œè¯¥å›¾åƒçš„ç‰¹å¾åŒ…æ‹¬ä¸åŒç©ºé—´å°ºåº¦ã€å¤æ‚èƒŒæ™¯å’Œæ¨¡ç³Šè¾¹ç•Œçš„å¯¹è±¡ï¼ˆLyu ç­‰ï¼Œ2020ï¼‰ã€‚æ­¤å¤–ï¼Œä¸¤ä¸ªç½‘ç»œçš„è§£ç å™¨éƒ½é‡‡ç”¨å¤šæ¡ä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·è·¯å¾„ï¼Œæ•´åˆç¼–ç å™¨æå–çš„å¤šå°ºåº¦ç‰¹å¾ï¼Œä»¥ä¿æŒæ›´æ¸…æ™°çš„åˆ†æ®µå¯¹è±¡è¾¹ç•Œã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒWang ç­‰äººï¼ˆ2023aï¼‰ç›´æ¥åˆ©ç”¨ Swin-T ä½œä¸ºæ— äººæœºè¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„ç¼–ç å™¨ï¼ŒåŒæ—¶æ›´å¼ºè°ƒè§£ç å™¨è®¾è®¡ï¼Œè¯¥è®¾è®¡ç”±å››ä¸ªä¸²è”çš„ NeW FC-CRFï¼ˆYuan ç­‰ï¼Œ2022ï¼‰ç»„æˆã€‚ä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€ææ–¹æ³• Swin-T-NFC CRF åœ¨ OA å’Œ mIoU æŒ‡æ ‡ä¸Šåˆ†åˆ«è·å¾—äº† 0.32% å’Œ 1.41% çš„æ€§èƒ½æå‡ã€‚\nSeveral comparative studies were conducted to verify the semantic segmentation models combined with transformers outperformed the CNN-based method in terms of accuracy and generalization on RGBbased UAV imagery. For instance, Ghali et al. (2021, 2022) explored the potential of transformers for wildfire segmentation using ground and aerial imagery. Compared with CNN-based segmentation methods, Transformer-based methods, such as TransUNet (Chen et al., 2021), TransFire (Ghali et al., 2021), and MedT (Ghali et al., 2022), presented more excellent performance for localizing and segmenting forest fire pixels as well as small fire regions due to their ability to determine long-range dependencies and extract fine-grained details within input features. Gibril et al. (2023) evaluated the generalizability and the transferability of deep vision transformers and CNN-based semantic segmentation models for accurate mapping of date palm trees from very-high spatial resolution UAV-based and aerial images. The segmentation performance of the Segformer (Xie et al., 2021a) and the UperNet-Swin outperformed that of previous date palm tree mapping from UAV images, which demonstrated their superiority in processing UAV images with limited spectral information, high intra-class variance, variations in the spatial resolutions, and differences in image contexts and backgrounds. Wang and Mahmoudian (2023) permuted five encoder backbones and three decoder structures to construct multiple semantic segmentation methods for aerial fluvial images. Comparative results concluded that the semantic segmentation models utilizing the transformer as the encoder presented better generalization performance than CNNs as the encoder. Similar conclusions can also be found in the study conducted by Asad et al. (2023) on whether Transformers can be applied to natural disaster assessment in high-resolution UAV imagery.\nè¿›è¡Œäº†å¤šé¡¹æ¯”è¾ƒç ”ç©¶ï¼Œä»¥éªŒè¯è¯­ä¹‰åˆ†å‰²æ¨¡å‹ç»“åˆå˜æ¢å™¨åœ¨åŸºäº RGB çš„æ— äººæœºå›¾åƒä¸­ï¼Œå‡†ç¡®æ€§å’Œæ³›åŒ–æ€§ä¼˜äºåŸºäº CNN çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼ŒGhali ç­‰äººï¼ˆ2021,2022ï¼‰æ¢ç´¢äº†åˆ©ç”¨åœ°é¢å’Œèˆªæ‹å½±åƒåœ¨é‡ç«åˆ†å‰²ä¸­çš„å˜å‹å™¨æ½œåŠ›ã€‚ä¸åŸºäº CNN çš„åˆ†å‰²æ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäº Transformer çš„æ–¹æ³•ï¼Œå¦‚ TransUNetï¼ˆChen ç­‰ï¼Œ2021ï¼‰ã€TransFireï¼ˆGhali ç­‰ï¼Œ2021ï¼‰å’Œ MedTï¼ˆGhali ç­‰ï¼Œ2022ï¼‰ï¼Œåœ¨å®šä½å’Œåˆ†å‰²æ£®æ—ç«ç¾åƒç´ ä»¥åŠå°ç«ç¾åŒºåŸŸæ–¹é¢è¡¨ç°æ›´ä½³ï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿç¡®å®šè¿œè·ç¦»ä¾èµ–å…³ç³»å¹¶æå–è¾“å…¥ç‰¹å¾ä¸­çš„ç»†ç²’åº¦ç»†èŠ‚ã€‚Gibrinl ç­‰äººï¼ˆ2023ï¼‰è¯„ä¼°äº†æ·±è§†å˜æ¢å™¨å’ŒåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹åœ¨é«˜ç©ºé—´åˆ†è¾¨ç‡æ— äººæœºå’Œèˆªæ‹å›¾åƒä¸­æ£æ¤°æ ‘å‡†ç¡®å®šä½çš„æ™®éæ€§å’Œå¯è¿ç§»æ€§ã€‚Segformerï¼ˆXie ç­‰ï¼Œ2021aï¼‰å’Œ UperNet-Swin çš„åˆ†å‰²æ€§èƒ½ä¼˜äºä»¥å¾€æ— äººæœºå›¾åƒçš„æ£æ¤°æ ‘æ˜ å°„ï¼Œåè€…å±•ç¤ºäº†å®ƒä»¬åœ¨å¤„ç†å…‰è°±ä¿¡æ¯æœ‰é™ã€ç±»å†…æ–¹å·®å¤§ã€ç©ºé—´åˆ†è¾¨ç‡å·®å¼‚ä»¥åŠå›¾åƒä¸Šä¸‹æ–‡å’ŒèƒŒæ™¯å·®å¼‚çš„æ— äººæœºå›¾åƒæ–¹é¢çš„ä¼˜åŠ¿ã€‚Wang å’Œ Mahmoudianï¼ˆ2023ï¼‰å¯¹äº”ä¸ªç¼–ç ä¸»é“¾å’Œä¸‰ä¸ªè§£ç ç»“æ„è¿›è¡Œäº†ç½®æ¢ï¼Œæ„å»ºäº†å¤šé‡èˆªæ‹æ²³æµå›¾åƒçš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•ã€‚æ¯”è¾ƒç»“æœå¾—å‡ºç»“è®ºï¼Œä½¿ç”¨å˜æ¢å™¨ä½œä¸ºç¼–ç å™¨çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼Œå…¶æ³›åŒ–æ€§èƒ½ä¼˜äºä½œä¸ºç¼–ç å™¨çš„ CNNã€‚ç±»ä¼¼ç»“è®ºä¹Ÿå‡ºç°åœ¨ Asad ç­‰äººï¼ˆ2023 å¹´ï¼‰å…³äºå˜å‹å™¨æ˜¯å¦å¯åº”ç”¨äºé«˜åˆ†è¾¨ç‡æ— äººæœºå½±åƒè‡ªç„¶ç¾å®³è¯„ä¼°çš„ç ”ç©¶ä¸­ã€‚\nHowever, Zefri et al. (2023) discovered that the semantic segmentation training process of TransUNet exhibited more instability and slower convergence than that of CNN-based models on thermal image data collected by UAVs for photovoltaic array inspections. They argued that recent advanced models had been evaluated using multiclass RGB datasets, whose strength could not be directly highlighted or demonstrated in restricted and domain-specific tasks. It is justifiable as most ViTs trained on a new medium-range dataset would not give competitive results (Khan et al., 2022; Xiao et al., 2023a). Many Transformer-based models require very large-scale data to learn prior knowledge about the images, also called inductive biases, such as translation equivariance and spatial invariance (Khan et al., 2022; Xiao et al., 2023a).\nç„¶è€Œï¼ŒZefri ç­‰äººï¼ˆ2023ï¼‰å‘ç°ï¼Œåœ¨æ— äººæœºæ”¶é›†çš„ç”¨äºå…‰ä¼é˜µåˆ—æ£€æŸ¥çš„çƒ­åƒæ•°æ®ä¸Šï¼ŒTransUNet çš„è¯­ä¹‰åˆ†å‰²è®­ç»ƒè¿‡ç¨‹æ¯”åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„æ¨¡å‹è¡¨ç°å‡ºæ›´ä¸ç¨³å®šä¸”æ”¶æ•›æ›´æ…¢ã€‚ä»–ä»¬è®¤ä¸ºï¼Œè¿‘æœŸçš„é«˜çº§æ¨¡å‹éƒ½æ˜¯ä½¿ç”¨å¤šç±» RGB æ•°æ®é›†è¿›è¡Œè¯„ä¼°çš„ï¼Œåœ¨å—é™ä¸”ç‰¹å®šé¢†åŸŸçš„ä»»åŠ¡ä¸­ï¼Œè¿™äº›æ¨¡å‹çš„ä¼˜ç‚¹æ— æ³•ç›´æ¥å‡¸æ˜¾æˆ–å±•ç¤ºå‡ºæ¥ã€‚è¿™æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºå¤§å¤šæ•°åœ¨æ–°çš„ä¸­è·ç¦»æ•°æ®é›†ä¸Šè®­ç»ƒçš„è§†è§‰å˜æ¢å™¨ï¼ˆViTsï¼‰éƒ½æ— æ³•ç»™å‡ºå…·æœ‰ç«äº‰åŠ›çš„ç»“æœï¼ˆKhan ç­‰äººï¼Œ2022 å¹´ï¼›Xiao ç­‰äººï¼Œ2023aï¼‰ã€‚è®¸å¤šåŸºäº Transformer çš„æ¨¡å‹éœ€è¦éå¸¸å¤§è§„æ¨¡çš„æ•°æ®æ¥å­¦ä¹ å›¾åƒçš„å…ˆéªŒçŸ¥è¯†ï¼Œä¹Ÿç§°ä¸ºå½’çº³åç½®ï¼Œå¦‚å¹³ç§»ç­‰å˜æ€§å’Œç©ºé—´ä¸å˜æ€§ï¼ˆKhan ç­‰äººï¼Œ2022 å¹´ï¼›Xiao ç­‰äººï¼Œ2023aï¼‰ã€‚\n# Light-weight methods\nè½»é‡åŒ–æ–¹æ³•\nAlthough most semantic segmentation tasks for UAV remote sensing images, such as ecological monitoring, urban scene, and agricultural management, can benefit from efficient feature extraction based on DL methods, these methods are computationally intensive and require professional GPU servers for back-end image processing. A large amount of computation, memory overhead, and computational power consumption also curb the application of the recently feature-learning-based algorithms on embedding UAV platforms. Therefore, it is essential to carry out edge computing and light-weight artificial intelligence technologies so that the UAVs themselves can capture images and extract contextual information, thereby providing UAVs with autonomous perceptual capabilities of the surrounding environment. There are two concurrent research directions in this area: one is to develop more lightweight algorithms suitable for embedding platforms, while the other is to design or utilize parallel vector processors, such as Tensor Processing Unit (TPU) and Neural Processing Unit (NPU). In this section, we will focus on exploring light-weight algorithms for semantic segmentation on UAVs.\nè™½ç„¶å¤§å¤šæ•°æ— äººæœºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼Œå¦‚ç”Ÿæ€ç›‘æµ‹ã€åŸå¸‚æ™¯è§‚å’Œå†œä¸šç®¡ç†ï¼Œéƒ½å¯ä»¥é€šè¿‡åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„é«˜æ•ˆç‰¹å¾æå–å—ç›Šï¼Œä½†è¿™äº›æ–¹æ³•è®¡ç®—é‡å¤§ï¼Œéœ€è¦ä¸“ä¸š GPU æœåŠ¡å™¨è¿›è¡Œåç«¯å›¾åƒå¤„ç†ã€‚å¤§é‡çš„è®¡ç®—é‡ã€å†…å­˜å¼€é”€å’Œè®¡ç®—åŠŸè€—ä¹Ÿé™åˆ¶äº†è¿‘æœŸåŸºäºç‰¹å¾å­¦ä¹ çš„ç®—æ³•åœ¨åµŒå…¥æ— äººæœºå¹³å°ä¸Šçš„åº”ç”¨ã€‚å› æ­¤ï¼Œå¿…é¡»å¼€å±•è¾¹ç¼˜è®¡ç®—å’Œè½»é‡åŒ–äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œä½¿æ— äººæœºèƒ½å¤Ÿæ•æ‰å›¾åƒå¹¶æå–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œèµ‹äºˆæ— äººæœºå¯¹å‘¨å›´ç¯å¢ƒçš„è‡ªä¸»æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥é¢†åŸŸæœ‰ä¸¤ä¸ªå¹¶è¡Œçš„ç ”ç©¶æ–¹å‘ï¼šä¸€æ˜¯å¼€å‘æ›´è½»é‡åŒ–çš„åµŒå…¥å¹³å°ç®—æ³•ï¼ŒäºŒæ˜¯è®¾è®¡æˆ–åˆ©ç”¨å¹¶è¡Œå‘é‡å¤„ç†å™¨ï¼Œå¦‚å¼ é‡å¤„ç†å•å…ƒï¼ˆTPUï¼‰å’Œç¥ç»å¤„ç†å•å…ƒï¼ˆNPUï¼‰ã€‚æœ¬èŠ‚å°†é‡ç‚¹æ¢è®¨æ— äººæœºè¯­ä¹‰åˆ†å‰²çš„è½»é‡çº§ç®—æ³•ã€‚\nThe light-weight methods of DL-based models can be divided into 6 groups: tensor decomposition (Jaderberg et al., 2014; Szegedy et al., 2016), low-precision quantization (Gholami et al., 2021), model pruning (Cheng et al., 2017), knowledge distillation (KD) (Hinton et al., 2015), neural architecture search (NAS) (Elsken et al., 2019), and efficient structures of light-weight networks (Howard et al., 2017; Tan and Le, 2019). Tensor decomposition aims to represent a high-dimensional tensor as the product of low-dimensional tensors, which can reduce the memory overhead of models and enable faster convolution with fewer and cheaper operations (Lebedev and Lempitsky, 2018). The lowprecision quantization method converts 32-bit floats into 16-bit floats or 8-bit integers. For instance, most processors allow faster processing for addition and multiplication operations of 8-bit integers, which means the light-weight CNNs after 8-bit quantization can be 4 times more efficient than 32-bit CNNs (Krishnamoorthi, 2018). NAS aims to automatically design and search efficient network structures beyond human experiences based on observation data. However, NAS on the large-scale datasets of UAV remote sensing imagery requires unaffordable computational resources for most researchers. Unfortunately, few recent literature found that the aforementioned light-weight methods are utilized in the research in the context of semantic segmentation of UAV remote sensing images due to limited expertise, repetitive fine-tuning, and restricted hardware resources.\nåŸºäº DL æ¨¡å‹çš„è½»é‡çº§æ–¹æ³•å¯åˆ†ä¸º 6 ç±»ï¼šå¼ é‡åˆ†è§£ï¼ˆJaderberg ç­‰ï¼Œ2014;Szegedy ç­‰ï¼Œ2016ï¼‰ã€ä½ç²¾åº¦é‡åŒ–ï¼ˆGholami ç­‰ï¼Œ2021ï¼‰ã€æ¨¡å‹å‰ªæï¼ˆCheng ç­‰ï¼Œ2017ï¼‰ã€çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰ï¼ˆHinton ç­‰ï¼Œ2015ï¼‰ã€ç¥ç»ç»“æ„æœç´¢ï¼ˆNASï¼‰ï¼ˆElsken ç­‰ï¼Œ2019ï¼‰ä»¥åŠè½»é‡çº§ç½‘ç»œçš„é«˜æ•ˆç»“æ„ï¼ˆHoward ç­‰ï¼Œ2017; è°­å’Œé»ï¼Œ2019ï¼‰ã€‚å¼ é‡åˆ†è§£æ—¨åœ¨å°†é«˜ç»´å¼ é‡è¡¨ç¤ºä¸ºä½ç»´å¼ é‡çš„ä¹˜ç§¯ï¼Œè¿™å¯ä»¥é™ä½æ¨¡å‹çš„å†…å­˜å¼€é”€ï¼Œå¹¶ä»¥æ›´å°‘ä¸”æ›´ä¾¿å®œçš„ä½œå®ç°æ›´å¿«çš„å·ç§¯ï¼ˆLebedev å’Œ Lempitskyï¼Œ2018ï¼‰ã€‚ä½ç²¾åº¦é‡åŒ–æ–¹æ³•å°† 32 ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º 16 ä½æµ®ç‚¹æˆ– 8 ä½æ•´æ•°ã€‚ä¾‹å¦‚ï¼Œå¤§å¤šæ•°å¤„ç†å™¨æ”¯æŒæ›´å¿«çš„ 8 ä½æ•´æ•°åŠ æ³•å’Œä¹˜æ³•å¤„ç†ï¼Œè¿™æ„å‘³ç€ 8 ä½é‡åŒ–åçš„è½»é‡çº§å·ç§¯ç¥ç»ç½‘ç»œæ•ˆç‡å¯æ˜¯ 32 ä½å·ç§¯ç¥ç»ç½‘ç»œçš„ 4 å€ï¼ˆKrishnamoorthiï¼Œ2018ï¼‰ã€‚NAS æ—¨åœ¨åŸºäºè§‚å¯Ÿæ•°æ®è‡ªåŠ¨è®¾è®¡å’Œæœç´¢è¶…è¶Šäººç±»ç»éªŒçš„é«˜æ•ˆç½‘ç»œç»“æ„ã€‚ç„¶è€Œï¼ŒNAS ç”¨äºå¤§è§„æ¨¡æ— äººæœºé¥æ„Ÿå›¾åƒæ•°æ®é›†ï¼Œå¯¹å¤§å¤šæ•°ç ”ç©¶äººå‘˜æ¥è¯´éœ€è¦è´Ÿæ‹…å¾—èµ·çš„è®¡ç®—èµ„æºã€‚é—æ†¾çš„æ˜¯ï¼Œç”±äºä¸“ä¸šçŸ¥è¯†æœ‰é™ã€é‡å¤å¾®è°ƒå’Œç¡¬ä»¶èµ„æºæœ‰é™ï¼Œè¿‘æœŸæ–‡çŒ®å¾ˆå°‘å‘ç°ä¸Šè¿°è½»é‡åŒ–æ–¹æ³•åœ¨æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ç ”ç©¶ä¸­è¢«å¹¿æ³›åº”ç”¨ã€‚\nModel pruning is one of the model compression methods that remove network branches or connection nodes that have low impacts on model performance, facilitating the deployment of deep networks to resource-constrained devices. To address the challenge of real-time scene parsing on UAV platforms, Zhang et al. (2019c) proposed slimYOLOv3, a narrow yet faster deep object detector by pruning less important feature channels of YOLOv3 (Redmon and Farhadi, 2018). The number of parameters and the amount of floating-point operations (FLOPS) of slimYOLOv3 were less than one-tenth of the original YOLOv3. However, it achieved about 2 times faster inference efficiency  and comparable detection accuracy to the YOLOv3. In addition, knowledge distillation (KD), as proposed by Hinton et al. (2015), is also one of the efficient methods for model compression. The knowledge distillation follows the fundamental rules that small models (students) can be trained by the output probability distribution or feature space distribution of large models (teachers). Recent studies had demonstrated the efficiency of knowledge distillation for object detection and action recognition in UAV remote sensing images (Liu et al., 2021a) or videos (Ding et al., 2020). To accommodate the need of embedded intelligence on UAVs, Wang et al. (2021b) proposed a real-time forest fire monitoring model on the top of YOLOv4 (Bochkovskiy et al., 2020) by combining model pruning and knowledge distillation. Specifically, they utilized channel-level sparsity-induced regularization to eliminate redundant feature channels and applied the knowledge distillation algorithm to enhance the detection accuracy of the pruned model. The light-weight model with pruning and KD fell to only 2.64M parameters, a reduction of 95.87% compared to the original model. The inference time was 4.11 times faster, while the mean average precision (mAP) is 3.9% lower than that of the original YOLOv4.\næ¨¡å‹å‰ªææ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©æ–¹æ³•ï¼Œç”¨äºå»é™¤å¯¹æ¨¡å‹æ€§èƒ½å½±å“è¾ƒå°çš„ç½‘ç»œåˆ†æ”¯æˆ–è¿æ¥èŠ‚ç‚¹ï¼Œä¾¿äºå°†æ·±åº¦ç½‘ç»œéƒ¨ç½²åˆ°èµ„æºå—é™çš„è®¾å¤‡ä¸Šã€‚ä¸ºè§£å†³æ— äººæœºå¹³å°ä¸Šå®æ—¶åœºæ™¯è§£æçš„æŒ‘æˆ˜ï¼ŒZhang ç­‰äººï¼ˆ2019cï¼‰æå‡ºäº† slimYOLOv3ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ä¿®å‰ª YOLOv3 ä¸­è¾ƒä¸é‡è¦çš„ç‰¹å¾é€šé“ï¼Œå®ç°ç‹­çª„ä½†æ›´å¿«çš„æ·±å±‚ç‰©ä½“æ¢æµ‹å™¨ï¼ˆRedmon å’Œ Farhadiï¼Œ2018ï¼‰ã€‚slimYOLOv3 çš„å‚æ•°æ•°é‡å’Œæµ®ç‚¹è¿ç®—ï¼ˆFLOPSï¼‰æ•°é‡ä¸åˆ°åŸå§‹ YOLOv3 çš„ååˆ†ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œå®ƒçš„æ¨æ–­æ•ˆç‡çº¦æ˜¯ YOLOv3 çš„ä¸¤å€ï¼Œæ£€æµ‹ç²¾åº¦ç›¸å½“ã€‚æ­¤å¤–ï¼ŒHinton ç­‰äººï¼ˆ2015ï¼‰æå‡ºçš„çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰ä¹Ÿæ˜¯æ¨¡å‹å‹ç¼©çš„é«˜æ•ˆæ–¹æ³•ä¹‹ä¸€ã€‚çŸ¥è¯†æç‚¼éµå¾ªåŸºæœ¬è§„åˆ™ï¼š== å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰å¯ä»¥é€šè¿‡å¤§å‹æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰çš„è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒæˆ–ç‰¹å¾ç©ºé—´åˆ†å¸ƒæ¥è®­ç»ƒã€‚== è¿‘æœŸç ”ç©¶å·²è¯æ˜ï¼Œåœ¨æ— äººæœºé¥æ„Ÿå›¾åƒï¼ˆLiu ç­‰ï¼Œ2021aï¼‰æˆ–è§†é¢‘ï¼ˆDing ç­‰ï¼Œ2020ï¼‰ä¸­ï¼ŒçŸ¥è¯†è’¸é¦åœ¨ç‰©ä½“æ£€æµ‹å’ŒåŠ¨ä½œè¯†åˆ«ä¸­çš„é«˜æ•ˆæ€§ã€‚ä¸ºæ»¡è¶³æ— äººæœºåµŒå…¥å¼æ™ºèƒ½çš„éœ€æ±‚ï¼Œ==Wang ç­‰ï¼ˆ2021bï¼‰æå‡ºäº†åŸºäº YOLOv4 çš„å®æ—¶æ£®æ—ç«ç¾ç›‘æµ‹æ¨¡å‹ï¼ˆBochkovskiy ç­‰ï¼Œ2020ï¼‰ï¼Œç»“åˆæ¨¡å‹ä¿®å‰ªä¸çŸ¥è¯†è’¸é¦ã€‚== å…·ä½“æ¥è¯´ï¼Œä»–ä»¬åˆ©ç”¨é€šé“çº§ç¨€ç–è¯±å¯¼çš„æ­£åˆ™åŒ–æ¶ˆé™¤äº†å†—ä½™ç‰¹å¾é€šé“ï¼Œå¹¶åº”ç”¨çŸ¥è¯†è’¸é¦ç®—æ³•æå‡äº†ä¿®å‰ªæ¨¡å‹çš„æ£€æµ‹å‡†ç¡®ç‡ã€‚è½»é‡æ¨¡å‹åŠ ä¿®å‰ªå’Œ KD åå‚æ•°é™è‡³ä»… 264 ä¸‡ï¼Œæ¯”åŸå§‹æ¨¡å‹å‡å°‘äº† 95.87%ã€‚æ¨æ–­æ—¶é—´å¿«äº† 4.11 å€ï¼Œå¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰æ¯”åŸå§‹ YOLOv4 ä½äº† 3.9%ã€‚\nThe design of efficient structures for light-weight networks is another commonly used technique for real-time semantic segmentation (Yu et al., 2018a; Orsic et al., 2019; Wang et al., 2020d; Gao et al., 2021a). The light-weight models designed following this paradigm are highly flexible and editable, as researchers can reduce the width, depth, and interlayer connections of the light-weight models according to the practical demands. Hence, the design of efficient structures can dynamically balance the computational complexity, number of parameters, computational power consumption, and model accuracy. Nguyen et al. (2019) designed MAVNet, a small but efficient light-weight network, for semantic segmentation on micro aerial vehicles (MAV) based on dilated convolution and depth-wise feature aggregation block (DWFab). Zuo et al. (2021) introduced BiSeNet (Yu et al., 2018a), a bilateral light-weight semantic segmentation network, to carry out the realtime aerial video semantic segmentation of UAV streetscape sequences. Both of their experiments were sufficient to demonstrate that efficient structures of light-weight networks achieve not only a good tradeoff between inference time, model size, and model accuracy, but also the rapid deployment without post-processing of the trained models. In addition, the combination of light-weight methods and efficient attention mechanisms enabled networks with limited parameters to capture more contextual information. Gao et al. (2021a) explored an asymmetric encoderâ€“decoder network composed of factorization depthwise and dilation convolution using the multi-scale context fusion scheme and multiple efficient attention branches. Pang et al. (2022) also proposed the Semantics Guided Bottleneck Network (SGBNet) based on BiSeNet and the Channel Pooled Attention (CPA) mechanism to balance segmentation accuracy, model size, and inference speed on the Land Cover Dataset. These models utilized semantic enhancement modules with small parameters increment to preserve the spatial presentation with more details and enhanced the contextual relationships and generalization performance of light-weight models.\nä¸ºè½»é‡çº§ç½‘ç»œè®¾è®¡é«˜æ•ˆç»“æ„æ˜¯å¦ä¸€ç§å¸¸ç”¨çš„å®æ—¶è¯­ä¹‰åˆ†å‰²æŠ€æœ¯ï¼ˆYu ç­‰ï¼Œ2018a;Orsic ç­‰ï¼Œ2019;Wang ç­‰ï¼Œ2020d;Gao ç­‰ï¼Œ2021aï¼‰ã€‚æŒ‰ç…§è¿™ä¸€èŒƒå¼è®¾è®¡çš„è½»é‡çº§æ¨¡å‹é«˜åº¦çµæ´»ä¸”å¯ç¼–è¾‘ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚ç¼©å°è½»é‡çº§æ¨¡å‹çš„å®½åº¦ã€æ·±åº¦å’Œå±‚é—´è¿æ¥ã€‚å› æ­¤ï¼Œé«˜æ•ˆç»“æ„çš„è®¾è®¡èƒ½å¤ŸåŠ¨æ€å¹³è¡¡è®¡ç®—å¤æ‚åº¦ã€å‚æ•°æ•°é‡ã€è®¡ç®—åŠŸè€—å’Œæ¨¡å‹å‡†ç¡®æ€§ã€‚Nguyen ç­‰äººï¼ˆ2019ï¼‰è®¾è®¡äº† MAVNetï¼Œè¿™æ˜¯ä¸€ä¸ªå°å·§ä½†é«˜æ•ˆçš„è½»é‡çº§ç½‘ç»œï¼Œç”¨äºå¾®å‹èˆªç©ºè½½å…·ï¼ˆMAVï¼‰è¯­ä¹‰åˆ†å‰²ï¼ŒåŸºäºè†¨èƒ€å·ç§¯å’Œæ·±åº¦ç‰¹å¾èšåˆå—ï¼ˆDWFabï¼‰ã€‚Zuo ç­‰ï¼ˆ2021ï¼‰å¼•å…¥äº† BiSeNetï¼ˆYu ç­‰ï¼Œ2018aï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŒè¾¹è½»é‡çº§è¯­ä¹‰åˆ†å‰²ç½‘ç»œï¼Œç”¨äºå®ç°æ— äººæœºè¡—æ™¯åºåˆ—çš„å®æ—¶èˆªæ‹è§†é¢‘è¯­ä¹‰åˆ†å‰²ã€‚== ä»–ä»¬çš„ä¸¤ä¸ªå®éªŒéƒ½è¶³ä»¥è¯æ˜ï¼Œé«˜æ•ˆçš„è½»é‡çº§ç½‘ç»œç»“æ„ä¸ä»…åœ¨æ¨ç†æ—¶é—´ã€æ¨¡å‹è§„æ¨¡å’Œæ¨¡å‹å‡†ç¡®æ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½æƒè¡¡ï¼Œè¿˜èƒ½åœ¨æ— éœ€åå¤„ç†çš„æƒ…å†µä¸‹å¿«é€Ÿéƒ¨ç½²è®­ç»ƒæ¨¡å‹ã€‚== æ­¤å¤–ï¼Œè½»é‡åŒ–æ–¹æ³•å’Œé«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶ç›¸ç»“åˆï¼Œä½¿å‚æ•°æœ‰é™çš„ç½‘ç»œèƒ½å¤Ÿæ•æ‰æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚Gao ç­‰ï¼ˆ2021aï¼‰åˆ©ç”¨å¤šå°ºåº¦ä¸Šä¸‹æ–‡èåˆæ–¹æ¡ˆå’Œå¤šé«˜æ•ˆæ³¨æ„åŠ›åˆ†æ”¯ï¼Œæ¢ç´¢äº†ç”±æ·±åº¦åˆ†è§£å’Œè†¨èƒ€å·ç§¯ç»„æˆçš„éå¯¹ç§°ç¼–ç å™¨ - è§£ç å™¨ç½‘ç»œã€‚Pang ç­‰äººï¼ˆ2022ï¼‰è¿˜æå‡ºäº†åŸºäº BiSeNet å’Œé€šé“é›†ä¸­æ³¨æ„åŠ›ï¼ˆCPAï¼‰æœºåˆ¶çš„è¯­ä¹‰å¼•å¯¼ç“¶é¢ˆç½‘ç»œï¼ˆSGBNetï¼‰ï¼Œä»¥å¹³è¡¡åœŸåœ°è¦†ç›–æ•°æ®é›†ä¸Šçš„åˆ‡åˆ†å‡†ç¡®æ€§ã€æ¨¡å‹è§„æ¨¡å’Œæ¨æ–­é€Ÿåº¦ã€‚è¿™äº›æ¨¡å‹ä½¿ç”¨äº†å‚æ•°å¢é‡è¾ƒå°çš„è¯­ä¹‰å¢å¼ºæ¨¡å—ï¼Œä»¥æ›´è¯¦ç»†çš„ç©ºé—´å‘ˆç°æ–¹å¼ä¿æŒç©ºé—´è¡¨ç°ï¼Œå¹¶æå‡äº†è½»é‡çº§æ¨¡å‹çš„ä¸Šä¸‹æ–‡å…³ç³»å’Œæ³›åŒ–æ€§èƒ½ã€‚\nHere we have described light-weight semantic segmentation methods in the context of UAVs, which is still a young research area awaiting in-depth explorations, with minimal published papers in this field. The design of efficient network structures seems to be the most practical approach in current literature compared to tensor decomposition, low-precision quantization, and NAS, for it does not require complex fine-tunings and post processes for model deployment on UAVs. Additionally, there are probably considerable benefits in combining different light-weight methods for model acceleration: more significant reduction of the model size and power consumption while maintaining model accuracy and accelerating the inference process (Wang et al., 2021b; Aghli and Ribeiro, 2021). Though light-weight semantic segmentation methods show encouraging achievements, the pretraining process of light-weight models is restricted by the limited image datasets with fine-gained annotations.\næœ¬æ–‡ä¸­æˆ‘ä»¬æè¿°äº†æ— äººæœºèƒŒæ™¯ä¸‹çš„è½»é‡çº§è¯­ä¹‰åˆ†å‰²æ–¹æ³•ï¼Œè¯¥é¢†åŸŸä»æ˜¯ä¸€ä¸ªå¹´è½»ä¸”ç­‰å¾…æ·±å…¥æ¢ç´¢çš„ç ”ç©¶é¢†åŸŸï¼Œä¸”è¯¥é¢†åŸŸçš„å‘è¡¨è®ºæ–‡æå°‘ã€‚ä¸å¼ é‡åˆ†è§£ã€ä½ç²¾åº¦é‡åŒ–å’Œæ— äººæœºå¯¼èˆªï¼ˆNASï¼‰ç›¸æ¯”ï¼Œé«˜æ•ˆç½‘ç»œç»“æ„çš„è®¾è®¡ä¼¼ä¹æ˜¯å½“å‰æ–‡çŒ®ä¸­æœ€å®ç”¨çš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒæ— éœ€å¤æ‚çš„å¾®è°ƒå’ŒåæœŸå¤„ç†å³å¯åœ¨æ— äººæœºä¸Šéƒ¨ç½²æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç»“åˆä¸åŒçš„è½»é‡åŒ–æ¨¡å‹åŠ é€Ÿæ–¹æ³•å¯èƒ½å¸¦æ¥æ˜¾è‘—å¥½å¤„ï¼šåœ¨ä¿æŒæ¨¡å‹å‡†ç¡®æ€§å’ŒåŠ é€Ÿæ¨ç†è¿‡ç¨‹çš„åŒæ—¶ï¼Œæ›´æ˜¾è‘—åœ°å‡å°‘æ¨¡å‹è§„æ¨¡å’ŒåŠŸè€—ï¼ˆWang ç­‰ï¼Œ2021b;Aghli å’Œ Ribeiroï¼Œ2021 å¹´ï¼‰ã€‚å°½ç®¡è½»é‡çº§è¯­ä¹‰åˆ†å‰²æ–¹æ³•å–å¾—äº†ä»¤äººé¼“èˆçš„æˆå°±ï¼Œä½†è½»é‡çº§æ¨¡å‹çš„é¢„è®­ç»ƒè¿‡ç¨‹å—é™äºæœ‰é™çš„å›¾åƒæ•°æ®é›†å’Œç»†è‡´å¢ç›Šæ³¨é‡Šã€‚\nResearchers prefer to transfer and fine-turn the pre-trained backbones for real-time semantic segmentation on UAVs due to the computational burden of pre-training the model from scratch, which also limits the diversification of efficient network structures.\nç”±äºä»é›¶å¼€å§‹é¢„è®­ç»ƒæ¨¡å‹çš„è®¡ç®—è´Ÿæ‹…è¾ƒå¤§ï¼Œä¸”ä¼šé™åˆ¶é«˜æ•ˆç½‘ç»œç»“æ„çš„å¤šæ ·æ€§ï¼Œç ”ç©¶äººå‘˜æ›´å€¾å‘äºè¿ç§»å¹¶å¾®è°ƒé¢„è®­ç»ƒçš„ä¸»å¹²ç½‘ç»œï¼Œä»¥ä¾¿åœ¨æ— äººæœºä¸Šè¿›è¡Œå®æ—¶è¯­ä¹‰åˆ†å‰²ã€‚\n# Datasets for UAV semantic segmentation\nUAV è¯­ä¹‰åˆ†å‰²æ•°æ®é›†\nThe rapid development of semantic segmentation owes much to large-scale datasets and relevant DL-based image analysis methods. Undoubtedly, large-scale datasets and massive semantic annotations allow models to improve generalization performance and learn more diverse semantic information. The data sources of remote sensing semantic segmentation datasets are mainly collected by satellite-based platforms, aerial platforms, and embedding UAV platforms (Toth and JÃ³zÌkÃ³w, 2016). Advanced surveys that summarized the remote sensing image datasets for different application scenarios mainly focused on datasets collected by satellite platforms (Song et al., 2019; Yuan et al., 2021; Osco et al., 2021). Satellites are constrained to catch the top vertical view from the sky, while UAVs are free to capture the perspective view in three dimensions, including vertical view, horizontal view, and oblique view, allowing researchers and practitioners to obtain unexplored viewpoints at various spatial scales than prior benchmarks (Nigam et al., 2018; Lyu et al., 2020). Due to many restrictions such as flight authorization and potential confidentiality requirements, we found that many restricted and domain-specific datasets collected by UAVs are not publicly available. Nevertheless, we believe that summarizing the publicly available UAV-based image datasets for semantic segmentation up to now may help scholars and practitioners understand the application trend of UAV platforms, reduce the labor cost for investigating relevant open-source datasets, as well as promote the emergence of more advanced semantic segmentation methods for UAVbased images. In this review, we have listed publicly available UAV datasets for semantic segmentation applied to different applications, as shown in Table 4.\nè¯­ä¹‰åˆ†å‰²çš„å¿«é€Ÿå‘å±•å¾ˆå¤§ç¨‹åº¦ä¸Šå¾—ç›Šäºå¤§è§„æ¨¡æ•°æ®é›†å’Œç›¸å…³çš„åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒåˆ†ææ–¹æ³•ã€‚æ¯«æ— ç–‘é—®ï¼Œå¤§è§„æ¨¡æ•°æ®é›†å’Œæµ·é‡è¯­ä¹‰æ³¨é‡Šä½¿æ¨¡å‹èƒ½å¤Ÿæå‡æ³›åŒ–æ€§èƒ½ï¼Œå­¦ä¹ æ›´å¤šæ ·çš„è¯­ä¹‰ä¿¡æ¯ã€‚é¥æ„Ÿè¯­ä¹‰åˆ†å‰²æ•°æ®é›†çš„æ•°æ®ä¸»è¦ç”±å«æ˜Ÿå¹³å°ã€ç©ºä¸­å¹³å°å’ŒåµŒå…¥æ— äººæœºå¹³å°æ”¶é›†ï¼ˆToth å’Œ JÃ³ÅºkÃ³wï¼Œ2016ï¼‰ã€‚é«˜çº§è°ƒæŸ¥æ€»ç»“äº†ä¸åŒåº”ç”¨åœºæ™¯ä¸‹çš„é¥æ„Ÿå›¾åƒæ•°æ®é›†ï¼Œä¸»è¦èšç„¦äºå«æ˜Ÿå¹³å°æ”¶é›†çš„æ•°æ®é›†ï¼ˆSong ç­‰ï¼Œ2019;Yuan ç­‰ï¼Œ2021;Osco ç­‰ï¼Œ2021ï¼‰ã€‚å«æ˜Ÿå—é™äºæ•æ‰å¤©ç©ºé¡¶éƒ¨çš„å‚ç›´è§†è§’ï¼Œè€Œæ— äººæœºåˆ™å¯è‡ªç”±æ•æ‰ä¸‰ç»´é€è§†è§†è§’ï¼ŒåŒ…æ‹¬å‚ç›´è§†è§’ã€æ°´å¹³è§†è§’å’Œæ–œè§†ï¼Œä½¿ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…èƒ½å¤Ÿè·å¾—ä¸åŒç©ºé—´å°ºåº¦ä¸Šæœªæ¢ç´¢çš„è§†è§’ï¼ˆNigam ç­‰ï¼Œ2018;Lyu ç­‰ï¼Œ2020ï¼‰ã€‚ç”±äºé£è¡Œæˆæƒå’Œæ½œåœ¨ä¿å¯†è¦æ±‚ç­‰è¯¸å¤šé™åˆ¶ï¼Œæˆ‘ä»¬å‘ç°è®¸å¤šç”±æ— äººæœºæ”¶é›†çš„å—é™å’Œç‰¹å®šé¢†åŸŸæ•°æ®é›†å¹¶æœªå…¬å¼€ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬è®¤ä¸ºï¼Œæ±‡æ€»è¿„ä»Šä¸ºæ­¢å…¬å¼€çš„æ— äººæœºå›¾åƒæ•°æ®é›†ç”¨äºè¯­ä¹‰åˆ†å‰²ï¼Œæœ‰åŠ©äºå­¦è€…å’Œå®è·µè€…ç†è§£æ— äººæœºå¹³å°çš„åº”ç”¨è¶‹åŠ¿ï¼Œé™ä½ç ”ç©¶ç›¸å…³å¼€æºæ•°æ®é›†çš„åŠ³åŠ¨æˆæœ¬ï¼Œå¹¶æ¨åŠ¨æ›´å…ˆè¿›çš„æ— äººæœºå›¾åƒè¯­ä¹‰åˆ†å‰²æ–¹æ³•çš„å‡ºç°ã€‚åœ¨æœ¬ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬åˆ—å‡ºäº†å…¬å¼€å¯ç”¨çš„ UAV æ•°æ®é›†ï¼Œç”¨äºä¸åŒåº”ç”¨çš„è¯­ä¹‰åˆ†å‰²ï¼Œå¦‚è¡¨ 4 æ‰€ç¤ºã€‚\nInspired by Cityscapes (Cordts et al., 2016; Nigam et al., 2018) released AeroScapes, which is designed for the image semantic segmentation tasks of the low-altitude scenes. It provides 3269 images  acquired from 141 video sequences of UAV fleets. Researchers prelabeled 11 ground truth classes with dense annotations, but the view variations caused by flexible flight altitude and movable perspective make it challenging for semantic segmentation tasks. Semantic Drone Dataset is another publicly available urban scene semantic understanding dataset that aims to increase the safety of UAV flight and landing procedures. The dataset consists of 400 training images with densely labeled semantic labels and 200 private testing images, all acquired by autonomous drones at an altitude of 5 to 30 m above the ground. Urban Drone Dataset (Chen et al., 2018c) (UDD5) is an urban scene collection of drone images acquired from 4 different cities in China at flight altitudes between 60 and 100 m. The original dataset comprises 5 categories, splitting 160 frames for the training set and 45 images for the verification set. In addition, the authors released a new public dataset with a new Roof class in 2020, which is also called UDD6. ManipalUAVid (Girisha et al., 2019) is a new UAV aerial video dataset collected in a closed university campus. It provides 33 videos and 667 key frames collected at six locations during the day. Only the key frames were finely annotated into 4 semantic classes, including constructions, greeneries, roads, and waterbodies. More recently, Lyu et al. (2020) released a high-resolution urban dataset called UAVid. The most characteristic of UAVid is the severe class imbalance of pixel distribution, making it challenging to preserve temporal consistency and obtain accurate segmentation results. It should be noted that this dataset only provides semantic label masks for specific image frames at selected time points within the video rather than for the entire video sequence. Their subsequent work added extra 12 sequences to strengthen the original 30 video sequences and released 42 sequences as UAVid2020, which can be available on their benchmark website.\nå—åŸå¸‚æ™¯è§‚å¯å‘ï¼ˆCordts ç­‰ï¼Œ2016;Nigam ç­‰äººï¼Œ2018 å¹´ï¼‰å‘å¸ƒäº† AeroScapesï¼Œè¯¥è½¯ä»¶ä¸“ä¸ºä½ç©ºåœºæ™¯çš„å›¾åƒè¯­ä¹‰åˆ†å‰²ä»»åŠ¡è®¾è®¡ã€‚å®ƒæä¾›äº†ä» 141 æ®µæ— äººæœºæœºé˜Ÿè§†é¢‘åºåˆ—ä¸­è·å–çš„ 3269 å¼ å›¾åƒã€‚ç ”ç©¶äººå‘˜é¢„å…ˆæ ‡è®°äº† 11 ä¸ªåœ°é¢çœŸå®ç±»å¹¶å¸¦æœ‰å¯†é›†æ³¨é‡Šï¼Œä½†ç”±äºçµæ´»é£è¡Œé«˜åº¦å’Œå¯ç§»åŠ¨è§†è§’å¼•èµ·çš„è§†è§’å˜åŒ–ï¼Œä½¿å¾—è¯­ä¹‰åˆ†å‰²ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¯­ä¹‰æ— äººæœºæ•°æ®é›†æ˜¯å¦ä¸€ä¸ªå…¬å¼€å¯ç”¨çš„åŸå¸‚åœºæ™¯è¯­ä¹‰ç†è§£æ•°æ®é›†ï¼Œæ—¨åœ¨æé«˜æ— äººæœºé£è¡Œå’Œç€é™†ç¨‹åºçš„å®‰å…¨æ€§ã€‚è¯¥æ•°æ®é›†åŒ…å« 400 å¼ å¸¦æœ‰å¯†é›†è¯­ä¹‰æ ‡ç­¾çš„è®­ç»ƒå›¾åƒå’Œ 200 å¼ ç§æœ‰æµ‹è¯•å›¾åƒï¼Œå‡ç”±è‡ªä¸»æ— äººæœºåœ¨åœ°é¢ 5 è‡³ 30 ç±³é«˜ç©ºæ‹æ‘„ã€‚åŸå¸‚æ— äººæœºæ•°æ®é›†ï¼ˆChen ç­‰ï¼Œ2018cï¼‰ï¼ˆUDD5ï¼‰æ˜¯ä¸€ç»„ä»ä¸­å›½ 4 ä¸ªä¸åŒåŸå¸‚åœ¨ 60 è‡³ 100 ç±³é£è¡Œé«˜åº¦æ‹æ‘„çš„åŸå¸‚åœºæ™¯å›¾åƒã€‚åŸå§‹æ•°æ®é›†åŒ…å« 5 ä¸ªç±»åˆ«ï¼Œè®­ç»ƒé›†åˆ†ä¸º 160 å¸§ï¼ŒéªŒè¯é›†åˆ†ä¸º 45 å¼ å›¾åƒã€‚æ­¤å¤–ï¼Œä½œè€…äº 2020 å¹´å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„å…¬å¼€æ•°æ®é›†ï¼ŒåŒ…å«ä¸€ä¸ªæ–°çš„ Roof ç±»ï¼Œä¹Ÿç§°ä¸º UDD6ã€‚ManipalUAVidï¼ˆGirisha ç­‰ï¼Œ2019ï¼‰æ˜¯ä¸€ä¸ªåœ¨å…³é—­å¤§å­¦æ ¡å›­å†…æ”¶é›†çš„æ–°æ— äººæœºèˆªæ‹è§†é¢‘æ•°æ®é›†ã€‚å®ƒæä¾› 33 ä¸ªè§†é¢‘å’Œ 667 ä¸ªå…³é”®å¸§ï¼Œè¿™äº›è§†é¢‘åœ¨ä¸€å¤©å†…æ”¶é›†åˆ°å…­ä¸ªåœ°ç‚¹ã€‚åªæœ‰å…³é”®å¸§è¢«ç²¾ç»†æ³¨é‡Šä¸º 4 ä¸ªè¯­ä¹‰ç±»åˆ«ï¼ŒåŒ…æ‹¬å»ºç­‘ã€ç»¿åœ°ã€é“è·¯å’Œæ°´ä½“ã€‚æœ€è¿‘ï¼ŒLyu ç­‰äººï¼ˆ2020ï¼‰å‘å¸ƒäº†ä¸€ä¸ªåä¸º UAVid çš„é«˜åˆ†è¾¨ç‡åŸå¸‚æ•°æ®é›†ã€‚UAVid æœ€æ˜¾è‘—çš„ç‰¹ç‚¹æ˜¯åƒç´ åˆ†å¸ƒçš„ä¸¥é‡ç±»åˆ«å¤±è¡¡ï¼Œè¿™ä½¿å¾—ä¿æŒæ—¶é—´ä¸€è‡´æ€§å’Œè·å¾—å‡†ç¡®åˆ†å‰²ç»“æœå˜å¾—å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ•°æ®é›†ä»…ä¸ºè§†é¢‘ä¸­ç‰¹å®šæ—¶é—´ç‚¹çš„ç‰¹å®šå›¾åƒå¸§æä¾›è¯­ä¹‰æ ‡ç­¾é®ç½©ï¼Œè€Œéæ•´ä¸ªè§†é¢‘åºåˆ—ã€‚ä»–ä»¬åç»­çš„ä½œå“å¢åŠ äº† 12 ä¸ªåºåˆ—ä»¥åŠ å¼ºåŸæœ‰ 30 ä¸ªè§†é¢‘åºåˆ—ï¼Œå¹¶å‘å¸ƒäº† 42 ä¸ªåºåˆ—\n\nDroneDeploy is a large-scale segmentation benchmark challenge that encourages state-of-the-art machine learning on aerial drone data. It consists of aerial orthomosaics and elevation images, and there are 55 tiles have been finely annotated into 6 categories. Inria Aerial Image Labeling Dataset (IAILD) (Maggiori et al., 2017) is another aerial dataset covering a wide range of urban landscapes with a spatial resolution of 30 cm. The 360 images, including 180 trading sets and 180 testing sets, have been annotated into two semantic classes. The scenes of different cities do not overlap in the training and testing sets, making it possible to powerfully validate the generalization of models for semantic segmentation.\nDroneDeploy æ˜¯ä¸€é¡¹å¤§è§„æ¨¡åˆ†å‰²åŸºå‡†æŒ‘æˆ˜èµ›ï¼Œæ—¨åœ¨é¼“åŠ±å¯¹æ— äººæœºèˆªæ‹æ•°æ®è¿›è¡Œæœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç ”ç©¶ã€‚è¯¥æ•°æ®é›†åŒ…å«èˆªæ‹æ­£å°„å½±åƒå’Œé«˜ç¨‹å›¾åƒï¼Œå…±æœ‰ 55 ä¸ªå›¾å—è¢«ç²¾ç»†æ ‡æ³¨ä¸º 6 ä¸ªç±»åˆ«ã€‚Inria èˆªæ‹å›¾åƒæ ‡æ³¨æ•°æ®é›†ï¼ˆIAILDï¼‰ï¼ˆMaggiori ç­‰äººï¼Œ2017ï¼‰æ˜¯å¦ä¸€ä¸ªèˆªæ‹æ•°æ®é›†ï¼Œè¦†ç›–äº†å¤šç§åŸå¸‚æ™¯è§‚ï¼Œç©ºé—´åˆ†è¾¨ç‡ä¸º 30 å˜ç±³ã€‚è¯¥æ•°æ®é›†åŒ…å« 360 å¹…å›¾åƒï¼ŒåŒ…æ‹¬ 180 ä¸ªè®­ç»ƒé›†å’Œ 180 ä¸ªæµ‹è¯•é›†ï¼Œå‡å·²æ ‡æ³¨ä¸ºä¸¤ä¸ªè¯­ä¹‰ç±»åˆ«ã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„ä¸åŒåŸå¸‚åœºæ™¯äº’ä¸é‡å ï¼Œä»è€Œèƒ½å¤Ÿæœ‰åŠ›åœ°éªŒè¯è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\nUAVs have received much attention in crack detection on highrise infrastructures due to their low budget and high efficiency. Yang et al. (2017) proposed the Concrete Structure Spalling and Crack (CSSC) database for automatic concrete inspection by UAVs, consisting of 278 spalling images and 954 crack images collected through web keyword search. Hong et al. (2021) relabeled the AerialCrackDetection dataset (Wang, 2017) that only provided bounding rectangles for crack detection. The proposed Highway Crack Dataset contains 1157 images with corresponding pixel-wise segmentation annotations. CrackUAS, a high-resolution crack dataset built by Arda et al. (2021), provided crack images with and without shell obstructions. In addition, the dataset containing synthetic images of surface cracks with shell obstructions enables researchers to verify the robustness of models and further validating their transfer learning performance. UAVs have also shown great potential for crop management, especially for tasks requiring human visual inspection, such as weed detection, lodging detection, and many others. Sa et al. (2017) released WeedNet, a multispectral (NR, Red channel, and NDVI) dataset with three semantic annotations, containing 132 crop images, 243 weeds images, and 90 crop-weeds mixtures. Another large-scale multispectral crop-weed dataset with 8 image modalities, called WeedMap Dataset (Sa et al., 2018) in this review, was proposed in their subsequent work. The spatial resolution of this dataset reached about 1 cm per pixel given the camera specification and flight altitude. To achieve precise crop mapping with hyperspectral feature space, Niu et al. (2022) acquired high-resolution images of 27 kinds of crops with a complex plantation structure based on UAV hyperspectral systems and then released the UAV-HSI-Crop dataset. The dataset is densely labeled with 29 classes, and the long-tail distribution of the pixel number histogram poses a great challenge for accurate crop mapping. In addition, the ease with which UAV sensors can provide high resolution is a unique advantage in infrastructure monitoring. The Massachusetts Dataset, published by Mnih (2013), contains 1711 road images and 151 building images at a spatial resolution of 100 cm. Since most datasets for road extractions from UAV images are not publicly available, the Massachusetts Roads Dataset (MRD) can be employed to validate the performance of UAV road extraction methods (Wang et al., 2021c). The Topo-boundary Dataset (Xu et al., 2021) is a largescale high-resolution road boundary extraction dataset applied to 8 sub-tasks. The dataset provides 25 295 optical images and eight pixellevel annotation labels. The most significant feature of this dataset is the imbalance between positive and negative sample pixels, which poses a significant challenge for the semantic segmentation of road boundaries. Besides, the heterogeneity in color intensity and significant variations in road width also curbed accurate segmentation of roads in high-resolution UAV images. Hence, Behera et al. (2023) built the NITRDrone dataset, which contains the occluded_road and vegetation classes in addition to the two commonly used binary semantic annotations of road and background. It presents more complex and diverse road context information due to its characteristics, such as occlusions, discontinuities, different viewpoints, and various road types.\nç”±äºä½æˆæœ¬å’Œé«˜æ•ˆï¼Œæ— äººæœºåœ¨é«˜å±‚åŸºç¡€è®¾æ–½çš„è£‚çº¹æ£€æµ‹ä¸­å¤‡å—å…³æ³¨ã€‚Yang ç­‰äººï¼ˆ2017ï¼‰æå‡ºäº†æ··å‡åœŸç»“æ„å‰¥è½ä¸è£‚ç¼ï¼ˆCSSCï¼‰æ•°æ®åº“ï¼Œç”¨äºæ— äººæœºè‡ªåŠ¨è¿›è¡Œæ··å‡åœŸæ£€æŸ¥ï¼ŒåŒ…å« 278 å¼ å‰¥è½å›¾åƒå’Œ 954 å¼ è£‚çº¹å›¾åƒï¼Œå‡é€šè¿‡ç½‘ç»œå…³é”®è¯æœç´¢æ”¶é›†ã€‚Hong ç­‰äººï¼ˆ2021ï¼‰é‡æ–°æ ‡è®°äº†ä»…æä¾›è¾¹ç•ŒçŸ©å½¢ç”¨äºè£‚çº¹æ£€æµ‹çš„ AerialCrackDetection æ•°æ®é›†ï¼ˆWangï¼Œ 2017ï¼‰ã€‚æ‹Ÿè®®çš„å…¬è·¯è£‚ç¼æ•°æ®é›†åŒ…å« 1157 å¼ å›¾åƒåŠç›¸åº”çš„åƒç´ åˆ†å‰²æ³¨é‡Šã€‚CrackUAS æ˜¯ Arda ç­‰äººï¼ˆ2021 å¹´ï¼‰æ„å»ºçš„é«˜åˆ†è¾¨ç‡è£‚çº¹æ•°æ®é›†ï¼Œæä¾›äº†æœ‰å£³ä½“éšœç¢å’Œæ— å£³ä½“éšœç¢çš„è£‚çº¹å›¾åƒã€‚æ­¤å¤–ï¼ŒåŒ…å«å¸¦æœ‰å£³ä½“éšœç¢çš„è¡¨é¢è£‚çº¹åˆæˆå›¾åƒçš„æ•°æ®é›†ï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤ŸéªŒè¯æ¨¡å‹çš„ç¨³å¥æ€§ï¼Œå¹¶è¿›ä¸€æ­¥éªŒè¯å…¶è¿ç§»å­¦ä¹ æ€§èƒ½ã€‚æ— äººæœºåœ¨ä½œç‰©ç®¡ç†æ–¹é¢ä¹Ÿå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦äººå·¥ç›®è§†æ£€æŸ¥çš„ä»»åŠ¡ä¸­ï¼Œå¦‚æ‚è‰æ£€æµ‹ã€åœæ³Šæ£€æµ‹ç­‰ã€‚Sa ç­‰äººï¼ˆ2017ï¼‰å‘å¸ƒäº† WeedNetï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šå…‰è°±ï¼ˆNRã€çº¢è‰²é€šé“å’Œ NDVIï¼‰æ•°æ®é›†ï¼ŒåŒ…å«ä¸‰ä¸ªè¯­ä¹‰æ³¨é‡Šï¼ŒåŒ…å« 132 å¼ è£å‰ªå›¾åƒã€243 å¼ æ‚è‰å›¾åƒå’Œ 90 å¼ è£å‰ª - æ‚è‰æ··åˆå›¾ã€‚ä»–ä»¬åœ¨åç»­ç ”ç©¶ä¸­æå‡ºäº†å¦ä¸€ä¸ªå…·æœ‰ 8 ç§å›¾åƒæ¨¡æ€çš„å¤§è§„æ¨¡å¤šå…‰è°±ä½œç‰© - æ‚è‰æ•°æ®é›†ï¼Œç§°ä¸º WeedMap æ•°æ®é›†ï¼ˆSa ç­‰ï¼Œ2018ï¼‰ã€‚æ ¹æ®ç›¸æœºè§„æ ¼å’Œé£è¡Œé«˜åº¦ï¼Œè¯¥æ•°æ®é›†çš„ç©ºé—´åˆ†è¾¨ç‡çº¦ä¸ºæ¯åƒç´  1 å˜ç±³ã€‚ä¸ºäº†å®ç°é«˜å…‰è°±ç‰¹å¾ç©ºé—´çš„ç²¾ç¡®ä½œç‰©æ˜ å°„ï¼ŒNiu ç­‰äººï¼ˆ2022ï¼‰åŸºäºæ— äººæœºé«˜å…‰è°±ç³»ç»Ÿï¼Œæ‹æ‘„äº† 27 ç§å…·æœ‰å¤æ¤ç»“æ„ä½œç‰©çš„é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œéšåå‘å¸ƒäº†æ— äººæœº - HSI - ä½œç‰©æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†å¯†é›†åœ°æ ‡æ³¨äº† 29 ä¸ªç±»åˆ«ï¼Œåƒç´ æ•°ç›´æ–¹å›¾çš„é•¿å°¾åˆ†å¸ƒå¯¹å‡†ç¡®çš„è£åˆ¤æ˜ å°„æ„æˆäº†å·¨å¤§æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæ— äººæœºä¼ æ„Ÿå™¨èƒ½å¤Ÿè½»æ¾æä¾›é«˜åˆ†è¾¨ç‡ï¼Œè¿™ä¹Ÿæ˜¯åŸºç¡€è®¾æ–½ç›‘æµ‹çš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚é©¬è¨è¯¸å¡å·æ•°æ®é›†ç”± Mnihï¼ˆ2013 å¹´ï¼‰å‘å¸ƒï¼ŒåŒ…å« 1711 å¼ é“è·¯å›¾åƒå’Œ 151 å¼ å»ºç­‘å›¾åƒï¼Œç©ºé—´åˆ†è¾¨ç‡ä¸º 100 å˜ç±³ã€‚ç”±äºå¤§å¤šæ•°æ— äººæœºå›¾åƒä¸­é“è·¯æå–çš„æ•°æ®é›†å°šæœªå…¬å¼€ï¼Œé©¬è¨è¯¸å¡å·é“è·¯æ•°æ®é›†ï¼ˆMRDï¼‰å¯ç”¨äºéªŒè¯æ— äººæœºé“è·¯æå–æ–¹æ³•çš„æ€§èƒ½ï¼ˆWang ç­‰ï¼Œ2021cï¼‰ã€‚åœ°å½¢è¾¹ç•Œæ•°æ®é›†ï¼ˆXu ç­‰ï¼Œ2021ï¼‰æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡é«˜åˆ†è¾¨ç‡é“è·¯è¾¹ç•Œæå–æ•°æ®é›†ï¼Œåº”ç”¨äº 8 ä¸ªå­ä»»åŠ¡ã€‚è¯¥æ•°æ®é›†æä¾› 25,295 å¼ å…‰å­¦å›¾åƒå’Œ 8 ä¸ªåƒç´ çº§æ³¨é‡Šæ ‡ç­¾ã€‚è¯¥æ•°æ®é›†æœ€é‡è¦çš„ç‰¹ç‚¹æ˜¯æ­£è´Ÿæ ·æœ¬åƒç´ çš„ä¸å¹³è¡¡ï¼Œè¿™å¯¹é“è·¯è¾¹ç•Œçš„è¯­ä¹‰åˆ†å‰²æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œè‰²å½©å¼ºåº¦çš„å¼‚è´¨æ€§å’Œé“è·¯å®½åº¦çš„æ˜¾è‘—å˜åŒ–ä¹Ÿé™åˆ¶äº†é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒä¸­é“è·¯çš„ç²¾ç¡®åˆ†å‰²ã€‚å› æ­¤ï¼ŒBehera ç­‰äººï¼ˆ2023ï¼‰æ„å»ºäº† NITRDrone æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†é™¤äº†å¸¸ç”¨çš„é“è·¯å’ŒèƒŒæ™¯è¿™ä¸¤ä¸ªå¸¸ç”¨äºŒè¿›åˆ¶è¯­ä¹‰æ³¨é‡Šå¤–ï¼Œè¿˜åŒ…å«äº† occluded_road ç±»å’Œæ¤è¢«ç±»ã€‚ç”±äºå…¶ç‰¹æ€§ï¼Œå¦‚é˜»å¡ã€ä¸è¿ç»­ã€ä¸åŒè§†è§’å’Œå¤šç§é“è·¯ç±»å‹ï¼Œå®ƒå‘ˆç°äº†æ›´å¤æ‚å’Œå¤šæ ·åŒ–çš„é“è·¯èƒŒæ™¯ä¿¡æ¯ã€‚\nIn recent years, the rapid dispatch of UAVs has been an efficient approach for emergency response and damage assessment of disaster scenarios. Chowdhury et al. (2020) collected a natural disaster dataset (HRUD) based on a high-resolution UAV platform. The dataset provides 1973 images with 4 kinds of damage polygons based on damage levels. The dataset also provided semantic labels of 8 objects and background to annotate all damaged objects in an image. Their subsequent work released RescueNet (Chowdhury et al., 2022), a highresolution post-disaster dataset, for damage assessment after the natural disaster. The dataset is annotated in a similar format to HRUD, which consists of 4494 high-resolution UAV images with 11 categories of  pixel-level annotations of damaged objects. Rahnemoonfar et al. (2021) published a flood disaster assessment dataset (FloodNet) based on the UAV platform applied to damage classification, semantic segmentation, and visual question answering (VQA). It is the first dataset designed to simultaneously address three critical computer vision tasks, presenting new opportunities and challenges for disaster assessment. Furthermore, we found a dataset called FLAME (Shamsoshoara et al., 2021), which exhibits prescribed burnings of piled slash in the Arizona pine forest, to motivate advanced solutions for early fire detection and management. It provides 2003 image frames of video recordings and corresponding frame-level semantic annotations for the fully-supervised binary semantic segmentation.\nè¿‘å¹´æ¥ï¼Œå¿«é€Ÿæ´¾é£æ— äººæœºæˆä¸ºåº”æ€¥å“åº”å’Œç¾å®³æƒ…æ™¯æŸå®³è¯„ä¼°çš„é«˜æ•ˆæ–¹æ³•ã€‚Chowdhury ç­‰äººï¼ˆ2020ï¼‰åŸºäºé«˜åˆ†è¾¨ç‡æ— äººæœºå¹³å°æ”¶é›†äº†è‡ªç„¶ç¾å®³æ•°æ®é›†ï¼ˆHRUDï¼‰ã€‚è¯¥æ•°æ®é›†æä¾›äº† 1973 å¼ å›¾åƒï¼ŒåŒ…å«åŸºäºæŸä¼¤ç­‰çº§çš„ 4 ç§æŸåå¤šè¾¹å½¢ã€‚æ•°æ®é›†è¿˜æä¾›äº† 8 ä¸ªç‰©ä½“çš„è¯­ä¹‰æ ‡ç­¾ï¼Œå¹¶ç”¨èƒŒæ™¯æ³¨é‡Šå›¾åƒä¸­æ‰€æœ‰å—æŸç‰©ä½“ã€‚ä»–ä»¬çš„åç»­å·¥ä½œå‘å¸ƒäº† RescueNetï¼ˆChowdhury ç­‰ï¼Œ2022ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜åˆ†è¾¨ç‡çš„ç¾åæ•°æ®é›†ï¼Œç”¨äºè‡ªç„¶ç¾å®³åçš„æŸå®³è¯„ä¼°ã€‚è¯¥æ•°æ®é›†çš„æ³¨é‡Šæ ¼å¼ä¸ HRUD ç±»ä¼¼ï¼Œåè€…åŒ…å« 4494 å¼ é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒï¼ŒåŒ…å« 11 ç±»åƒç´ çº§çš„å—æŸç‰©ä½“æ³¨é‡Šã€‚Rahnemoonfar ç­‰äººï¼ˆ2021ï¼‰å‘è¡¨äº†åŸºäºæ— äººæœºå¹³å°çš„æ´ªæ°´ç¾å®³è¯„ä¼°æ•°æ®é›†ï¼ˆFloodNetï¼‰ï¼Œè¯¥æ•°æ®é›†åº”ç”¨äºæŸå®³åˆ†ç±»ã€è¯­ä¹‰åˆ†å‰²å’Œè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ã€‚è¿™æ˜¯é¦–ä¸ªåŒæ—¶è®¾è®¡ç”¨äºè§£å†³ä¸‰ä¸ªå…³é”®è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„æ•°æ®é›†ï¼Œä¸ºç¾å®³è¯„ä¼°å¸¦æ¥äº†æ–°çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å‘ç°äº†ä¸€ä¸ªåä¸º FLAME çš„æ•°æ®é›†ï¼ˆShamsoshoara ç­‰ï¼Œ2021ï¼‰ï¼Œè¯¥æ•°æ®é›†å±•ç¤ºäº†äºšåˆ©æ¡‘é‚£æ¾æ—ä¸­æ¡©æŸ±çš„è§„å®šçƒ§é™¤ï¼Œä»¥æ¿€åŠ±æ—©æœŸç«ç¾æ£€æµ‹å’Œç®¡ç†çš„å…ˆè¿›è§£å†³æ–¹æ¡ˆã€‚å®ƒæä¾›äº† 2003 å¸§è§†é¢‘å½•åˆ¶çš„å›¾åƒå¸§åŠç›¸åº”çš„å¸§çº§è¯­ä¹‰æ³¨é‡Šï¼Œç”¨äºå…¨ç›‘ç£äºŒå…ƒè¯­ä¹‰åˆ†å‰²ã€‚\nTo quantify whether DL-based classifiers can imitate human experts and achieve higher accuracy in RGB fluvial scene classification on hyperspatial resolution airborne images, Carbonneau et al. (2020) released the 11 Rivers dataset, which comprises 305 hyperspatial (&lt;10 cm) resolution color imagery as well as corresponding label masks with 5 semantic classes. Wang and Mahmoudian (2023) created the Aerial River Image Dataset (AFID), which offers various perspectives of river scenes and focuses specifically on labeling water and waterborne obstacles. This dataset also suffers from imbalanced distribution in class pixel percentages and contains a small part of blurred images due to residual moisture on the camera lens surface. To promote studies on river ice monitoring based on DL technologies, Zhang et al. (2020d) released a publicly available UAV-based image dataset, called NWPU_YRCC, for river ice segmentation. This dataset provides 814 images captured by two UAVs in the region of the Yellow River with various appearances at different times, as well as three categories, including ice, water, and shore. To satisfy the training requirements of the neural network, they then added 74 images to the original dataset and renamed it NWPU_YRCC_EX. In their subsequent work (Zhang et al., 2021b), a new NWPU_YRCC2 dataset, which contains 1525 typical river ice images with different characteristics, was built for fine-grained river ice semantic segmentation. The new dataset puts more emphasis on distinguishing between drift ice and shore ice, and provides two other semantic categories, including water and other. In this section, we have introduced semantic segmentation datasets of UAV remote sensing images applied to different scenarios. In addition to optical UAV images, multispectral and hyperspectral modalities are gradually adopted in current UAV image acquisition tasks. Turning to 3D point cloud labeling, UAVs have also attracted attention in the semantic understanding of fine-grained geographic scenes. Researchers have already published relevant 3D point cloud datasets collected by UAVs, including The Hessigheim 3D (H3D) benchmark (KÃ¶lle et al., 2021), SensatUrban (Hu et al., 2021b), Swiss3DCities (Can et al., 2021), and many others. Recent publicly available UAV datasets suggest that the semantic segmentation on UAV-based platforms is trending towards sophisticated, multi-tasking, and multimodal.\nä¸ºäº†é‡åŒ–åŸºäº DL çš„åˆ†ç±»å™¨æ˜¯å¦èƒ½æ¨¡ä»¿äººç±»ä¸“å®¶ï¼Œå¹¶åœ¨é«˜ç©ºé—´åˆ†è¾¨ç‡çš„ç©ºä¸­å›¾åƒä¸Šå®ç° RGB æ²³æµåœºæ™¯åˆ†ç±»çš„æ›´é«˜å‡†ç¡®æ€§ï¼ŒCarbonneau ç­‰äººï¼ˆ2020ï¼‰å‘å¸ƒäº† 11 Rivers æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å« 305 å¼ è¶…ç©ºé—´ï¼ˆ&lt;10 å˜ç±³ï¼‰åˆ†è¾¨ç‡å½©è‰²å›¾åƒåŠå¯¹åº”çš„æ ‡ç­¾æ©ç ï¼ŒåŒ…å« 5 ä¸ªè¯­ä¹‰ç±»åˆ«ã€‚Wang å’Œ Mahmoudianï¼ˆ2023ï¼‰åˆ›å»ºäº†èˆªæ‹æ²³æµå›¾åƒæ•°æ®é›†ï¼ˆAFIDï¼‰ï¼Œæä¾›äº†æ²³æµåœºæ™¯çš„å¤šæ ·è§†è§’ï¼Œå¹¶ç‰¹åˆ«å…³æ³¨æ°´ä½“åŠæ°´ä¸Šéšœç¢ç‰©çš„æ ‡æ³¨ã€‚è¯¥æ•°æ®é›†è¿˜å­˜åœ¨ç±»åˆ«åƒç´ ç™¾åˆ†æ¯”åˆ†å¸ƒä¸å¹³è¡¡çš„é—®é¢˜ï¼Œä¸”ç”±äºç›¸æœºé•œå¤´è¡¨é¢æ®‹ç•™çš„æ¹¿æ°”ï¼Œå›¾åƒå‡ºç°äº†å°‘é‡æ¨¡ç³Šã€‚ä¸ºä¿ƒè¿›åŸºäº DL æŠ€æœ¯çš„æ²³å·å†°ç›‘æµ‹ç ”ç©¶ï¼ŒZhang ç­‰äººï¼ˆ2020dï¼‰å‘å¸ƒäº†ä¸€é¡¹å…¬å¼€çš„åŸºäºæ— äººæœºçš„å›¾åƒæ•°æ®é›†ï¼Œç§°ä¸º NWPU_YRCCï¼Œç”¨äºæ²³å·å†°å±‚åˆ‡å‰²ã€‚è¯¥æ•°æ®é›†åŒ…å«ä¸¤æ¶æ— äººæœºåœ¨é»„æ²³åœ°åŒºæ‹æ‘„çš„ 814 å¼ ä¸åŒæ—¶é—´å‡ºç°çš„å›¾åƒï¼Œä»¥åŠå†°ã€æ°´ã€å²¸ä¸‰ç±»ã€‚ä¸ºäº†æ»¡è¶³ç¥ç»ç½‘ç»œçš„è®­ç»ƒéœ€æ±‚ï¼Œä»–ä»¬å‘åŸå§‹æ•°æ®é›†æ·»åŠ äº† 74 å¼ å›¾åƒå¹¶å°†å…¶æ›´åä¸º NWPU_YRCC_EXã€‚åœ¨ä»–ä»¬åç»­çš„å·¥ä½œä¸­ï¼ˆZhang ç­‰ï¼Œ2021bï¼‰ï¼Œæ„å»ºäº†ä¸€ä¸ªæ–°çš„ NWPU_YRCC2 æ•°æ®é›†ï¼ŒåŒ…å« 1525 å¼ å…·æœ‰ä¸åŒç‰¹å¾çš„å…¸å‹æ²³æµå†°å›¾åƒï¼Œç”¨äºç»†ç²’åº¦æ²³å·å†°è¯­ä¹‰åˆ†å‰²ã€‚æ–°æ•°æ®é›†æ›´å¼ºè°ƒåŒºåˆ†æ¼‚æµå†°å’Œå²¸å†°ï¼Œå¹¶æä¾›äº†å¦å¤–ä¸¤ä¸ªè¯­ä¹‰ç±»åˆ«ï¼ŒåŒ…æ‹¬æ°´å’Œå…¶ä»–ã€‚æœ¬èŠ‚ä»‹ç»äº†åº”ç”¨äºä¸åŒåœºæ™¯çš„æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²æ•°æ®é›†ã€‚é™¤äº†å…‰å­¦æ— äººæœºå›¾åƒå¤–ï¼Œå¤šå…‰è°±å’Œé«˜å…‰è°±æ¨¡æ€ä¹Ÿé€æ¸è¢«åº”ç”¨äºå½“å‰æ— äººæœºå›¾åƒé‡‡é›†ä»»åŠ¡ä¸­ã€‚è½¬å‘ä¸‰ç»´ç‚¹äº‘æ ‡è®°ï¼Œæ— äººæœºåœ¨ç»†ç²’åº¦åœ°ç†åœºæ™¯çš„è¯­ä¹‰ç†è§£ä¸­ä¹Ÿå—åˆ°å…³æ³¨ã€‚ç ”ç©¶äººå‘˜å·²ç»å‘å¸ƒäº†ç”±æ— äººæœºæ”¶é›†çš„ç›¸å…³ä¸‰ç»´ç‚¹äº‘æ•°æ®é›†ï¼ŒåŒ…æ‹¬èµ«è¥¿æ ¼æµ·å§† 3Dï¼ˆH3Dï¼‰åŸºå‡†æµ‹è¯•ï¼ˆKÃ¶lle ç­‰ï¼Œ2021ï¼‰ã€SensatUrbanï¼ˆèƒ¡ç­‰ï¼Œ2021bï¼‰ã€Swiss3DCitiesï¼ˆCan ç­‰ï¼Œ2021ï¼‰ç­‰ã€‚è¿‘æœŸå…¬å¼€çš„æ— äººæœºæ•°æ®é›†è¡¨æ˜ï¼ŒåŸºäºæ— äººæœºå¹³å°çš„è¯­ä¹‰åˆ†å‰²æ­£è¶‹å‘äºå¤æ‚åŒ–ã€å¤šä»»åŠ¡å¤„ç†å’Œå¤šæ¨¡æ€åŒ–ã€‚\n# Evaluations and comparisons\nè¯„ä¼°ä¸æ¯”è¾ƒ\nEvaluation metrics are necessary to assess the effectiveness and reliability of semantic segmentation methods for UAV remote sensing images. Commonly used evaluation metrics evaluating the accuracy of semantic segmentation methods consist of overall accuracy (OA), mean intersection over union (mIoU) (Eigen and Fergus, 2015; Yu et al., 2018b), Precision, Recall, and F1-score. Due to the distinctions in features, datasets, algorithms, or tricks, it is tough to demonstrate which methods are better than others by comparing published papers directly. Hence, we conduct comparative experiments to evaluate the semantic segmentation accuracy of representative methods according to OA, mIoU, and F1-score on two recent UAV-based RGB image datasets from different scenarios, including the UAVid dataset and the FloodNet dataset. In addition, we adopt the number of parameters, Multiply-Accumulate Operations (MACs), and Frames Per Second (FPS) to evaluate the model inference efficiency, considering the necessity of loading the model onto the airborne device for real-time image processing.\nè¯„ä¼°æŒ‡æ ‡å¯¹äºè¯„ä¼°æ— äººæœºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§æ˜¯å¿…è¦çš„ã€‚å¸¸ç”¨çš„è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬æ•´ä½“å‡†ç¡®ç‡ï¼ˆOAï¼‰ã€å¹³å‡äº¤é›†ä¸å¹¶é›†ï¼ˆmIoUï¼‰ï¼ˆEigen å’Œ Fergusï¼Œ2015;Yu ç­‰ï¼Œ2018bï¼‰ã€ç²¾ç¡®åº¦ã€å›å¿†å’Œ F1 è¯„åˆ†ã€‚ç”±äºç‰¹å¾ã€æ•°æ®é›†ã€ç®—æ³•æˆ–æŠ€å·§çš„å·®å¼‚ï¼Œç›´æ¥æ¯”è¾ƒå·²å‘è¡¨è®ºæ–‡å¾ˆéš¾è¯æ˜å“ªäº›æ–¹æ³•ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ¯”è¾ƒå®éªŒï¼Œè¯„ä¼°ä»£è¡¨æ€§æ–¹æ³•æ ¹æ® OAã€mIoU å’Œ F1 è¯„åˆ†ï¼Œé’ˆå¯¹ä¸¤ä¸ªæ¥è‡ªä¸åŒåœºæ™¯çš„æ— äººæœº RGB å›¾åƒæ•°æ®é›†ï¼ˆåŒ…æ‹¬ UAVid æ•°æ®é›†å’Œ FloodNet æ•°æ®é›†ï¼‰çš„è¯­ä¹‰åˆ†å‰²å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨å‚æ•°æ•°é‡ã€ä¹˜æ³•ç´¯åŠ ä½œï¼ˆMACsï¼‰å’Œæ¯ç§’å¸§æ•°ï¼ˆFPSï¼‰æ¥è¯„ä¼°æ¨¡å‹æ¨ç†æ•ˆç‡ï¼ŒåŒæ—¶è€ƒè™‘å°†æ¨¡å‹åŠ è½½åˆ°æœºè½½è®¾å¤‡è¿›è¡Œå®æ—¶å›¾åƒå¤„ç†çš„å¿…è¦æ€§ã€‚\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["python","æ·±åº¦å­¦ä¹ ","åˆ†å‰²æ–¹æ³•ä¸æ•°æ®é›†","è¯­ä¹‰åˆ†å‰²","ç»¼è¿°","é¥æ„Ÿå›¾åƒ"]},{"title":"NumPyæ ¸å¿ƒå¤„ç†æ–¹æ³•","url":"/python/numpy/","content":"# NumPy æ ¸å¿ƒå¤„ç†æ–¹æ³•\nNumPyï¼ˆNumerical Pythonï¼‰æ˜¯ä¸€ä¸ªç”¨äºç§‘å­¦è®¡ç®—çš„ Python ç¬¬ä¸‰æ–¹åº“ï¼Œå®ƒæä¾›äº†ï¼š\n# æ ¸å¿ƒåŠŸèƒ½ï¼š\n\nå¤šç»´æ•°ç»„å¯¹è±¡\n\né«˜æ•ˆåœ°å­˜å‚¨å’Œæ“ä½œå¤§è§„æ¨¡æ•°å­—æ•°æ®ã€‚\næ¯”åŸç”Ÿ Python çš„åˆ—è¡¨ï¼ˆlistï¼‰æ›´å¿«ã€æ›´èŠ‚çœå†…å­˜ã€‚\n\n\nå¹¿æ’­åŠŸèƒ½\n\nå…è®¸ä¸åŒå½¢çŠ¶çš„æ•°ç»„è¿›è¡Œæ•°å­¦è¿ç®—ï¼Œç®€æ´é«˜æ•ˆã€‚\n\n\næ•°å­¦å‡½æ•°åº“\n\nåŒ…æ‹¬çº¿æ€§ä»£æ•°ã€å‚…é‡Œå¶å˜æ¢ã€éšæœºæ•°ç”Ÿæˆã€ç»Ÿè®¡åˆ†æç­‰ã€‚\n\n\næ•°ç»„ç´¢å¼•ä¸åˆ‡ç‰‡\n\næ”¯æŒå¸ƒå°”ç´¢å¼•ã€èŠ±å¼ç´¢å¼•ï¼Œæ¯” Python åŸç”Ÿæ›´çµæ´»å¼ºå¤§ã€‚\n\n\n\n# å¼•ç”¨\nimport numpy as np# å¤šç»´æ€§\narr = np.array(5)  # åˆ›å»ºäº†ä¸€ä¸ª 0 ç»´åº¦çš„æ•°ç»„print(arr)print('arrçš„ç»´åº¦ï¼š', arr.ndim)  # æ‰“å°ç»´åº¦ ndimarr = np.array([1, 2, 3])  # åˆ›å»ºäº†ä¸€ä¸ª 1 ç»´åº¦çš„æ•°ç»„print(arr)print('arrçš„ç»´åº¦ï¼š', arr.ndim)  # æ‰“å°ç»´åº¦ ndim# åŒè´¨æ€§\narr = np.array([1, 'hello', 3])  #æµ‹è¯•ä¸åŒè´¨print(arr)ç»“æœå…¨éƒ¨è½¬åŒ–ä¸ºå­—ç¬¦ä¸²\n# ndarray çš„å±æ€§\narr = np.array(1)print(arr)print('arrçš„ç»´åº¦ï¼š', arr.ndim)print('arrçš„å½¢çŠ¶ï¼š', arr.shape)print('arrçš„å…ƒç´ ä¸ªæ•°', arr.size)print('arrçš„æ•°æ®ç±»å‹', arr.dtype)\n1\narr çš„ç»´åº¦ï¼š 0\narr çš„å½¢çŠ¶ï¼š ()\n arr çš„å…ƒç´ ä¸ªæ•° 1\narr çš„æ•°æ®ç±»å‹ int64\n\narr = np.array([1, 2.7, 3])print(arr)print('arrçš„ç»´åº¦ï¼š', arr.ndim)print('arrçš„å½¢çŠ¶ï¼š', arr.shape)print('arrçš„å…ƒç´ ä¸ªæ•°', arr.size)print('arrçš„æ•°æ®ç±»å‹', arr.dtype)print('arrçš„è½¬ç½®', arr.T)\n[1.  2.7 3. ]\n arr çš„ç»´åº¦ï¼š 1\narr çš„å½¢çŠ¶ï¼š (3,)\n arr çš„å…ƒç´ ä¸ªæ•° 3\narr çš„æ•°æ®ç±»å‹ float64\narr çš„è½¬ç½® [1.  2.7 3.]\n\narr = np.array([[1, 2, 3], [4, 5, 6]])print(arr)print('arrçš„ç»´åº¦ï¼š', arr.ndim)print('arrçš„å½¢çŠ¶ï¼š', arr.shape)print('arrçš„å…ƒç´ ä¸ªæ•°', arr.size)print('arrçš„æ•°æ®ç±»å‹', arr.dtype)print('arrçš„è½¬ç½®', arr.T)\n[[1 2 3]\n[4 5 6]]\n arr çš„ç»´åº¦ï¼š 2\narr çš„å½¢çŠ¶ï¼š (2, 3)\n arr çš„å…ƒç´ ä¸ªæ•° 6\narr çš„æ•°æ®ç±»å‹ int64\narr çš„è½¬ç½® [[1 4]\n[2 5]\n[3 6]]\n\n# æŒ‡å®šå…ƒç´ æ•°æ®ç±»å‹\nlist1 = [4, 5, 6]arr = np.array(list1, dtype=np.float64)# é¢„å®šä¹‰æ•°ç»„\n# å…¨é›¶é˜µ\narr = np.zeros((4, 4), dtype=np.int64)arr = np.zeros((60,), dtype=np.int64)# å…¨ä¸€é˜µ\narr = np.ones((4, 4), dtype=np.int64)# ç©ºé˜µ\narr = np.empty((3, 4))# æ»¡é˜µ\narr = np.full((3, 4), 2)\n[[2 2 2 2]\n[2 2 2 2]\n[2 2 2 2]]\n\n# å½¢çŠ¶æ¨¡ä»¿\narr1 = np.zeros_like(arr)arr2 = np.ones_like(arr)arr3 = np.empty_like(arr)# å®šå¢é‡ï¼ˆç­‰å·®æ•°åˆ—ï¼‰\narr = np.arange(1, 106, 1)# å®šé—´éš”ï¼ˆç­‰åˆ†æ•°åˆ—ï¼‰\napp = np.linspace(1, 100, 10)# å¯¹è§’é˜µ\narr = np.diag([1, 2, 3, 4, 5])# éšæœºæ•°ç»„\n# é»˜è®¤é›¶åˆ°ä¸€\narr = np.random.rand(2, 4)# å‡åŒ€åˆ†å¸ƒï¼Œ 0~1# æŒ‡å®šåŒºé—´\narr = np.random.uniform(1, 4, (4, 4))# éšæœºæ•´æ•°\narr = np.random.randint(1, 10, (4, 4))# éšæœºæ­£æ€åˆ†å¸ƒ\narr = np.random.randn(4, 4)# éšæœºç§å­\n# è®¾ç½®éšæœºç§å­ï¼Œæ¯æ¬¡ç”Ÿæˆçš„éšæœºæ•°ç›¸åŒnp.random.seed(20)arr = np.random.randint(1, 4, (4, 4))# å•ä½çŸ©é˜µ\narr = np.eye(5, dtype=int)# æ•°æ®ç±»å‹\n# ndarray çš„æ•°æ®ç±»å‹\n\nå¸ƒå°”ç±»å‹\næ•´å½¢\næµ®ç‚¹å‹\nå¤æ•°å‹\n\nä¸»è¦é€šè¿‡ dtype æŒ‡å®š\narr = np.array([1, 2, 3, 0, -1], dtype=np.int8)arr = np.array([1, 2, 3, 0, -1], dtype=np.float32)# ç´¢å¼•ä¸åˆ‡ç‰‡\n# ç´¢å¼•\n# ä¸€ç»´æ•°ç»„arr = np.random.randint(10, 100, 30)# ä¸€ç»´ç´¢å¼•print(arr[3])print(arr[7])# ä¸€ç»´å¸ƒå°”ç´¢å¼•print(arr[(arr > 30) &amp; (arr &lt; 50)])# äºŒç»´æ•°ç»„arr = np.random.randint(10, 100, (5, 8))# äºŒç»´ç´¢å¼•print(arr[2, 3])print(arr[2][3])# åˆ‡ç‰‡\n# ä¸€ç»´åˆ‡ç‰‡print(arr[3:7])print(arr[slice(3, 7)])print(arr[slice(0, 10, 2)])# äºŒç»´åˆ‡ç‰‡print(arr[0, 1:3])print(arr[arr > 70])print(arr[0][arr[0] > 90])print(arr[3])print(arr[:, 3])# è¿ç®—\n# å¸¸è§„è¿ç®—\narr1 = np.array([1, 2, 3])arr2 = np.array([4, 5, 6])print(arr1 + arr2)print(arr1 * arr2)print(arr1 - arr2)print(arr1 / arr2)print(arr1 ** arr2)# python åŸç”ŸlistA = [1, 2, 3]listB = [4, 5, 6]for i in range(len(listA)):    print(listA[i] + listB[i])python åŸç”Ÿåªæ˜¯çº¯ç²¹çš„æ‹¼æ¥ï¼Œndarray æ˜¯åœ¨å¸®ä½ åšè®¡ç®—\narr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])arr2 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(arr1 + arr2)print(arr1 * arr2)print(arr1 - arr2)print(arr1 / arr2)print(arr1 ** arr2)# å¹¿æ’­æœºåˆ¶\n# å¹¿æ’­æœºåˆ¶ï¼Œä½†æ˜¯éœ€æ»¡è¶³ç»´åº¦ä¸€è‡´arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])arr2 = np.array([1, 2, 3])  # [1, 2, 3],[1, 2, 3],[1, 2, 3]print(arr1 + arr2)print(arr1 * arr2)arr1 = np.array([[1, 2, 3]])arr2 = np.array([[1], [2], [3]])print(arr1 + arr2)# çŸ©é˜µçš„è¿ç®—\n# çŸ©é˜µè¿ç®—arr1 = np.array([[1, 2, 3], [4, 5, 6]])arr2 = np.array([[4, 5], [1, 2], [7, 8]])print(arr1.dot(arr2))  # çŸ©é˜µçš„ä¹˜æ³•ï¼ŒçŸ©é˜µçš„è¡Œæ•°å¿…é¡»ç­‰äºçŸ©é˜µçš„åˆ—æ•°ï¼Œä¸æ˜¯ç®€å•çš„å¯¹åº”ç›¸ä¹˜print(arr1 @ arr2)# å¸¸ç”¨å‡½æ•°\n# æ•°å­¦å‡½æ•°\n# å¹³æ–¹æ ¹\nprint(np.sqrt(9))print(np.sqrt([1, 4, 9]))# æŒ‡æ•°\n# è®¡ç®—æŒ‡æ•°print(np.exp(1))  #  e^1print(np.exp([0, 2, 3]))# è‡ªç„¶å¯¹æ•°\n# è®¡ç®—è‡ªç„¶å¯¹æ•°print(np.log(np.e))print(np.log([1, np.e, np.e ** 2]))print(np.log10(100))# ä¸‰è§’å‡½æ•°\n# è®¡ç®—ä¸‰è§’å‡½æ•°print(np.sin(np.pi / 2))  # sin(Ï€/2)print(np.cos(np.pi))  # cos(Ï€)# ç»å¯¹å€¼\n# è®¡ç®—ç»å¯¹å€¼print(np.abs(-1))print(np.abs(np.array([1, -1, 0, -2, 2, -3, 3, -4, 4, -5, 5])))# a çš„ b æ¬¡å¹‚\n# è®¡ç®— a çš„ b æ¬¡å¹‚print(np.power(2, 3))# å››èˆäº”å…¥\n# å››èˆäº”å…¥print(np.round(3.14))print(np.round([3.14, 2.7, 1.5, 1.2]))# ä¸Šå–æ•´ä¸ä¸‹å–æ•´\n# å‘ä¸Šå–æ•´ï¼Œå‘ä¸‹å–æ•´arr = np.array([1.2, 1.5, 1.6, 1.7, 2.2, 2.5, 2.6, 2.7])print(np.ceil(arr))print(np.floor(arr))# æ£€æµ‹ç¼ºå¤±å€¼\narr = np.array([1, 2, np.nan, 4, np.nan])print(np.isnan(arr))# ç»Ÿè®¡å‡½æ•°\næ±‚å’Œã€è®¡ç®—å¹³å‡å€¼ã€è®¡ç®—ä¸­ä½æ•°ã€æ ‡å‡†å·®ã€æ–¹å·®ã€æœ€å¤§å€¼ã€æœ€å°å€¼ã€è®¡ç®—åˆ†ä½æ•°ã€ç´¯ç§¯å’Œã€ç´¯ç§¯å·®\narr = np.random.randint(1, 10, 10)print(arr)  # åˆ›å»ºä¸€ä¸ª 10 ä¸ªå…ƒç´ çš„æ•°ç»„print('æ’åº', np.sort(arr))print('æ±‚å’Œ', np.sum(arr))  # æ±‚å’Œprint('è®¡ç®—å¹³å‡å€¼', np.mean(arr))  # è®¡ç®—å¹³å‡å€¼print('è®¡ç®—ä¸­ä½æ•°', np.median(arr))  # è®¡ç®—ä¸­ä½æ•°print('æ ‡å‡†å·®', np.std(arr))  # æ ‡å‡†å·® print('æ–¹å·®', np.var(arr))  # æ–¹å·® ((1-2)^2 + (2-2)^2 + ... + (9-2)^2) / 9print('æœ€å¤§å€¼', np.max(arr))  # æœ€å¤§å€¼print('æœ€å°å€¼', np.min(arr))  # æœ€å°å€¼print('è®¡ç®—åˆ†ä½æ•°', np.quantile(arr, 0.5))  # è®¡ç®—åˆ†ä½æ•°print('ç´¯ç§¯å’Œ', np.cumsum(arr))  # ç´¯ç§¯å’Œprint('ç´¯ç§¯å·®', np.cumprod(arr))  # ç´¯ç§¯å·®# æ¯”è¾ƒå‡½æ•°\n# æ˜¯å¦å¤§äºprint(np.greater([1, 3, 5, 1, 8, 0, -23, 3], 2))# æ˜¯å¦å°äºprint(np.less([1, 3, 5, 1, 8, 0, -23, 3], 2))# æ˜¯å¦ç­‰äºprint(np.equal([1, 3, 5, 1, 8, 0, -23, 3], 3))# é€»è¾‘è¿ç®—\n# é€»è¾‘è¿ç®—print(np.logical_and([1, 3, 5, 1, 8, 0, -23, 3], [1, 3, 5, 1, 8, 0, -23, 3]))print(np.logical_or([1, 3, 5, 1, 8, 0, -23, 3], [1, 3, 5, 1, 8, 0, -23, 3]))# è‡ªå®šä¹‰æ¡ä»¶\narr = np.array([1, 3, 5, 1, 8, 0, -23, 3])print(np.where(arr > 3, arr, 0))print(np.select([arr > 3, arr &lt; 0], [arr, 0], default=arr))# æ’åºå‡½æ•°\narr = np.random.randint(1, 10, 20)print(arr)print(np.sort(arr))print(np.argsort(arr))  # è¿”å›æ’åºåçš„ç´¢å¼•# å»é‡\narr = np.array([1, 3, 5, 1, 8, 0, -23, 3])print(np.unique(arr))# æ•°ç»„çš„æ‹¼æ¥\narr1 = np.array([1, 2, 3])arr2 = np.array([4, 5, 6])print(np.concatenate((arr1, arr2)))# æ•°ç»„åˆ†å‰²\narr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])print(np.split(arr, [3, 5]))  # åˆ†æˆ 3 ä»½# è°ƒæ•´å½¢çŠ¶\narr = np.random.randint(1, 10, 20)print(arr)print(arr.reshape(4, 5))# æ¡ˆä¾‹ç»ƒä¹ \n# æ¸©åº¦æ•°æ®åˆ†æ\næŸåŸå¸‚ä¸€å‘¨çš„æœ€é«˜æ°”æ¸©ï¼ˆâ„ƒï¼‰ä¸º [28, 30, 29, 31, 32, 30, 29]ã€‚\n\nè®¡ç®—å¹³å‡æ°”æ¸©ã€æœ€é«˜æ°”æ¸©å’Œæœ€ä½æ°”æ¸©ã€‚\næ‰¾å‡ºæ°”æ¸©è¶…è¿‡ 30â„ƒ çš„å¤©æ•°ã€‚\n\narr = np.array([28, 30, 29, 31, 32, 30, 29])print('å¹³å‡å¤©æ°”ï¼š', np.mean(arr))print('æœ€é«˜æ°”æ¸©ï¼š', np.max(arr))print('æœ€ä½æ°”æ¸©ï¼š', np.min(arr))print('æ°”æ¸©è¶…è¿‡30â„ƒçš„å¤©æ•°ï¼š', np.sum(arr > 30))# å­¦ç”Ÿæˆç»©ç»Ÿè®¡\næŸç­çº§ 5 åå­¦ç”Ÿçš„æ•°å­¦æˆç»©ä¸º [85, 90, 78, 92, 88]ã€‚\n\nè®¡ç®—æˆç»©çš„å¹³å‡åˆ†ã€ä¸­ä½æ•°å’Œæ ‡å‡†å·®ã€‚\nå°†æˆç»©è½¬æ¢ä¸ºç™¾åˆ†åˆ¶ï¼ˆå‡è®¾æ»¡åˆ†ä¸º 100ï¼‰ã€‚\n\narr = np.array([85, 90, 78, 92, 88])print('å¹³å‡æˆç»©ï¼š', np.mean(arr))print('ä¸­ä½æ•°ï¼š', np.median(arr))print('æ ‡å‡†å·®ï¼š', np.std(arr))print('æˆç»©è½¬æ¢ä¸ºç™¾åˆ†åˆ¶ï¼š', arr / 100 * 100)# æ•°ç»„å˜å½¢\né¢˜ç›®ï¼šåˆ›å»ºä¸€ä¸ª 1 åˆ° 12 çš„ä¸€ç»´æ•°ç»„ï¼Œå¹¶è½¬æ¢ä¸º (3, 4) çš„äºŒç»´æ•°ç»„ã€‚\n\nè®¡ç®—æ¯è¡Œçš„å’Œä¸æ¯åˆ—çš„å¹³å‡å€¼ã€‚\nå°†æ•°ç»„å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ã€‚\n\narr = np.linspace(1, 12, 12, dtype=int)arr = arr.reshape(3, 4)print(arr)print(arr.sum(axis=1))print(arr.mean(axis=0))print(arr.flatten())","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","python_NumPy"]},{"title":"Pandasæ ¸å¿ƒå¤„ç†æ–¹æ³•","url":"/python/pandas/","content":"# Pandas æ ¸å¿ƒå¤„ç†æ–¹æ³•\n# ä»€ä¹ˆæ˜¯ Pandas\nPandas æ˜¯ä¸€ä¸ªåŸºäº Python çš„å¼€æºæ•°æ®åˆ†æå’Œæ•°æ®å¤„ç†åº“\nå®ƒæä¾›äº†ä¸¤ç§æ ¸å¿ƒæ•°æ®ç»“æ„ï¼š\n\n\n\næ•°æ®ç»“æ„\næè¿°\nç±»ä¼¼äº\nç´¢å¼•\næ•°æ®å­˜å‚¨\nç±»æ¯”\n\n\n\n\nSeries\nä¸€ç»´å¸¦æ ‡ç­¾çš„æ•°ç»„\nä¸€åˆ—\nå•ç´¢å¼•\nåŒè´¨åŒ–\nExcel å•åˆ—\n\n\nDataFrame\näºŒç»´å¸¦æ ‡ç­¾çš„è¡¨æ ¼æ•°æ®ç»“æ„\nä¸€å¼ è¡¨æ ¼ï¼ˆåƒ Excel è¡¨ï¼‰\nåŒç´¢å¼•\nå„ä¸ªåˆ—ä¹‹é—´å¯ä»¥æ˜¯ä¸åŒçš„\næ•´ä¸ª Excel è¡¨æ ¼\n\n\n\nåº”ç”¨åœºæ™¯ï¼š\n\næ•°æ®é¢„å¤„ç†ï¼ˆæœºå™¨å­¦ä¹ å‰ï¼‰\næ•°æ®ç»Ÿè®¡åˆ†æ\nè‡ªåŠ¨åŒ–æŠ¥è¡¨\næ•°æ®å¯è§†åŒ–å‰å¤„ç†\n\n# Series\nSeries å°±åƒè¿™æ ·ï¼š\n\n\n\nSeries Index\nSeries Name\n\n\n\n\n1\nSeries Values\n\n\n2\nSeries Values\n\n\n3\nSeries Values\n\n\n\n# åˆ›å»ºæ–¹æ³•\n# series çš„åˆ›å»ºimport pandas as pds = pd.Series([1,2,3,4,5])print(s)# è‡ªå®šä¹‰ç´¢å¼•s = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])print(s)# å®šä¹‰ Names = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'], name='æˆ‘æ˜¯xxx')print(s)å·¦ä¾§æ˜¯ç´¢å¼•ï¼Œå³ä¾§æ˜¯å€¼\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\na    1\nb    2\nc    3\nd    4\ne    5\nName: æˆ‘æ˜¯ xxx, dtype: int64\n\n# é€šè¿‡å­—å…¸æ–¹å¼æ¥åˆ›å»ºs = pd.Series(&#123;'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5&#125;)print(s)# é€šè¿‡ Series å¯¹è±¡æ¥åˆ›å»ºï¼ˆæˆªå–ï¼‰s1=pd.Series(s,index=['a','c'])print(s1)# åŸºæœ¬å±æ€§\n\n\n\nå±æ€§\nè¯´æ˜\nç¤ºä¾‹\n\n\n\n\nindex\nè¡Œç´¢å¼•ï¼ˆæ ‡ç­¾ï¼‰å¯¹è±¡\ns.index\n\n\nvalues\næ•°æ®å€¼ç»„æˆçš„  numpy  æ•°ç»„\ns.values\n\n\ndtype\næ•°æ®ç±»å‹\ns.dtype\n\n\nsize\nå…ƒç´ æ€»ä¸ªæ•°\ns.size\n\n\nshape\næ•°æ®ç»“æ„çš„å½¢çŠ¶ï¼ˆé•¿åº¦ï¼Œï¼‰\ns.shape\n\n\nndim\nç»´åº¦ï¼ŒSeries æ°¸è¿œæ˜¯ 1\ns.ndim\n\n\nname\nSeries çš„åç§°ï¼ˆå¯è‡ªå®šä¹‰ï¼‰\ns.name\n\n\nis_unique\næ˜¯å¦å…¨æ˜¯å”¯ä¸€å€¼\ns.is_unique\n\n\nhasnans\næ˜¯å¦å«æœ‰ç¼ºå¤±å€¼ï¼ˆNaNï¼‰\ns.hasnans\n\n\n\n# Series å¯¹è±¡å±æ€§s = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])print(s.values)print(s.index)print(s.name)print(s.dtype)print(s.size)print(s.empty)print(s.ndim)print(s.shape)print(s.is_unique)print(s.loc['e'])  # é€šè¿‡ç´¢å¼•è·å–ï¼Œæ˜¾ç¤ºç´¢å¼•print(s.iloc[4])  # é€šè¿‡ä½ç½®è·å–ï¼Œéšå¼ç´¢å¼•# æ”¯æŒåˆ‡ç‰‡print(s.loc['a':'d'])print(s.iloc[0:3])# è®¿é—®æ•°æ®\nprint(s.iloc[2])print(s['b'])print(s[s &lt; 3]) # å¸ƒå°”ç´¢å¼•print(s.isin([1, 2, 3]))print(s[s.isin([1, 2, 3])])s = pd.Series([1, np.nan, 3, None, 5, 6, 7, 8, 9, 10], index=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'], name='testData')s.head()s.tail(2)# è®¡ç®—ä¸å¸¸ç”¨ç»Ÿè®¡æ–¹æ³•\n# æ‰€æœ‰æè¿°ä¿¡æ¯çš„è¯­å¥s.describe()# æ˜¯å¦åŒ…å«åœ¨å…¶ä¸­s.isin([1, 9, 3])# æ’åºs.sort_values()# åˆ†ä½æ•°s.quantile(0.5)# ç»Ÿè®¡ä¸ªæ•°s.value_counts()# ä¼—æ•°s.mode()# Series æ¡ˆä¾‹\n\nåˆ›å»ºä¸€ä¸ªåŒ…å«ååå­¦ç”Ÿæ•°å­¦æˆç»©çš„ Seriesï¼Œæˆç»©èŒƒå›´åœ¨ 50 åˆ° 100 é—´ï¼Œè®¡ç®—å¹³å‡åˆ†ã€æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹¶æ‰¾å‡ºé«˜äºå¹³å‡åˆ†çš„å­¦ç”Ÿäººæ•°ã€‚\n\nprint(scores.mean())print(scores.max())print(scores.min())print(scores[scores.mean() &lt; scores].count())\nç»™å®šæŸåŸå¸‚ä¸€å‘¨æ¯å¤©çš„æœ€é«˜æ¸©åº¦ Seriesï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\næ‰¾å‡ºæ¸©åº¦è¶…è¿‡ 30 åº¦çš„å¤©æ•°\nè®¡ç®—å¹³å‡æ¸©åº¦å°†æ¸©åº¦ä»é«˜åˆ°ä½æ’åº\næ‰¾å‡ºæ¸©åº¦å˜åŒ–æœ€å¤§çš„ä¸¤å¤©\n\nprint(temperatures[temperatures > 30].count())print(temperatures.sort_values(ascending=False))temperatures.diff().abs().sort_values(ascending=False).head(2)\nè‚¡ç¥¨ä»·æ ¼åˆ†æç»™å®šæŸè‚¡ç¥¨è¿ç»­ 10 ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»· Series:\nè®¡ç®—æ¯æ—¥æ”¶ç›Šç‡ (å½“æ—¥æ”¶ç›˜ä»· / å‰æ—¥æ”¶ç›˜ä»· - 1)\næ‰¾å‡ºæ”¶ç›Šç‡æœ€é«˜å’Œæœ€ä½çš„æ—¥æœŸ\nè®¡ç®—æ³¢åŠ¨ç‡ (æ”¶ç›Šç‡çš„æ ‡å‡†å·®)\n\n# è®¡ç®—æ”¶ç›Šç‡ pct->percent price.pct_change()a = price.pct_change()a.idxmax()price.pct_change().idxmin()price.pct_change().std()\næŸäº§å“è¿‡å» 12 ä¸ªæœˆçš„é”€å”®é‡ Series:\nè®¡ç®—å­£åº¦å¹³å‡é”€é‡ (æ¯ 3 ä¸ªæœˆä¸ºä¸€ä¸ªå­£åº¦)\næ‰¾å‡ºé”€é‡æœ€é«˜çš„æœˆä»½\nè®¡ç®—æœˆç¯æ¯”å¢é•¿ç‡\næ‰¾å‡ºè¿ç»­å¢é•¿è¶…è¿‡ 2 ä¸ªæœˆçš„æœˆä»½\n\n# resample->qs æŒ‰ç…§å­£åº¦å¼€å§‹é‡æ–°é‡‡æ ·sales.resample('QS').mean()sales.idxmax()# æœˆç™¾åˆ†æ¯”å˜åŒ–ï¼Œå³ä¸ºç¯æ¯”sales.pct_change()# ç¯æ¯”å¤§äºé›¶ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£ï¼Œå’Œä¸º 3pct_c = sales.pct_change()b = pct_c > 0b[b.rolling(window=3).sum() == 3].keys().tolist()\næŸå•†åº—æ¯å°æ—¶é”€å”®é¢ Series:\næŒ‰å¤©é‡é‡‡æ ·è®¡ç®—æ¯æ—¥æ€»é”€å”®é¢\nè®¡ç®—æ¯å¤©è¥ä¸šæ—¶é—´ (8:00-22:00) å’Œéè¥ä¸šæ—¶é—´çš„é”€å”®é¢æ¯”ä¾‹\næ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„ 3 ä¸ªå°æ—¶\n\nhourly_sales.resample('D').sum()# ä¸¤ç§æ–¹æ³•hourly_sales[(hourly_sales.index.hour>=8)&amp;(hourly_sales.index.hour&lt;=22)].sum()hourly_sales.between_time('8:00', '22:00')# æœ€ç»ˆè®¡ç®—hourly_sales[(hourly_sales.index.hour>=8)&amp;(hourly_sales.index.hour&lt;=22)].sum()/(hourly_sales.sum() - hourly_sales[(hourly_sales.index.hour>=8)&amp;(hourly_sales.index.hour&lt;=22)].sum())# å¯åœ¨å…¨éƒ¨çš„ç´¢å¼•ä¸­å»é™¤è¥ä¸šç´¢å¼•hourly_sales.drop(hourly_sales[(hourly_sales.index.hour>=8)&amp;(hourly_sales.index.hour&lt;=22)].index)# é”€å”®é¢æœ€é«˜çš„ 3 ä¸ªå°æ—¶ï¼Œä¸¤ç§æ–¹æ³•hourly_sales.sort_values(ascending=False).head(3)hourly_sales.nlargest(3).keys()# DataFrame\n# è¯»å– JSONL\npd.read_json(\"../data/raw/synthesized_.jsonl\", lines=True)# ä¿å­˜ä¸º JSON / JSONL\nimport pandas as pdframe = pd.DataFrame(dict(A=range(1, 4), B=range(4, 7), C=range(7, 10)), columns=['A', 'B', 'C'], index=['x', 'y', 'z'])print(frame)print(frame.to_json(orient='index'))print(frame.to_json(orient='columns'))vprint(frame.to_json(orient='split'))print(frame.to_json(orient='records', lines=True))\nA  B  C\nx  1  4  7\ny  2  5  8\nz  3  6  9\n{â€œxâ€:{â€œAâ€:1,â€œBâ€:4,â€œCâ€:7},â€œyâ€:{â€œAâ€:2,â€œBâ€:5,â€œCâ€:8},â€œzâ€:{â€œAâ€:3,â€œBâ€:6,â€œCâ€:9}}\n\n{â€œAâ€:1,â€œBâ€:4,â€œCâ€:7}\n\n\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","python_Pandas"]},{"title":"PyTorchæ·±åº¦å­¦ä¹ ","url":"/python/pytorch/","content":"# PyTorch æ·±åº¦å­¦ä¹ \nåŸºäºå°åœŸå †ï¼šhttps://www.bilibili.com/video/BV1hE411t7RN\n# å®‰è£…\nåŸºäº conda ç¯å¢ƒæ¥å®‰è£…\nconda create --name pytorch python=3.11æŸ¥è¯¢å·²æœ‰ç¯å¢ƒ\nconda info --envs\nconda environments:\nbase                   * D:\\anaconda\npytorch              D:\\anaconda\\envs\\pytorch\n\næ¿€æ´» pytorch ç¯å¢ƒ\nconda activate pytorchå…¶ä»–å‘½ä»¤\nconda remove -n xxxxx(åå­—) --all\t# ç¯å¢ƒåˆ é™¤å‘½ä»¤deactivate\t# é€€å‡ºè™šæ‹Ÿç¯å¢ƒpip list\t# æŸ¥çœ‹è™šæ‹Ÿç¯å¢ƒçš„åº“è®¿é—® pytorch ç½‘ç«™ï¼šhttps://pytorch.org/get-started/locally/\n\næˆªè‡³ 2025 å¹´ 8 æœˆ Start Locally æ¡ç›®ç»™äºˆ python ç‰ˆæœ¬æç¤ºï¼š\nNOTE: Latest PyTorch requires Python 3.9 or later.\n\nåŸºäºï¼šStable (2.7.1) - Windows - Pip - Python - CUDA 11.8\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118(pytorch) C:\\Users\\Karry>pip listPackage           Version----------------- ------------filelock          3.13.1fsspec            2024.6.1Jinja2            3.1.4MarkupSafe        2.1.5mpmath            1.3.0networkx          3.3numpy             2.1.2pillow            11.0.0pip               25.1setuptools        78.1.1sympy             1.13.3torch             2.7.1+cu118torchaudio        2.7.1+cu118torchvision       0.22.1+cu118typing_extensions 4.12.2wheel             0.45.1éªŒè¯ï¼š\nimport torchtorch.cuda.is_available()\t# True# ä¸¤å¤§æ³•å®å‡½æ•° - dir ä¸ help\ndir ä¸»è¦æ˜¯æ¥æŸ¥çœ‹ä¸€ä¸ªå·¥å…·åŒ…ä¸‹è¿˜æœ‰ä»€ä¹ˆå­å·¥å…·åŒ…æˆ–è€…å·¥å…·\nhelp ä¸»è¦æ˜¯æŸ¥çœ‹ä¸€äº›å·¥å…·æœ‰ä»€ä¹ˆä½œç”¨\næ¯”å¦‚ help (torch.cuda.is_available)\nhelp(torch.cuda.is_available)Help on function is_available in module torch.cuda:is_available() -> bool    Return a bool indicating if CUDA is currently available.# PyTorch æ•°æ®è¯»å–\næ•°æ® â€”â€” Datasetï¼ˆæä¾›ä¸€ç§æ–¹å¼è·å– labelï¼‰ â€”â€” Dataloaderï¼ˆä¸ºåé¢çš„ç½‘ç»œæä¾›ä¸åŒçš„æ•°æ®å½¢å¼ï¼‰\nç»„ç»‡ç»“æ„ï¼š\n+â€”â€” hymenoptera_data| +â€”â€” train| | â€”â€” ants| | â€”â€” beeså¯¹åº”ä»£ç ï¼š\nfrom torch.utils.data import Datasetfrom PIL import Imageimport os# MyData æ˜¯è‡ªå®šä¹‰çš„æ•°æ®é›†ç±»ï¼Œä»–ç»§æ‰¿äº† Dataset ç±»ï¼ŒMyData (Dataset) è¿™æ˜¯ç»§æ‰¿åŠ¨ä½œclass MyData(Dataset):    # åˆå§‹åŒ–å‡½æ•°ï¼Œåˆå§‹åŒ–ä¸€äº›æ•°æ®ï¼Œæ¯”å¦‚å›¾ç‰‡è·¯å¾„ï¼Œæ ‡ç­¾è·¯å¾„ç­‰ç­‰ï¼Œ__init__è¿™æ˜¯é‡å†™çˆ¶ç±»çš„æ–¹æ³•    def __init__(self, root_dir, label_dir):        # æ ¹é›†è·¯å¾„        self.root_dir = root_dir        # æ ‡ç­¾è·¯å¾„ï¼Œè¿™å…¶å®è¡¨è¾¾äº†å›¾ç‰‡æ˜¯ä»€ä¹ˆåˆ†ç±»        self.label_dir = label_dir        # è·å–å›¾ç‰‡çš„è·¯å¾„ï¼Œè¿™ä¸ªè·¯å¾„ä¸‹å­˜æ”¾ç€å›¾ç‰‡        self.path = os.path.join(self.root_dir, self.label_dir)        # è·å–å›¾ç‰‡è·¯å¾„åˆ—è¡¨ listdir        self.img_path = os.listdir(self.path)    # è·å–æ•°æ®ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯å¿…é¡»å†™çš„ï¼Œå¹¶ä¸”æ˜¯å¿…é¡»è¿”å›ä¸¤ä¸ªå€¼ï¼Œä¸€ä¸ªæ˜¯å›¾ç‰‡ï¼Œä¸€ä¸ªæ˜¯æ ‡ç­¾    def __getitem__(self, idx):        img_name = self.img_path[idx]        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)        img = Image.open(img_item_path)        label = self.label_dir        return img, label    def __len__(self):        return len(self.img_path)root_dir = \"hymenoptera_data\\\\train\"ant_label_dir = \"ants\"bees_label_dir = \"bees\"ants_dataset = MyData(root_dir, ant_label_dir)bees_dataset = MyData(root_dir, bees_label_dir)train_dataset = ants_dataset + bees_datasetç»„ç»‡ç»“æ„ï¼š\n+â€”â€” hymenoptera_data_ex| +â€”â€” train| | â€”â€” ants_image| | â€”â€” ants_label| | â€”â€” bees_image| | â€”â€” bees_labelå¯¹åº”ä»£ç ï¼š\nfrom torch.utils.data import Datasetfrom PIL import Imageimport osclass MyData(Dataset):    def __init__(self, root_dir, img_dir, label_dir):        self.root_dir = root_dir        self.img_dir = img_dir        self.label_dir = label_dir        self.path_img = os.path.join(self.root_dir, self.img_dir)        self.path_label = os.path.join(self.root_dir, self.label_dir)        self.img_path = os.listdir(self.path_img)        self.label_path = os.listdir(self.path_label)    def __getitem__(self, item):        img_name = self.img_path[item]        img_item_path = os.path.join(self.path_img, img_name)        img = Image.open(img_item_path)        label_name = self.label_path[item]        label_item_path = os.path.join(self.path_label, label_name)        with open(label_item_path, \"r\", encoding=\"utf-8\") as f:            label = f.read()            return img, labelroot_dir = \"hymenoptera_data_ex\\\\train\"img_dir = \"ants_image\"label_dir = \"ants_label\"ants_dataset = MyData(root_dir, img_dir, label_dir)# Tensorboard çš„ä½¿ç”¨\n# add_scalar\nfrom torch.utils.tensorboard import SummaryWriterwriter = SummaryWriter(\"logs\")# writer.add_image()# y = xfor i in range(100):    writer.add_scalar(\"y=i^2\", i * i, i)writer.close()tensorboard --logdir=logs --port=6007\nwriter.add_scalar (â€œy=i^2â€, i * i, i)ï¼Œè¿™ä¸ªçš„å‚æ•°åˆ†åˆ«æ˜¯ï¼šæ ‡ç­¾ã€yã€x\n# add_image\nimport numpy as npfrom PIL import Imagefrom torch.utils.tensorboard import SummaryWriterimg_path = \"hymenoptera_data/train/ants/0013035.jpg\"img_PIL = Image.open(img_path)img_array = np.array(img_PIL)# hymenoptera_data/train/ants/0013035.jpgwriter = SummaryWriter(\"logs\")writer.add_image(\"img\", img_array, 1,dataformats=\"HWC\")# y = xfor i in range(100):    writer.add_scalar(\"y=i^2\", i * i, i)writer.close()\nadd_image (â€œimgâ€, img_array, 1,dataformats=â€œHWCâ€)ï¼Œè¿™ä¸ªå‚æ•°åˆ†åˆ«æ˜¯ï¼šæ ‡ç­¾ã€ndarray ç±»å‹çš„å›¾ç‰‡ã€æ­¥éª¤ã€dataformats-HWC\n# Transforms çš„ä½¿ç”¨\nTransforms ä¸»è¦æ˜¯å¯¹å›¾ç‰‡çš„å„ç§å˜æ¢ï¼Œæ˜¯é¢„å¤„ç†ï¼Ÿ\nfrom PIL import Imagefrom torchvision import transformsimg = Image.open('hymenoptera_data/train/ants/0013035.jpg')tensor_trans = transforms.ToTensor()tensor_img = tensor_trans(img)print(tensor_img)Image.open è¿”å›äº† PIL ç±»å‹çš„å›¾ç‰‡ï¼Œé€šè¿‡ transforms.ToTensor () åˆ›å»ºäº†å·¥å…·å¯¹è±¡ï¼Œæœ€åä½¿ç”¨ tensor_trans (img) è½¬åŒ–ä¸º tensor ç±»å‹\n\ntensor æ•°æ®ç±»å‹ï¼šåŒ…è£…äº†ç¥ç»ç½‘ç»œæ‰€éœ€è¦çš„ç†è®ºåŸºç¡€å‚æ•°\n\nä½¿ç”¨ SummaryWriter å°† tensor_img å†™å…¥\nfrom PIL import Imagefrom torch.utils.tensorboard import SummaryWriterfrom torchvision import transformsimg = Image.open('hymenoptera_data/train/ants/0013035.jpg')tensor_trans = transforms.ToTensor()tensor_img = tensor_trans(img)# print(tensor_img)writer = SummaryWriter('logs')writer.add_image('tensor_img', tensor_img)writer.close()\n\né¢˜å¤–è¯ï¼Œç†è§£ä¸€ä¸‹ py çš„é¢å‘å¯¹è±¡ï¼š\nclass Person:    def __init__(self, name):        self.name = name    def __call__(self):        print(\"hello\", self.name)    def hello(self):        print(\"hello_ex\", self.name)person = Person(\"Karry\")person()person.hello()init æ–¹æ³•å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ„é€ æ–¹æ³•ï¼Œperson = Person (â€œKarryâ€) æ‰§è¡Œåè°ƒç”¨æ„é€ æ–¹æ³•\ncall æ–¹æ³•åƒåˆæ¬¡è§é¢é—®å¥½ä¸€æ · person () æ‰§è¡Œåï¼Œè°ƒç”¨ call æ–¹æ³•ï¼Œæ˜¯è®©å®ä¾‹åƒå‡½æ•°ä¸€æ ·ç”¨çš„é’©å­æ–¹æ³•\nperson.hello () åªæ˜¯ä¸€ä¸ªç±»çš„æ™®é€šæ–¹æ³•\n\n# ToTensor çš„ä½¿ç”¨\nToTensor å›¾ç‰‡å¼ é‡åŒ–å·¥å…·\nfrom PIL import Imagefrom torch.utils.tensorboard import SummaryWriterfrom torchvision import transformswriter = SummaryWriter('logs')img = Image.open('images/pytorch.png')toTensorTools = transforms.ToTensor()img_tensor = toTensorTools(img)writer.add_image('ToTensor', img_tensor)writer.close()# Normalize çš„ä½¿ç”¨\nNormalize å½’ä¸€åŒ–ã€æ ‡å‡†åŒ–ï¼Œå‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1ï¼Œæ•°å€¼ä½äº - 1 åˆ° 1 ä¹‹é—´\nå¦‚æœå›¾ç‰‡ä¸æ˜¯ RGB æ¨¡å¼éœ€è¦åš img.convert (â€˜RGBâ€™)\nwriter = SummaryWriter('logs')img = Image.open('images/pytorch.png')# img è½¬åŒ–ä¸º RGBimg = img.convert('RGB')toTensorTools = transforms.ToTensor()img_tensor = toTensorTools(img)writer.add_image('ToTensor', img_tensor)print(img_tensor[0][0][0])# å½’ä¸€åŒ–transforms_normalize = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])img_normalize = transforms_normalize(img_tensor)print(img_normalize[0][0][0])writer.close()tensor(0.1333)\ntensor(-0.7333)\n0.1333*2 - 1 = -0.7333\n# Resize çš„ä½¿ç”¨\nResize é‡è°ƒæ•´\n# Resize çš„ä½¿ç”¨print(img.size)transforms_resize = transforms.Resize([128, 128])img_resize = transforms_resize(img_tensor)writer.add_image('Resize', img_resize, 0)print(img_resize.size())resize_2 = transforms.Resize(512)transforms_compose = transforms.Compose([resize_2, toTensorTools])img_resize_2 = transforms_compose(img)writer.add_image('Compose', img_resize_2, 1)èµ·åˆæˆ‘ä»¬ä½¿ç”¨ img = Image.open (â€˜images/testFG.jpgâ€™)ï¼Œæ­¤æ—¶è¿™æ˜¯ä¸€ä¸ª PIL å›¾ç‰‡ï¼Œå¦‚ä½•æˆ‘ä»¬ä½¿ç”¨ toTensorTools = transforms.ToTensor () åˆ›å»ºå¼ é‡è½¬æ¢å·¥å…·ï¼Œä½¿ç”¨ img_tensor = toTensorTools (img) å°† PIL å›¾ç‰‡è½¬åŒ–ä¸º img_tensor å¼ é‡å›¾ç‰‡ï¼Œç´§æ¥ç€æˆ‘ä»¬ä½¿ç”¨ transforms_resize = transforms.Resize ([128, 128]) åˆ›å»ºå°ºå¯¸è°ƒæ•´å·¥å…·ï¼Œä½¿ç”¨ img_resize = transforms_resize (img_tensor) å¯¹å¼ é‡å›¾ç‰‡é‡è°ƒæ•´ã€‚\nCompose çš„æ„ä¹‰åœ¨äºå®ƒå¯ä»¥å°†å¤šä¸ªå›¾åƒå˜æ¢æ“ä½œï¼ˆå¦‚ç¼©æ”¾ã€è£å‰ªã€å½’ä¸€åŒ–ç­‰ï¼‰æŒ‰é¡ºåºç»„åˆæˆä¸€ä¸ªæµæ°´çº¿ï¼Œè¾“å…¥å›¾åƒä¼šä¾æ¬¡é€šè¿‡è¿™äº›å˜æ¢ã€‚\næˆ‘ä»¬ä½¿ç”¨ transforms_compose = transforms.Compose ([resize_2, toTensorTools]) åˆ›å»ºäº†ä¸€ä¸ªå·¥å…·é“¾ï¼Œresize_2 ç”¨äºè°ƒæ•´å›¾åƒå°ºå¯¸ï¼ŒtoTensorTools ç”¨äºå…¶è½¬åŒ–ä¸ºå¼ é‡å›¾ç‰‡ã€‚\nä» img_resize_2 = transforms_compose (img) æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå‚æ•° img æ˜¯ä¸€ä¸ª PIL å›¾ç‰‡ä»–é€šè¿‡ Compose å…ˆåè¿›è¡Œäº†é‡è°ƒæ•´å’Œå¼ é‡åŒ–ï¼Œæœ€ç»ˆè¿”å› img_resize_2 å¼ é‡å›¾ç‰‡ã€‚\n\næç¤ºï¼šresize_2 = transforms.Resize (512) æ˜¯ä¸€ä¸ªç­‰æ¯”ä¾‹è°ƒæ•´ã€‚\ntensor(0.4039)\ntensor(0.6797)\n(3600, 2700)\ntorch.Size([3, 128, 128])\ntorch.Size([3, 512, 682])\n\n# RandomCrop çš„ä½¿ç”¨\nRandomCrop éšæœºè£å‰ª\n# RandomCrop çš„ä½¿ç”¨# random_crop = transforms.RandomCrop(500, 1000)random_crop = transforms.RandomCrop(512)compose_random_crop = transforms.Compose([random_crop, toTensorTools])for i in range(10):    img_random_crop = compose_random_crop(img)    writer.add_image('RandomCrop', img_random_crop, i)# ä½¿ç”¨ TorchVision çš„æ•°æ®é›†ï¼ˆDataSetï¼‰\nCIFAR â€”â€” Canadian Institute For Advanced Researchï¼ˆåŠ æ‹¿å¤§é«˜çº§ç ”ç©¶æ‰€ï¼‰\nroot æ•°æ®é›†æ‰€åœ¨ç›®å½•ã€train æ˜¯è®­ç»ƒé›†è¿˜æ˜¯æµ‹è¯•é›†ã€transform åº”ç”¨çš„å˜æ¢æ“ä½œæˆ–æ“ä½œé›†åˆã€download æ˜¯å¦å¯ç”¨ä¸‹è½½\ntrain_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transforms_compose_dataset, download=True)test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=transforms_compose_dataset, download=True)\nCIFAR-10 and CIFAR-100 datasets\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\nCIFAR-10 æ•°æ®é›†ç”± 10 ç±»çš„ 60000 å¼  32x32 å½©è‰²å›¾åƒç»„æˆï¼Œæ¯ç±» 6000 å¼ å›¾åƒã€‚æœ‰ 50000 å¼ è®­ç»ƒå›¾åƒå’Œ 10000 å¼ æµ‹è¯•å›¾åƒã€‚\nThe dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\næ•°æ®é›†åˆ†ä¸ºäº”ä¸ªè®­ç»ƒæ‰¹æ¬¡å’Œä¸€ä¸ªæµ‹è¯•æ‰¹æ¬¡ï¼Œæ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡æœ‰ 10000 å¼ å›¾åƒã€‚æµ‹è¯•æ‰¹æ¬¡æ°å¥½åŒ…å«æ¯ä¸ªç±»ä¸­éšæœºé€‰æ‹©çš„ 1000 å¼ å›¾åƒã€‚è®­ç»ƒæ‰¹æ¬¡ä»¥éšæœºé¡ºåºåŒ…å«å‰©ä½™çš„å›¾åƒï¼Œä½†æŸäº›è®­ç»ƒæ‰¹æ¬¡å¯èƒ½åŒ…å«æ¥è‡ªä¸€ä¸ªç±»çš„å›¾åƒå¤šäºå¦ä¸€ä¸ªç±»çš„å›¾åƒã€‚åœ¨å®ƒä»¬ä¹‹é—´ï¼Œè®­ç»ƒæ‰¹æ¬¡æ°å¥½åŒ…å«æ¯ä¸ªç±»çš„ 5000 å¼ å›¾åƒã€‚\n\n# æ•°æ®é›†è”åŠ¨ Tensorboard\nimport torchvisionfrom torch.utils.tensorboard import SummaryWritertensorboard = SummaryWriter(\"p10\")transforms_compose_dataset = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transforms_compose_dataset, download=True)test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=transforms_compose_dataset, download=True)print(test_set[0])for i in range(20):    img, target = test_set[i]    tensorboard.add_image(\"test_set\", img, i)tensorboard.close()å…¶ä¸­ img, target = test_set [i] è¿”å›äº†ä¸€ä¸ªå…ƒç»„\n\n0 å·ä½æ˜¯è½¬åŒ–è¿‡åçš„å¼ é‡å›¾ï¼Œ1 å·ä½æ˜¯å…¶æ ‡ç­¾ç´¢å¼•ï¼Œæ•°æ®çš„æ ‡ç­¾åˆ—è¡¨å¯ä»¥åœ¨ test_set.classes ä¸­çœ‹åˆ°ã€‚\n# add_image æºç æç¤º\ndef add_image(    self, tag, img_tensor, global_step=None, walltime=None, dataformats=\"CHW\"):tag, img_tensor, global_step=None åˆ†åˆ«å¯¹åº” tensorboard æ ‡ç­¾ï¼Œå¼ é‡å›¾ï¼Œä»¥åŠæ­¥éª¤ i\ntensorboard.add_image(\"test_set\", img, i)æ³¨æ„ï¼štensorboard ä½¿ç”¨è¿‡åé¡»å…³é—­ tensorboard.close ()\n# DataLoader çš„ä½¿ç”¨\ntorch.utils.data â€” PyTorch 2.8 documentation\nå‚æ•°åˆè§ï¼š\n\n\ndataset (Dataset) â€“ dataset from which to load the data.\n\n\nbatch_size (int, optional) â€“ how many samples per batch to load (default:  1 ).\n\n\nshuffle (bool, optional) â€“ set to  True  to have the data reshuffled at every epoch (default:  False ).\n\n\nbatch_sampler (Sampler or Iterable*,* optional) â€“ like  sampler , but returns a batch of indices at a time. Mutually exclusive with  batch_size ,  shuffle ,  sampler , and  drop_last .\n\n\nnum_workers (int, optional) â€“ how many subprocesses to use for data loading.  0  means that the data will be loaded in the main process. (default:  0 )\n\n\ndrop_last (bool, optional) â€“ set to  True  to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If  False  and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default:  False )\n\n\n# å‡†å¤‡çš„æµ‹è¯•æ•°æ®test_data = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=torchvision.transforms.ToTensor(),                                         download=True)# åˆ›å»ºæµ‹è¯•æ•°æ®é›†test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True, num_workers=0, drop_last=True)dataset æ•°æ®é›†ã€batch_size ä¸€æ¬¡æ‰“åŒ…å¤šå°‘ä¸ªã€shuffle æ˜¯å¦æ‰“ä¹±ã€num_workers åŠ è½½æ•°æ®å­è¿›ç¨‹æ•°ã€drop_last å¤šä½™éƒ¨åˆ†æ˜¯å¦åˆ é™¤\ntorch.Size([3, 32, 32])3cat# è”åŠ¨ Tensorboard\nimport torchvision.datasetsfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriter# å‡†å¤‡çš„æµ‹è¯•æ•°æ®test_data = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=torchvision.transforms.ToTensor(),                                         download=True)# åˆ›å»ºæµ‹è¯•æ•°æ®é›†test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True, num_workers=0, drop_last=True)image, target = test_data[0]# æµ‹è¯•æ•°æ®ç¬¬ä¸€å¼ å›¾åƒçš„ shape å’Œæ ‡ç­¾print(image.shape)print(target)print(test_data.classes[target])print(\"____________________\")writer = SummaryWriter(\"DataLoader\")step = 0for loaderX in test_loader:    images, targets = loaderX    # print(images.shape)    # print(targets)    writer.add_images(\"test_data_drop_last\", images, step)    step += 1writer.close()# åˆ©ç”¨ Epoch å˜é‡æ§åˆ¶è®­ç»ƒæˆ–æµ‹è¯•è½®æ¬¡\nfor epoch in range(2):    step = 0    for loaderX in test_loader:        images, targets = loaderX        # print(images.shape)        # print(targets)        writer.add_images(\"Epoch:&#123;&#125;\".format(epoch), images, step)        step += 1&quot;Epoch:&#123;&#125;&quot;.format(epoch)  æ˜¯ Python çš„ å­—ç¬¦ä¸²æ ¼å¼åŒ– æ–¹æ³•ï¼Œå®ƒä¼šå°†  epoch  çš„å€¼åŠ¨æ€æ’å…¥åˆ°å­—ç¬¦ä¸²çš„  &#123;&#125;  å ä½ç¬¦ä¸­ã€‚\n\næ­¤æ—¶å½“ shuffle=True æ—¶ï¼ŒEpoch0 å’Œ Epoch1 å¹¶ä¸ä¸€æ ·\ntest_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True, num_workers=0, drop_last=True)\n# ç¥ç»ç½‘ç»œ (Neural Network) åŸºæœ¬éª¨æ¶\ntorch.nn â€” PyTorch 2.8 documentation\nModule â€” PyTorch 2.8 documentation\nimport torch.nn as nnimport torch.nn.functional as Fclass Model(nn.Module):    def __init__(self) -> None:        super().__init__()        self.conv1 = nn.Conv2d(1, 20, 5)        self.conv2 = nn.Conv2d(20, 20, 5)    def forward(self, x):        x = F.relu(self.conv1(x))        return F.relu(self.conv2(x))forward å‰å‘ä¼ æ’­ï¼š\ndef forward(self, x):        x = F.relu(self.conv1(x))        return F.relu(self.conv2(x))x  å…ˆç»è¿‡ä¸€æ¬¡ conv1  å·ç§¯ï¼Œå†ç»è¿‡ä¸€æ¬¡ relu  éçº¿æ€§å¤„ç† x = F.relu(self.conv1(x))\nç„¶å x  åœ¨ç»è¿‡ä¸€æ¬¡ conv2  å·ç§¯ï¼Œå†ç»è¿‡ä¸€æ¬¡ relu  éçº¿æ€§å¤„ç†ï¼Œæœ€åè¿”å› return F.relu(self.conv2(x))\n# ç®€å•çš„éª¨æ¶\nç®€å•çš„éª¨æ¶å°±æ˜¯è¿™æ ·ï¼Œæœ‰ä¸€ä¸ªè¾“å…¥ç»è¿‡ forward åæ¯æ¬¡åŠ ä¸€\nimport torchfrom torch import nnclass Module(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)    def forward(self, input):        output = input + 1        return outputkarry = Module()x = torch.tensor(1.0)print(karry(x))# convolution å·ç§¯æ“ä½œ\nhttps://www.bilibili.com/video/BV1hE411t7RN?p=17\n# Stride è·¨æ­¥ = 1\nStride æ˜¯æ¯æ¬¡è·¨æ­¥æ•°ï¼Œ1 å°±æ˜¯æ¯æ¬¡è·¨ä¸€æ­¥\n\næ³¨æ„åˆ°çº¢è‰²éƒ¨åˆ†å°±æ˜¯å¯¹åº”ä½ç½®ç›¸ä¹˜å†ç›¸åŠ \nimport torchimport torch.nn.functional as F# åˆ›å»ºè¾“å…¥å’Œæ ¸input_matrix = torch.tensor([[1, 2, 0, 3, 1], [0, 1, 2, 3, 1], [1, 2, 1, 0, 0], [5, 2, 3, 1, 1], [2, 1, 0, 1, 1]])kernel = torch.tensor([[1, 2, 1], [0, 1, 0], [2, 1, 0]])# æ”¹å˜ç»´åº¦input_matrix = torch.reshape(input_matrix, (1, 1, 5, 5))kernel = torch.reshape(kernel, (1, 1, 3, 3))# å·ç§¯output_ans = F.conv2d(input_matrix, kernel, stride=1)print(input_matrix.shape)print(kernel.shape)print(output_ans)\ntorch.Size([1, 1, 5, 5])\ntorch.Size([1, 1, 3, 3])\ntensor([[[[10, 12, 12],\n[18, 16, 16],\n[13,  9,  3]]]])\n\n# Stride è·¨æ­¥ = 2\n\n# å·ç§¯output_ans = F.conv2d(input_matrix, kernel, stride=2)print(output_ans)\ntensor([[[[10, 12],\n[13,  3]]]])\n\n# Padding å¡«å…… = 1\nPadding å¡«å……å°±æ˜¯åœ¨åŸå§‹æ•°æ®çš„æœ€å¤–ä¾§å¡«å……ä¸€äº›æ•°æ®ï¼ˆåƒç´ ï¼‰ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æ˜¯è®¾ç½®ä¸ºé›¶\n\nä¸€æ ·åœ°ï¼Œçº¢è‰²éƒ¨åˆ†å¯¹åº”ä½ç½®ç›¸ä¹˜å†ç›¸åŠ ï¼Œæœ€å¤–åœˆç»¿è‰²ä¸º padding=1 æ‰€äº§ç”Ÿçš„é¢å¤–å¡«å……\n# å·ç§¯output_ans = F.conv2d(input_matrix, kernel, stride=1, padding=1)print(output_ans)\ntensor([[[[ 1,  3,  4, 10,  8],\n[ 5, 10, 12, 12,  6],\n[ 7, 18, 16, 16,  8],\n[11, 13,  9,  3,  4],\n[14, 13,  9,  7,  4]]]])\n\n# Convolution Layers å·ç§¯å±‚\ntorch.nn â€” PyTorch 2.8 documentation\nclass torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=â€˜zerosâ€™, device=None, dtype=None)\nå…¶ä¸­æœ€ä¸»è¦çš„å‚æ•°è®¾ç½®æ˜¯è¿™äº”ä¸ªï¼šin_channels, out_channels, kernel_size, stride=1, padding=0\n\nweight å®é™…ä¸Šå°±æ˜¯å·ç§¯æ ¸ï¼Œinput æ˜¯é€šé“æ•°æ®ï¼Œbias æ˜¯åç½®\n\nå·ç§¯å±‚çš„ æ¯ä¸ªè¾“å‡ºé€šé“ éƒ½æ˜¯ æ‰€æœ‰è¾“å…¥é€šé“çš„åŠ æƒå·ç§¯ç»“æœç›¸åŠ ï¼Œæƒé‡å°±æ˜¯  weight[j, k] ã€‚\nå‡è®¾è¾“å…¥æ˜¯ RGB å½©è‰²å›¾åƒï¼ˆ3 ä¸ªé€šé“ï¼šRã€Gã€Bï¼‰ï¼Œå·ç§¯å±‚çš„ä¸€ä¸ªè¾“å‡ºé€šé“æ˜¯è¿™æ ·ç®—çš„ï¼š\n\nä¸ºä»€ä¹ˆè¦ â€œæ‰€æœ‰è¾“å…¥é€šé“ç›¸åŠ â€ï¼Ÿ\n\nå›¾åƒçš„ç‰¹å¾å¯èƒ½è·¨é€šé“ï¼ˆæ¯”å¦‚çº¢ç»¿è“ç»„åˆæ‰èƒ½æ„æˆé¢œè‰²ä¿¡æ¯ï¼‰\nä¸€ä¸ªå·ç§¯æ ¸åªçœ‹å•ä¸ªé€šé“çš„ä¿¡æ¯æ˜¯ä¸å®Œæ•´çš„\næŠŠå¤šä¸ªè¾“å…¥é€šé“çš„å·ç§¯ç»“æœåŠ åœ¨ä¸€èµ·ï¼Œå°±ç›¸å½“äºåœ¨èåˆè¿™äº›é€šé“çš„ä¿¡æ¯\n\nè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå¤šé€šé“å·ç§¯çš„  weight  æ˜¯å››ç»´çš„ï¼šC_outã€C_inã€k_hã€k_w\n\nConvolution animationsï¼šconv_arithmetic/README.md at master Â· vdumoulin/conv_arithmetic Â· GitHub\n# in_channel=1, out_channel=1\nåªæœ‰ä¸€ä¸ªè¾“å…¥é€šé“å’Œä¸€ä¸ªè¾“å‡ºé€šé“ï¼Œä¸å­˜åœ¨è·¨é€šé“æ±‚å’Œã€‚\n\n1Ã—1+2Ã—0+3Ã—0+4Ã—(âˆ’1)=1+0+0âˆ’4=âˆ’3\n[[âˆ’3]]\nin_channel=1, out_channel=1 æ—¶ï¼Œå°±æ˜¯ç”¨ä¸€ä¸ªå·ç§¯æ ¸ç›´æ¥ä½œç”¨äºè¾“å…¥é€šé“ï¼Œå·ç§¯ååŠ ä¸Š bias å¾—åˆ°ç»“æœã€‚\næ²¡æœ‰è·¨é€šé“åŠ æƒï¼Œæ²¡æœ‰é¢å¤–æ±‚å’Œæ­¥éª¤ã€‚\nimport torchfrom torch import nnnn_conv_d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, stride=1, padding=0, bias=False)nn_conv_d.weight.data = torch.tensor([[[[1, 0],                                        [0, -1]]]], dtype=torch.float32)input = torch.tensor([[[[1, 2], [3, 4]]]], dtype=torch.float32)print(nn_conv_d(input))\ntensor([[[[-3.]]]], grad_fn=)\n\nèµ·æ­¥è§£é‡Šï¼š\n\nnn_conv_d.weight.data è‡ªå®šä¹‰å·ç§¯æ ¸\nnn.Conv2d  è¦æ±‚  [batch, channels, height, width] ï¼Œæ‰€ä»¥äºŒç»´çŸ©é˜µè¦ç”¨  unsqueeze  æ‰©æˆ 4 ç»´ï¼Œæˆ–è€…åœ¨åˆå§‹åŒ–æ—¶å°±æ˜¯å››ç»´çš„\nå·ç§¯å±‚çš„æƒé‡å’Œ bias æ˜¯ ** æµ®ç‚¹å‹ ( torch.float32 )** å› æ­¤è¦ dtype=torch.float32\nä¸ºäº†å¾—åˆ°ç²¾ç¡®å€¼åç½®é‡åº”å½“è®¾ä¸ºå‡ï¼ˆä¸åç½®ï¼‰ï¼šbias=False\n\nä»¥ä¸Šå‡ä¸º torch æ¡†æ¶ä¸­è‡ªå¸¦çš„å‚æ•°è°ƒè¯•å˜é‡ï¼Œè¿™äº›æ“ä½œä¸»è¦æ˜¯ è°ƒè¯•å’Œç†è§£å·ç§¯çš„è®¡ç®—è¿‡ç¨‹\nåœ¨å®é™…ç¥ç»ç½‘ç»œè®­ç»ƒä¸­ï¼š\n\næƒé‡  weight  ä¼šè¢«ä¼˜åŒ–å™¨è‡ªåŠ¨æ›´æ–°\nè¾“å…¥é€šå¸¸æ˜¯å››ç»´ tensor\nbias æ˜¯å¦å¯ç”¨è§†ç½‘ç»œè®¾è®¡è€Œå®š\n\næŒæ¡è¿™äº›åŸºæœ¬å‚æ•°è°ƒè¯•æ–¹æ³•ï¼Œæ˜¯ä¸ºäº†ï¼š\n\nç†è§£å·ç§¯è®¡ç®—æœºåˆ¶\néªŒè¯å·ç§¯æ“ä½œæ˜¯å¦å¦‚é¢„æœŸ\nä¸ºåç»­åšå›¾åƒæˆ–ç‰¹å¾è¯†åˆ«çš„ç¥ç»ç½‘ç»œæ‰“åŸºç¡€\n\n# in_channel=1, out_channel=2\næ¯ä¸ªè¾“å‡ºé€šé“æ˜¯ç‹¬ç«‹çš„å·ç§¯ç»“æœ\n\n1Ã—1+2Ã—0+3Ã—0+4Ã—(âˆ’1)=1+0+0âˆ’4=âˆ’3\n1Ã—0+2Ã—1+3Ã—(âˆ’1)+4Ã—0=0+2âˆ’3+0=âˆ’1\nè¾“å‡ºå¼ é‡ (batch=1, out_channel=2, H=1, W=1)ï¼šoutput=[[âˆ’3],[âˆ’1]]\nin_channel=1 æ—¶ï¼Œæ¯ä¸ªè¾“å‡ºé€šé“éƒ½ç›´æ¥åœ¨è¿™ä¸ªè¾“å…¥é€šé“ä¸Šç”¨ä¸åŒå·ç§¯æ ¸ç‹¬ç«‹è¿ç®—ã€‚\næœ€ç»ˆçš„ä¸¤ä¸ªé€šé“ç»“æœæ˜¯å¹¶åˆ—å­˜å‚¨ï¼Œä¸åšæ±‚å’Œã€‚\nimport torchfrom torch import nnnn_conv_d = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2, stride=1, padding=0, bias=False)nn_conv_d.weight.data = torch.tensor([    [[[1, 0], [0, -1]]],  # è¾“å‡ºé€šé“ 1 çš„å·ç§¯æ ¸ï¼Œå¯¹åº”è¾“å…¥é€šé“ 1    [[[0, 1], [-1, 0]]]  # è¾“å‡ºé€šé“ 2 çš„å·ç§¯æ ¸ï¼Œå¯¹åº”è¾“å…¥é€šé“ 1], dtype=torch.float32)input = torch.tensor([[[[1, 2], [3, 4]]]], dtype=torch.float32)print(nn_conv_d(input))\ntensor([[[[-3.]],\nâ€‹\t\t\t\t[[-1.]]]], grad_fn=)\n\n# in_channel=2, out_channel=1\nä¸¤ä¸ªè¾“å…¥é€šé“å„è‡ªç”¨è‡ªå·±çš„å·ç§¯æ ¸å·ç§¯ â†’ å¾—åˆ°ä¸¤ä¸ªç»“æœã€‚\n\n1Ã—1+2Ã—0+3Ã—0+4Ã—(âˆ’1)=1+0+0âˆ’4=âˆ’3\n5Ã—0+6Ã—1+7Ã—(âˆ’1)+8Ã—0=0+6âˆ’7+0=âˆ’1\nåŠ æƒæ±‚å’Œï¼ˆåˆæˆä¸€ä¸ªè¾“å‡ºé€šé“ï¼‰ï¼šoutput=(âˆ’3)+(âˆ’1)=âˆ’4\nè¾“å‡ºå¼ é‡ (batch=1, out_channel=1, H=1, W=1)ï¼š[[âˆ’4]]\nimport torchfrom torch import nnnn_conv_d = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=2, stride=1, padding=0, bias=False)nn_conv_d.weight.data = torch.tensor([    [        [[1, 0], [0, -1]],    # è¾“å…¥é€šé“ 1 çš„å·ç§¯æ ¸        [[0, 1], [-1, 0]]     # è¾“å…¥é€šé“ 2 çš„å·ç§¯æ ¸    ]], dtype=torch.float32)input = torch.tensor([    [        [            [1, 2],            [3, 4]        ], [        [5, 6],        [7, 8]    ]    ]], dtype=torch.float32)print(nn_conv_d(input))\ntensor([[[[-4.]]]], grad_fn=)\n\n# in_channel=2, out_channel=2\n\nX_channel1 * W_out1_in1 = [[11+20+30+41]] = [[1+0+0+4]] = [[5]]\nX_channel2 * W_out1_in2 = [[00+11+11+00]] = [[0+1+1+0]] = [[2]]\nY_out1 = 5 + 2 = 7\nX_channel1 * W_out2_in1 = [[1+2+3+4]] = [[10]]\nX_channel2 * W_out2_in2 = [[0* -1 + 10 + 10 + 0*-1]] = [[0]]\nY_out2 = 10 + 0 = 10\nY_out1 = [[7]]\t\tY_out2 = [[10]]\nç»“æœä¸ºï¼š[[7],[10]]\nimport torchfrom torch import nnnn_conv_d = nn.Conv2d(in_channels=2, out_channels=2, kernel_size=2, stride=1, padding=0, bias=False)nn_conv_d.weight.data = torch.tensor([    [        [[1, 0], [0, 1]],        [[0, 1], [1, 0]]    ], [        [[1, 1], [1, 1]],        [[-1, 0], [0, -1]]    ]], dtype=torch.float32)input = torch.tensor([[    [        [1, 2],        [3, 4]    ], [        [0, 1],        [1, 0]    ]]], dtype=torch.float32)print(nn_conv_d(input))\ntensor([[[[ 7.]],\nâ€‹\t\t\t\t[[10.]]]], grad_fn=)\n\n# å‘å‰ä¼ æ’­çš„å·ç§¯ï¼ˆæ­£å‘ä¼ æ’­ï¼‰\nimport torchimport torchvisionfrom torch import nnfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                       download=True)dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)    def forward(self, x):        x = self.conv1(x)        return xwriter = SummaryWriter(\"logs\")net = Net()step = 0for data in dataloader:    imgs, targets = data    outputs = net(imgs)    print(imgs.shape)    print(outputs.shape)    # torch.Size([64, 3, 32, 32])    writer.add_images(\"input\", imgs, global_step=step)    # torch.Size([64, 6, 30, 30])    outputs = torch.reshape(outputs, (-1, 3, 30, 30))    writer.add_images(\"output\", outputs, global_step=step)    step += 1self.conv1  æ˜¯ä¸€ä¸ª å·ç§¯å±‚ï¼ˆ nn.Conv2d ï¼‰ï¼Œåœ¨  forward  é‡Œå†™  x = self.conv1(x) ï¼Œå°±æ˜¯æŠŠè¾“å…¥  x  é€šè¿‡å·ç§¯å±‚è¿›è¡Œå‰å‘è®¡ç®—ã€‚\n# Pooling Layers æ± åŒ–å±‚\ntorch.nn â€” PyTorch 2.8 documentation\næ± åŒ–æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä¸­ä¸€ä¸ªå¾ˆé‡è¦çš„æ“ä½œã€‚å®ƒçš„ä¸»è¦ä½œç”¨å¯ä»¥æ€»ç»“ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š\n\né™ç»´ä¸å‡å°‘è®¡ç®—é‡\n\n\nä¸ºä»€ä¹ˆï¼šå·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾é€šå¸¸å¾ˆå¤§ï¼Œå¦‚æœä¸ç¼©å°ï¼Œåé¢ç½‘ç»œå±‚çš„è®¡ç®—é‡ä¼šéå¸¸åºå¤§ã€‚\næ€ä¹ˆåšï¼šæ± åŒ–é€šè¿‡å–å±€éƒ¨åŒºåŸŸçš„æœ€å¤§å€¼ï¼ˆMax Poolingï¼‰æˆ–å¹³å‡å€¼ï¼ˆAverage Poolingï¼‰æ¥ç¼©å°ç‰¹å¾å›¾å°ºå¯¸ã€‚\næ•ˆæœï¼šå‡å°‘å‚æ•°é‡å’Œè®¡ç®—é‡ï¼ŒåŠ å¿«è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ã€‚\n\n\n\nç‰¹å¾çš„å¹³ç§»ä¸å˜æ€§\n\n\nä»€ä¹ˆæ„æ€ï¼šå¦‚æœå›¾ç‰‡é‡Œä¸€ä¸ªç‰©ä½“ç¨å¾®ç§»åŠ¨äº†ï¼Œç½‘ç»œä¾ç„¶èƒ½è¯†åˆ«ã€‚\nä¸ºä»€ä¹ˆèƒ½åšåˆ°ï¼šæ± åŒ–ä¼šåœ¨ä¸€ä¸ªå°èŒƒå›´å†…æå–ç»Ÿè®¡ç‰¹å¾ï¼ˆæœ€å¤§å€¼æˆ–å¹³å‡å€¼ï¼‰ï¼Œå› æ­¤å³ä½¿è¾“å…¥å›¾åƒæœ‰å¾®å°çš„åç§»ï¼Œç»“æœå˜åŒ–ä¹Ÿä¸ä¼šå¤ªå¤§ã€‚\n\n\n\nçªå‡ºé‡è¦ç‰¹å¾ï¼ŒæŠ‘åˆ¶ä¸é‡è¦ä¿¡æ¯\n\n\nMax Poolingï¼šä¿ç•™ä¸€ä¸ªåŒºåŸŸçš„æœ€å¤§å€¼ï¼Œå€¾å‘äºä¿ç•™æœ€æ˜¾è‘—çš„è¾¹ç¼˜æˆ–çº¹ç†ç‰¹å¾ã€‚\nAverage Poolingï¼šä¿ç•™åŒºåŸŸçš„å¹³å‡å€¼ï¼Œå¾—åˆ°æ›´åŠ å¹³æ»‘çš„ç‰¹å¾ã€‚\nä½œç”¨ï¼šç›¸å½“äº â€œç‰¹å¾å‹ç¼©â€ï¼Œè®©åç»­å±‚æ›´å®¹æ˜“æå–å…¨å±€ä¿¡æ¯ã€‚\n\n\n\né˜²æ­¢è¿‡æ‹Ÿåˆ\n\n\né€šè¿‡å‡å°‘å‚æ•°å’Œå¯¹ç»†èŠ‚çš„ä¾èµ–ï¼Œç½‘ç»œæ›´å…³æ³¨å¤§å±€ç‰¹å¾è€Œä¸æ˜¯å±€éƒ¨å™ªå£°ï¼Œä»è€Œå‡è½»è¿‡æ‹Ÿåˆé£é™©ã€‚\n\n\næ ¸å¿ƒå‚æ•°\n\nkernel_size (Union[int, tuple[int, int]]) â€“ the size of the window to take a max over\nstride (Union[int, tuple[int, int]]) â€“ the stride of the window. Default value is kernel_size\npadding (Union[int, tuple[int, int]]) â€“ Implicit negative infinity padding to be added on both sides\ndilation (Union[int, tuple[int, int]]) â€“ a parameter that controls the stride of elements in the window\nreturn_indices (bool) â€“ if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later\nceil_mode (bool) â€“ when True, will use ceil instead of floor to compute the output shape\n\næ± åŒ–ç¤ºæ„å›¾ï¼š\n\n# dilation æ‰©å¼ ç‡ï¼ˆç©ºæ´å·ç§¯ï¼‰\nè¿™ä¸ªå‚æ•°åœ¨ å·ç§¯ï¼ˆç‰¹åˆ«æ˜¯å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„å·ç§¯å±‚ï¼‰é‡Œèµ·å¾ˆé‡è¦çš„ä½œç”¨ã€‚å®ƒå’Œ  kernel_size ã€ stride  ä¸€æ ·ï¼Œå†³å®šäº†å·ç§¯æ ¸æ˜¯æ€ä¹ˆåœ¨è¾“å…¥ç‰¹å¾å›¾ä¸Šå–å€¼çš„ã€‚\n\n dilation  å·ç§¯ï¼Œå…¶å®å°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„ ç©ºæ´å·ç§¯ (Dilated Convolution / Atrous Convolution)ã€‚\n# ceil æ¨¡å¼å’Œ floor æ¨¡å¼\n\nfloor æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰\n\n\nå–æ•´æ—¶å‘ä¸‹å–æ•´ï¼ˆfloorï¼‰ã€‚\nå¤šä½™çš„è¾¹ç¼˜ï¼ˆä¸è¶³ä¸€ä¸ª kernel çš„åŒºåŸŸï¼‰ä¼šè¢«ä¸¢å¼ƒã€‚\næ¯”å¦‚ï¼š\n\nè¾“å…¥é•¿åº¦ 5\nkernel=2, stride=2\nè®¡ç®—ï¼š(5âˆ’2)/2+1=2.5 (5-2)/2 + 1 = 2.5 (5âˆ’2)/2+1=2.5 â†’ floor â†’ 2\nè¾“å‡ºé•¿åº¦å°±æ˜¯ 2ï¼ˆæœ€åä¸€ä¸ªä½ç½®æ²¡è¦†ç›–åˆ°ï¼‰ã€‚\n\n\n\n\nceil æ¨¡å¼ï¼ˆå¼€å¯  ceil_mode=True ï¼‰\n\n\nå–æ•´æ—¶å‘ä¸Šå–æ•´ï¼ˆceilï¼‰ã€‚\nè¾¹ç¼˜ä¸è¶³ kernel çš„éƒ¨åˆ†ï¼Œä¹Ÿä¼šè¢«ä¿ç•™ï¼ˆé€šå¸¸ä¼šç”¨ padding è¡¥é½ï¼‰ã€‚\nä¸Šé¢ä¾‹å­ï¼š\n\nè¾“å…¥é•¿åº¦ 5\nkernel=2, stride=2, ceil_mode=True\nè®¡ç®—ï¼š2.5 â†’ ceil â†’ 3\nè¾“å‡ºé•¿åº¦å°±æ˜¯ 3ï¼ˆæœ€åä¸€ä¸ªåŒºåŸŸä¼šåªè¦†ç›–éƒ¨åˆ†è¾“å…¥ï¼Œæˆ–è€…è¡¥ 0ï¼‰ã€‚\n\n\n\nfloor æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼šè®¡ç®—ç¨³å®šï¼Œå¸¸ç”¨äºè®­ç»ƒã€‚\nceil æ¨¡å¼ï¼šå½“ä½ å¸Œæœ›è¾“å…¥å’Œè¾“å‡ºä¸¥æ ¼å¯¹é½ï¼Œæˆ–è€…æƒ³ä¿ç•™æ›´å¤šè¾¹ç¼˜ä¿¡æ¯æ—¶ä½¿ç”¨ï¼ˆæ¯”å¦‚æŸäº›å›¾åƒåˆ†å‰²ä»»åŠ¡ï¼‰ã€‚\n# æç¤º\nå·ç§¯æ˜¯æå–ç‰¹å¾ï¼Œæ± åŒ–æ˜¯å‹ç¼©ç‰¹å¾\n1080P -&gt; 720P\n# æœ€å¤§æ± åŒ–\næ± åŒ–çš„é»˜è®¤æ­¥é•¿ç­‰äºæ± åŒ–æ ¸çš„å¤§å°ï¼Œæ± åŒ–çš„é»˜è®¤æ­¥é•¿ç­‰äºæ± åŒ–æ ¸çš„å¤§å°ï¼Œæ± åŒ–çš„é»˜è®¤æ­¥é•¿ç­‰äºæ± åŒ–æ ¸çš„å¤§å°\n\n# æœ€å¤§æ± åŒ–å®ä¾‹\nceil_mode=Trueï¼š\nimport torchimport torch.nn as nninput = torch.tensor([[1, 2, 0, 3, 1],                      [0, 1, 2, 3, 1],                      [1, 2, 1, 0, 0],                      [5, 2, 3, 1, 1],                      [2, 1, 0, 1, 1]])input = torch.reshape(input, (-1, 1, 5, 5))class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.maxPool1 = nn.MaxPool2d(kernel_size=3, ceil_mode=True)    def forward(self, input):        output = self.maxPool1(input)        return outputnet = Net()output = net(input)print(output.shape)print(output)\ntorch.Size([1, 1, 2, 2])\ntensor([[[[2, 3],\n[5, 1]]]])\n\nceil_mode=Falseï¼š\nself.maxPool1 = nn.MaxPool2d(kernel_size=3, ceil_mode=False)\ntorch.Size([1, 1, 1, 1])\ntensor([[[[2]]]])\n\n# å›¾ç‰‡æ“ä½œ\nimport torchimport torch.nn as nnimport torchvision.datasetsfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterinput = torch.tensor([[1, 2, 0, 3, 1],                      [0, 1, 2, 3, 1],                      [1, 2, 1, 0, 0],                      [5, 2, 3, 1, 1],                      [2, 1, 0, 1, 1]])input = torch.reshape(input, (-1, 1, 5, 5))data_set = torchvision.datasets.CIFAR10(root=\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                        download=True)dataloader = DataLoader(data_set, batch_size=64, shuffle=True, num_workers=0)class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.maxPool1 = nn.MaxPool2d(kernel_size=3, ceil_mode=False)    def forward(self, input):        output = self.maxPool1(input)        return outputwriter = SummaryWriter(\"logs_maxpool\")net = Net()step = 0for data in dataloader:    img, label = data    writer.add_images(\"input\", img, global_step=step)    output = net(img)    writer.add_images(\"output\", output, global_step=step)    step += 1writer.close()å¯ä»¥çœ‹åˆ°ï¼Œå˜æˆé©¬èµ›å…‹äº†ï¼š\n\n# Padding Layers å¡«å……å±‚\ntorch.nn â€” PyTorch 2.8 documentation\nå¡«å……æ˜¯åº”ç”¨äºå›¾ç‰‡å¤–å›´çš„ï¼Œä¸»è¦è¿›è¡Œä¸€äº›å€¼çš„å¡«å……ï¼ŒåŸºæœ¬ä¸ç”¨åˆ°\næœ€å¤šçš„ä¼šä½¿ç”¨åˆ°ï¼šnn.ZeroPad2d Pads the input tensor boundaries with zero.\n# Non-linear Activations éçº¿æ€§æ¿€æ´»\næœ€å¸¸è§çš„æ˜¯ï¼šReLU â€” PyTorch 2.8 documentation\n\nå…¶æ¬¡æ˜¯ï¼šSigmoid â€” PyTorch 2.8 documentation\n\n# ReLU ç¤ºä¾‹\nimport torchinput = torch.tensor([[1, -0.5], [-1, 3]])output = torch.reshape(input, (-1, 1, 2, 2))print(output)class Net(torch.nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.relu = torch.nn.ReLU()    def forward(self, input) -> torch.Tensor:        output = self.relu(input)        return outputnet = Net()output = net(output)print(output)# inplace æºç æç¤º\ndef __init__(self, inplace: bool = False):    super().__init__()    self.inplace = inplaceå½“ inplace ä¸ºå‡æ—¶ï¼Œä¸æ”¹å˜æºæ•°æ®\nå½“ inplace ä¸ºçœŸæ—¶ï¼Œæ‰§è¡Œæ—¶æ”¹å˜åŸå§‹æ•°æ®ï¼ˆå°±åœ°ç®—æ³•ï¼‰\n# å›¾ç‰‡æ“ä½œ\nimport torchimport torchvision.datasetsfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)class Net(torch.nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.relu = torch.nn.ReLU()        self.sigmoid = torch.nn.Sigmoid()    def forward(self, input) -> torch.Tensor:        # output = self.relu(input)        output = self.sigmoid(input)        return outputnet = Net()writer = SummaryWriter(\"logs_relu\")step = 0for data in dataloader:    imgs, targets = data    writer.add_images(\"input\", imgs, global_step=step)    output = net(imgs)    writer.add_images(\"output\", output, global_step=step)    step += 1writer.close()ç»“æœå¦‚ä¸‹ï¼š\n\n# Normalization Layers æ­£åˆ™åŒ–å±‚\nhttps://docs.pytorch.org/docs/stable/nn.html#normalization-layers\næœ‰ä¸€ç¯‡è®ºæ–‡æåˆ°æ­£åˆ™åŒ–å±‚å¯ä»¥åŠ é€Ÿè®­ç»ƒ\n# Recurrent Layers å¾ªç¯å±‚\næç¤ºï¼šRNN\ntorch.nn â€” PyTorch 2.8 documentation\nåºåˆ—çš„æ¯ä¸€æ­¥è®¡ç®—éƒ½ä¼šä¾èµ–å‰ä¸€æ­¥çš„éšè—çŠ¶æ€ï¼Œä»è€Œèƒ½æ•æ‰åºåˆ—çš„æ—¶é—´ä¾èµ–æ€§ã€‚\n# Transformer Layers\nhttps://docs.pytorch.org/docs/stable/nn.html#transformer-layers\nTransformer çš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯ç”¨ è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰ æ¥æ›¿ä»£ä¼ ç»Ÿ RNN æˆ– CNN å¤„ç†åºåˆ—æ—¶çš„ç¼ºé™·ã€‚\n# Linear Layers çº¿æ€§å±‚ï¼ˆå…¨è¿æ¥ï¼‰\ntorch.nn â€” PyTorch 2.8 documentation\n\n# æºç æç¤º\ntorch.nn.Linear(in_features, out_features, bias=True)\n\nin_features  å«ä¹‰ï¼šè¾“å…¥ç‰¹å¾çš„ç»´åº¦ï¼ˆæ¯ä¸ªæ ·æœ¬çš„è¾“å…¥å‘é‡é•¿åº¦ï¼‰ã€‚\nout_features  å«ä¹‰ï¼šè¾“å‡ºç‰¹å¾çš„ç»´åº¦ï¼ˆæ¯ä¸ªæ ·æœ¬çš„è¾“å‡ºå‘é‡é•¿åº¦ï¼‰ã€‚\nbias  æ˜¯å¦ä½¿ç”¨åç½®é¡¹ï¼Œé»˜è®¤ True\n\nimport torchimport torchvisionfrom torch import nnfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterdataset = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                       download=True)dataLoader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)# writer = SummaryWriter(\"log_liner\")class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.linear1 = nn.Linear(196608, 10)    def forward(self, input):        output = self.linear1(input)        return outputnet = Net()for data in dataLoader:    img, label = data    print(img.shape)    output = torch.flatten(img)    print(output.shape)    output = net(output)    print(output.shape)å±•å¹³åŠ¨ä½œï¼štorch.flatten (img)\nè¾“å…¥ 196608ï¼Œè¾“å‡º 10ï¼šnn.Linear (196608, 10)\n# Dropout Layers\ntorch.nn â€” PyTorch 2.8 documentation\n# Sequential åºåˆ—æ“ä½œ â€”â€” ä»¥ç®€å•ç½‘ç»œæ¨¡å‹å®æˆ˜ä¸ºä¾‹\nç›¸å½“äº transforms çš„ composeï¼Œå°†ä¸€äº›æ“ä½œç»„è£…åˆ°ä¸€èµ·\n\nimport torchfrom torch import nnfrom torch.nn import Conv2d, MaxPool2d, Flatten, Linearclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)        self.maxPool1 = MaxPool2d(kernel_size=2, ceil_mode=False)        self.conv2 = Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)        self.maxPool2 = MaxPool2d(kernel_size=2, ceil_mode=False)        self.conv3 = Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)        self.maxPool3 = MaxPool2d(kernel_size=2, ceil_mode=False)        self.flatten = Flatten()        self.linear0 = Linear(1024, 64)        self.linear1 = Linear(64, 10)    def forward(self, x):        x = self.conv1(x)        x = self.maxPool1(x)        x = self.conv2(x)        x = self.maxPool2(x)        x = self.conv3(x)        x = self.maxPool3(x)        x = self.flatten(x)        x = self.linear0(x)        x = self.linear1(x)        return xnet = Net()print(net)# æµ‹è¯•ç½‘ç»œinput = torch.ones(64, 3, 32, 32)outputs = net(input)print(outputs.shape)è¾“å…¥æ˜¯ä¸€å¼ å½©è‰²å›¾ç‰‡ï¼ˆ3 ä¸ªé€šé“ï¼‰\n\né¦–å…ˆç”¨ä¸€ä¸ªå·ç§¯å±‚ï¼ˆconv1ï¼‰å»æå–ä¸€äº›ä½çº§ç‰¹å¾ï¼Œæ¯”å¦‚è¾¹ç¼˜ã€é¢œè‰²å—ï¼Œç„¶åé€šè¿‡ä¸€æ¬¡æ± åŒ–ï¼ˆmaxPool1ï¼‰æŠŠå›¾ç‰‡ â€œç¼©å°ä¸€åŠâ€ï¼ŒåŒæ—¶ä¿ç•™ä¸»è¦ç‰¹å¾\næ¥ç€å†æ¥ä¸€æ¬¡å·ç§¯ï¼ˆconv2ï¼‰ï¼Œè¿™æ—¶å€™çš„è¾“å…¥å·²ç»æœ‰ 32 ä¸ªé€šé“äº†ï¼Œç½‘ç»œä¼šç»§ç»­åœ¨å‰é¢æå–åˆ°çš„ç‰¹å¾åŸºç¡€ä¸Šï¼Œæ‰¾åˆ°æ›´å¤æ‚çš„å½¢çŠ¶ã€çº¹ç†ï¼Œç„¶åå†åšä¸€æ¬¡æ± åŒ–ï¼ˆmaxPool2ï¼‰ï¼Œå›¾åƒå†ç¼©å°ä¸€åŠ\nç„¶åå†å·ç§¯ä¸€æ¬¡ï¼ˆconv3ï¼‰ï¼Œè¿™æ¬¡è¾“å‡ºé€šé“å˜æˆ 64 ä¸ªï¼Œèƒ½æå–æ›´ä¸°å¯Œã€æ›´æŠ½è±¡çš„ç‰¹å¾ï¼Œæ¯”å¦‚å±€éƒ¨çš„ç»“æ„ã€ç‰©ä½“çš„ä¸€éƒ¨åˆ†ï¼Œå†æ± åŒ–ä¸€æ¬¡ï¼ˆmaxPool3ï¼‰ï¼Œå›¾åƒåˆç¼©å°\næ¥ä¸‹æ¥æŠŠè¿™äº› â€œç¼©å°åçš„ç‰¹å¾å›¾â€ æ‹‰ç›´æˆä¸€ç»´å‘é‡ï¼ˆflattenï¼‰ï¼Œç„¶åç»è¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆlinear0ï¼‰ï¼ŒæŠŠå¤§è§„æ¨¡çš„ç‰¹å¾å‹ç¼©æˆä¸€ä¸ª 64 ç»´çš„å‘é‡\næœ€åå†ç»è¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆlinear1ï¼‰ï¼Œè¾“å‡º 10 ä¸ªæ•°ï¼Œè¿™é€šå¸¸å¯¹åº” 10 ä¸ªåˆ†ç±»çš„å¯èƒ½æ€§\n\næ€»ç»“ä¸€ä¸‹ï¼šå®ƒå°±æ˜¯ä¸€ä¸ªå…¸å‹çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå‰é¢å‡ å±‚å·ç§¯ + æ± åŒ–è´Ÿè´£é€æ­¥æå–å’Œæµ“ç¼©å›¾åƒç‰¹å¾ï¼Œåé¢çš„å…¨è¿æ¥å±‚è´Ÿè´£æŠŠè¿™äº›ç‰¹å¾è½¬æˆåˆ†ç±»ç»“æœã€‚\n# Sequential\nclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)        self.maxPool1 = MaxPool2d(kernel_size=2, ceil_mode=False)        self.conv2 = Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)        self.maxPool2 = MaxPool2d(kernel_size=2, ceil_mode=False)        self.conv3 = Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)        self.maxPool3 = MaxPool2d(kernel_size=2, ceil_mode=False)        self.flatten = Flatten()        self.linear0 = Linear(1024, 64)        self.linear1 = Linear(64, 10)        self.model1 = Sequential(self.conv1, self.maxPool1, self.conv2, self.maxPool2, self.conv3, self.maxPool3,self.flatten, self.linear0, self.linear1)    def forward(self, x):        x = self.model1(x)        return xå…¶ä¸­ Sequential å°†ä¸€äº›æ“ä½œç»„è£…åˆ°ä¸€èµ·ï¼š\nself.model1 = Sequential(self.conv1, self.maxPool1, self.conv2, self.maxPool2, self.conv3, self.maxPool3,self.flatten, self.linear0, self.linear1)è¿›ä¸€æ­¥åœ°å¯ä»¥è¿™æ ·å†™ï¼š\nclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model2 = Sequential(            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Flatten(),            Linear(1024, 64),            Linear(64, 10))    def forward(self, x):        x = self.model2(x)        return x# æµç¨‹å¯è§†åŒ–\nwriter = SummaryWriter(\"logs_seq\")writer.add_graph(net, input)writer.close()\nå¯ä»¥è§‚å¯Ÿåˆ°å…·ä½“æµç¨‹å°±æ˜¯ï¼šå·ç§¯ 1ã€æ± åŒ– 1ã€å·ç§¯ 2ã€æ± åŒ– 2ã€å·ç§¯ 3ã€æ± åŒ– 3ã€å±•å¹³ã€å…¨è¿æ¥ 1ï¼ˆçº¿æ€§ 1ï¼‰ã€å…¨è¿æ¥ 2ï¼ˆçº¿æ€§ 2ï¼‰ã€‚\n# æŸå¤±å‡½æ•°ä¸åå‘ä¼ æ’­\nè®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·ï¼Œä¸ºæˆ‘ä»¬æ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ®ï¼ˆåå‘ä¼ æ’­ï¼‰, grad\ntorch.nn â€” PyTorch 2.8 documentation\n\n nn.L1Loss \nnn.L1Lossï¼š\nX:1, 2, 3\nY:1, 2, 5\nL1loss = (0+0+2) /3=0.6ï¼Œè¿™é‡Œè‡ªç„¶æ˜¯è¶Šå°è¶Šå¥½\nimport torchfrom torch.nn import L1Lossinput = torch.tensor([1, 2, 3], dtype=torch.float32)target = torch.tensor([1, 2, 5], dtype=torch.float32)input = torch.reshape(input, (1, 1, 1, 3))target = torch.reshape(target, (1, 1, 1, 3))loss = L1Loss()result = loss(input, target)print(result)è¾“å‡ºï¼štensor (0.6667)\n\n nn.MSELoss \nMSE = (0+0+2^2)/3=4/3=1.333\næ³¨æ„æ¯ä¸ªä½ç½®è¦å¹³æ–¹\nimport torchfrom torch.nn import L1Lossinput = torch.tensor([1, 2, 3], dtype=torch.float32)target = torch.tensor([1, 2, 5], dtype=torch.float32)input = torch.reshape(input, (1, 1, 1, 3))target = torch.reshape(target, (1, 1, 1, 3))loss_Mse = torch.nn.MSELoss()result_Mse = loss_Mse(input, target)print(result_Mse)\näº¤å‰ç†µï¼š nn.CrossEntropyLoss  åˆ†ç±»é—®é¢˜\n\næ­¤å¤„ log æ—¶ä»¥ e ä¸ºåº•æ•°çš„ï¼ˆlnï¼‰ï¼Œå¸¸è§ target å°±æ˜¯ç›®æ ‡ä»£å·ï¼Œ1 å°±æ˜¯ç¬¬äºŒä¸ªæ ‡ç­¾\n\nä½¿ç”¨ result_loss.backward () å¼€å¯åå‘ä¼ æ’­\nbackward æ ¹æ®æŸå¤±å€¼  result_loss  è‡ªåŠ¨è®¡ç®—å‡ºæ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ï¼Œå¹¶æŠŠæ¢¯åº¦å­˜åˆ°å‚æ•°çš„  .grad  å±æ€§ä¸­ã€‚\nimport torchimport torchvisionfrom torch import nnfrom torch.nn import Conv2d, Sequential, MaxPool2d, Linear, Flattendataset = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                       download=True)dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model1 = Sequential(            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Flatten(),            Linear(1024, 64),            Linear(64, 10))    def forward(self, x):        x = self.model1(x)        return xnet = Net()loss = nn.CrossEntropyLoss()for data in dataloader:    imgs, targets = data    outputs = net(imgs)    result_loss = loss(outputs, targets)    result_loss.backward()    print(\"ok\")    print(result_loss)# optim ä¼˜åŒ–å™¨\nå®ƒè´Ÿè´£æ ¹æ®å‚æ•°çš„æ¢¯åº¦  .grad  æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œè®©æ¨¡å‹è¶Šæ¥è¶Šæ¥è¿‘ç›®æ ‡ã€‚\nè®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ—¶æµç¨‹æ˜¯è¿™æ ·çš„ï¼š\n\nå‰å‘ä¼ æ’­ (forward)\n è¾“å…¥æ•°æ® â†’ æ¨¡å‹è¾“å‡º â†’ è®¡ç®—æŸå¤±  loss ã€‚\nåå‘ä¼ æ’­ (backward)\n è°ƒç”¨  loss.backward() ï¼ŒPyTorch ä¼šè‡ªåŠ¨ç®—å‡ºæ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ï¼Œå¹¶å­˜åˆ°  param.grad  é‡Œã€‚\nå‚æ•°æ›´æ–° (update step)\n è¿™ä¸€æ­¥å°±æ˜¯ ä¼˜åŒ–å™¨çš„ä½œç”¨ã€‚\nä¼˜åŒ–å™¨ä¼šè¯»å–å‚æ•°çš„  .grad ï¼Œç„¶åæ ¹æ®ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚ SGDã€Adamï¼‰æ¥è°ƒæ•´å‚æ•°å€¼ã€‚\n\noptimï¼ˆupdate stepï¼‰ä¼šæ ¹æ® backward è®¡ç®—å‡ºæ¥çš„æ¢¯åº¦æ¥æ›´æ–°å‚æ•°\nimport torchimport torchvisionfrom torch import nnfrom torch.nn import Conv2d, Sequential, MaxPool2d, Linear, Flattendataset = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                       download=True)dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model1 = Sequential(            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Flatten(),            Linear(1024, 64),            Linear(64, 10))    def forward(self, x):        x = self.model1(x)        return xnet = Net()loss = nn.CrossEntropyLoss()optim = torch.optim.SGD(net.parameters(), lr=0.01)for epoch in range(20):    print(\"Epoch:&#123;&#125;\".format(epoch))    running_loss = 0.0    for data in dataloader:        imgs, targets = data        outputs = net(imgs)        result_loss = loss(outputs, targets)        optim.zero_grad()        result_loss.backward()        optim.step()        running_loss += result_loss    print(\"Loss:&#123;&#125;\".format(running_loss))å…³é”®åœ¨äºï¼š\noptim.zero_grad()\nresult_loss.backward()\noptim.step()\né¦–å…ˆ optim æ¢¯åº¦æ•°æ®æ¸…é›¶ï¼Œç„¶å backward è®¡ç®—è¿™ä¸€æ¬¡çš„æ¢¯åº¦ã€‚æœ€å optim åšå‚æ•°çš„ä¼˜åŒ–\nå¯¹äºè¿™é‡Œçš„å¾ªç¯ï¼š\nfor data in dataloader:        imgs, targets = data        outputs = net(imgs)        result_loss = loss(outputs, targets)        optim.zero_grad()        result_loss.backward()        optim.step()        running_loss += result_lossåªæ˜¯å¯¹æ•°æ®è¿›è¡Œäº†ä¸€è½®çš„å­¦ä¹ ï¼Œæˆ‘ä»¬éœ€è¦å¤šè½®å­¦ä¹ æ‰èƒ½æœ€ä¼˜åŒ–ç»“æœï¼š\nfor epoch in range(20):    print(\"Epoch:&#123;&#125;\".format(epoch))    running_loss = 0.0    for data in dataloader:        imgs, targets = data        outputs = net(imgs)        result_loss = loss(outputs, targets)        optim.zero_grad()        result_loss.backward()        optim.step()        running_loss += result_loss    print(\"Loss:&#123;&#125;\".format(running_loss))å› æ­¤æˆ‘ä»¬è¿™æ ·æ“ä½œ\n# SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\nè®­ç»ƒç¥ç»ç½‘ç»œçš„ç›®æ ‡æ˜¯è®© æŸå¤±å‡½æ•° Loss æœ€å°åŒ–\næƒ³è±¡æŸå¤±å‡½æ•°æ˜¯ä¸€ä¸ª â€œå±±è°·åœ°å½¢â€ï¼Œæˆ‘ä»¬è¦æ²¿ç€å±±å¡å¾€ä¸‹èµ°ï¼Œç›´åˆ°æ‰¾åˆ°æœ€ä½ç‚¹\næ¢¯åº¦ï¼ˆGradientï¼‰ å°±æ˜¯å‘Šè¯‰æˆ‘ä»¬ â€œå¾€å“ªä¸ªæ–¹å‘ä¸‹å¡æœ€å¿«â€\n\noptim = torch.optim.SGD(net.parameters(), lr=0.01)æ¨¡å‹å‚æ•°å³ net.parameters ()ï¼Œå­¦ä¹ é€Ÿç‡å³ lr=0.01\nå­¦ä¹ ç‡ (learning rate, lr)ï¼š\nlr å¤ªå°ï¼šèµ°å¾—æ…¢ï¼Œæ”¶æ•›é€Ÿåº¦æ…¢ï¼Œå¯èƒ½è®­ç»ƒå¾ˆä¹… loss æ‰ä¸‹é™ã€‚\nlr å¤ªå¤§ï¼šèµ°å¾—å¿«ï¼Œä½†å¯èƒ½ â€œè·¨è¿‡å±±è°·åº•éƒ¨â€ï¼Œé€ æˆéœ‡è¡ç”šè‡³å‘æ•£ï¼ˆloss å˜å¤§ï¼‰ã€‚\n# ç°æœ‰æ¨¡å‹çš„ä½¿ç”¨ä¸ä¿®æ”¹ï¼ˆè¿ç§»å­¦ä¹ ï¼‰\nå€Ÿç”¨åˆ«äººè®­ç»ƒå¥½çš„æ¨¡å‹çŸ¥è¯†ï¼Œåœ¨æ–°ä»»åŠ¡ä¸Šå‡å°‘è®­ç»ƒæˆæœ¬ï¼Œæé«˜æ•ˆæœã€‚\nåœ¨ç°æœ‰ vgg16 ä¸­åŠ ä¸€äº›æ–°çš„å±‚\nimport osimport torchvision.datasetsfrom torch import nnos.environ[\"TORCH_HOME\"] = \"E:/PyCharmCode/pytorchSTU/data\"vgg16_false = torchvision.models.vgg16(pretrained=False)vgg16_true = torchvision.models.vgg16(pretrained=True)print(vgg16_true)train_data = torchvision.datasets.CIFAR10(root=\"data\", train=True, transform=torchvision.transforms.ToTensor(),                                          download=True)vgg16_true.classifier.add_module(\"add_linear\", nn.Linear(1000, 10))print(vgg16_true)æºï¼š\n\n(classifier): Sequential(\n(0): Linear(in_features=25088, out_features=4096, bias=True)\n(1): ReLU(inplace=True)\n(2): Dropout(p=0.5, inplace=False)\n(3): Linear(in_features=4096, out_features=4096, bias=True)\n(4): ReLU(inplace=True)\n(5): Dropout(p=0.5, inplace=False)\n(6): Linear(in_features=4096, out_features=1000, bias=True)\n)\n\nç°ï¼š\n\n(classifier): Sequential(\n(0): Linear(in_features=25088, out_features=4096, bias=True)\n(1): ReLU(inplace=True)\n(2): Dropout(p=0.5, inplace=False)\n(3): Linear(in_features=4096, out_features=4096, bias=True)\n(4): ReLU(inplace=True)\n(5): Dropout(p=0.5, inplace=False)\n(6): Linear(in_features=4096, out_features=1000, bias=True)\n(add_linear): Linear(in_features=1000, out_features=10, bias=True)\n)\n\nåœ¨ç°æœ‰ vgg16 ä¸­ä¿®æ”¹å±‚\nimport osimport torchvision.datasetsfrom torch import nn# train_data = torchvision.datasets.ImageNet(root=\"data\", split=\"train\", download=True,#                                            transform=torchvision.transforms.ToTensor())os.environ[\"TORCH_HOME\"] = \"E:/PyCharmCode/pytorchSTU/data\"vgg16_false = torchvision.models.vgg16(pretrained=False)vgg16_true = torchvision.models.vgg16(pretrained=True)print(vgg16_false)vgg16_false.classifier[6] = nn.Linear(in_features=4096, out_features=10)print(vgg16_false)æºï¼š\n\n(classifier): Sequential(\n(0): Linear(in_features=25088, out_features=4096, bias=True)\n(1): ReLU(inplace=True)\n(2): Dropout(p=0.5, inplace=False)\n(3): Linear(in_features=4096, out_features=4096, bias=True)\n(4): ReLU(inplace=True)\n(5): Dropout(p=0.5, inplace=False)\n(6): Linear(in_features=4096, out_features=1000, bias=True)\n)\n\nç°ï¼š\n\n(classifier): Sequential(\n(0): Linear(in_features=25088, out_features=4096, bias=True)\n(1): ReLU(inplace=True)\n(2): Dropout(p=0.5, inplace=False)\n(3): Linear(in_features=4096, out_features=4096, bias=True)\n(4): ReLU(inplace=True)\n(5): Dropout(p=0.5, inplace=False)\n(6): Linear(in_features=4096, out_features=10, bias=True)\n)\n\n# æ¨¡å‹çš„ä¿å­˜ä¸åŠ è½½\nä¿å­˜ï¼š\nimport osimport torchimport torchvision.modelsfrom torch import nnos.environ[\"TORCH_HOME\"] = \"E:/PyCharmCode/pytorchSTU/data\"vgg16 = torchvision.models.vgg16(pretrained=False)# æ–¹å¼ 1ï¼šä¿å­˜æ¨¡å‹ç»“æ„ + å‚æ•°torch.save(vgg16, \"vgg16_method1.pth\")# æ–¹å¼ 2ï¼šä¿å­˜æ¨¡å‹å‚æ•° (å®˜æ–¹æ¨è)torch.save(vgg16.state_dict(), \"vgg16_method2.pth\")# é™·é˜± 1class Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.conv1 = nn.Conv2d(3, 32, 5, 1, 2)    def forward(self, x):        x = self.conv1(x)        return xnet = Net()torch.save(net, \"net.pth\")åŠ è½½ï¼š\nimport torchimport torchvision.modelsimport model_savefrom torch import nn# æ–¹å¼ 1ï¼šæ¨¡å‹ç»“æ„ + å‚æ•°åŠ è½½ 1torch_load = torch.load(\"vgg16_method1.pth\", weights_only=False)# print(torch_load)# æ–¹å¼ 2ï¼šæ¨¡å‹å‚æ•°åŠ è½½ 2vgg16 = torchvision.models.vgg16(pretrained=False)torch_load = torch.load(\"vgg16_method2.pth\", weights_only=True)vgg16.load_state_dict(torch_load)# print(vgg16)# é™·é˜± 1: éœ€è¦æŠŠæ¨¡å‹å¼•å…¥æ‰èƒ½è¿›è¡ŒåŠ è½½ import model_savemodel = torch.load(\"net.pth\", weights_only=False)print(model)# æ¨¡å‹çš„å®Œæ•´è®­ç»ƒå¥—è·¯\n\nå‡†å¤‡æ•°æ®é›†ã€è·å–æ•°æ®é›†å¤§å°ï¼ˆå¯é€‰ï¼‰\ndataLoader åŠ è½½æ•°æ®é›†\næ­å»ºç¥ç»ç½‘ç»œ Net\nåˆ›å»ºæŸå¤±å‡½æ•° loss_fnã€åˆ›å»ºä¼˜åŒ–å™¨ optimizerã€å¯é€‰ä½¿ç”¨ tenser board\nè®¾ç½®è®­ç»ƒç½‘ç»œä¸€äº›å‚æ•°ï¼šè®­ç»ƒçš„è½®æ•° total_train_stepã€æµ‹è¯•çš„è½®æ•° total_test_stepã€æ€»è®­ç»ƒçš„è½®æ•° epoch\nå¼€å§‹è®­ç»ƒï¼Œå¯¼å‡º imgs, targets å¹¶è¿›å…¥ç½‘ç»œ\nè®¡ç®—æŸå¤±å‡½æ•°\næ¸…é›¶æ¢¯åº¦ã€è®¡ç®—æ¢¯åº¦ã€åˆ©ç”¨åå‘ä¼ æ’­ï¼Œè‡´ä½¿ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°\næš‚æ—¶å…³é—­æ¢¯åº¦è®¡ç®—ã€å¼€å§‹æµ‹è¯•\nè®¡ç®—æŸå¤±å‡½æ•°å¹¶ç´¯è®¡ã€è®¡ç®—å½“å‰è½®æ¬¡å‡†ç¡®ç‡\né‡å¤ 6~10ï¼Œç›´åˆ°å®Œæˆæ‰€æœ‰è½®æ¬¡\n\nimport torchimport torchvision.datasetsfrom torch.utils.tensorboard import SummaryWriterfrom model import *from torch.utils.data import DataLoader# å‡†å¤‡æ•°æ®é›†train_data = torchvision.datasets.CIFAR10(\"data\", train=True, transform=torchvision.transforms.ToTensor(),                                          download=True)test_data = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                         download=True)# è·å–æ•°æ®é›†å¤§å°train_data_size = len(train_data)test_data_size = len(test_data)print(f\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸º&#123;train_data_size&#125;\")print(f\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ä¸º&#123;test_data_size&#125;\")# dataLoader åŠ è½½æ•°æ®é›†dataLoader_train = DataLoader(train_data, batch_size=64)dataLoader_test = DataLoader(test_data, batch_size=64)# æ­å»ºç¥ç»ç½‘ç»œnet = Net()# åˆ›å»ºæŸå¤±å‡½æ•°loss_fn = nn.CrossEntropyLoss()# åˆ›å»ºä¼˜åŒ–å™¨lr = 0.01optimizer = torch.optim.SGD(net.parameters(), lr=lr)# tenser boardwriter = SummaryWriter(\"logs\")# è®¾ç½®è®­ç»ƒç½‘ç»œä¸€äº›å‚æ•°# è®­ç»ƒçš„è½®æ•°total_train_step = 0# æµ‹è¯•çš„è½®æ•°total_test_step = 0# è®­ç»ƒçš„è½®æ•°epoch = 10for i in range(epoch):    print(\"--------ç¬¬ &#123;&#125; è½®è®­ç»ƒå¼€å§‹--------\".format(i + 1))    # è®­ç»ƒå¼€å§‹    net.train()    for data in dataLoader_train:        imgs, targets = data        outputs = net(imgs)        loss = loss_fn(outputs, targets)  # æŸå¤±å‡½æ•°        optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦        loss.backward()  # åå‘ä¼ æ’­        optimizer.step()  # ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°        total_train_step += 1        if total_train_step % 100 == 0:            print(\"è®­ç»ƒæ¬¡æ•°ï¼š&#123;&#125;, Loss: &#123;&#125;\".format(total_train_step, loss.item()))            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)    # æµ‹è¯•æ­¥éª¤å¼€å§‹    net.eval()    total_test_loss = 0    total_acc = 0    with torch.no_grad():  # ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®— with çš„ä½œç”¨æ˜¯ï¼šä¸´æ—¶å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œé€€å‡ºåè‡ªåŠ¨æ¢å¤ã€‚åœ¨ä¸Šä¸‹æ–‡é‡Œå…³é—­ï¼Œå‡ºäº†ä¸Šä¸‹æ–‡å°±æ¢å¤ã€‚        for data in dataLoader_test:            imgs, targets = data            outputs = net(imgs)  # æµ‹è¯•æ­¥éª¤å¼€å§‹            loss = loss_fn(outputs, targets)  # æŸå¤±å‡½æ•°            total_test_loss += loss.item()  # æ±‚å’Œ            acc = (outputs.argmax(1) == targets).sum()            total_acc += acc        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Lossï¼š&#123;&#125;\".format(total_test_loss))        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡ï¼š&#123;&#125;\".format(total_acc / test_data_size))        writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)        writer.add_scalar(\"test_acc\", total_acc / test_data_size, total_test_step)        total_test_step += 1    torch.save(net, \"net_&#123;&#125;.pth\".format(i))    print(\"æ¨¡å‹å·²ä¿å­˜\")writer.close()10 è½®å­¦ä¹ åï¼Œæ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡ï¼š0.5428000092506409\n# test_acc\n\n# test_loss\n\n# train_loss\n\n# ä½¿ç”¨ GPU è®­ç»ƒ 1ï¼ˆ.cudaï¼‰\n\n\nç½‘ç»œå¯ä»¥ä½¿ç”¨ GPU åŠ é€Ÿ\nnet = Net()# äº¤ç»™ GPUif torch.cuda.is_available():    net = net.cuda()\n\næŸå¤±å‡½æ•°å¯ä»¥ä½¿ç”¨ GPU åŠ é€Ÿ\nloss_fn = nn.CrossEntropyLoss()# äº¤ç»™ GPUif torch.cuda.is_available():    loss_fn = loss_fn.cuda()\n\næ•°æ®å’Œæ ‡ç­¾å’Œä½¿ç”¨ GPU åŠ é€Ÿ\n# äº¤ç»™ GPUif torch.cuda.is_available():    imgs = imgs.cuda()    targets = targets.cuda()\n\nä¼˜åŒ–åï¼š\n# _*_ coding : utf-8 _*_# @Time : 2025/8/26 14:38# @Author : KarryLiu# File : train_gpu_1# @Project : pytorchSTUimport torchimport torchvision.datasetsfrom torch import nnfrom torch.nn import Sequential, Conv2d, MaxPool2d, Linear, Flattenfrom torch.utils.tensorboard import SummaryWriterfrom torch.utils.data import DataLoader# å‡†å¤‡æ•°æ®é›†train_data = torchvision.datasets.CIFAR10(\"data\", train=True, transform=torchvision.transforms.ToTensor(),                                          download=True)test_data = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                         download=True)# è·å–æ•°æ®é›†å¤§å°train_data_size = len(train_data)test_data_size = len(test_data)print(f\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸º&#123;train_data_size&#125;\")print(f\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ä¸º&#123;test_data_size&#125;\")# dataLoader åŠ è½½æ•°æ®é›†dataLoader_train = DataLoader(train_data, batch_size=64)dataLoader_test = DataLoader(test_data, batch_size=64)# æ­å»ºç¥ç»ç½‘ç»œclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model = Sequential(            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Flatten(),            Linear(1024, 64),            Linear(64, 10)        )    def forward(self, x):        x = self.model(x)        return xnet = Net()# äº¤ç»™ GPUif torch.cuda.is_available():    net = net.cuda()# åˆ›å»ºæŸå¤±å‡½æ•°loss_fn = nn.CrossEntropyLoss()# äº¤ç»™ GPUif torch.cuda.is_available():    loss_fn = loss_fn.cuda()# åˆ›å»ºä¼˜åŒ–å™¨lr = 0.01optimizer = torch.optim.SGD(net.parameters(), lr=lr)# tenser boardwriter = SummaryWriter(\"logs\")# è®¾ç½®è®­ç»ƒç½‘ç»œä¸€äº›å‚æ•°# è®­ç»ƒçš„è½®æ•°total_train_step = 0# æµ‹è¯•çš„è½®æ•°total_test_step = 0# è®­ç»ƒçš„è½®æ•°epoch = 10for i in range(epoch):    print(\"--------ç¬¬ &#123;&#125; è½®è®­ç»ƒå¼€å§‹--------\".format(i + 1))    # è®­ç»ƒå¼€å§‹    net.train()    for data in dataLoader_train:        imgs, targets = data        # äº¤ç»™ GPU        if torch.cuda.is_available():            imgs = imgs.cuda()            targets = targets.cuda()        outputs = net(imgs)        loss = loss_fn(outputs, targets)  # æŸå¤±å‡½æ•°        optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦        loss.backward()  # åå‘ä¼ æ’­        optimizer.step()  # ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°        total_train_step += 1        if total_train_step % 100 == 0:            print(\"è®­ç»ƒæ¬¡æ•°ï¼š&#123;&#125;, Loss: &#123;&#125;\".format(total_train_step, loss.item()))            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)    # æµ‹è¯•æ­¥éª¤å¼€å§‹    net.eval()    total_test_loss = 0    total_acc = 0    with torch.no_grad():  # ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®— with çš„ä½œç”¨æ˜¯ï¼šä¸´æ—¶å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œé€€å‡ºåè‡ªåŠ¨æ¢å¤ã€‚åœ¨ä¸Šä¸‹æ–‡é‡Œå…³é—­ï¼Œå‡ºäº†ä¸Šä¸‹æ–‡å°±æ¢å¤ã€‚        for data in dataLoader_test:            imgs, targets = data            # äº¤ç»™ GPU            if torch.cuda.is_available():                imgs = imgs.cuda()                targets = targets.cuda()            outputs = net(imgs)  # æµ‹è¯•æ­¥éª¤å¼€å§‹            loss = loss_fn(outputs, targets)  # æŸå¤±å‡½æ•°            total_test_loss += loss.item()  # æ±‚å’Œ            acc = (outputs.argmax(1) == targets).sum()            total_acc += acc        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Lossï¼š&#123;&#125;\".format(total_test_loss))        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡ï¼š&#123;&#125;\".format(total_acc / test_data_size))        writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)        writer.add_scalar(\"test_acc\", total_acc / test_data_size, total_test_step)        total_test_step += 1    torch.save(net, \"net_&#123;&#125;.pth\".format(i))    print(\"æ¨¡å‹å·²ä¿å­˜\")writer.close()ä½¿ç”¨ GPU åï¼Œå­¦ä¹  100 æ¬¡åªéœ€è¦å¤§çº¦ 1.23s\n# ä½¿ç”¨ GPU è®­ç»ƒ 2ï¼ˆ.toï¼‰\nä½¿ç”¨ï¼š\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nç½‘ç»œå¯ä»¥ä½¿ç”¨ GPU åŠ é€Ÿ\nnet = Net()# äº¤ç»™ GPUnet = net.to(device)\n\næŸå¤±å‡½æ•°å¯ä»¥ä½¿ç”¨ GPU åŠ é€Ÿ\nloss_fn = nn.CrossEntropyLoss()# äº¤ç»™ GPUloss_fn = loss_fn.to(device)\n\næ•°æ®å’Œæ ‡ç­¾å’Œä½¿ç”¨ GPU åŠ é€Ÿ\n# äº¤ç»™ GPUimgs = imgs.to(device)targets = targets.to(device)\n\nä¼˜åŒ–åï¼š\nimport torchimport torchvision.datasetsfrom torch import nnfrom torch.nn import Sequential, Conv2d, MaxPool2d, Linear, Flattenfrom torch.utils.tensorboard import SummaryWriterfrom torch.utils.data import DataLoaderdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")# å‡†å¤‡æ•°æ®é›†train_data = torchvision.datasets.CIFAR10(\"data\", train=True, transform=torchvision.transforms.ToTensor(),                                          download=True)test_data = torchvision.datasets.CIFAR10(\"data\", train=False, transform=torchvision.transforms.ToTensor(),                                         download=True)# è·å–æ•°æ®é›†å¤§å°train_data_size = len(train_data)test_data_size = len(test_data)print(f\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸º&#123;train_data_size&#125;\")print(f\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ä¸º&#123;test_data_size&#125;\")# dataLoader åŠ è½½æ•°æ®é›†dataLoader_train = DataLoader(train_data, batch_size=64)dataLoader_test = DataLoader(test_data, batch_size=64)# æ­å»ºç¥ç»ç½‘ç»œclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model = Sequential(            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Flatten(),            Linear(1024, 64),            Linear(64, 10)        )    def forward(self, x):        x = self.model(x)        return xnet = Net()# äº¤ç»™ GPUnet = net.to(device)# åˆ›å»ºæŸå¤±å‡½æ•°loss_fn = nn.CrossEntropyLoss()# äº¤ç»™ GPUloss_fn = loss_fn.to(device)# åˆ›å»ºä¼˜åŒ–å™¨lr = 0.01optimizer = torch.optim.SGD(net.parameters(), lr=lr)# tenser boardwriter = SummaryWriter(\"logs\")# è®¾ç½®è®­ç»ƒç½‘ç»œä¸€äº›å‚æ•°# è®­ç»ƒçš„è½®æ•°total_train_step = 0# æµ‹è¯•çš„è½®æ•°total_test_step = 0# è®­ç»ƒçš„è½®æ•°epoch = 10for i in range(epoch):    print(\"--------ç¬¬ &#123;&#125; è½®è®­ç»ƒå¼€å§‹--------\".format(i + 1))    # è®­ç»ƒå¼€å§‹    net.train()    for data in dataLoader_train:        imgs, targets = data        # äº¤ç»™ GPU        imgs = imgs.to(device)        targets = targets.to(device)        outputs = net(imgs)        loss = loss_fn(outputs, targets)  # æŸå¤±å‡½æ•°        optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦        loss.backward()  # åå‘ä¼ æ’­        optimizer.step()  # ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°        total_train_step += 1        if total_train_step % 100 == 0:            print(\"è®­ç»ƒæ¬¡æ•°ï¼š&#123;&#125;, Loss: &#123;&#125;\".format(total_train_step, loss.item()))            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)    # æµ‹è¯•æ­¥éª¤å¼€å§‹    net.eval()    total_test_loss = 0    total_acc = 0    with torch.no_grad():  # ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®— with çš„ä½œç”¨æ˜¯ï¼šä¸´æ—¶å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œé€€å‡ºåè‡ªåŠ¨æ¢å¤ã€‚åœ¨ä¸Šä¸‹æ–‡é‡Œå…³é—­ï¼Œå‡ºäº†ä¸Šä¸‹æ–‡å°±æ¢å¤ã€‚        for data in dataLoader_test:            imgs, targets = data            # äº¤ç»™ GPU            imgs = imgs.to(device)            targets = targets.to(device)            outputs = net(imgs)  # æµ‹è¯•æ­¥éª¤å¼€å§‹            loss = loss_fn(outputs, targets)  # æŸå¤±å‡½æ•°            total_test_loss += loss.item()  # æ±‚å’Œ            acc = (outputs.argmax(1) == targets).sum()            total_acc += acc        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Lossï¼š&#123;&#125;\".format(total_test_loss))        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡ï¼š&#123;&#125;\".format(total_acc / test_data_size))        writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)        writer.add_scalar(\"test_acc\", total_acc / test_data_size, total_test_step)        total_test_step += 1    torch.save(net, \"net_&#123;&#125;.pth\".format(i))    print(\"æ¨¡å‹å·²ä¿å­˜\")writer.close()# éªŒè¯å¥—è·¯ï¼ˆåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç»™ä»–æä¾›è¾“å…¥ï¼‰\nimport torchimport torchvision.transformsfrom PIL import Imagefrom torch import nnfrom torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear# å¦‚æœæ˜¯ç”± GPU è®­ç»ƒå¾—åˆ°æ¨¡å‹ï¼Œåˆ™éœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ° GPU ä¸Š# å¦‚æœä»…æƒ³ä½¿ç”¨ CPU æµ‹è¯•å¯ä»¥åœ¨ model ä¸­ä½¿ç”¨ï¼šmap_location=\"cpu\"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")image_path = \"images/fff.png\"# æ­¤å¤„ png æ˜¯ RGBA æ¨¡å¼ï¼Œæˆ‘ä»¬è½¬æ¢æˆ RGB æ¨¡å¼image = Image.open(image_path).convert(\"RGB\")trans = torchvision.transforms.Compose([    torchvision.transforms.Resize(size=(32, 32)),    torchvision.transforms.ToTensor(),])image = trans(image)# æ·»åŠ ä¸€ä¸ªç»´åº¦ä»£è¡¨ 1 å¼ å›¾ç‰‡ï¼Œå¹¶äº¤ç»™ GPUimage = torch.reshape(image, (1, 3, 32, 32)).to(device)print(image.shape)# æ­å»ºç¥ç»ç½‘ç»œclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model = Sequential(            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),            MaxPool2d(kernel_size=2, ceil_mode=False),            Flatten(),            Linear(1024, 64),            Linear(64, 10)        )    def forward(self, x):        x = self.model(x)        return x# ä»…ä»…åœ¨ CPU æµ‹è¯•# model = torch.load(\"net_9.pth\", weights_only=False, map_location=\"cpu\")model = torch.load(\"net_9.pth\", weights_only=False)model.eval()with torch.no_grad():    output = model(image)    print(output)    print(torch.argmax(output))\ntorch.Size([1, 3, 32, 32])\ntensor([[ 4.1824, -0.9885,  2.4846, -0.8212,  0.5465, -1.7889, -1.6802, -0.3970,\n0.7540, -0.7934]])\ntensor(0)\n\n\n\n# GPU50 è½®å­¦ä¹ å\n\nåé¢å‡ºç°äº†è¿‡æ‹Ÿåˆ\n# é™„å½•\nç®€å•å…¥é—¨äº†ä¸€ä¸‹ï¼Œåé¢è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ï¼Œç»§ç»­ä¿æŒæŒç»­å­¦ä¹ çš„åŠ¨åŠ›ã€‚\nç›¸å…³ä»£ç å·²å…¬å¼€åœ¨ GitHub ä¸­ï¼šhttps://github.com/735690757/pytorch_stu_up\nSwim in the ocean of art and programming, weave the future with code art.\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","python_PyTorch"]},{"title":"FastAPI","url":"/python/fastapi/","content":"# FastAPI\nFastAPI æ˜¯ä¸€ä¸ªç”¨äºæ„å»º Web åº”ç”¨çš„ Python æ¡†æ¶ã€‚\n# å¤©ç”Ÿéé˜»å¡\n\n\n# ç±»å‹æç¤ºä¸éªŒè¯\n\n# è‡ªå¸¦äº¤äº’å¼æ–‡æ¡£\n\n# å¿«é€Ÿå¼€å§‹\nfrom fastapi import FastAPI# åˆ›å»ºä¸€ä¸ª FastAPI å®ä¾‹app = FastAPI()@app.get(\"/\")async def root():    return &#123;\"message\": \"Hello World\"&#125;@app.get(\"/hello/&#123;name&#125;\")async def say_hello(name: str):    return &#123;\"message\": f\"Hello &#123;name&#125;\"&#125;# å¯åŠ¨å‘½ä»¤\nuvicorn main:app --reloaduvicornï¼Ÿ uvicorn  æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„ Python ASGI Web æœåŠ¡å™¨ï¼Œä¸“é—¨ç”¨æ¥è¿è¡Œ FastAPI / Starlette / Django ASGI è¿™ç±»ç°ä»£ Web æ¡†æ¶ã€‚\nâ€“reloadï¼Ÿæ”¯æŒçƒ­éƒ¨ç½²ã€‚\n# ç»“æœ\n\n\n\n# Python è£…é¥°å™¨\nåœ¨ä¸æ”¹åŸå‡½æ•°ä»£ç çš„æƒ…å†µä¸‹ï¼Œç»™å‡½æ•°å¤–æŒ‚ä¸€å±‚åŠŸèƒ½ã€‚\n# Java æ³¨è§£æœ¬èº«åªæ˜¯ä¸ªæ ‡ç­¾\n@GetMapping(\"/hello\")public String hello() &#123;    return \"hi\";&#125;@GetMapping  æœ¬èº«ä¸æ‹¦æˆªï¼Œä¸æ‰§è¡Œï¼Œä¸æ”¹æ–¹æ³•ï¼ŒçœŸæ­£å¹²æ´»çš„æ˜¯ Spring æ¡†æ¶ + åå°„ + AOP\n# Python è£…é¥°å™¨æ˜¯å¯æ‰§è¡Œçš„\ndef log(func):    def wrapper(*args, **kwargs):        print(\"before\")        return func(*args, **kwargs)    return wrapper@logdef hello():    print(\"hi\")ç­‰ä»·äºï¼š\nhello = log(hello)è¿™é‡Œå·²ç»æ‰§è¡Œä»£ç äº†\n# è·¯ç”±\n@app.get(\"/hello/\")async def say_hello():    return &#123;\"message\": \"Hello World è¿™æ˜¯é»˜è¾“å‡º\"&#125;è¿™æ˜¯ä¸€ä¸ª get æ–¹æ³•ï¼Œé€šè¿‡ @app.get  è£…é¥°ã€‚\n# æ¥å£çš„åŠ¨æ€äº¤äº’\nè·¯å¾„å‚æ•°å†™åœ¨ URL è·¯å¾„é‡Œï¼Œç”¨æ¥æ ‡è¯†å…·ä½“èµ„æº\næŸ¥è¯¢å‚æ•°å†™åœ¨ URL  ?  åé¢ï¼Œç”¨æ¥ç­›é€‰ / é™„åŠ æ¡ä»¶\nè¯·æ±‚ä½“å‚æ•°æ”¾åœ¨è¯·æ±‚ä½“ä¸­ï¼Œç”¨æ¥æäº¤å¤æ‚æ•°æ®\n# è·¯å¾„å‚æ•°\n@app.get(\"/book/&#123;id&#125;\")async def getBook(id: int):    return &#123;        \"id\": id,        \"title\": f\"FastAPI book-&#123;id&#125;\"    &#125;# æ ¡éªŒ â€”â€” å¤§å°æ ¡éªŒä¸é•¿åº¦æ ¡éªŒ\n@app.get(\"/book/&#123;id&#125;\")async def getBook(id: int = Path(description=\"The ID of the book to get\", gt=0, lt=1000)):    return &#123;        \"id\": id,        \"title\": f\"FastAPI book-&#123;id&#125;\"    &#125;@app.get(\"/classify/&#123;name&#125;\")async def classify(name: str=Path(title=\"classify\", min_length=3, max_length=10)):    return &#123;        \"name\": name,        \"class\": \"FastAPI\"    &#125;# æŸ¥è¯¢å‚æ•°\n@app.get(\"/query_book\")async def query_book(        classify: str = Query(\"é»˜è®¤åˆ†ç±»\", min_length=2, max_length=255),        price: float = Query(10.0, gt=50.0, le=100.0)):    return &#123;        \"classify\": classify,        \"price\": price    &#125;# è¯·æ±‚ä½“å‚æ•°\nä½¿ç”¨ pydanticã€‚\nfrom pydantic import BaseModelclass User(BaseModel):    username: str    password: str@app.post(\"/register\")async def register(user: User):    return userclass Book(BaseModel):    title: str    author: str    publisher: str    price: float@app.post(\"/book/add\")async def add_book(book: Book):    return bookè¯·æ±‚ä½“å‚æ•°çš„çº¦æŸï¼š\nclass User(BaseModel):    username: str = Field(default=\"é»˜è®¤ç”¨æˆ·å\", min_length=2, max_length=10, description=\"ç”¨æˆ·å\")    password: str = Field(default=\"é»˜è®¤å¯†ç \", min_length=6, max_length=20, description=\"å¯†ç \")@app.post(\"/register\")async def register(user: User):    return user# å“åº”ç±»å‹\né€šè¿‡ response_class æŒ‡å®š\n\n# JSON\nè¿™ä¸ªä½ è¿”å›ä¸€ä¸ªå­—å…¸å¯¹è±¡çš„æ—¶å€™ï¼ŒFastAPI å°±è‡ªåŠ¨å¸®ä½ åšå¥½è½¬æ¢äº†ã€‚\n# HTML / çº¯æ–‡æœ¬\n@app.get(\"/html\",response_class=HTMLResponse)async def html():    return \"\"\"    &lt;html>        &lt;head>            &lt;title>FastAPI&lt;/title>        &lt;/head>        &lt;body>            &lt;h1>Hello World&lt;/h1>        &lt;/body>    &lt;/html>    \"\"\"# File æ–‡ä»¶\n@app.get(\"/file\")async def file():    path = \"./files/dd.txt\"    return FileResponse(path)# è‡ªå®šä¹‰å“åº”ç±»å‹\nclass R(BaseModel):    code: int    msg: str    data: dict = Field(default=&#123;&#125;, description=\"è¿”å›æ•°æ®\")@app.get(\"/api\", response_model=R)async def api():    return &#123;        \"code\": 200,        \"msg\": \"success\",        \"data\": &#123;            \"name\": \"KarryLiu\",            \"age\": 18        &#125;,    &#125;å½“ä½ ç¼ºå¤±æ•°æ®æ—¶ä¼šæŠ¥é”™ï¼Œå½“ä½ æ•°æ®è¶…å‡ºçº¦å®šæ—¶ä¼šè‡ªåŠ¨è¿‡æ»¤æ‰ã€‚\n# å¼‚å¸¸å¤„ç†\n@app.get(\"/api/news\", response_model=R)async def api_news(id: int = Query(1, gt=0, lt=1000)):    news_list = [1, 2, 3]    if id not in news_list:        raise HTTPException(status_code=404, detail=\"æ–°é—»ä¸å­˜åœ¨\")    return &#123;        \"code\": 200,        \"msg\": \"success\",        \"data\": &#123;            \"id\": id,            \"title\": f\"æ–°é—»æ ‡é¢˜-&#123;id&#125;\",            \"content\": f\"æ–°é—»å†…å®¹-&#123;id&#125;\"        &#125;,    &#125;# ä¸­é—´ä»¶\nä¸­é—´ä»¶ç»™æ¯ä¸€ä¸ªè¯·æ±‚æä¾›ç»Ÿä¸€çš„å¤„ç†é€»è¾‘ã€‚ä½¿ç”¨ @app.middleware(&quot;http&quot;)  æ¥å®šä¹‰ã€‚å¤šä¸ªä¸­é—´ä»¶æ˜¯è‡ªåº•å‘ä¸Šæ‰§è¡Œçš„\n@app.middleware(\"http\")async def middleware1(request, call_next):    print(\"ä¸­é—´ä»¶1å¼€å§‹æ‰§è¡Œ\")    response = await call_next(request)    print(\"ä¸­é—´ä»¶1ç»“æŸæ‰§è¡Œ\")    return response@app.middleware(\"http\")async def middleware2(request, call_next):    print(\"ä¸­é—´ä»¶2å¼€å§‹æ‰§è¡Œ\")    response = await call_next(request)    print(\"ä¸­é—´ä»¶2ç»“æŸæ‰§è¡Œ\")    return response@app.get(\"/api/mid\")async def api_mid():    return &#123;        \"code\": 200,        \"msg\": \"success\",        \"data\": &#123;            \"name\": \"KarryLiu\",            \"age\": 18        &#125;,    &#125;\nå±…ç„¶æ˜¯è‡ªåº•å‘ä¸Šæ‰§è¡Œçš„\n# ä¾èµ–æ³¨å…¥\n\n\nasync def common_parameters(skip: int = 0, limit: int = 10):    return &#123;\"skip\": skip, \"limit\": limit&#125;@app.get(\"/api/news_list\")async def get_news_list(commons=Depends(common_parameters)):    return &#123;\"msg\": \"news_list\"&#125;@app.get(\"api/user_list\")async def get_user_list(commons=Depends(common_parameters)):    return &#123;\"msg\": \"user_list\"&#125;common_parameters  é‡Œ  return &#123;&quot;skip&quot;: skip, &quot;limit&quot;: limit&#125;  è¿”å›å€¼ä¸ä¼šç›´æ¥è¿”å›ç»™å®¢æˆ·ç«¯ï¼Œ è€Œæ˜¯ ä½œä¸ºå‚æ•°å€¼ï¼Œä¼ ç»™  get_news_list  é‡Œçš„  commons  å˜é‡ã€‚æˆ‘ä»¬å¯ä»¥æ‰“å°ä¸€ä¸‹ï¼š\n@app.get(\"/api/news_list\")async def get_news_list(commons=Depends(common_parameters)):    print(commons)    print(commons[\"skip\"])    print(commons[\"limit\"])    return &#123;\"msg\": \"news_list\n# ORM å·¥å…· â€”â€”SQLAlchemy\n# å®‰è£… sqlalchemy [asyncio] å’Œ aiomysql\npip install sqlalchemy[asyncio] aiomysql# è‡ªåŠ¨å»ºè¡¨\nASYNC_DATABASE_URL = \"mysql+aiomysql://root:123456@localhost:3306/fastapi_first?charsetutf-8\"engine = create_async_engine(ASYNC_DATABASE_URL, echo=True, pool_size=10, max_overflow=20, pool_recycle=3600,                             pool_pre_ping=True, pool_use_lifo=True, pool_timeout=30, future=True, )class Base(DeclarativeBase):    create_time: Mapped[datetime] = mapped_column(DateTime, insert_default=func.now(), comment=\"åˆ›å»ºæ—¶é—´\")    update_time: Mapped[datetime] = mapped_column(DateTime, insert_default=func.now(), comment=\"æ›´æ–°æ—¶é—´\")class Book(Base):    __tablename__ = \"book\"    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True, comment=\"ID\")    title: Mapped[str] = mapped_column(String(100), comment=\"æ ‡é¢˜\")    author: Mapped[str] = mapped_column(String(50), comment=\"ä½œè€…\")    publisher: Mapped[str] = mapped_column(String(100), comment=\"å‡ºç‰ˆç¤¾\")    price: Mapped[float] = mapped_column(Float, comment=\"ä»·æ ¼\")class User(Base):    __tablename__ = \"user\"    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True, comment=\"ID\")    username: Mapped[str] = mapped_column(String(50), comment=\"ç”¨æˆ·å\")    password: Mapped[str] = mapped_column(String(50), comment=\"å¯†ç \")async def create_table():    async with engine.begin() as conn:        await conn.run_sync(Base.metadata.create_all)@asynccontextmanagerasync def lifespan(apps: FastAPI):    await create_table()    yield    await engine.dispose()app = FastAPI(lifespan=lifespan)\n# ORM ä¾èµ–æ³¨å…¥ä¸æ•°æ®æŸ¥è¯¢\nAsyncSessionLocal = async_sessionmaker(    engine,    class_=AsyncSession,    expire_on_commit=False,)async def get_database():    async with AsyncSessionLocal() as session:        try:            yield session            await session.commit()        except Exception as e:            await session.rollback()            raise        finally:            await session.close()@app.get(\"/book/books\")async def get_books(session: AsyncSession = Depends(get_database)):    query = select(Book)    result = await session.execute(query)    books = result.scalars().all()    print(books)    return books\n# æŸ¥è¯¢\n# æ¯”è¾ƒåˆ¤æ–­\n==ï¼›&gt;ï¼›&lt;ï¼›&gt;=ï¼›&lt;=\n@app.get(\"/book/book/&#123;id&#125;\")async def get_book(id: int, session: AsyncSession = Depends(get_database)):    query = select(Book).where(Book.id == id)    result = await session.execute(query)    book = result.scalars().first()    return book@app.get(\"/book/book/&#123;id&#125;\")async def get_book(id: int, session: AsyncSession = Depends(get_database)):    query = select(Book).where(Book.id == id)    result = await session.execute(query)    book = result.scalars().one_or_none()    return book# æ¨¡ç³ŠæŸ¥è¯¢\n@app.get(\"/book/like\")async def get_like_book(title: str, session: AsyncSession = Depends(get_database)):    query = select(Book).where(Book.title.like(f\"%&#123;title&#125;%\"))    result = await session.execute(query)    book = result.scalars().all()    return book\n# å–é¦–æ¡æ•°æ®\n@app.get(\"/book/first\")async def get_first_book(session: AsyncSession = Depends(get_database)):    query = select(Book)    result = await session.execute(query)    book = result.scalars().first()    return book# å¤šæ¡ä»¶\n@app.get(\"/book/like_start\")async def get_like_start_book(title: str, session: AsyncSession = Depends(get_database)):    query = select(Book).where(Book.title.like(f\"&#123;title&#125;%\")).where(Book.id == 2)    result = await session.execute(query)    book = result.scalars().all()    return book# èšåˆæŸ¥è¯¢\nfuncâ€”â€”count / avg / max / min / sum\n@app.get(\"/book/get_avg_price\")async def get_avg_price(session: AsyncSession = Depends(get_database)):    query = select(func.avg(Book.price))    result = await session.execute(query)    avg_price = result.scalars().one()    return avg_price\n\n","categories":["å¼€å‘ç»éªŒ"],"tags":["python","Fast API"]},{"title":"v2yWdtcï¼šæ— èŠå†™äº†ä¸€ä¸ªæ ¼å¼è½¬æ¢å·¥å…·","url":"/python/v2yWdtc/","content":"# v2yWdtc\nv2yWdtc æ˜¯æˆ‘æ— èŠç¼–å†™çš„ä¸€æ¬¾å°† VOC æ ¼å¼è½¬æ¢ä¸º YOLO æ ¼å¼çš„å·¥å…·ï¼Œå®ƒçš„æ„æˆéå¸¸ç®€å•ï¼Œå°½ç®¡å¦‚æ­¤å®ƒå¾ˆå¼ºå¤§ï¼Œå®ƒå¯ä»¥è¾…åŠ©ä½ åˆ†æä½ çš„æ•°æ®é›†æ˜¯å¦æœ‰å¼‚å¸¸çš„æ•°æ®ï¼ŒåŒæ—¶é’ˆå¯¹ç©ºæ ‡ç­¾è¿˜æœ‰è¿‡æ»¤åŠŸèƒ½ã€‚\n\nå¿«é€Ÿè½¬æ¢ï¼šä¸€é”®å°† VOC æ ¼å¼æ ‡ç­¾è½¬æ¢ä¸º YOLO æ ¼å¼ã€‚\næ•°æ®é¢„æ£€æµ‹ï¼šç»Ÿè®¡æ•°æ®é›†ï¼Œè¾…åŠ©ä½ å‘ç°å¼‚å¸¸æ ‡ç­¾æˆ–æ ‡æ³¨é—®é¢˜ã€‚\nç©ºæ ‡ç­¾è¿‡æ»¤ï¼šè‡ªåŠ¨è¿‡æ»¤ç©ºæ ‡ç­¾ï¼Œä¿è¯è®­ç»ƒæ•°æ®è´¨é‡ã€‚\nç®€å•æ˜“ç”¨ï¼šæ— éœ€å¤æ‚é…ç½®ï¼Œå‡ æ­¥æ“ä½œå³å¯å®Œæˆæ•°æ®é¢„å¤„ç†ã€‚\n\n# å¼€æºåœ°å€ - â­ï¼\nv2yWdtcï¼šhttps://github.com/735690757/v2yWdtc\n# é¡¹ç›®ç»“æ„\n\n\n\nç›®å½• / æ–‡ä»¶\næ ¸å¿ƒèŒèƒ½è¯´æ˜\n\n\n\n\n Annotations/ \nåŸå§‹æ ‡ç­¾å­˜æ”¾åœ°ã€‚é€šå¸¸å­˜æ”¾æ ‡å‡†çš„ XML æ ¼å¼æ–‡ä»¶ï¼ŒåŒ…å«ç›®æ ‡ç±»åˆ«å’Œè¾¹ç•Œæ¡†åæ ‡ã€‚\n\n\n Imagesets/ \næ•°æ®é›†ç´¢å¼•ä¸­å¿ƒã€‚å­˜æ”¾  train.txt ,  val.txt ,  test.txt  ç­‰ã€‚ä¹‹å‰çš„æŠ¥é”™æ­£æ˜¯å› ä¸ºç¨‹åºæ— æ³•åœ¨æ­¤æ‰¾åˆ°è¿™äº›ç´¢å¼•æ–‡ä»¶ã€‚\n\n\n JPEGImages/ \nåŸå§‹å›¾åƒåº“ã€‚å­˜æ”¾æ‰€æœ‰è®­ç»ƒå’Œæµ‹è¯•ç”¨çš„å›¾ç‰‡ï¼ˆ  .jpg  æ ¼å¼ï¼‰ã€‚\n\n\n Tools/ \næ•°æ®è¯Šæ–­å·¥å…·ç®±ã€‚åŒ…å«ç”¨äºåˆ†ææ•°æ®é›†è´¨é‡çš„è„šæœ¬ï¼ˆå¦‚  check.py  æ£€æŸ¥å®Œæ•´æ€§ï¼Œ cbox.py  åˆ†æè¾¹ç•Œæ¡†åˆ†å¸ƒï¼‰ã€‚\n\n\n images_tag.py \næ ‡ç­¾å¤„ç†æ¨¡å—ã€‚å¯èƒ½æ¶‰åŠå›¾åƒæ ‡æ³¨çš„è‡ªåŠ¨åŒ–å¤„ç†æˆ–ç±»åˆ«åç§°æ˜ å°„ã€‚\n\n\n imgsWlabels.py \næ•°æ®åˆ†å‘å¼•æ“ã€‚è´Ÿè´£æ ¹æ®ç´¢å¼•æ–‡ä»¶å°†å›¾ç‰‡å’Œè½¬æ¢åçš„æ ‡ç­¾æ–‡ä»¶åˆ†å‘åˆ°æŒ‡å®šçš„è®­ç»ƒ / éªŒè¯æ–‡ä»¶å¤¹ä¸­ã€‚\n\n\n main.py \né¡¹ç›®æ€»å…¥å£ã€‚ä¸€é”®åŒ–æ“ä½œçš„æ§åˆ¶å°ï¼Œé€šè¿‡è°ƒç”¨å…¶ä»–æ¨¡å—å®Œæˆå…¨æµç¨‹è½¬æ¢ã€‚\n\n\n voc_to_yolo.py \næ ¼å¼è½¬æ¢æ ¸å¿ƒã€‚æ‰§è¡Œæœ€å…³é”®çš„ XML åˆ° TXT å½’ä¸€åŒ–è½¬æ¢é€»è¾‘ã€‚\n\n\n\n\n# train ä¸ val æ¨¡å¼ã€trainval æ¨¡å¼\nåˆ‡æ¢æ¨¡å¼åªéœ€è¦ä¿®æ”¹ main.py çš„æ­¤å¤„ï¼š\n\n# train ä¸ val æ¨¡å¼ï¼ˆ0 æ¨¡å¼ï¼‰ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰\nåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œæ•°æ®é›†è¢«åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ï¼Œè¿™ç§æ¨¡å¼çš„ç‰¹ç‚¹æ˜¯ï¼šè®­ç»ƒé›†å’ŒéªŒè¯é›†æ˜¯åˆ†å¼€çš„ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼Œç¡®ä¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n# trainval æ¨¡å¼ï¼ˆ1 æ¨¡å¼ï¼‰\nåœ¨ trainval æ¨¡å¼ä¸‹ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†è¢«åˆå¹¶ä¸ºä¸€ä¸ªæ•´ä½“çš„æ•°æ®é›†ï¼Œæ¨¡å‹åœ¨æ•´ä¸ª  trainval  æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚è¿™ç§æ¨¡å¼é€šå¸¸ç”¨äºç‰¹å®šçš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ•°æ®é‡ä¸å¤§æ—¶ï¼Œå¯ä»¥é€šè¿‡åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†æ¥æå‡è®­ç»ƒé›†çš„å¤šæ ·æ€§å’Œå¤§å°ã€‚\n# ä½¿ç”¨æ–¹æ³•\n\nå°†å›¾ç‰‡æ•°æ®æ”¾åœ¨ JPEGImages ä¸‹\nå°† xml æ”¾åœ¨ Annotation ä¸‹\næ‰§è¡Œä¸»å‡½æ•°\nok äº†å°±\n\n# æ‰§è¡Œè¿‡ç¨‹\n\n# ç»“æœæ–‡ä»¶\n\nç´«è‰²è¾“å‡ºç»“æœæ˜¯å›¾ç‰‡ï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰å’Œæ ‡ç­¾ï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰\nç™½è‰²è¾“å‡ºç»“æœæ˜¯è¿™æ ·çš„ç´¢å¼•è®°å½•æ ¼å¼ï¼š\n\n# å‚è€ƒå¼€æºè„šæœ¬\nhttps://github.com/JieZzzoo/Data_Trans\n","categories":["æ·±åº¦å­¦ä¹ ","é¡¹ç›®ä¸å®æˆ˜"],"tags":["python"]},{"title":"åŸºäºPyTorchçš„æ‰‹å†™æ•°å­—è¯†åˆ«","url":"/python/pytorch_nn_digital_identification/","content":"# åŸºäº PyTorch çš„æ‰‹å†™æ•°å­—è¯†åˆ«\n# MNIST æ•°æ®é›†\nMNIST æ˜¯ä¸€ä¸ªç»å…¸çš„æ‰‹å†™æ•°å­—è¯†åˆ«æ•°æ®é›†ï¼ŒåŒ…å« 60,000 å¼ ç”¨äºè®­ç»ƒçš„å›¾ç‰‡å’Œ 10,000 å¼ ç”¨äºæµ‹è¯•çš„å›¾ç‰‡ã€‚æ¯å¼ å›¾ç‰‡åˆ†è¾¨ç‡ä¸º 28Ã—28 åƒç´ ï¼Œå†…å®¹æ˜¯æ•°å­— 0â€“9 çš„æ‰‹å†™ä½“ã€‚æˆ‘ä»¬å°†åŸºäºè¯¥æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚\n\n# ç¥ç»ç½‘ç»œçš„å®šä¹‰\n# è¾“å…¥\n\nä¸€å¼ å›¾ç‰‡å¤§å°ï¼š 1 Ã— 28 Ã— 28  ï¼ˆç°åº¦å›¾ï¼Œé€šé“æ•° = 1ï¼‰\n\n\n# ç¬¬ä¸€å±‚å·ç§¯\nnn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\nè¾“å…¥ï¼š 1 Ã— 28 Ã— 28\nå·ç§¯æ ¸ï¼š5Ã—5ï¼Œpadding=2 â†’ è¾“å‡ºå¤§å°ä»ç„¶æ˜¯ 28Ã—28\nè¾“å‡ºï¼š 16 Ã— 28 Ã— 28 ï¼ˆæå– 16 ä¸ªä¸åŒç‰¹å¾å›¾ï¼‰\n\n\n# ReLU æ¿€æ´»\nnn.ReLU()\nä¸æ”¹å˜å½¢çŠ¶ï¼Œåªæ˜¯æŠŠè´Ÿæ•°å˜æˆ 0ã€‚\nè¾“å‡ºï¼š 16 Ã— 28 Ã— 28\n\n\n# ç¬¬ä¸€æ¬¡æ± åŒ–\nnn.MaxPool2d(kernel_size=2)\næ± åŒ–çª—å£ï¼š2Ã—2ï¼Œæ­¥é•¿ = 2 â†’ å°ºå¯¸å‡åŠ\nè¾“å‡ºï¼š 16 Ã— 14 Ã— 14\n\n\n# ç¬¬äºŒå±‚å·ç§¯\nnn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\nè¾“å…¥ï¼š 16 Ã— 14 Ã— 14\nè¾“å‡ºï¼š 32 Ã— 14 Ã— 14\n\n\n# ReLU æ¿€æ´»\nnn.ReLU()\nè¾“å‡ºï¼š 32 Ã— 14 Ã— 14\n\n\n# ç¬¬äºŒæ¬¡æ± åŒ–\nnn.MaxPool2d(kernel_size=2)\nå°ºå¯¸å†å‡åŠ\nè¾“å‡ºï¼š 32 Ã— 7 Ã— 7\n\n\n# å±•å¹³\nnn.Flatten()\næŠŠ  32 Ã— 7 Ã— 7  å±•å¹³æˆä¸€ç»´å‘é‡\nè¾“å‡ºï¼š 32*7*7 = 1568\n\n\n# å…¨è¿æ¥å±‚ 1\nnn.Linear(32*7*7, 500)\nè¾“å…¥ï¼š 1568\nè¾“å‡ºï¼š 500\n\n\n# ReLU æ¿€æ´»\nnn.ReLU()\nè¾“å‡ºï¼š 500\n\n\n# å…¨è¿æ¥å±‚ 2\nnn.Linear(500, 100)\nè¾“å…¥ï¼š 500\nè¾“å‡ºï¼š 100\n\n\n# å…¨è¿æ¥å±‚ 3ï¼ˆè¾“å‡ºå±‚ï¼‰\nnn.Linear(100, 10)\nè¾“å…¥ï¼š 100\nè¾“å‡ºï¼š 10 ï¼ˆå¯¹åº”æ•°å­— 0â€“9 çš„ç±»åˆ«ï¼‰\n\n# æ€»ç»“\nç½‘ç»œçš„æµç¨‹å°±æ˜¯ï¼š\nè¾“å…¥  1Ã—28Ã—28  å›¾åƒ â†’ ä¸¤æ¬¡å·ç§¯ + ReLU + æ± åŒ–æå–ç‰¹å¾ â†’ å±•å¹³ â†’ ä¸‰å±‚å…¨è¿æ¥åˆ†ç±» â†’ è¾“å‡º 10 ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼ˆé¢„æµ‹æ•°å­— 0â€“9ï¼‰ã€‚\n\n# å­˜åœ¨çš„é—®é¢˜\nå…¨è¿æ¥å±‚æ•°é‡å’Œå¤§å°\n\nä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼ˆ500 â†’ 100 â†’ 10ï¼‰å¯¹ MNIST æ¥è¯´ç¨å¾®å¤§äº†ä¸€ç‚¹\nå¯ä»¥ç®€åŒ–ä¸º  500 â†’ 10  æˆ–  256 â†’ 10 ï¼Œè®­ç»ƒæ›´å¿«ï¼Œå‚æ•°æ›´å°‘\n\nå·ç§¯å±‚é€šé“æ•°\n\nç¬¬ä¸€å±‚ 16ã€ç¬¬äºŒå±‚ 32 å¯ä»¥å†å°ä¸€ç‚¹ï¼ˆå¦‚ 8 â†’ 16ï¼‰ï¼ŒMNIST å¤ªç®€å•äº†ï¼Œç”¨å¤ªå¤šç‰¹å¾å›¾å¯èƒ½æ²¡å¿…è¦\n\n# ä»£ç \nimport torchfrom torch import nnclass Net(nn.Module):    def __init__(self, *args, **kwargs) -> None:        super().__init__(*args, **kwargs)        self.model = nn.Sequential(            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, ceil_mode=False),            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, ceil_mode=False),            nn.Flatten(),            nn.Linear(32 * 7 * 7, 500),            nn.ReLU(),            nn.Linear(500, 100),            nn.Linear(100, 10)        )    def forward(self, x):        x = self.model(x)        return xif __name__ == '__main__':    net = Net()    print(net)    output = net(torch.ones((64, 1, 28, 28)))    print(output.shape)# æ¨¡å‹è®­ç»ƒ\n# å¯¼å…¥åº“\nimport torchimport torch.nn as nnimport torchvision.datasetsfrom torch.utils.data import DataLoaderfrom torchvision import transformsfrom torch.utils.tensorboard import SummaryWriterfrom nn_DI_NNFramework import Net\ntorch ï¼šPyTorch ä¸»åº“\ntorch.nn ï¼šç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…æ‹¬å„ç§å±‚ã€æŸå¤±å‡½æ•°\ntorchvision.datasets ï¼šå¸¸ç”¨æ•°æ®é›†ï¼ˆè¿™é‡Œç”¨ MNISTï¼‰\nDataLoader ï¼šæ‰¹é‡åŠ è½½æ•°æ®\ntransforms ï¼šå¯¹å›¾åƒè¿›è¡Œè½¬æ¢ï¼ˆå¦‚æ ‡å‡†åŒ–ã€å¼ é‡åŒ–ï¼‰\nSummaryWriter ï¼šTensorBoard æ—¥å¿—å†™å…¥ï¼Œç”¨äºå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\nNet ï¼šè‡ªå·±å®šä¹‰çš„ç¥ç»ç½‘ç»œ\n\n\n# æ•°æ®é¢„å¤„ç†\ntransform = transforms.Compose([    transforms.ToTensor(),  # è½¬ä¸º PyTorch å¼ é‡ï¼Œå½¢çŠ¶ä¸º [C,H,W]    transforms.Normalize((0.1307,), (0.3081,))  # æ ‡å‡†åŒ–ï¼šå‡å€¼ 0.1307ï¼Œæ ‡å‡†å·® 0.3081])\nå°†å›¾ç‰‡ä»  [0,255]  æ˜ å°„åˆ°  [0,1]\nå†åšæ ‡å‡†åŒ–ï¼Œä¾¿äºæ¨¡å‹æ”¶æ•›æ›´å¿«\n\n\n# TensorBoard æ—¥å¿— &amp; è®¾å¤‡è®¾ç½®\nwriter = SummaryWriter(\"log_digital\")device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSummaryWriter  ç”¨äºè®°å½•è®­ç»ƒå’Œæµ‹è¯•çš„ lossã€accuracy\ndevice  åˆ¤æ–­æ˜¯å¦æœ‰ GPU å¯ç”¨ï¼Œæœ‰å°±ç”¨ GPU å¦åˆ™ CPU\n\n\n# åŠ è½½æ•°æ®é›†\ndatasets_mnist_train = torchvision.datasets.MNIST(\"data\", train=True, transform=transform, download=True)datasets_mnist_test = torchvision.datasets.MNIST(\"data\", train=False, transform=transform, download=True)\ntrain=True ï¼šè®­ç»ƒé›† 60000 å¼ å›¾ç‰‡\ntrain=False ï¼šæµ‹è¯•é›† 10000 å¼ å›¾ç‰‡\n\n\n# DataLoader\ndataLoader_train = DataLoader(datasets_mnist_train, batch_size=64, shuffle=True, num_workers=0)dataLoader_test = DataLoader(datasets_mnist_test, batch_size=64, shuffle=False, num_workers=0)\nbatch_size=64 ï¼šæ¯æ¬¡é€å…¥ç½‘ç»œ 64 å¼ å›¾ç‰‡\nshuffle=True ï¼šæ‰“ä¹±è®­ç»ƒé¡ºåº\nnum_workers=0 ï¼šåŠ è½½æ•°æ®çš„çº¿ç¨‹æ•°\n\n\n# æ‰“å°æ•°æ®é›†å¤§å°\ntrain_data_size = len(datasets_mnist_train)test_data_size = len(datasets_mnist_test)print(f\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸º&#123;train_data_size&#125;\")print(f\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ä¸º&#123;test_data_size&#125;\")\næ–¹ä¾¿ç¡®è®¤æ•°æ®é›†æ˜¯å¦åŠ è½½æˆåŠŸ\n\n\n# åˆ›å»ºç½‘ç»œå’ŒæŸå¤±å‡½æ•°\nnet = Net().to(device)loss_fn = nn.CrossEntropyLoss().to(device)\nNet() ï¼šå®ä¾‹åŒ–ä½ çš„å·ç§¯ç¥ç»ç½‘ç»œ\nCrossEntropyLoss ï¼šå¸¸ç”¨çš„å¤šåˆ†ç±»æŸå¤±å‡½æ•°ï¼Œå†…éƒ¨åŒ…å« softmax\n\n\n# ä¼˜åŒ–å™¨\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\nä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ä¼˜åŒ–\nlr=0.01 ï¼šå­¦ä¹ ç‡\nmomentum=0.5 ï¼šåŠ¨é‡ï¼Œå¸®åŠ©åŠ é€Ÿæ”¶æ•›\n\n\n# è®­ç»ƒè®¾ç½®\ntotal_train_step = 0total_test_step = 0epoch = 15\ntotal_train_step ï¼šè®­ç»ƒæ€»æ­¥æ•°\ntotal_test_step ï¼šæµ‹è¯•æ€»æ­¥æ•°\nepoch=15 ï¼šè®­ç»ƒè½®æ•°\n\n\n# è®­ç»ƒå¾ªç¯\nfor i in range(epoch):    print(\"--------ç¬¬ &#123;&#125; è½®è®­ç»ƒå¼€å§‹--------\".format(i + 1))    net.train()  # è®¾ç½®ç½‘ç»œä¸ºè®­ç»ƒæ¨¡å¼\nnet.train() ï¼šå¯ç”¨è®­ç»ƒæ¨¡å¼ï¼ˆä¾‹å¦‚ Dropoutã€BatchNorm ç”Ÿæ•ˆï¼‰\n\n# è®­ç»ƒæ­¥\nfor data in dataLoader_train:    imgs, targets = data    imgs = imgs.to(device)    targets = targets.to(device)    outputs = net(imgs)    loss = loss_fn(outputs, targets)    optimizer.zero_grad()    loss.backward()    optimizer.step()\nimgs ï¼šå›¾ç‰‡ batch\ntargets ï¼šæ ‡ç­¾ batch\nloss.backward() ï¼šè®¡ç®—æ¢¯åº¦\noptimizer.step() ï¼šæ›´æ–°å‚æ•°\noptimizer.zero_grad() ï¼šæ¸…ç©ºä¸Šä¸€æ­¥æ¢¯åº¦\n\n# è®°å½•æ—¥å¿—\nif total_train_step % 100 == 0:    print(f\"è®­ç»ƒæ¬¡æ•°ï¼š&#123;total_train_step&#125;ï¼Œlossï¼š&#123;loss&#125;\")    writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\næ¯ 100 æ­¥æ‰“å° loss\nå†™å…¥ TensorBoard\n\n\n# æµ‹è¯•å¾ªç¯\nnet.eval()  # è®¾ç½®ç½‘ç»œä¸ºè¯„ä¼°æ¨¡å¼total_test_loss = 0total_test_accuracy = 0with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦    for data in dataLoader_test:        imgs, targets = data        imgs = imgs.to(device)        targets = targets.to(device)        outputs = net(imgs)        loss = loss_fn(outputs, targets)        total_test_loss += loss.item()        accuracy = (outputs.argmax(1) == targets).sum()        total_test_accuracy += accuracy.item()\nnet.eval() ï¼šå…³é—­ Dropoutã€BatchNorm ç­‰è®­ç»ƒç‰¹æ€§\ntorch.no_grad() ï¼šèŠ‚çœæ˜¾å­˜ï¼Œä¸è®¡ç®—æ¢¯åº¦\noutputs.argmax(1) ï¼šå¾—åˆ°é¢„æµ‹çš„æ•°å­—\nç´¯è®¡ loss å’Œæ­£ç¡®æ•°\n\n# æ‰“å°å’Œè®°å½•\nprint(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Lossï¼š&#123;&#125;\".format(total_test_loss))print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡ï¼š&#123;&#125;\".format(total_test_accuracy / test_data_size))writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)writer.add_scalar(\"test_accuracy\", total_test_accuracy / test_data_size, total_test_step)total_test_step += 1\n# ä¿å­˜æ¨¡å‹\ntorch.save(net, \"net_DI.pth\")print(\"æ¨¡å‹å·²ä¿å­˜\")writer.close()\nå°†è®­ç»ƒå¥½çš„ç½‘ç»œä¿å­˜ä¸º  net_DI.pth\nå…³é—­ TensorBoard å†™å…¥å™¨\n\n# å…¨éƒ¨ä»£ç \nimport torchimport torch.nn as nnimport torchvision.datasetsfrom torch.utils.data import DataLoaderfrom torchvision import transformsfrom torch.utils.tensorboard import SummaryWriterfrom nn_DI_NNFramework import Nettransform = transforms.Compose([    transforms.ToTensor(),  # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡    transforms.Normalize((0.1307,), (0.3081,))  # æ ‡å‡†åŒ–å›¾åƒ])writer = SummaryWriter(\"log_digital\")device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")datasets_mnist_train = torchvision.datasets.MNIST(\"data\", train=True, transform=transform,                                                  download=True)datasets_mnist_test = torchvision.datasets.MNIST(\"data\", train=False, transform=transform,                                                 download=True)dataLoader_train = DataLoader(datasets_mnist_train, batch_size=64, shuffle=True, num_workers=0)dataLoader_test = DataLoader(datasets_mnist_test, batch_size=64, shuffle=False, num_workers=0)# è·å–æ•°æ®é›†å¤§å°train_data_size = len(datasets_mnist_train)test_data_size = len(datasets_mnist_test)print(f\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸º&#123;train_data_size&#125;\")print(f\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ä¸º&#123;test_data_size&#125;\")net = Net().to(device)# åˆ›å»ºæŸå¤±å‡½æ•°loss_fn = nn.CrossEntropyLoss()# äº¤ç»™ GPUloss_fn = loss_fn.to(device)# åˆ›å»ºä¼˜åŒ–å™¨optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.5)# è®¾ç½®è®­ç»ƒç½‘ç»œä¸€äº›å‚æ•°# è®­ç»ƒçš„è½®æ•°total_train_step = 0# æµ‹è¯•çš„è½®æ•°total_test_step = 0# è®­ç»ƒçš„è½®æ•°epoch = 15for i in range(epoch):    print(\"--------ç¬¬ &#123;&#125; è½®è®­ç»ƒå¼€å§‹--------\".format(i + 1))    net.train()    for data in dataLoader_train:        imgs, targets = data        imgs = imgs.to(device)        targets = targets.to(device)        outputs = net(imgs)        loss = loss_fn(outputs, targets)        optimizer.zero_grad()        loss.backward()        optimizer.step()        total_train_step += 1        if total_train_step % 100 == 0:            print(f\"è®­ç»ƒæ¬¡æ•°ï¼š&#123;total_train_step&#125;ï¼Œlossï¼š&#123;loss&#125;\")            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)    net.eval()    total_test_loss = 0    total_test_accuracy = 0    with torch.no_grad():        for data in dataLoader_test:            imgs, targets = data            imgs = imgs.to(device)            targets = targets.to(device)            outputs = net(imgs)            loss = loss_fn(outputs, targets)            total_test_loss += loss.item()            accuracy = (outputs.argmax(1) == targets).sum()            total_test_accuracy += accuracy.item()        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Lossï¼š&#123;&#125;\".format(total_test_loss))        print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡ï¼š&#123;&#125;\".format(total_test_accuracy / test_data_size))        writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)        writer.add_scalar(\"test_accuracy\", total_test_accuracy / test_data_size, total_test_step)        total_test_step += 1torch.save(net, \"net_DI.pth\")print(\"æ¨¡å‹å·²ä¿å­˜\")writer.close()# è®­ç»ƒè¿‡ç¨‹\n\næ¨¡å‹åœ¨ 15 è½®è®­ç»ƒåï¼Œæµ‹è¯•é›†ä¸Šå‡†ç¡®ç‡è¶…è¿‡ 99%\n# ç®€å•éªŒè¯\n# å¯¼å…¥åº“\nimport torchimport torchvisionfrom PIL import Imageimport nn_DI_NNFramework\ntorch ï¼šPyTorch ä¸»åº“\ntorchvision ï¼šç”¨äºå›¾åƒå¤„ç†å’Œå˜æ¢\nPIL.Image ï¼šå¤„ç†å›¾ç‰‡æ–‡ä»¶\nnn_DI_NNFramework ï¼šä½ è‡ªå·±å®šä¹‰çš„ç½‘ç»œï¼ˆNetï¼‰\n\n\n# è®¾å¤‡è®¾ç½®\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nåˆ¤æ–­æ˜¯å¦æœ‰ GPU å¯ç”¨ï¼Œå¦‚æœæœ‰å°±ç”¨ GPUï¼Œå¦åˆ™ç”¨ CPU\n\n\n# åŠ è½½æ¨¡å‹\nmodel = torch.load(\"net_DI.pth\", weights_only=False)\nåŠ è½½ä¹‹å‰è®­ç»ƒå¥½çš„æ¨¡å‹  net_DI.pth\nweights_only=False  è¡¨ç¤ºåŠ è½½æ•´ä¸ªæ¨¡å‹å¯¹è±¡ï¼Œè€Œä¸ä»…ä»…æ˜¯æƒé‡\n\n\nä¸€èˆ¬æ¨èä¿å­˜  state_dict  åŠ è½½æƒé‡ï¼Œè¿™æ ·æ›´çµæ´»ï¼š\n\nnet = nn_DI_NNFramework.Net().to(device)net.load_state_dict(torch.load(\"net_DI.pth\"))\n# æ‰“å¼€å›¾ç‰‡\nimage_path = \"images/333.png\"image = Image.open(image_path).convert(\"L\")\næ‰“å¼€å›¾ç‰‡\n.convert(&quot;L&quot;) ï¼šå°†å›¾ç‰‡è½¬æ¢ä¸ºç°åº¦ï¼ˆ1 é€šé“ï¼‰\n\n\n# å›¾åƒé¢„å¤„ç†\ntrans = torchvision.transforms.Compose([    torchvision.transforms.Resize(size=(28, 28)),  # è°ƒæ•´å›¾ç‰‡å¤§å°    torchvision.transforms.ToTensor(),             # è½¬ä¸ºå¼ é‡])image = trans(image)\nå°†å›¾ç‰‡ç¼©æ”¾åˆ° 28Ã—28ï¼ˆMNIST è¾“å…¥å°ºå¯¸ï¼‰\nè½¬æˆ PyTorch å¼ é‡ï¼Œå½¢çŠ¶  [C,H,W] ï¼ŒèŒƒå›´  [0,1]\n\n\n# è°ƒæ•´ batch ç»´åº¦å¹¶å‘é€åˆ° GPU\nimage = torch.reshape(image, (1, 1, 28, 28)).to(device)print(image.shape)\næ¨¡å‹æœŸæœ›è¾“å…¥  [batch, channel, height, width]\nè¿™é‡Œ batch=1ï¼Œchannel=1ï¼Œ28Ã—28\n.to(device) ï¼šæŠŠå›¾ç‰‡å‘é€åˆ° GPU æˆ– CPU\n\n\n# æ¨¡å‹æ¨ç†\nmodel.eval()with torch.no_grad():    output = model(image)    print(output)\nmodel.eval() ï¼šè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ Dropout/BatchNormï¼‰\ntorch.no_grad() ï¼šä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜\noutput ï¼šæ¨¡å‹è¾“å‡º logitsï¼ˆé•¿åº¦ä¸º 10 çš„å‘é‡ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”æ•°å­— 0â€“9 çš„å¾—åˆ†ï¼‰\n\n\n# è·å–é¢„æµ‹ç»“æœ\nitem = torch.argmax(output).item()print(item)\ntorch.argmax(output) ï¼šæ‰¾åˆ°å¾—åˆ†æœ€å¤§çš„ç´¢å¼•ï¼ˆé¢„æµ‹æ•°å­—ï¼‰\n.item() ï¼šæŠŠå¼ é‡è½¬æˆ Python æ•´æ•°\n\n# å…¨éƒ¨ä»£ç \nimport torchimport torchvisionfrom PIL import Imageimport nn_DI_NNFrameworkdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")model = torch.load(\"net_DI.pth\", weights_only=False)image_path = \"images/333.png\"image = Image.open(image_path).convert(\"L\")trans = torchvision.transforms.Compose([    torchvision.transforms.Resize(size=(28, 28)),    torchvision.transforms.ToTensor(),])image = trans(image)# æ·»åŠ ä¸€ä¸ªç»´åº¦ä»£è¡¨ 1 å¼ å›¾ç‰‡ï¼Œå¹¶äº¤ç»™ GPUimage = torch.reshape(image, (1, 1, 28, 28)).to(device)print(image.shape)model.eval()with torch.no_grad():    output = model(image)    print(output)    item = torch.argmax(output).item()    print(item)# è‡ªå®šä¹‰æµ‹è¯•\n\n\n\n0\n2\n3\n7\n9\n\n\n\n\n\n\n\n\n\n\n\n\nä»¥ä¸Šæ‰‹å†™æ•°å­—å‡å‡†ç¡®è¯†åˆ«\n","categories":["æ·±åº¦å­¦ä¹ ","é¡¹ç›®ä¸å®æˆ˜"],"tags":["python","python_PyTorch","pytorch_nn_digital_identification"]},{"title":"è¯­ä¹‰åˆ†å‰²","url":"/python/ss/","content":"# è¯­ä¹‰åˆ†å‰²\n# å¸¸è§åˆ†å‰²ä»»åŠ¡\n\nè¯­ä¹‰åˆ†å‰²\nå®ä¾‹åˆ†å‰²\nå…¨æ™¯åˆ†å‰²\n\n# å¸¸è§è¯­ä¹‰åˆ†å‰²è¯„ä»·æŒ‡æ ‡\n# Pixel Accuracy / Global Acc åƒç´ å‡†ç¡®ç‡\nè¿™æ˜¯æœ€ç›´è§‚çš„æŒ‡æ ‡ï¼Œåæ˜ äº†æ¨¡å‹å¯¹æ‰€æœ‰åƒç´ ç‚¹åˆ†ç±»æ­£ç¡®çš„æ¯”ä¾‹ã€‚\nPA=âˆ‘iniiâˆ‘itiPA = \\frac{\\sum_{i} n_{ii}}{\\sum_{i} t_{i}}\nPA=âˆ‘iâ€‹tiâ€‹âˆ‘iâ€‹niiâ€‹â€‹\nniin_{ii}niiâ€‹ï¼šè¡¨ç¤ºç¬¬ iii ç±»è¢«æ­£ç¡®é¢„æµ‹ä¸ºç¬¬ iii ç±»çš„åƒç´ æ•°é‡ï¼ˆå¯¹è§’çº¿å…ƒç´ ï¼‰ã€‚\ntit_{i}tiâ€‹ï¼šè¡¨ç¤ºç¬¬ iii ç±»æ€»å…±åŒ…å«çš„åƒç´ ç‚¹æ•°é‡ã€‚\næ‰€æœ‰åˆ†ç±»æ­£ç¡®çš„åƒç´ æ€»æ•° Ã·\\divÃ· å›¾åƒåƒç´ æ€»æ•°ã€‚\nå±€é™æ€§ï¼šç”±äºå®ƒè®¡ç®—çš„æ˜¯å…¨å±€å‡†ç¡®åº¦ï¼Œå¦‚æœå›¾åƒä¸­æŸä¸ªç±»åˆ«å¦‚èƒŒæ™¯å æ¯”æå¤§ï¼ŒPA å°±ä¼šè¢«è¯¥ç±»åˆ«ä¸»å¯¼ï¼Œæ— æ³•åæ˜ æ¨¡å‹å¯¹å°ç›®æ ‡çš„è¯†åˆ«èƒ½åŠ›ã€‚\n# mean Accuracy å¹³å‡å‡†ç¡®ç‡\nä¸ºäº†è§£å†³ä¸Šè¿°ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œè¯¥æŒ‡æ ‡å…ˆè®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ï¼Œå†å–å¹³å‡å€¼.\nmAcc=1nclsâ‹…âˆ‘iniitimAcc = \\frac{1}{n_{cls}} \\cdot \\sum_{i} \\frac{n_{ii}}{t_{i}}\nmAcc=nclsâ€‹1â€‹â‹…iâˆ‘â€‹tiâ€‹niiâ€‹â€‹\nnclsn_{cls}nclsâ€‹ï¼šç±»åˆ«çš„æ€»æ•°ã€‚\nniiti\\frac{n_{ii}}{t_{i}}tiâ€‹niiâ€‹â€‹ï¼šç¬¬ iii ä¸ªç±»åˆ«çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚\næ„ä¹‰ï¼šå®ƒç»™æ¯ä¸ªç±»åˆ«ï¼ˆæ— è®ºå¤§å°ï¼‰åˆ†é…äº†ç›¸åŒçš„æƒé‡ã€‚å¦‚æœä½ çš„ä»»åŠ¡ä¸­åŒ…å«å¾ˆå¤šç»†é•¿æˆ–å¾®å°çš„ç‰©ä½“ï¼Œè¿™ä¸ªæŒ‡æ ‡æ¯” PA æ›´æœ‰å‚è€ƒä»·å€¼ã€‚\n# mean IoU å¹³å‡äº¤å¹¶æ¯”\nmIoU=1nclsâ‹…âˆ‘iniiti+âˆ‘jnjiâˆ’niimIoU = \\frac{1}{n_{cls}} \\cdot \\sum_{i} \\frac{n_{ii}}{t_{i} + \\sum_{j} n_{ji} - n_{ii}}\nmIoU=nclsâ€‹1â€‹â‹…iâˆ‘â€‹tiâ€‹+âˆ‘jâ€‹njiâ€‹âˆ’niiâ€‹niiâ€‹â€‹\nåˆ†æ¯ï¼šti+âˆ‘jnjiâˆ’niit_{i} + \\sum_{j} n_{ji} - n_{ii}tiâ€‹+âˆ‘jâ€‹njiâ€‹âˆ’niiâ€‹ å®é™…ä¸Šå°±æ˜¯å¹¶é›†ã€‚å®ƒç”± â€œçœŸå®åŒºåŸŸâ€ åŠ ä¸Š â€œé¢„æµ‹åŒºåŸŸâ€ï¼Œå†å‡å»é‡å¤è®¡ç®—çš„ â€œäº¤é›†éƒ¨åˆ†â€ ç»„æˆã€‚\nåˆ†å­ï¼šniin_{ii}niiâ€‹ å°±æ˜¯ ** äº¤é›† ã€‚\næ ¸å¿ƒé€»è¾‘ï¼šIoU=äº¤é›†å¹¶é›†IoU = \\frac{äº¤é›†}{å¹¶é›†}IoU=å¹¶é›†äº¤é›†â€‹ã€‚åªæœ‰å½“é¢„æµ‹çš„å½¢çŠ¶ä¸çœŸå®çš„å½¢çŠ¶é«˜åº¦é‡åˆæ—¶ï¼ŒmIoU æ‰ä¼šæ¥è¿‘ 1ã€‚\n# ä¸€ä¸ªä¾‹å­\n\n\n\n\n\n# å…¨å±€å‡†ç¡®ç‡\nPA=16+3+16+12+864â‰ˆ0.859PA=\\frac{16+3+16+12+8}{64}\\approx0.859\nPA=6416+3+16+12+8â€‹â‰ˆ0.859\n# å¹³å‡å‡†ç¡®ç‡\nåˆ†æ¯æ˜¯åˆ—ä¹‹å’Œï¼Œåˆ†å­æ˜¯å¯¹è§’é‚£ä¸ªå…ƒç´ ã€‚\ncls0acc=1620cls0_{acc}=\\frac{16}{20}cls0accâ€‹=2016â€‹ï¼Œcls1acc=34cls1_{acc}=\\frac{3}{4}cls1accâ€‹=43â€‹ï¼Œcls2acc=1616cls2_{acc}=\\frac{16}{16}cls2accâ€‹=1616â€‹ï¼Œcls3acc=1216cls3_{acc}=\\frac{12}{16}cls3accâ€‹=1612â€‹ï¼Œcls0_{acc}=\\frac{8}\nmA=cls0acc+cls1acc+cls2acc+cls3acc+cls4acc5mA=\\frac{cls0_{acc}+cls1_{acc}+cls2_{acc}+cls3_{acc}+cls4_{acc}}{5}\nmA=5cls0accâ€‹+cls1accâ€‹+cls2accâ€‹+cls3accâ€‹+cls4accâ€‹â€‹\n# å¹³å‡äº¤å¹¶æ¯”\nåˆ†æ¯æ˜¯è¡Œä¸åˆ—ä¹‹å’Œå‡å»é‡å¤éƒ¨åˆ†é‚£ä¸ªï¼Œåˆ†å­å°±æ˜¯å¯¹è§’çº¿é‚£ä¸ªå…ƒç´ ã€‚\ncls0IoU=1616+1+1+2+2cls0_{IoU}=\\frac{16}{16+1+1+2+2}cls0IoUâ€‹=16+1+1+2+216â€‹ï¼Œcls1IoU=33+1+1cls1_{IoU}=\\frac{3}{3+1+1}cls1IoUâ€‹=3+1+13â€‹ï¼Œcls2IoU=1616+1+1cls2_{IoU}=\\frac{16}{16+1+1}cls2IoUâ€‹=16+1+116â€‹ï¼Œcls3IoU=1212+2cls3_{IoU}=\\frac{12}{12+2}cls3IoUâ€‹=12+212â€‹ï¼Œcls0_{IoU}=\\frac{8}\nmA=cls0IoU+cls1IoU+cls2IoU+cls3IoU+cls4IoU5mA=\\frac{cls0_{IoU}+cls1_{IoU}+cls2_{IoU}+cls3_{IoU}+cls4_{IoU}}{5}\nmA=5cls0IoUâ€‹+cls1IoUâ€‹+cls2IoUâ€‹+cls3IoUâ€‹+cls4IoUâ€‹â€‹\n# Transposed Convolution è½¬ç½®å·ç§¯\nTransposed Convolution/ fractionally-strided / deconvolution\nè½¬ç½®å·ç§¯ä¸æ˜¯å·ç§¯çš„é€†è¿ç®—\nN.B.: Blue maps are inputs, and cyan maps are outputs.\n\n  \n    \n    \n    \n    \n  \n  \n    No padding, no strides, transposed\n    Arbitrary padding, no strides, transposed\n    Half padding, no strides, transposed\n    Full padding, no strides, transposed\n  \n  \n    \n    \n    \n    \n  \n  \n    No padding, strides, transposed\n    Padding, strides, transposed\n    Padding, strides, transposed (odd)\n    \n  \n\nHout=(Hinâˆ’1)Ã—stride[0]âˆ’2Ã—padding[0]+kernel_size[0]H_{out} = (H_{in} - 1) \\times stride[0] - 2 \\times padding[0] + kernel\\_size[0]\nHoutâ€‹=(Hinâ€‹âˆ’1)Ã—stride[0]âˆ’2Ã—padding[0]+kernel_size[0]\nWout=(Winâˆ’1)Ã—stride[1]âˆ’2Ã—padding[1]+kernel_size[1]W_{out} = (W_{in} - 1) \\times stride[1] - 2 \\times padding[1] + kernel\\_size[1]\nWoutâ€‹=(Winâ€‹âˆ’1)Ã—stride[1]âˆ’2Ã—padding[1]+kernel_size[1]\n# ä¸‹é‡‡æ · vs ä¸Šé‡‡æ ·\næ™®é€šå·ç§¯ï¼šä¸»è¦ç”¨äºç‰¹å¾æå–å’Œç©ºé—´é™ç»´ï¼ˆä¸‹é‡‡æ ·ï¼‰ã€‚é€šè¿‡æ»‘åŠ¨çª—å£å°†å¤šä¸ªè¾“å…¥åƒç´ æ˜ å°„ä¸ºä¸€ä¸ªè¾“å‡ºåƒç´ ï¼Œé€šå¸¸ä¼šå‡å°ç‰¹å¾å›¾çš„å°ºå¯¸ã€‚\nè½¬ç½®å·ç§¯ï¼šä¸»è¦ç”¨äºæ¢å¤ç©ºé—´åˆ†è¾¨ç‡æˆ–è¿›è¡Œå¯å­¦ä¹ çš„ä¸Šé‡‡æ ·ã€‚å°†ä¸€ä¸ªè¾“å…¥åƒç´ æ˜ å°„åˆ°å¤šä¸ªè¾“å‡ºåƒç´ ï¼Œä»è€Œäº§ç”Ÿæ¯”è¾“å…¥æ›´å¤§çš„è¾“å‡ºç‰¹å¾å›¾ã€‚å¸¸ç”¨äºè¯­ä¹‰åˆ†å‰²ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç­‰éœ€è¦è¿˜åŸå›¾åƒå°ºå¯¸çš„ä»»åŠ¡ã€‚\n# FCN\n\n21 æ·±åº¦å°±æ˜¯ 21 ç§ç±»åˆ«ï¼ŒVOC æ˜¯ 20 ç±»ç„¶åè¿˜æœ‰ä¸€ä¸ªæ˜¯èƒŒæ™¯ä¸€å…± 21 ç±»ï¼Œç„¶åç»è¿‡ä¸Šé‡‡æ ·å¾—åˆ°æ¯ä¸€ä¸ªåƒç´ çš„ç±»åˆ«å°±å®Œæˆåˆ†å‰²äº†ï¼ŒFCN ä½¿ç”¨å…¨å·ç§¯æ“ä½œï¼Œè¿™é¿å…äº†å…¨è¿æ¥å±‚å¯¹å›¾ç‰‡å¤§å°çš„ä¸¥æ ¼é™åˆ¶æ‰€å¯¼è‡´çš„æŠ¥é”™é—®é¢˜ã€‚\n\nå…¶å®è¿™ä¸ªä¸»è¦æ˜¯æŠŠ VGG çš„å…¨è¿æ¥å±‚ä¿®æ”¹ä¸ºå·ç§¯ï¼Œå½“ç„¶è¿˜æœ‰æ›´å¤šç»†èŠ‚ï¼Œä¸‹é¢æ˜¯ FCN-32Sï¼Œå³ç›´æ¥è¿›è¡Œå¯¹ pool5 çš„ 32 å€ä¸Šé‡‡æ ·ï¼ŒVGG16 çš„éª¨å¹²ç½‘ç»œå°±æ˜¯å¯¹åŸå›¾è¿›è¡Œ 32 å€ä¸‹é‡‡æ ·\n# FCN-32S\n\n# FCN-16S\n\n# FCN-8S\n\n# FCN æŸå¤±å‡½æ•° - åƒç´ çº§å¤šç±»åˆ«äº¤å‰ç†µæŸå¤±\nå¯¹äºå•å¼ å›¾ç‰‡ï¼Œæ€»æŸå¤± LLL å®šä¹‰ä¸ºï¼š\nL=âˆ’1HÃ—Wâˆ‘i=1HÃ—Wâˆ‘c=1Cyi,clogâ¡(y^i,c)L = -\\frac{1}{H \\times W}\\sum_{i=1}^{H \\times W} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c})\nL=âˆ’HÃ—W1â€‹i=1âˆ‘HÃ—Wâ€‹c=1âˆ‘Câ€‹yi,câ€‹log(y^â€‹i,câ€‹)\nFCN çš„æŸå¤±å‡½æ•°æ˜¯å¯¹æ¯ä¸€ä¸ªåƒç´ è¿›è¡Œ softmax åˆ†ç±»äº¤å‰ç†µåï¼Œåœ¨å¯¹å…¨å›¾è¿›è¡Œå¹³å‡ã€‚\n# ç©ºæ´å·ç§¯ / è†¨èƒ€å·ç§¯\nPyTorch æ·±åº¦å­¦ä¹  - åŸºç¡€ - æ·±åº¦å­¦ä¹  | KarryLiu = è¯—å²¸æ¢¦è¡ŒèˆŸ = åˆ†äº«è®¡ç®—æœºçŸ¥è¯†ä»¥åŠå„ç§å¿ƒå¾—æ€»ç»“\nå¢å¤§æ„Ÿå—é‡ï¼Œä¸€èˆ¬æˆ‘ä»¬ä¼šä¸»åŠ¨ä¿æŒç‰¹å¾å›¾å¤§å°ã€‚\n# FCN æ¨¡å‹è®­ç»ƒ\nç°åœ¨åŸºæœ¬ä¸ŠæŠŠéª¨å¹²ç½‘ç»œéƒ½æ¢æˆ ResNet-50 äº†ã€‚\n\nç¯å¢ƒä¸º RTX 3080 x4 åŸºäº fcn_resnet50: https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth é¢„è®­ç»ƒæƒé‡è®­ç»ƒ 20 è½®ã€‚\n\nç»“æœï¼š\n\n  \n  \n\nå®é™…ä¸Šè¿™ä¸ªé¢„è®­ç»ƒå·²ç»ä¸é”™äº†ï¼Œæˆ‘è¿™ 20 è½®åŸºæœ¬ä¸Šæ²¡å•¥è´¡çŒ®ï¼Œä¹Ÿå°±è®© meanIoU æå‡äº†ä¸€ç‚¹ç‚¹ã€‚ã€‚\n# U-Net\nU-Net æ˜¯ç”± Ronneberger ç­‰äººäº 2015 å¹´æå‡ºçš„ä¸€ç§ç«¯åˆ°ç«¯çš„å…¨å·ç§¯ç½‘ç»œï¼Œä¸»è¦ç”¨äºåƒç´ çº§åˆ†ç±»ã€‚\n\nè¿™ä¸ªä¸­é—´çš„è¿æ¥å¹¶ä¸æ˜¯å…¨åƒç´ çš„è¿æ¥ï¼Œä»–ä¼šä»æºç‰¹å¾å›¾è£å‰ªä¸€éƒ¨åˆ†è¿æ¥åˆ°ä¸Šé‡‡ç”¨åçš„ç‰¹å¾å›¾ã€‚\n# åœ¨ DRIVE æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒ\nDRIVE æ•°æ®é›†ä¸€èˆ¬æŒ‡çš„æ˜¯æ˜¯è§†ç½‘è†œè¡€ç®¡åˆ†å‰²é¢†åŸŸæœ€ç»å…¸ã€ä½¿ç”¨æœ€å¹¿æ³›çš„æ•°æ®é›†ä¹‹ä¸€ã€‚\n\n\n200 è½®è®­ç»ƒåâ€¦\n[epoch: 199]train_loss: 0.3152lr: 0.000000dice coefficient: 0.814global correct: 95.3average row correct: ['97.2', '82.0']IoU: ['94.7', '68.8']mean IoU: 81.7\n  \n  \n\n# VOC é•œåƒç«™\nhttps://data.brainchip.com/dataset-mirror/voc\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","FCN"]},{"title":"YOLO-V1","url":"/python/YOLO/YOLO_V1/","content":"# YOLO ç³»åˆ—\nYOLOï¼ˆYou Only Look Onceï¼‰\n# YOLOv1\n\nè¾“å…¥æ˜¯ 448x448x3ï¼Œæœ€ç»ˆè¾“å‡ºæ˜¯ 7x7x30ã€‚å¯¹åº”åŸå§‹å›¾ç‰‡å¯¹åº”åŒºåŸŸçš„ç»“æœã€‚å°±æ˜¯æ‰€è°“çš„å°†åŸå§‹å›¾ç‰‡åˆ’åˆ†ä¸º 7x7 ä¸ªå°æ–¹æ ¼å¤§å°çš„å›¾ç‰‡ã€‚\nå…¶å®è¿™æ˜¯ä¸€ç§ä¸€ä¸€æ˜ å°„ 7x7 è¿™æ ·çš„å°æ–¹æ ¼ï¼Œ7Ã—7 ä¸ª cellï¼Œæ¯ä¸ª cell è´Ÿè´£ â€œè¿™ä¸ª cell ä¸­å¿ƒè½åœ¨è¿™é‡Œçš„ç›®æ ‡â€ çš„æ£€æµ‹ä»»åŠ¡ã€‚\n\n# x, y, w, h\nx,y æ˜¯ä¸­å¿ƒç‚¹åæ ‡ï¼Œw,h æ˜¯é¢„æµ‹æ¡†çš„å®½å’Œé«˜ã€‚\næ¯ä¸ª bounding box çš„ 5 ä¸ªå‚æ•°ï¼šx,y,w,h,confidence,\nx,yï¼šæ¡†ä¸­å¿ƒç›¸å¯¹äºå½“å‰ cell çš„åæ ‡ï¼ˆä¸€èˆ¬åœ¨ 0ï½1ï¼‰\nw,hï¼šæ¡†çš„å®½é«˜ï¼ˆé€šå¸¸ç›¸å¯¹äºæ•´å¼ å›¾åƒå½’ä¸€åŒ–ï¼‰\nconfidenceï¼šè¿™ä¸ªæ¡†ä¸­æœ‰ç‰©ä½“çš„ç½®ä¿¡åº¦ Ã— è¯¥æ¡†ä¸çœŸå®æ¡†çš„ IoU\næ¯ä¸ª cell çš„è¾“å‡ºç»´åº¦ = BÃ—5+C\nBÃ—5+C=2Ã—5+20=10+20=30\n# ç½®ä¿¡åº¦\nå…¬å¼å°±æ˜¯ï¼š\nIoU=IntersectionÂ AreaUnionÂ Area\\text{IoU} = \\frac{\\text{Intersection Area}}{\\text{Union Area}}\nIoU=UnionÂ AreaIntersectionÂ Areaâ€‹\n\nIntersection Areaï¼šä¸¤ä¸ªæ¡†ç›¸äº¤çš„é‚£ä¸€å—åŒºåŸŸçš„é¢ç§¯ï¼ˆäº¤é›†ï¼‰\nUnion Areaï¼šä¸¤ä¸ªæ¡†åˆèµ·æ¥è¦†ç›–ä½çš„æ€»é¢ç§¯ï¼ˆå¹¶é›†ï¼‰\n\n\nè¿™é‡Œæ‰€è¯´çš„ç‰©ä½“çœŸå®çš„ box å®é™…æ˜¯ä¸å­˜åœ¨çš„ï¼Œè¿™åªæ˜¯æ¨¡å‹è¡¨è¾¾è‡ªå·±æ¡†å‡ºäº†ç‰©ä½“çš„è‡ªä¿¡ç¨‹åº¦ã€‚å› æ­¤æ­¤æ—¶ç½®ä¿¡åº¦çš„å…¬å¼ä¸º:\nC=Pr(Object)âˆ—IoUpredtruthC=Pr(Object)*IoU_{pred}^{truth}\nC=Pr(Object)âˆ—IoUpredtruthâ€‹\n# NMS éæå¤§å€¼æŠ‘åˆ¶\næƒ³è±¡ä¸€ç¾¤å€™é€‰æ¡†åœ¨å‚åŠ é€‰ç§€ï¼Œè§„åˆ™å¦‚ä¸‹ï¼š\næ’åºï¼šæŠŠæ‰€æœ‰å€™é€‰æ¡†æŒ‰ç½®ä¿¡åº¦ä»é«˜åˆ°ä½æ’å¥½é˜Ÿã€‚\né€‰å† å†›ï¼šæŠŠå¾—åˆ†æœ€é«˜çš„æ¡†æ‹¿å‡ºæ¥ï¼Œç¡®å®šå®ƒå°±æ˜¯ä¸€ä¸ªæ£€æµ‹ç»“æœã€‚\nå‰”é™¤è·Ÿé£è€…ï¼š\n\nè®¡ç®—å‰©ä½™æ‰€æœ‰æ¡†ä¸è¿™ä¸ª â€œå† å†›æ¡†â€ çš„é‡åˆåº¦ï¼ˆIOUï¼‰ã€‚\nå¦‚æœæŸä¸ªæ¡†ä¸å† å†›æ¡†çš„ IOU è¶…è¿‡äº†é¢„è®¾çš„é˜ˆå€¼ï¼Œè¯´æ˜å®ƒä»¬åœ¨é¢„æµ‹åŒä¸€ä¸ªç‰©ä½“ã€‚\nç”±äºå®ƒçš„å¾—åˆ†æ²¡å† å†›é«˜ï¼Œè¿™ä¸ª â€œè·Ÿé£æ¡†â€ å°±ä¼šè¢«ç›´æ¥è¸¢å‡ºå±€ï¼ˆåˆ é™¤ï¼‰ã€‚\n\nå¾ªç¯ï¼šåœ¨å‰©ä¸‹çš„æ¡†é‡Œç»§ç»­æ‰¾å¾—åˆ†æœ€é«˜çš„ï¼Œé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´åˆ°æ‰€æœ‰æ¡†éƒ½è¢«å¤„ç†å®Œã€‚\n# YOLOV1 æŸå¤±å‡½æ•°\næŸå¤±å‡½æ•°ä¸ºï¼š\n\n# YOLOV1 æ€»ç»“\nYOLO éå¸¸å¿«ï¼Œå› ä¸ºå°†ç‰©ä½“æ£€æµ‹å®šä¹‰ä¸ºå›å½’é—®é¢˜ï¼Œæ‰€ä»¥æ£€æµ‹ä¹Ÿä¸éœ€è¦å¤æ‚ç»„ä»¶ã€‚\nYOLO åŸºäºå…¨å›¾è¿›è¡Œæ£€æµ‹ï¼Œæ‰€ä»¥ä¸åƒæ™ƒåŠ¨çª—å£å’Œé¢„é€‰åŒºæŠ€æœ¯ï¼ŒYOLO ä¸­éšå«ç€éšå¼ç¼–ç çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\nYOLOv1 çš„å‡†ç¡®ç‡ä¸å¤Ÿé«˜ï¼ŒYOLO åœ¨å®šä½å°ç‰©ä½“ä¸Šè¡¨ç°åå·®ï¼Œå¯ä»¥æ£€æµ‹åˆ°çš„ç›®æ ‡ç‰©ä½“è¾ƒå°‘ã€‚\nä»¥ä¸Šç¼ºç‚¹å°†ä¼šåœ¨ä¸‹é¢æŒç»­æ”¹è¿›ã€‚\n# å‚è€ƒ\n\nã€YOLOv1ã€YOLOv2ã€YOLOv3 ç›®æ ‡æ£€æµ‹ç®—æ³•åŸç†ä¸å®æˆ˜ã€‘https://www.bilibili.com/video/BV1WT421r72w\n\n","categories":["æ·±åº¦å­¦ä¹ ","YOLO"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","YOLO"]},{"title":"YOLO-V2","url":"/python/YOLO/YOLO_V2/","content":"# YOLOv2\n# åŸæ–‡\nYOLO9000: Better, Faster, Stronger(YOLOv2): [https://arxiv.org/abs/1612.08242]\n\nYOLO-v2 ç›¸è¾ƒäº v1ï¼Œä¸ä»…å‡†ç¡®ç‡é«˜ï¼Œè€Œä¸”æ£€æµ‹é€Ÿåº¦æ›´å¿«ï¼ŒmAP æŒ‡æ ‡ç”± 63.4% æå‡åˆ° 78.6%ã€‚\n# V2 çš„æ”¹è¿›\n\nBatch Normalization - æ‰¹å½’ä¸€åŒ– ï¼šæ˜¯æ·±åº¦å­¦ä¹ ä¸­ä¸€ç§å¸¸ç”¨çš„æŠ€æœ¯ï¼Œç”¨äºåŠ é€Ÿç¥ç»ç½‘ç»œçš„è®­ç»ƒå¹¶æé«˜æ¨¡å‹çš„ç¨³å®šæ€§ã€‚å®ƒé€šè¿‡å¯¹æ¯ä¸€å±‚çš„è¾“å…¥è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†æ¥è§£å†³ â€œå†…éƒ¨åå˜é‡åç§»â€ é—®é¢˜ã€‚\nHi-res classifierï¼šYolov2 ç›¸è¾ƒäº Yolovl é‡‡ç”¨æ›´é«˜åˆ†è¾¨ç‡çš„ç½‘ç»œè¿›è¡Œåˆ†ç±»ä¸»å¹²ç½‘ç»œçš„è®­ç»ƒã€‚\nConvolutional+anchorï¼šYolov2 ç›¸è¾ƒäº Yolovl å»é™¤å…¨è¿æ¥å±‚ï¼Œé‡‡ç”¨å·ç§¯å±‚è¿›è¡Œæ¨¡å‹çš„è¾“å‡ºï¼›åŒæ—¶é‡‡ç”¨ä¸é”šæ¡† (é¢„é€‰æ¡†) è¿›è¡Œ boundingbox çš„é¢„æµ‹\nnewnetworkï¼šé‡‡ç”¨æ–°çš„ç½‘ç»œæ¶æ„ Darknet-19\ndimension priorsï¼šé‡‡ç”¨ k-means èšç±»æ–¹æ³•å¯¹è®­ç»ƒé›†ä¸­çš„æ ‡å‡†æ¡†åšäº†èšç±»åˆ†æï¼Œè·å– anchor boxes;\nlocation predictionï¼šä½¿ç”¨ sigmoid å‡½æ•°å¤„ç†ä½ç½®é¢„æµ‹å€¼ã€‚\npassthroughï¼špassthrough ç½‘ç»œæ¨¡å‹çš„è¿æ¥æ–¹å¼ (ç±»ä¼¼ resnet)\nmulti-scaleï¼šå¤šå°ºåº¦è¾“å…¥æ•°æ®è®­ç»ƒæ¨¡å‹\nhi-res detectorï¼šYolov2 ç›¸è¾ƒäº Yolovl é‡‡ç”¨æ›´é«˜åˆ†è¾¨ç‡çš„ç½‘ç»œè¿›è¡Œæ£€æµ‹ä¸»å¹²ç½‘ç»œçš„è®­ç»ƒ\n# anchor box\nåœ¨ YOLO v2 ä¸­ï¼Œ**Anchor æ¡†ï¼ˆé”šæ¡† / å…ˆéªŒæ¡†ï¼‰** æ˜¯è¿™ä¸ªç®—æ³•çš„ä¸€é¡¹é‡å¤§æ”¹è¿›ã€‚å¦‚æœè¯´ â€œä¸­å¿ƒç‚¹â€ å†³å®šäº†ç‰©ä½“åœ¨å“ªä¸ªä½ç½®ï¼Œé‚£ä¹ˆ Anchor æ¡†å°±å†³å®šäº†ç‰©ä½“çš„ â€œä½“å‹â€ å’Œ â€œé•¿ç›¸â€ã€‚\nåœ¨ä¸€å¼€å§‹ï¼Œè¿™ 5 ä¸ª Anchor æ¡†å°±é•¿å¾—ä¸ä¸€æ ·ã€‚å®ƒä»¬ä¸æ˜¯éšæ„ç”Ÿæˆçš„ï¼Œè€Œæ˜¯æ ¹æ®æ•°æ®ç»Ÿè®¡å‡ºæ¥çš„æœ€å…¸å‹çš„ 5 ç§å½¢çŠ¶ã€‚\nå½“å›¾ç‰‡è¾“å…¥æ¨¡å‹æ—¶ï¼Œæ¯ä¸€ä¸ªç½‘æ ¼é‡Œçš„è¿™ 5 ä¸ª Anchor éƒ½ä¼šå»å’ŒçœŸå®ç‰©ä½“æ¯”å¯¹ï¼š\n\nè®¡ç®—é‡åˆåº¦ IoUï¼š æ¨¡å‹ä¼šè®¡ç®—çœŸå®ç‰©ä½“çš„å½¢çŠ¶å’Œè¿™ 5 ä¸ªæ¨¡æ¿å“ªä¸ªæœ€æ¥è¿‘ã€‚\nåˆ†é…ä»»åŠ¡ï¼š é‡åˆåº¦ IoU æœ€é«˜çš„é‚£ä¸ª Anchor è¢«é€‰ä¸º â€œå¤©é€‰ä¹‹å­â€ï¼Œåªæœ‰å®ƒè´Ÿè´£é¢„æµ‹è¿™ä¸ªç‰©ä½“ã€‚å…¶ä»–çš„ 4 ä¸ª Anchor åœ¨è¿™ä¸ªæ ¼å­é‡Œå°±è¢«å½“ä½œ â€œèƒŒæ™¯â€ å¿½ç•¥æ‰ã€‚\n\nä¸€æ—¦é€‰å®šäº†æœ€åƒçš„é‚£ä¸ªæ¡†ï¼Œå®ƒåªé’ˆå¯¹é€‰ä¸­çš„è¿™ä¸€ä¸ªè¿›è¡Œä¿®æ­£ã€‚\nè™½ç„¶æˆ‘ä»¬è¯´æ˜¯ â€œæŒ‘ä¸€ä¸ªâ€ï¼Œä½†åœ¨æ¨ç† / é¢„æµ‹é˜¶æ®µï¼Œå…¶å® 5 ä¸ªæ¡†éƒ½ä¼šç»™å‡ºè‡ªå·±çš„åˆ†æ•°ï¼ˆç½®ä¿¡åº¦ï¼‰ã€‚åªæœ‰é‚£äº›å¾—åˆ†è¶…è¿‡ä½ è®¾å®šé˜ˆå€¼çš„æ¡†æ‰ä¼šè¢«æ˜¾ç¤ºå‡ºæ¥ã€‚å¦‚æœä¸€ä¸ªæ ¼å­é‡Œç¡®å®æœ‰ä¸¤ä¸ªé‡å çš„ç‰©ä½“ï¼Œæ¯”å¦‚äººæŒ¡ä½äº†è½¦ï¼Œé‚£ä¹ˆè´Ÿè´£äººçš„ Anchor å’Œè´Ÿè´£è½¦çš„ Anchor éƒ½ä¼šç»™å‡ºé«˜åˆ†ï¼Œè¿™æ ·ä¸¤ä¸ªç‰©ä½“å°±éƒ½èƒ½è¢«æŒ‘å‡ºæ¥ï¼\n# æµç¨‹æè¿°\nYOLOv2 æŠŠä¸€å¼ å›¾åˆ†æˆ  S Ã— S  ä¸ª gridï¼Œæ¯ä¸ª grid é¢„æµ‹  B  ä¸ªå€™é€‰æ¡†ï¼ˆanchorï¼‰ã€‚\næ¯ä¸ªå€™é€‰æ¡†è¾“å‡ºï¼š\n(bx,by,bw,bh,confidence,p1,p2,â€¦,pC)(b_x, b_y, b_w, b_h, \\text{confidence}, p_1, p_2, \\dots, p_C)\n(bxâ€‹,byâ€‹,bwâ€‹,bhâ€‹,confidence,p1â€‹,p2â€‹,â€¦,pCâ€‹)\nå…¶ä¸­ï¼š\n\nconfidence = Pr(object) Ã— IoU(pred, gt)\np_c = Pr(class_c | object)\n\nçœŸæ­£ç”¨äºæ’åºå’Œç­›é€‰çš„æ˜¯ï¼š\nscorec=confidenceÃ—pc\\text{score}_{c} = \\text{confidence} \\times p_c\nscorecâ€‹=confidenceÃ—pcâ€‹\nå¯¹åŒä¸€ç±»åˆ«æ¥è¯´ï¼Œscore æœ€å¤§çš„é‚£ä¸ªæ¡†\nscore=Pr(object)Ã—IoUÃ—Pr(class)score=Pr(object)Ã—IoUÃ—Pr(class)\nscore=Pr(object)Ã—IoUÃ—Pr(class)\n\n\n\nå› ç´ \nå«ä¹‰\n\n\n\n\nPr(object)\næœ‰æ²¡æœ‰ç›®æ ‡\n\n\nIoU\næ¡†å¾—å‡†ä¸å‡†\n\n\nPr(class)\næ˜¯ä¸æ˜¯è¿™ä¸ªç±»åˆ«\n\n\n\n# DarkNet-19 åˆ†ç±»æ¨¡å‹\n\n# DarkNet-19 æ£€æµ‹æ¨¡å‹ï¼ˆéå®Œæ•´ç‰ˆï¼‰\n\n# å‡­ä»€ä¹ˆ 13x13 å¯ä»¥ä»£è¡¨é‚£äº›æ ¼å­ï¼Ÿ\nä¸æ˜¯ YOLO æŠŠå›¾ç‰‡ â€œåˆ‡æˆäº† 13Ã—13â€ï¼Œè€Œæ˜¯å·ç§¯ç½‘ç»œåœ¨ç»è¿‡å¤šæ¬¡ stride=2 ä¸‹é‡‡æ ·åï¼Œåªå‰©ä¸‹ 13Ã—13 ä¸ªç©ºé—´ä½ç½®å¯ä»¥è¯´è¯ã€‚YOLO çš„ grid ç»“æ„å¹¶éäººä¸ºåˆ’åˆ†ï¼Œè€Œæ˜¯å…¨å·ç§¯ç½‘ç»œåœ¨å¤šæ¬¡ä¸‹é‡‡æ ·åè‡ªç„¶å½¢æˆçš„ç©ºé—´ç¦»æ•£åŒ–ç»“æœã€‚\n# åº”å½“æœ‰ 5 ä¸ªé”šæ¡†æ˜¯å¦‚ä½•å¾—å‡ºçš„ï¼Ÿ\nYOLOv2 ä½¿ç”¨ K-means èšç±»æ¥ç»Ÿè®¡ï¼ŒK-means èšç±»å®é™…ä¸Šæ˜¯é€šè¿‡è®¡ç®—è®­ç»ƒæ•°æ®ä¸­æ¯ä¸ªç›®æ ‡æ¡†çš„ å®½åº¦ å’Œ é«˜åº¦ æ¥è¿›è¡Œçš„ï¼Œå¹¶ä¸”è¿™äº›æ¡†çš„ ä¸­å¿ƒç‚¹ è¢«è§†ä¸ºä¸€ä¸ªå…³é”®çš„å‚ç…§æ¥è¿›è¡Œèšç±»ã€‚\næ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„ç›®æ ‡æ¡†é€šå¸¸ç”±å…¶ å®½åº¦ å’Œ é«˜åº¦ ç»„æˆã€‚YOLOv2 å¹¶ä¸ä¼šç›´æ¥ä½¿ç”¨æ¯ä¸ªæ¡†çš„å·¦ä¸Šè§’åæ ‡ï¼Œè€Œæ˜¯å°†æ¡†çš„ å®½åº¦ å’Œ é«˜åº¦ ä½œä¸ºè¾“å…¥ç‰¹å¾ã€‚\nèšç±»çš„ç›®çš„æ˜¯æ‰¾åˆ°ä¸€ç»„èƒ½å¤Ÿå¾ˆå¥½åœ°è¦†ç›–è¿™äº›æ¡†çš„ ä¸­å¿ƒç‚¹ å’Œ å°ºå¯¸ã€‚\nK-means èšç±»åœ¨é€‰æ‹©é”šæ¡†æ—¶ä½¿ç”¨çš„æ˜¯ IoUï¼Œå³äº¤å¹¶æ¯”ï¼Œæ¥åº¦é‡ç‰©ä½“æ¡†ä¸é”šæ¡†ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚\nIoU=Area_of_overlapArea_of_unionAreaIoU=\\frac{Area\\_of\\_overlap}{Area\\_of\\_unionArea}\nIoU=Area_of_unionAreaArea_of_overlapâ€‹\n\nå¯¹äºæ¯ä¸ªè®­ç»ƒé›†ä¸­çš„ç‰©ä½“æ¡†ï¼ŒYOLOv2 ä¼šè®¡ç®—å®ƒä¸æ¯ä¸ªå€™é€‰é”šæ¡†çš„ IoUã€‚ç‰©ä½“æ¡†å’Œé”šæ¡†ä¹‹é—´çš„ IoU å€¼è¶Šå¤§ï¼Œè¡¨ç¤ºå®ƒä»¬è¶Šç›¸ä¼¼ã€‚\nèšç±»ä¹‹åå¾—åˆ°çš„ 5 ä¸ªæ¡†å®ƒä»¬ ä¸æ˜¯æ‹¿æ¥ç›´æ¥ç”¨çš„é¢„æµ‹ç»“æœ è€Œæ˜¯ç”¨æ¥ çº¦æŸç½‘ç»œ â€œæ€ä¹ˆé¢„æµ‹æ¡†â€ï¼Œè®©å›å½’é—®é¢˜å˜å¾—å®¹æ˜“ã€ç¨³å®šã€å¯å­¦\nK-means èšç±»åï¼Œå¾—åˆ°çš„æ˜¯ï¼š\n(w1,h1),(w2,h2),â€¦,(w5,h5){(w_1,h_1),(w_2,h_2),â€¦,(w_5,h_5)}\n(w1â€‹,h1â€‹),(w2â€‹,h2â€‹),â€¦,(w5â€‹,h5â€‹)\nè¿™ 5 ç»„ å®½é«˜æ¯”ä¾‹åªå’Œ å½¢çŠ¶ã€å°ºåº¦ æœ‰å…³ï¼Œä¸å«ä½ç½®ï¼Œè¿™é€šå¸¸æ˜¯ç›¸å¯¹äºè¾“å…¥å›¾åƒçš„æ¯”ä¾‹\nåœ¨ YOLO æ¨¡å‹ä¸­ï¼Œç½‘ç»œä¼šä¸ºæ¯ä¸ªç›®æ ‡é¢„æµ‹å››ä¸ªåç§»é‡ï¼štx,ty,tw,tht_x, t_y, t_w, t_htxâ€‹,tyâ€‹,twâ€‹,thâ€‹ã€‚é€šè¿‡ä»¥ä¸‹å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æœ€ç»ˆçš„è¾¹ç•Œæ¡†åæ ‡ï¼š\nbx=Ïƒ(tx)+cxb_x = \\sigma(t_x) + c_x\nbxâ€‹=Ïƒ(txâ€‹)+cxâ€‹\nby=Ïƒ(ty)+cyb_y = \\sigma(t_y) + c_y\nbyâ€‹=Ïƒ(tyâ€‹)+cyâ€‹\nbw=pwâ‹…etwb_w = p_w \\cdot e^{t_w}\nbwâ€‹=pwâ€‹â‹…etwâ€‹\nbh=phâ‹…ethb_h = p_h \\cdot e^{t_h}\nbhâ€‹=phâ€‹â‹…ethâ€‹\ncx,cyc_x, c_ycxâ€‹,cyâ€‹ï¼šå½“å‰ç½‘æ ¼å·¦ä¸Šè§’çš„åæ ‡ï¼ˆé€šå¸¸ä»¥ç½‘æ ¼å¤§å°ä¸ºå•ä½ï¼‰ã€‚\npw,php_w, p_hpwâ€‹,phâ€‹ï¼šé”šæ¡†çš„å®½åº¦å’Œé«˜åº¦ã€‚è¿™æ˜¯é¢„è®¾å¥½çš„å‚è€ƒåŸºå‡†ï¼Œåœ¨å…¬å¼ä¸­ï¼Œpwp_wpwâ€‹ å’Œ php_hphâ€‹ å°±æ˜¯ç›´æ¥ä»é”šæ¡†é‡Œæ‹¿å‡ºæ¥çš„ã€‚åé¢ä¹˜ä¸ª e çš„æŒ‡æ•°å€ã€‚\n# YOLOv2 è¾¹ç•Œæ¡†é¢„æµ‹ + æŸå¤±è®¡ç®—æµç¨‹\n# è·‘å®Œä¸€éè¾“å‡º\nç½‘ç»œæœ€åä¸€å±‚è¾“å‡ºçš„å¼ é‡ï¼š\n[S,S,BÃ—(5+C)][S, S, B \\times (5 + C)]\n[S,S,BÃ—(5+C)]\n\nSÃ—S = ç½‘æ ¼æ•°ï¼ˆæ¯”å¦‚ 13Ã—13ï¼‰\nB = anchor æ•°ï¼Œåœ¨ YOLOv2 é‡Œæ˜¯ 5\n5 =  [t_x, t_y, t_w, t_h, t_&#123;obj&#125;]\nC = ç±»åˆ«æ•°\n\n\ntx,ty,tw,tht_x, t_y, t_w, t_htxâ€‹,tyâ€‹,twâ€‹,thâ€‹ éƒ½æ˜¯ç½‘ç»œé¢„æµ‹çš„åç§»é‡ï¼ˆå®æ•°ï¼‰ï¼Œè¿˜ä¸æ˜¯æ¡†çš„çœŸå®åæ ‡ã€‚\n\n# è§£ç ä¸ºçœŸå®æ¡†\nä½¿ç”¨å…¬å¼ï¼š\nbx=Ïƒ(tx)+cxb_x = \\sigma(t_x) + c_x\nbxâ€‹=Ïƒ(txâ€‹)+cxâ€‹\nby=Ïƒ(ty)+cyb_y = \\sigma(t_y) + c_y\nbyâ€‹=Ïƒ(tyâ€‹)+cyâ€‹\nbw=pwâ‹…etwb_w = p_w \\cdot e^{t_w}\nbwâ€‹=pwâ€‹â‹…etwâ€‹\nbh=phâ‹…ethb_h = p_h \\cdot e^{t_h}\nbhâ€‹=phâ€‹â‹…ethâ€‹\nè¾“å‡ºbx,by,bw,bhb_x, b_y, b_w, b_hbxâ€‹,byâ€‹,bwâ€‹,bhâ€‹ï¼Œè¿™æ˜¯ç›¸å¯¹æ•´ä¸ªè¾“å…¥å›¾åƒçœŸå®æ¡†åæ ‡ï¼Œ\n# åŒ¹é… ground-truth æ¡†\nè®­ç»ƒæ—¶ï¼š\n\nå¯¹æ¯ä¸ª GT æ¡†ï¼š\n\næ‰¾åˆ° IoU æœ€å¤§çš„ anchor â†’ è¿™ä¸ª anchor æ¥é¢„æµ‹å®ƒ\nå…¶å®ƒ anchor å¿½ç•¥æˆ–å½“è´Ÿæ ·æœ¬\n\n\nè®¡ç®—é¢„æµ‹æ¡†bx,by,bw,bhb_x, b_y, b_w, b_hbxâ€‹,byâ€‹,bwâ€‹,bhâ€‹ ä¸ GT æ¡†çš„è¯¯å·®\n\n# æŸå¤±è®¡ç®—ï¼ˆv2 å¯¹æ¯” v1ï¼‰\nYOLOv1 æŸå¤± = è¾¹ç•Œæ¡†å›å½’ + ç½®ä¿¡åº¦ + åˆ†ç±»æŸå¤±\nLoss=coord_loss+obj_loss+noobj_loss+class_lossLoss=coord\\_loss+obj\\_loss+noobj\\_loss+class\\_loss\nLoss=coord_loss+obj_loss+noobj_loss+class_loss\ncoord_losscoord\\_losscoord_loss åæ ‡åç§»æŸå¤±ï¼Œè¿™é‡Œç›´æ¥åœ¨åç§»é‡ç©ºé—´è®¡ç®—è¯¯å·®ï¼Œè€Œä¸æ˜¯åœ¨è½¬æ¢åçš„åƒç´ ç©ºé—´\nobj_lossobj\\_lossobj_loss æœ‰ç‰©ä½“ç½®ä¿¡åº¦æŸå¤±ï¼Œå¦‚æœè¿™é‡Œæœ‰ç‰©ä½“ï¼Œæ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦åº”è¯¥æ¥è¿‘å®ƒä¸çœŸå®ç›®æ ‡çš„é‡åˆåº¦ã€‚\nnoobj_lossnoobj\\_lossnoobj_loss æ— ç‰©ä½“ç½®ä¿¡åº¦æŸå¤±ã€‚\nclass_lossclass\\_lossclass_loss åˆ†ç±»æŸå¤±ï¼ŒYOLO v2 åœ¨åˆ†ç±»ä¸Šä¹Ÿä½¿ç”¨äº†å‡æ–¹è¯¯å·®ï¼Œè€Œåç»­ç‰ˆæœ¬æ”¹æˆäº†äº¤å‰ç†µã€‚\næœ‰ç‰©ä½“ç½®ä¿¡åº¦æŸå¤±å’Œæ— ç‰©ä½“ç½®ä¿¡åº¦æŸå¤±ï¼Œåƒæ˜¯æ¨¡å‹é‡Œçš„ â€œå®‰æ£€å‘˜â€ å’Œ â€œçº é”™å‘˜â€ï¼Œå®ƒä»¬å…±åŒè§£å†³ç›®æ ‡ï¼šå¦‚ä½•ä»æˆåƒä¸Šä¸‡ä¸ªå€™é€‰æ¡†ä¸­ï¼ŒæŠŠçœŸæ­£åŒ…å«ç‰©ä½“çš„é‚£ä¸ªæ‰¾å‡ºæ¥ï¼Œå¹¶è¿‡æ»¤æ‰èƒŒæ™¯ã€‚\nåœ¨ä¸€å¼ å›¾ä¸­ï¼ŒèƒŒæ™¯æ¡†çš„æ•°é‡è¿œå¤šäºç‰©ä½“æ¡†ã€‚å¦‚æœä¸¤è€…çš„æƒé‡ä¸€æ ·ï¼Œæ¨¡å‹ä¼šå‘ç°ï¼ŒæŠŠæ‰€æœ‰æ¡†éƒ½é¢„æµ‹æˆèƒŒæ™¯æ˜¯æœ€çœåŠ›çš„åšæ³•ï¼Œä½†å…¶å®è¿™æ ·å¹¶æ²¡æœ‰è¾¾åˆ°æˆ‘ä»¬çš„é¢„æœŸã€‚\nå› æ­¤ï¼Œæˆ‘ä»¬é€šå¸¸è®¾ç½® Î»noobj\\lambda_{noobj}Î»noobjâ€‹ è¾ƒå°ä¾‹å¦‚ 0.5ï¼Œè€Œ Î»obj\\lambda_{obj}Î»objâ€‹ è¾ƒå¤§ã€‚è¿™æ ·å³ä½¿èƒŒæ™¯æ¡†å¾ˆå¤šï¼Œå®ƒä»¬äº§ç”Ÿçš„æ€»æ¢¯åº¦ä¹Ÿä¸ä¼šå®Œå…¨æ·¹æ²¡æ‰å°‘æ•°ç‰©ä½“æ¡†å¸¦æ¥çš„ä¿¡å·ã€‚\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæœ‰å¥½å¤šÎ»\\lambdaÎ» ï¼Œæ€»æŸå¤± LossLossLoss æ˜¯æ‰€æœ‰å­æŸå¤±çš„åŠ æƒå’Œï¼Œå¦‚æœä½ å‘ç°æ¨¡å‹æ¡†ç”»å¾—ä¸å‡†ï¼Œå°±è°ƒå¤§ Î»coord\\lambda_{coord}Î»coordâ€‹ï¼Œæ¨¡å‹é€šè¿‡è¯¯å·®åå‘ä¼ æ’­ï¼Œä¼šå‘Šè¯‰è‡ªå·±ï¼šä¸‹æ¬¡æŠŠæ¡†å¾€å·¦æŒªç‚¹ï¼Œèƒ†å­å¤§ä¸€ç‚¹ï¼Œæé«˜ objobjobj åˆ†æ•°ï¼Œå¹¶ä¸”å¤šçœ‹çœ‹çŒ«çš„ç‰¹å¾ï¼\nYOLOv2 æŸå¤± = èƒŒæ™¯ç½®ä¿¡åº¦æŸå¤± + é¢„çƒ­æœŸ Anchor åŒ¹é…æŸå¤± + æœ‰ç‰©ä½“åæ ‡æŸå¤± + æœ‰ç‰©ä½“ç½®ä¿¡åº¦æŸå¤± + åˆ†ç±»æŸå¤±\nLossv2=NoObjectLoss+PriorLoss+CoordinateLoss+ObjectLoss+ClassLossLoss_{v2}=NoObjectLoss+PriorLoss+CoordinateLoss+ObjectLoss+ClassLoss\nLossv2â€‹=NoObjectLoss+PriorLoss+CoordinateLoss+ObjectLoss+ClassLoss\nLoss=âˆ‘i=0Wâˆ‘j=0Hâˆ‘k=0A1MaxÂ IoU&lt;Threshâ‹…Î»noobjâ‹…(0âˆ’bijko)2+1t&lt;12800â‹…Î»priorâ‹…âˆ‘râˆˆ{x,y,w,h}(priorkrâˆ’bijkr)2+1ktruth[Î»coordâ‹…âˆ‘râˆˆ{x,y,w,h}(truthrâˆ’bijkr)2+Î»objâ‹…(IOUtruthkâˆ’bijko)2+Î»classâ‹…âˆ‘c=1C(truthcâˆ’bijkc)2]\\begin{aligned}\nLoss = &amp; \\sum_{i=0}^{W} \\sum_{j=0}^{H} \\sum_{k=0}^{A} \\mathbb{1}_{\\text{Max IoU} &lt; \\text{Thresh}} \\cdot \\lambda_{noobj} \\cdot (0 - b_{ijk}^o)^2 \\\\\n&amp; + \\mathbb{1}_{t &lt; 12800} \\cdot \\lambda_{prior} \\cdot \\sum_{r \\in \\{x,y,w,h\\}} (prior_k^r - b_{ijk}^r)^2 \\\\\n&amp; + \\mathbb{1}_k^{truth} \\left[ \\lambda_{coord} \\cdot \\sum_{r \\in \\{x,y,w,h\\}} (truth^r - b_{ijk}^r)^2 \\right. \\\\\n&amp; + \\lambda_{obj} \\cdot (IOU_{truth}^k - b_{ijk}^o)^2 \\\\\n&amp; + \\left. \\lambda_{class} \\cdot \\sum_{c=1}^{C} (truth^c - b_{ijk}^c)^2 \\right]\n\\end{aligned}\nLoss=â€‹i=0âˆ‘Wâ€‹j=0âˆ‘Hâ€‹k=0âˆ‘Aâ€‹1MaxÂ IoU&lt;Threshâ€‹â‹…Î»noobjâ€‹â‹…(0âˆ’bijkoâ€‹)2+1t&lt;12800â€‹â‹…Î»priorâ€‹â‹…râˆˆ{x,y,w,h}âˆ‘â€‹(priorkrâ€‹âˆ’bijkrâ€‹)2+1ktruthâ€‹â£â¢â¡â€‹Î»coordâ€‹â‹…râˆˆ{x,y,w,h}âˆ‘â€‹(truthrâˆ’bijkrâ€‹)2+Î»objâ€‹â‹…(IOUtruthkâ€‹âˆ’bijkoâ€‹)2+Î»classâ€‹â‹…c=1âˆ‘Câ€‹(truthcâˆ’bijkcâ€‹)2]â€‹\n\n# èƒŒæ™¯ç½®ä¿¡åº¦æŸå¤± No-Object Loss\n\nå…¬å¼ï¼šÎ»noobjâ‹…(0âˆ’bijko)2\\lambda_{noobj} \\cdot (0 - b_{ijk}^o)^2Î»noobjâ€‹â‹…(0âˆ’bijkoâ€‹)2ï¼Œé‚£ä¹ˆé•¿ä¸€ä¸²æ ¸å¿ƒå°±æ˜¯è¿™ä¸ªï¼Œå‰é¢çš„éƒ½æ˜¯ä¸€äº›æ¡ä»¶ã€‚\nå«ä¹‰ï¼šå¦‚æœé¢„æµ‹æ¡†ä¸æ‰€æœ‰çœŸå®æ¡†çš„ IoU éƒ½å°äºé˜ˆå€¼ï¼ˆé€šå¸¸ä¸º 0.6ï¼‰ï¼Œå®ƒå°±è¢«åˆ¤å®šä¸ºèƒŒæ™¯ã€‚\nç›®æ ‡ï¼šå¼ºåˆ¶è¯¥æ¡†çš„ç½®ä¿¡åº¦ bob^obo è¶‹å‘ 0ï¼Œæ‰€ä»¥é‡‡ç”¨ 0 å‡å»å®ƒè‡ªå·±ã€‚\næƒé‡ï¼šÎ»noobj=1\\lambda_{noobj} = 1Î»noobjâ€‹=1ã€‚\n\n# é¢„çƒ­æœŸ Anchor åŒ¹é…æŸå¤± Prior Loss\n\nå…¬å¼ï¼š1t&lt;12800â‹…Î»priorâ€¦\\mathbb{1}_{t &lt; 12800} \\cdot \\lambda_{prior} \\dots1t&lt;12800â€‹â‹…Î»priorâ€‹â€¦\nå«ä¹‰ï¼šè¿™æ˜¯ YOLOv2 çš„ç‰¹æ®Šè®¾è®¡ã€‚åœ¨è®­ç»ƒçš„å‰ 12800 æ­¥ï¼Œè®©é¢„æµ‹æ¡†å»æ‹Ÿåˆ Anchor Box çš„åŸå§‹å½¢çŠ¶ã€‚\nä½œç”¨ï¼šé˜²æ­¢è®­ç»ƒåˆæœŸé¢„æµ‹æ¡†ä¹±è·³ï¼Œèµ·åˆ°ç¨³å®šæ¨¡å‹çš„ä½œç”¨ã€‚è¿‡äº†è¿™ä¸ªé˜¶æ®µï¼Œè¿™ä¸€é¡¹å°±æ¶ˆå¤±äº†ã€‚\n\n# æœ‰ç‰©ä½“åæ ‡æŸå¤± Coordinate Loss\n\nå…¬å¼ï¼šÎ»coordâ‹…âˆ‘(truthâˆ’b)2\\lambda_{coord} \\cdot \\sum (truth - b)^2Î»coordâ€‹â‹…âˆ‘(truthâˆ’b)2\næ³¨æ„ï¼šè¿™é‡Œçš„è®¡ç®—æ˜¯åœ¨ ttt ç©ºé—´ï¼ˆåç§»é‡ç©ºé—´ï¼‰è¿›è¡Œçš„ï¼Œå³æ¨¡å‹ç›´æ¥è¾“å‡ºçš„æ•°å€¼ä¸è½¬åŒ–åçš„æ ‡ç­¾è¿›è¡Œå¯¹æ¯”ã€‚\næƒé‡ï¼šÎ»coord=1\\lambda_{coord} = 1Î»coordâ€‹=1ã€‚\n\n# æœ‰ç‰©ä½“ç½®ä¿¡åº¦æŸå¤± Object Loss\n\nå…¬å¼ï¼šÎ»objâ‹…(IOUtruthkâˆ’bijko)2\\lambda_{obj} \\cdot (IOU_{truth}^k - b_{ijk}^o)^2Î»objâ€‹â‹…(IOUtruthkâ€‹âˆ’bijkoâ€‹)2\næ ¸å¿ƒç»†èŠ‚ï¼š\n\næ ‡ç­¾ä¸æ˜¯ 1ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯é¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„ å®é™… IoU ä½œä¸ºå­¦ä¹ ç›®æ ‡ã€‚\né«˜æƒé‡ï¼šÎ»obj=5\\lambda_{obj} = 5Î»objâ€‹=5ã€‚è¿™åæ˜ äº† YOLOv2 éå¸¸é‡è§†å¯¹çœŸå®ç›®æ ‡çš„æå–ã€‚\n\n\n\n# åˆ†ç±»æŸå¤± Class Loss\n\nå…¬å¼ï¼šÎ»classâ‹…âˆ‘(truthcâˆ’bijkc)2\\lambda_{class} \\cdot \\sum (truth^c - b_{ijk}^c)^2Î»classâ€‹â‹…âˆ‘(truthcâˆ’bijkcâ€‹)2\nè®¡ç®—æ–¹å¼ï¼šYOLOv2 ä¾ç„¶ä½¿ç”¨äº† MSE å‡æ–¹è¯¯å·®ï¼Œè€Œä¸æ˜¯åæ¥ç‰ˆæœ¬å¸¸ç”¨çš„äº¤å‰ç†µã€‚\n\n# æ€»ç»“\n\n\n\næŸå¤±é¡¹\næƒé‡å˜é‡\næ¨èå€¼\nä½œç”¨\n\n\n\n\nèƒŒæ™¯ç½®ä¿¡åº¦\n\\lambda_\n1\næŠ‘åˆ¶è¯¯æŠ¥\n\n\nç‰©ä½“ç½®ä¿¡åº¦\n\\lambda_\n5\næé«˜å¬å›ç‡\n\n\nåæ ‡å›å½’\n\\lambda_\n1\nç²¾å‡†å®šä½\n\n\nåˆ†ç±»æ¦‚ç‡\n\\lambda_\n1\nç±»åˆ«åˆ¤å®š\n\n\nAnchor é¢„çƒ­\n\\lambda_\n0.01\nåˆæœŸç¨³å®šè®­ç»ƒ\n\n\n\n# passthrough\nåœ¨ YOLOv2 æ¶æ„ä¸­ï¼ŒPassthrough Layer ç›´é€šå±‚ / é‡ç»„å±‚æ˜¯ä¸€ä¸ªéå¸¸ç²¾å¦™çš„è®¾è®¡ã€‚å®ƒçš„æ ¸å¿ƒç›®çš„æ˜¯ä¸ºäº†æ›´å¥½åœ°æ£€æµ‹å¾®å°ç‰©ä½“ã€‚\n\n# DarkNet-19 æ£€æµ‹æ¨¡å‹ï¼ˆå®Œæ•´ç‰ˆï¼‰\n\n# å¤šå°ºåº¦è®­ç»ƒ\nå¤šå°ºåº¦è®­ç»ƒæ˜¯ YOLOv2 æå‡ºçš„ä¸€ç§éå¸¸èªæ˜çš„è®­ç»ƒæŠ€å·§ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯è®©æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­çœ‹åˆ°ä¸åŒåˆ†è¾¨ç‡çš„å›¾ç‰‡ï¼Œä»è€Œå¢å¼ºæ¨¡å‹å¯¹ä¸åŒå°ºå¯¸ç‰©ä½“çš„é²æ£’æ€§ã€‚\næ¨¡å‹ä¸å†ä¾èµ–äºç‰©ä½“çš„ â€œç»å¯¹åƒç´ å¤§å°â€ï¼Œè€Œæ˜¯å­¦ä¹ ç‰©ä½“çš„ â€œç›¸å¯¹å½¢çŠ¶ç‰¹å¾â€ã€‚\n# å‚è€ƒ\n\nã€YOLOv1ã€YOLOv2ã€YOLOv3 ç›®æ ‡æ£€æµ‹ç®—æ³•åŸç†ä¸å®æˆ˜ã€‘https://www.bilibili.com/video/BV1WT421r72w\n\n","categories":["æ·±åº¦å­¦ä¹ ","YOLO"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","YOLO"]},{"title":"ultralytics YOLOv3","url":"/python/YOLO/YOLOv3_ultralytics/","content":"# YOLOv3 ultralytics\n# å®‰è£… ultralytics åŸºç¡€ç¯å¢ƒ\nconda install -c conda-forge ultralytics# å…‹éš† YOLOv3 ä»£ç \ngit clone https://github.com/ultralytics/yolov3\n# è§£å†³ git 443 æŠ¥é”™\næ¨èä½¿ç”¨ v2Ray è¿›è¡Œä»£ç†ï¼Œè®¾ç½® git çš„ http åŠ https ä»£ç†ï¼š\ngit config --global http.proxy socks5://127.0.0.1:10808git config --global https.proxy socks5://127.0.0.1:10808è‹¥ä½¿ç”¨ v2Ray çš„è¯ï¼Œå…¶ä»£ç†ç«¯å£ä¸º 10808ï¼Œè‹¥ä¸º clash åˆ™åº”ä¸º 7891ã€‚\n# å®‰è£…ç¼ºå°‘çš„ä¾èµ–åº“\n\nå½“ç„¶ä½ å¯ä»¥ä¸€ä¸ªä¸€ä¸ªå®‰è£…ï¼Œä½†é‚£æ ·æœ‰ç‚¹éº»çƒ¦ï¼Œè¯·ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š\npip install -r .\\requirements.txt# æƒé‡æ–‡ä»¶\nè¯·è®¿é—®ï¼šhttps://gitcode.com/open-source-toolkit/b5126/\nå…¶ä¸­åŒ…å«äº†ï¼š\n\nyolov3.pt\nYOLOv3 çš„æ ‡å‡†æƒé‡æ–‡ä»¶ï¼Œé€‚ç”¨äºå¤§å¤šæ•°ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚\nyolov3-spp.pt\nYOLOv3-SPP çš„æƒé‡æ–‡ä»¶ï¼Œé€šè¿‡ç©ºé—´é‡‘å­—å¡”æ± åŒ–ï¼ˆSpatial Pyramid Poolingï¼‰å¢å¼ºäº†æ¨¡å‹çš„æ€§èƒ½ï¼Œç‰¹åˆ«é€‚ç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒçš„ç›®æ ‡æ£€æµ‹ã€‚\nyolov3-tiny.pt\nYOLOv3-Tiny çš„æƒé‡æ–‡ä»¶ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒï¼Œå¦‚åµŒå…¥å¼è®¾å¤‡æˆ–ç§»åŠ¨è®¾å¤‡ï¼Œå…·æœ‰è¾ƒå¿«çš„æ¨ç†é€Ÿåº¦å’Œè¾ƒå°çš„æ¨¡å‹ä½“ç§¯ã€‚\n\n# è¯•è¿è¡Œ\né¦–å…ˆä¿®æ”¹æƒé‡æ–‡ä»¶è·¯å¾„\n\nè¿è¡Œ detect.py\nFusing layers... yolov3 summary: 261 layers, 61922845 parameters, 0 gradients, 155.9 GFLOPsimage 1/2 D:\\PycharmProjects\\yolov3\\data\\images\\bus.jpg: 640x480 4 persons, 1 bicycle, 1 bus, 70.7msimage 2/2 D:\\PycharmProjects\\yolov3\\data\\images\\zidane.jpg: 384x640 2 persons, 2 ties, 55.0msSpeed: 1.0ms pre-process, 62.8ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)Results saved to runs\\detect\\exp3è¾“å‡ºç»“æœï¼š\n\n\næ•ˆæœæƒŠè‰³ï¼Œèµ·åˆæˆ‘è§‚å¯Ÿè¾“å‡ºæ—¶  4 persons, 1 bicycle, 1 bus, 70.7ms ï¼Œæˆ‘åœ¨æƒ³è¿™ä¸ª  1 bicycle  åˆ°åº•åœ¨å“ªé‡Œã€‚\næˆ‘åå¤ç›¯ç€å›¾ç‰‡çœ‹äº†å¥½å‡ éï¼šå…¬äº¤è½¦å¾ˆæ˜æ˜¾ï¼Œäººä¹Ÿæ•°å¾—æ¸…ï¼Œå¯è‡ªè¡Œè½¦å‘¢ï¼Ÿç”»é¢é‡Œæ²¡æœ‰å®Œæ•´çš„è½¦è½®ï¼Œæ²¡æœ‰æ¸…æ™°çš„è½¦æ¶ï¼Œç”šè‡³ä¹Ÿæ²¡æœ‰éª‘è½¦çš„äººã€‚é‚£ä¸€åˆ»æˆ‘ç”šè‡³æ€€ç–‘ï¼Œæ˜¯ä¸æ˜¯æ¨¡å‹è¯¯åˆ¤äº†ã€‚\nç›´åˆ°æˆ‘çœŸæ­£æŠŠ YOLO çš„æ ‡æ³¨æ¡†å›¾ç‰‡æ‰“å¼€ï¼Œé‚£è¾†è‡ªè¡Œè½¦å°±åœ¨å…¬äº¤è½¦çš„å³ä¸Šè§’ï¼Œä½äºå±…æ°‘çª—æˆ·å›´æ ä¹‹ä¸­ï¼Œä¸€ä¸ªå‡ ä¹è¢«é®æŒ¡ã€åªéœ²å‡ºå±€éƒ¨è½®å»“çš„ç‰©ä½“ï¼Œè¢«ä¸€ä¸ªç»†å°å´åšå®šçš„æ¡†ç‰¢ç‰¢åœˆä½ã€‚é‚£ä¸€ç¬é—´ï¼Œæˆ‘æ‰ç†è§£ You Only Look Once çš„çœŸæ­£å«ä¹‰â€¦\n# é¡¹ç›®ç»“æ„\n# èµ„æºå’Œå·¥å…·\n\n data ï¼šå­˜æ”¾æ•°æ®ç›¸å…³çš„é…ç½®æ–‡ä»¶æ¯”å¦‚ç±»åˆ«åç§°ã€è·¯å¾„é…ç½®å’Œå›¾ç‰‡æµ‹è¯•æ•°æ®ã€‚\n models ï¼šå­˜æ”¾æ¨¡å‹ç›¸å…³çš„é…ç½®æ–‡ä»¶ï¼Œå®šä¹‰ç¥ç»ç½‘ç»œå±‚çº§ç»“æ„å’Œæ ¸å¿ƒä»£ç ã€‚\n runs ï¼šç»“æœæ–‡ä»¶å¤¹ã€‚å½“ä½ è¿è¡Œç¨‹åºè¿›è¡Œæ¨ç†ã€è®­ç»ƒæˆ–æµ‹è¯•åï¼Œç”Ÿæˆçš„å›¾è¡¨ã€ä¿å­˜çš„æ£€æµ‹ç»“æœéƒ½ä¼šæ”¾åœ¨è¿™é‡Œã€‚\n utils ï¼šå·¥å…·ä»£ç åº“ã€‚å­˜æ”¾ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œæ¯”å¦‚è®¡ç®—æŸå¤±çš„ä»£ç ã€åœ¨å›¾ç‰‡ä¸Šç”»æ¡†æ¡†çš„ä»£ç ç­‰ã€‚\n VOCdevkit ï¼šæ•°æ®é›†æ–‡ä»¶å¤¹ã€‚é€šå¸¸æ˜¯æŒ‰ç…§å®˜æ–¹ VOC æ ‡å‡†å­˜æ”¾çš„åŸå§‹å›¾ç‰‡å’Œæ ‡ç­¾æ–‡ä»¶ã€‚\n weight ï¼šæƒé‡æ–‡ä»¶å¤¹ã€‚ä¸“é—¨ç”¨æ¥æ”¾è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°ï¼ˆæƒé‡æ–‡ä»¶ï¼‰ï¼Œæ²¡æœ‰å®ƒæ¨¡å‹å°±æ— æ³•å·¥ä½œã€‚\n\n# è§†é¢‘ä¸ç¯å¢ƒæ–‡ä»¶\n\n che.avi ï¼šä¸€ä¸ªæµ‹è¯•è§†é¢‘ã€‚æ–¹ä¾¿ä½ å†™å¥½ç¨‹åºåï¼Œç›´æ¥è¿è¡Œæ¥çœ‹çœ‹èƒ½ä¸èƒ½è¯†åˆ«å‡ºè§†é¢‘é‡Œçš„ç‰©ä½“ã€‚\n requirements.txt ï¼šç¯å¢ƒé…ç½®æ–‡ä»¶ã€‚è®°å½•äº†è¿è¡Œè¿™ä¸ªé¡¹ç›®éœ€è¦å®‰è£…å“ªäº› Python æ’ä»¶å’Œåº“ï¼Œä»¥åŠå¯¹åº”çš„ç‰ˆæœ¬ã€‚\n\n# Python è„šæœ¬éƒ¨åˆ†ï¼ˆæ ¸å¿ƒè¿è¡Œç¨‹åºï¼‰\n\n Dataset_partitioning.py ï¼šæ•°æ®é›†åˆ’åˆ†ä»£ç ã€‚ç”¨æ¥æŠŠä½ çš„å›¾ç‰‡éšæœºåˆ†æˆ â€œè®­ç»ƒé›†â€ å’Œ â€œéªŒè¯é›†â€ã€‚\n detect.py ï¼šæ£€æµ‹æ¨ç†ä»£ç ã€‚æœ€å¸¸ç”¨çš„æ–‡ä»¶ï¼Œè¿è¡Œå®ƒå°±å¯ä»¥è°ƒç”¨æ¨¡å‹å»è¯†åˆ«ä¸€å¼ å›¾ç‰‡æˆ–ä¸€æ®µè§†é¢‘ã€‚\n hubconf.py ï¼šPyTorch Hub ç›¸å…³çš„è„šæœ¬ï¼ˆç”¨äºæ–¹ä¾¿åœ°åœ¨å…¶ä»–åœ°æ–¹è°ƒç”¨è¿™ä¸ªæ¨¡å‹ï¼‰ã€‚\n train.py ï¼šæ¨¡å‹è®­ç»ƒä»£ç ã€‚å¦‚æœä½ æƒ³ç”¨è‡ªå·±çš„æ•°æ®æ•™æ¨¡å‹è®¤ä¸œè¥¿ï¼Œå°±è¿è¡Œè¿™ä¸ªæ–‡ä»¶ã€‚\n val.py ï¼šæ¨¡å‹æµ‹è¯• / éªŒè¯ä»£ç ã€‚ç”¨æ¥è·‘åˆ†ï¼Œçœ‹çœ‹è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹å‡†ç¡®ç‡ï¼ˆmAPï¼‰åˆ°åº•æœ‰å¤šé«˜ã€‚\n\n# è¶…å‚æ•°æ–‡ä»¶ï¼šhyp.scratch-high.yaml\nlr0 è¡¨ç¤ºåˆå§‹å­¦ä¹ ç‡ï¼Œå³è®­ç»ƒåˆšå¼€å§‹æ—¶ä¼˜åŒ–å™¨ä½¿ç”¨çš„å­¦ä¹ ç‡ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒSGD å¸¸ç”¨ 0.01ï¼ŒAdam å¸¸ç”¨ 0.001ã€‚å­¦ä¹ ç‡è¿‡å¤§ä¼šå¯¼è‡´è®­ç»ƒéœ‡è¡ç”šè‡³å‘æ•£ï¼Œè¿‡å°åˆ™æ”¶æ•›ç¼“æ…¢ã€‚\nlrf è¡¨ç¤ºæœ€ç»ˆå­¦ä¹ ç‡ä¸åˆå§‹å­¦ä¹ ç‡çš„æ¯”ä¾‹ï¼Œé€šå¸¸ç”¨äº OneCycle å­¦ä¹ ç‡ç­–ç•¥ã€‚è®­ç»ƒåæœŸçš„å­¦ä¹ ç‡ç­‰äº lr0 ä¹˜ä»¥ lrfï¼Œä¾‹å¦‚ lr0 ä¸º 0.01ï¼Œlrf ä¸º 0.1ï¼Œåˆ™æœ€ç»ˆå­¦ä¹ ç‡ä¸º 0.001ã€‚è¿™æ ·å¯ä»¥åœ¨è®­ç»ƒåæœŸå‡å°æ­¥é•¿ï¼Œä½¿æ¨¡å‹æ›´ç¨³å®šåœ°æ”¶æ•›ã€‚\nmomentum è¡¨ç¤ºåŠ¨é‡å‚æ•°ã€‚åœ¨ä½¿ç”¨ SGD æ—¶å®ƒæ˜¯ momentumï¼Œåœ¨ä½¿ç”¨ Adam æ—¶å¯¹åº” beta1ã€‚åŠ¨é‡çš„ä½œç”¨æ˜¯ä¿ç•™å†å²æ¢¯åº¦æ–¹å‘ï¼Œå‡å°‘å‚æ•°æ›´æ–°çš„æŠ–åŠ¨ï¼ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦ã€‚\nweight_decay è¡¨ç¤ºæƒé‡è¡°å‡ç³»æ•°ï¼Œä¹Ÿå°±æ˜¯ L2 æ­£åˆ™åŒ–å¼ºåº¦ã€‚å®ƒé€šè¿‡æƒ©ç½šè¿‡å¤§çš„æƒé‡æ¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œ0.0005 æ˜¯ç›®æ ‡æ£€æµ‹ä¸­éå¸¸å¸¸è§çš„ç»éªŒå€¼ã€‚\nwarmup_epochs è¡¨ç¤ºå­¦ä¹ ç‡é¢„çƒ­çš„è½®æ•°ï¼Œå‰è‹¥å¹²ä¸ª epoch å†…å­¦ä¹ ç‡ä¼šä»è¾ƒå°å€¼é€æ­¥å¢åŠ åˆ°è®¾å®šçš„åˆå§‹å­¦ä¹ ç‡ï¼Œä¸»è¦ç›®çš„æ˜¯é˜²æ­¢è®­ç»ƒåˆæœŸæ¢¯åº¦è¿‡å¤§å¯¼è‡´ä¸ç¨³å®šã€‚\nwarmup_momentum è¡¨ç¤ºåœ¨ warmup é˜¶æ®µä½¿ç”¨çš„åˆå§‹åŠ¨é‡å€¼ï¼Œéšç€ warmup çš„ç»“æŸé€æ¸è¿‡æ¸¡åˆ°æ­£å¸¸çš„ momentumï¼Œæœ‰åŠ©äºå¹³æ»‘è®­ç»ƒåˆæœŸçš„å‚æ•°æ›´æ–°ã€‚\nwarmup_bias_lr è¡¨ç¤ºåç½®å‚æ•°åœ¨ warmup é˜¶æ®µä½¿ç”¨çš„å­¦ä¹ ç‡ã€‚é€šå¸¸ä¼šç»™ bias ä¸€ä¸ªç›¸å¯¹æ›´å¤§çš„å­¦ä¹ ç‡ï¼Œä½¿æ¨¡å‹èƒ½æ›´å¿«åœ°å­¦ä¼šç›®æ ‡çš„å¤§è‡´ä½ç½®å’Œå­˜åœ¨æ€§ã€‚\nbox è¡¨ç¤ºè¾¹ç•Œæ¡†å›å½’æŸå¤±çš„æƒé‡ï¼Œç”¨äºæ§åˆ¶æ¨¡å‹å¯¹ç›®æ ‡ä½ç½®å’Œå¤§å°å›å½’ç²¾åº¦çš„å…³æ³¨ç¨‹åº¦ã€‚è¯¥å€¼è¶Šå¤§ï¼Œæ¨¡å‹è¶Šé‡è§†æ¡†çš„ä½ç½®å‡†ç¡®æ€§ã€‚\ncls è¡¨ç¤ºåˆ†ç±»æŸå¤±çš„æƒé‡ï¼Œç”¨äºå¹³è¡¡å¤šç±»åˆ«é¢„æµ‹çš„é‡è¦æ€§ã€‚å¦‚æœç±»åˆ«æ•°è¾ƒå¤šæˆ–ç±»åˆ«åŒºåˆ†å›°éš¾ï¼Œé€šå¸¸éœ€è¦é€‚å½“å¢å¤§è¯¥å€¼ã€‚\ncls_pw è¡¨ç¤ºåˆ†ç±»æŸå¤±ä¸­æ­£æ ·æœ¬çš„æƒé‡ï¼Œä¸»è¦ç”¨äºç¼“è§£æ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡é—®é¢˜ã€‚å€¼ä¸º 1 è¡¨ç¤ºä¸é¢å¤–åŠ æƒã€‚\nobj è¡¨ç¤ºç›®æ ‡ç½®ä¿¡åº¦æŸå¤±çš„æƒé‡ï¼Œç”¨äºè¡¡é‡æ¨¡å‹åˆ¤æ–­ â€œè¯¥ä½ç½®æ˜¯å¦å­˜åœ¨ç›®æ ‡â€ çš„èƒ½åŠ›ï¼Œè¿™æ˜¯ YOLO æ£€æµ‹ä¸­éå¸¸æ ¸å¿ƒçš„ä¸€é¡¹ã€‚\nobj_pw è¡¨ç¤ºç›®æ ‡ç½®ä¿¡åº¦æŸå¤±ä¸­æ­£æ ·æœ¬çš„æƒé‡ï¼ŒåŒæ ·ç”¨äºæ ·æœ¬ä¸å¹³è¡¡åœºæ™¯ã€‚\niou_t è¡¨ç¤ºè®­ç»ƒæ—¶ä½¿ç”¨çš„ IoU é˜ˆå€¼ï¼Œåªæœ‰é¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„ IoU å¤§äºè¯¥å€¼æ—¶æ‰ä¼šå‚ä¸æ­£æ ·æœ¬è®­ç»ƒã€‚é˜ˆå€¼è¾ƒä½æ—¶æœ‰åˆ©äºæé«˜å¬å›ç‡ï¼Œè¾ƒé«˜æ—¶æœ‰åˆ©äºæé«˜å®šä½ç²¾åº¦ã€‚\nanchor_t è¡¨ç¤º anchor åŒ¹é…é˜ˆå€¼ï¼Œç”¨äºæ§åˆ¶çœŸå®æ¡†ä¸ anchor åœ¨å®½é«˜æ¯”ä¾‹ä¸Šçš„åŒ¹é…å®½æ¾ç¨‹åº¦ã€‚æ•°å€¼è¶Šå¤§ï¼Œå…è®¸åŒ¹é…çš„ anchor è¶Šå¤šã€‚\nanchors è¡¨ç¤ºæ¯ä¸ªè¾“å‡ºå±‚ä½¿ç”¨çš„ anchor æ•°é‡ï¼Œè¯¥é¡¹è¢«æ³¨é‡Šæ‰è¯´æ˜ä½¿ç”¨æ¨¡å‹é»˜è®¤çš„ anchor è®¾ç½®ã€‚\nfl_gamma è¡¨ç¤º Focal Loss çš„ gamma å‚æ•°ï¼Œå½“è¯¥å€¼ä¸º 0 æ—¶è¡¨ç¤ºä¸å¯ç”¨ Focal Lossã€‚Focal Loss ä¸»è¦ç”¨äºç¼“è§£æ­£è´Ÿæ ·æœ¬æåº¦ä¸å¹³è¡¡çš„é—®é¢˜ã€‚\nhsv_h è¡¨ç¤ºå¯¹å›¾åƒè‰²è°ƒçš„éšæœºæ‰°åŠ¨å¹…åº¦ï¼Œç”¨äºå¢å¼ºæ¨¡å‹å¯¹ä¸åŒè‰²å½©å˜åŒ–çš„é²æ£’æ€§ã€‚\nhsv_s è¡¨ç¤ºå¯¹å›¾åƒé¥±å’Œåº¦çš„éšæœºæ‰°åŠ¨å¹…åº¦ï¼Œä½¿æ¨¡å‹é€‚åº”é¢œè‰²æ·±æµ…å˜åŒ–ã€‚\nhsv_v è¡¨ç¤ºå¯¹å›¾åƒäº®åº¦çš„éšæœºæ‰°åŠ¨å¹…åº¦ï¼Œæé«˜æ¨¡å‹åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\ndegrees è¡¨ç¤ºéšæœºæ—‹è½¬è§’åº¦çš„èŒƒå›´ï¼Œå½“å‰ä¸º 0 è¡¨ç¤ºä¸è¿›è¡Œæ—‹è½¬å¢å¼ºã€‚\ntranslate è¡¨ç¤ºå›¾åƒéšæœºå¹³ç§»çš„æ¯”ä¾‹ï¼Œ0.1 è¡¨ç¤ºåœ¨ä¸Šä¸‹å·¦å³æ–¹å‘æœ€å¤šå¹³ç§»å›¾åƒå°ºå¯¸çš„ 10%ã€‚\nscale è¡¨ç¤ºå›¾åƒçš„éšæœºç¼©æ”¾æ¯”ä¾‹ï¼Œæ•°å€¼è¶Šå¤§ï¼Œç¼©æ”¾èŒƒå›´è¶Šå¹¿ï¼Œæœ‰åŠ©äºå¢å¼ºå°ºåº¦ä¸å˜æ€§ã€‚\nshear è¡¨ç¤ºé”™åˆ‡å˜æ¢çš„è§’åº¦èŒƒå›´ï¼Œå½“å‰ä¸º 0 è¡¨ç¤ºä¸ä½¿ç”¨é”™åˆ‡å˜æ¢ã€‚\nperspective è¡¨ç¤ºé€è§†å˜æ¢çš„å¼ºåº¦ï¼Œé€šå¸¸ç”¨äºæ¨¡æ‹Ÿä¸åŒæ‹æ‘„è§’åº¦çš„æ•ˆæœã€‚\nflipud è¡¨ç¤ºå›¾åƒä¸Šä¸‹ç¿»è½¬çš„æ¦‚ç‡ï¼Œ0 è¡¨ç¤ºä¸è¿›è¡Œä¸Šä¸‹ç¿»è½¬ã€‚\nfliplr è¡¨ç¤ºå›¾åƒå·¦å³ç¿»è½¬çš„æ¦‚ç‡ï¼Œ0.5 è¡¨ç¤ºä¸€åŠæ¦‚ç‡è¿›è¡Œå·¦å³ç¿»è½¬ï¼Œè¿™æ˜¯ç›®æ ‡æ£€æµ‹ä¸­éå¸¸å¸¸ç”¨çš„å¢å¼ºæ–¹å¼ã€‚\nmosaic è¡¨ç¤º Mosaic æ•°æ®å¢å¼ºçš„ä½¿ç”¨æ¦‚ç‡ï¼Œ1.0 è¡¨ç¤ºå§‹ç»ˆä½¿ç”¨ã€‚è¯¥æ–¹æ³•å°†å››å¼ å›¾ç‰‡æ‹¼æ¥æˆä¸€å¼ ï¼Œå¯¹å°ç›®æ ‡æ£€æµ‹å’Œå¤æ‚åœºæ™¯æ•ˆæœæ˜¾è‘—ã€‚\nmixup è¡¨ç¤º MixUp æ•°æ®å¢å¼ºçš„æ¦‚ç‡ï¼Œé€šè¿‡å°†ä¸¤å¼ å›¾ç‰‡å’Œæ ‡ç­¾è¿›è¡Œçº¿æ€§æ··åˆæ¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\ncopy_paste è¡¨ç¤º Copy-Paste æ•°æ®å¢å¼ºçš„æ¦‚ç‡ï¼Œå³ä»ä¸€å¼ å›¾ä¸­è£å‰ªç›®æ ‡å¹¶ç²˜è´´åˆ°å¦ä¸€å¼ å›¾ä¸­ï¼Œç”¨äºå¢åŠ ç›®æ ‡ç»„åˆçš„å¤šæ ·æ€§ã€‚\n# no-aug / Object365/ scratch-high/med/low / VOC\n# hyp.no-augment\nhyp.no-augment éå¸¸ç‰¹æ®Šï¼Œå®ƒè¡¨ç¤ºå‡ ä¹å…³é—­æ‰€æœ‰æ•°æ®å¢å¼ºã€‚mosaicã€mixupã€é¢œè‰²æ‰°åŠ¨åŸºæœ¬éƒ½ä¸å¼€ã€‚å®ƒä¸»è¦æœ‰ä¸‰ç§ç”¨é€”ï¼šç¬¬ä¸€ï¼Œç”¨æ¥åšæ¶ˆèå®éªŒï¼ŒéªŒè¯ â€œæ•°æ®å¢å¼ºåˆ°åº•æœ‰æ²¡æœ‰ç”¨â€ï¼›ç¬¬äºŒï¼Œç”¨åœ¨æ•°æ®æœ¬èº«å·²ç»è¢«ä¸¥æ ¼å¯¹é½ã€å¢å¼ºä¼šç ´åè¯­ä¹‰çš„ä»»åŠ¡ä¸­æ¯”å¦‚å·¥ä¸šç¼ºé™·ã€åŒ»å­¦å½±åƒï¼›ç¬¬ä¸‰ï¼Œç”¨äºè°ƒè¯•æˆ–å¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹æ˜¯å¦æ­£ç¡®ã€‚\n# hyp.scratch-object365\nhyp.scratch-object365 æ˜¯ä¸º Object365 è¿™ç§è¶…å¤§è§„æ¨¡ã€ç±»åˆ«æå¤šçš„æ•°æ®é›†è®¾è®¡çš„ã€‚å®ƒä¼šæ›´åŠ é‡è§†åˆ†ç±»ç¨³å®šæ€§ï¼Œå¯¹ cls lossã€æ­£è´Ÿæ ·æœ¬å¹³è¡¡å’Œ anchor åŒ¹é…éƒ½æœ‰ç‰¹æ®Šè°ƒä¼˜ã€‚è¿™å¥—å‚æ•°ä¸€èˆ¬ä¸å»ºè®®ç›´æ¥æ‹¿æ¥ç”¨åœ¨æ™®é€šè‡ªåˆ¶æ•°æ®é›†ä¸Šã€‚\n# hyp.scratch\nscratch çš„æ„æ€æ˜¯ â€œä»é›¶å¼€å§‹è®­ç»ƒâ€ï¼Œä¹Ÿå°±æ˜¯ä¸åŠ è½½ä»»ä½•é¢„è®­ç»ƒæƒé‡ï¼Œç½‘ç»œå‚æ•°å®Œå…¨éšæœºåˆå§‹åŒ–ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒå¯¹å­¦ä¹ ç‡ã€æ•°æ®å¢å¼ºå’Œ warmup éƒ½éå¸¸æ•æ„Ÿï¼Œæ‰€ä»¥å®˜æ–¹ç»™äº†å¤šå¥—ç»è¿‡éªŒè¯çš„ hyp é…ç½®ã€‚\n# hyp.scratch-high\nhyp.scratch-high æ˜¯ä¸ºå¤§æ•°æ®é›† + å¼ºæ•°æ®å¢å¼ºå‡†å¤‡çš„é…ç½®ã€‚å®ƒé€šå¸¸ç”¨äº COCO è¿™ç§è§„æ¨¡åœ¨åä¸‡çº§ä»¥ä¸Šçš„æ•°æ®é›†ï¼Œæˆ–è€…ä½ æœ‰éå¸¸å¤šæ ·ã€å¤æ‚åœºæ™¯çš„æ•°æ®ã€‚å®ƒçš„å…¸å‹ç‰¹å¾æ˜¯æ•°æ®å¢å¼ºéå¸¸æ¿€è¿›ï¼Œæ¯”å¦‚ mosaicã€mixupã€é¢œè‰²æ‰°åŠ¨éƒ½å¼€å¾—æ¯”è¾ƒå¤§ï¼Œå­¦ä¹ ç‡ä¹Ÿç›¸å¯¹åé«˜ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›æœ€å¼ºï¼Œä½†å‰æœŸè®­ç»ƒä¸ç¨³å®šï¼Œå¯¹å°æ•°æ®é›†éå¸¸ä¸å‹å¥½ã€‚\n# hyp.scratch-med\nhyp.scratch-med æ˜¯ä¸€ä¸ªæŠ˜ä¸­æ–¹æ¡ˆã€‚æ•°æ®å¢å¼ºå’Œå­¦ä¹ ç‡éƒ½æ¯” high æ¸©å’Œä¸€äº›ï¼Œé€‚åˆä¸­ç­‰è§„æ¨¡æ•°æ®é›†ï¼Œæ¯”å¦‚å‡ åƒåˆ°ä¸€ä¸¤ä¸‡å¼ å›¾ç‰‡ã€‚å¾ˆå¤šäººåœ¨è‡ªå®šä¹‰æ•°æ®é›†æ—¶ï¼Œå…¶å®ç”¨çš„å°±æ˜¯è¿™ä¸€å¥—ï¼Œåªæ˜¯æ²¡æ„è¯†åˆ°ã€‚\n# hyp.scratch-low\nhyp.scratch-low æ˜¯ä¸ºå°æ•°æ®é›†å‡†å¤‡çš„ã€‚å®ƒä¼šæ˜æ˜¾å‡å¼±æ•°æ®å¢å¼ºå¼ºåº¦ï¼Œå­¦ä¹ ç‡ä¹Ÿæ›´ä¿å®ˆï¼Œé¿å…æ¨¡å‹åœ¨å¼ºå¢å¼ºä¸‹ â€œå­¦æ­ªâ€ã€‚å¦‚æœä½ çš„æ•°æ®åªæœ‰å‡ ç™¾åˆ°ä¸€ä¸¤åƒå¼ ï¼Œç”¨ high æˆ– med å¾ˆå®¹æ˜“å‡ºç° loss éœ‡è¡ã€mAP ä¸å‡ç”šè‡³ä¸‹é™ï¼Œè¿™æ—¶ low åè€Œæ•ˆæœæ›´å¥½ã€‚\n# hyp.scratch-voc\nhyp.scratch-vocã€‚å®ƒæ˜¯ä¸“é—¨ä¸º PASCAL VOC æ•°æ®é›†è°ƒçš„ï¼Œè€Œä¸æ˜¯ç®€å•çš„ low æˆ– medã€‚VOC çš„ç‰¹ç‚¹æ˜¯ç±»åˆ«å°‘ã€ç›®æ ‡ç›¸å¯¹å¤§ã€åœºæ™¯ç®€å•ï¼Œæ‰€ä»¥è¿™ä¸ªé…ç½®é€šå¸¸ä¼šé™ä½åˆ†ç±»æŸå¤±æƒé‡ã€è°ƒæ•´ anchor åŒ¹é…ç­–ç•¥ï¼Œæ›´åå‘äº â€œç¨³è€Œå‡†â€ã€‚\n# æœ€ä½³å®è·µï¼Ÿ\n90% çš„è‡ªå®šä¹‰æ•°æ®é›†ï¼Œscratch-med æˆ– scratch-low èµ·æ­¥æ˜¯æœ€ç¨³çš„ï¼Œä¸è¦ä¸€ä¸Šæ¥å°± highã€‚\n# æ•°æ®é›†åˆ†ç±»æ–‡ä»¶åŠå…¶ä¸‹è½½è„šæœ¬\n\næ¯ä¸€ä¸ª  .yaml  æ–‡ä»¶éƒ½åƒæ˜¯ä¸€ä»½è¯´æ˜ä¹¦ï¼Œå‘Šè¯‰æ¨¡å‹ï¼š\n\nè®­ç»ƒ / éªŒè¯æ•°æ®åœ¨å“ªé‡Œï¼šå›¾ç‰‡å’Œæ ‡ç­¾å­˜å‚¨åœ¨ç¡¬ç›˜çš„å“ªä¸ªè·¯å¾„ä¸‹ã€‚\næœ‰å¤šå°‘ä¸ªç±»åˆ«ï¼šä¾‹å¦‚æ¨¡å‹éœ€è¦è¯†åˆ« 80 ç§ç‰©ä½“è¿˜æ˜¯ 10 ç§ã€‚\nç±»åˆ«çš„åå­—æ˜¯ä»€ä¹ˆï¼šä¾‹å¦‚  0: person ,  1: bicycle  ç­‰ã€‚\n\n# è·¯å¾„è®¾ç½®path: ../datasets/coco128  # æ•°æ®é›†æ ¹ç›®å½•train: images/train2017    # è®­ç»ƒé›†å›¾ç‰‡è·¯å¾„val: images/train2017      # éªŒè¯é›†å›¾ç‰‡è·¯å¾„# ç±»åˆ«ä¿¡æ¯nc: 80  # ç±»åˆ«æ•°é‡ (number of classes)names:  0: person  1: bicycle  2: car# labelimg æ ‡æ³¨è½¯ä»¶\nå¼€æºåœ°å€ï¼šhttps://github.com/HumanSignal/labelImg\n\nLabelImg is now part of the Label Studio community. The popular image annotation tool created by Tzutalin is no longer actively being developed, but you can check out Label Studio, the open source data labeling tool for images, text, hypertext, audio, video and time-series data.\nLabelImg ç°å·²æˆä¸º Label Studio ç¤¾åŒºçš„ä¸€éƒ¨åˆ†ã€‚Tzutalin å¼€å‘çš„æµè¡Œå›¾åƒæ³¨é‡Šå·¥å…·å·²ä¸å†ç§¯æå¼€å‘ï¼Œä½†ä½ å¯ä»¥çœ‹çœ‹ Label Studioï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„æ•°æ®æ ‡æ³¨å·¥å…·ï¼Œç”¨äºå›¾åƒã€æ–‡æœ¬ã€è¶…æ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘å’Œæ—¶é—´åºåˆ—æ•°æ®ã€‚\n\nLabel Studioï¼šhttps://labelstud.io/ ï¼ˆOpen Source Data Labeling Platformï¼‰\nå¼€æºåœ°å€ï¼šhttps://github.com/HumanSignal/label-studio/\nlabelimg æœ€ç»ˆç‰ˆæœ¬ä¸ºï¼š1.8.1 /released this Dec 3, 2018 https://github.com/tzutalin/labelImg/files/2638199/windows_v1.8.1.zip\n\næ¨èä½¿ç”¨ VOC æ ¼å¼çš„ xml ä¿¡æ¯ã€‚\n# VOC2007\næºï¼šhttp://host.robots.ox.ac.uk/pascal/VOC/voc2007 ä½†æ˜¯æˆ‘è®¿é—®è¿™ä¸ªæ—¶å€™è¢«é˜²ç«å¢™æ‹¦æˆªäº†ã€‚\næºç ä¸­çš„ï¼š\n\nè®­ç»ƒé›†ä¸éªŒè¯é›†ï¼šhttps://github.com/ultralytics/assets/releases/download/v0.0.0/VOCtrainval_06-Nov-2007.zip\næµ‹è¯•é›†ï¼šhttps://github.com/ultralytics/assets/releases/download/v0.0.0/VOCtest_06-Nov-2007.zip\n\n# å°† VOC æ ¼å¼è½¬ä¸º YOLO æ ¼å¼\n# Data_Trans è„šæœ¬\nè¯·è®¿é—®å¼€æºè„šæœ¬ï¼šhttps://github.com/JieZzzoo/Data_Trans\nä½¿ç”¨è¯´æ˜ï¼šhttps://blog.csdn.net/Thebest_jack/article/details/125637099\n\n          \n          è“èƒ–èƒ–\n          æ„Ÿè°¢ä½œè€…å¼€æº\n          \nè¿™ä¸ªè„šæœ¬å¯ä»¥å°† VOC æ ¼å¼è½¬ä¸º YOLO æ ¼å¼ï¼Œä¸è¿‡ä»–æŠŠæ•°æ®é›†ç´¢å¼•å†™åœ¨äº† testã€train å’Œ val çš„æ–‡æœ¬æ–‡ä»¶é‡Œäº†ã€‚\nä¸è¿‡ä»–è¿™ä¸ªæå–è„šæœ¬æœ‰ç‚¹å° bugï¼Œåç»­æˆ‘å°†ä¼šåˆ¶ä½œä¸€ä¸ªå®Œæ•´çš„è„šæœ¬ã€‚\nå¦‚æœè¦äº§ç”Ÿå›¾ç‰‡ï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰å’Œæ ‡ç­¾ï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰é‚£æ ·çš„ç»“æ„ï¼Œéœ€è¦è¿›ä¸€æ­¥æ”¹å†™ï¼Œå› æ­¤æˆ‘è®¾è®¡äº†è¿™æ ·çš„è„šæœ¬ï¼š imgsWlabels\n# imgsWlabels è„šæœ¬\nimgsWlabels æ˜¯æˆ‘è‡ªåˆ›çš„ä¸€ä¸ªæå–ä¸æ•´ç†çš„è„šæœ¬ï¼Œå¦‚ç”¨æ–¹å¼å¦‚ä¸‹ï¼Œé¦–å…ˆä½ éœ€è¦æŠŠ Data_Trans  ä¸­çš„çš„ Imagesetsã€labels ä»¥åŠ JPEGImages å¤åˆ¶ä¸‹æ¥æ”¾åˆ° imgsWlabels  çš„ pre ç›®å½•ä¸‹ï¼Œå½¢å¦‚ï¼š\n\nimgsWlabels  æœ‰ä¸¤ç§æ¨¡å¼ï¼Œåˆ†åˆ«æ˜¯ â€œtrain ä¸ valâ€ æ¨¡å¼å’Œâ€trainvalâ€œæ¨¡å¼ã€‚\n# train ä¸ val æ¨¡å¼\nåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œæ•°æ®é›†è¢«åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ï¼Œè¿™ç§æ¨¡å¼çš„ç‰¹ç‚¹æ˜¯ï¼šè®­ç»ƒé›†å’ŒéªŒè¯é›†æ˜¯åˆ†å¼€çš„ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼Œç¡®ä¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n# trainval æ¨¡å¼\nåœ¨ trainval æ¨¡å¼ä¸‹ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†è¢«åˆå¹¶ä¸ºä¸€ä¸ªæ•´ä½“çš„æ•°æ®é›†ï¼Œæ¨¡å‹åœ¨æ•´ä¸ª  trainval  æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚è¿™ç§æ¨¡å¼é€šå¸¸ç”¨äºç‰¹å®šçš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ•°æ®é‡ä¸å¤§æ—¶ï¼Œå¯ä»¥é€šè¿‡åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†æ¥æå‡è®­ç»ƒé›†çš„å¤šæ ·æ€§å’Œå¤§å°ã€‚\n# ä»£ç \n# åˆ’åˆ†æ•°æ®é›†æ¨¡å¼ï¼Œ0 ä¸º train ä¸ val æ¨¡å¼ï¼Œ1 ä¸º trainval æ¨¡å¼split_mode = 0# ----import osimport timeimport shutilfrom tqdm import tqdmroot_dir = 'pre'root_img_dir = os.path.join(root_dir, 'JPEGImages')root_label_dir = os.path.join(root_dir, 'labels')indexes = os.path.join(root_dir, 'Imagesets')train_index = os.path.join(indexes, 'train.txt')val_index = os.path.join(indexes, 'val.txt')trainval_index = os.path.join(indexes, 'trainval.txt')test_index = os.path.join(indexes, 'test.txt')def read_file_return_list(file_path):    try:        with open(file_path, 'r') as f:            lines = f.readlines()            return [line.strip() for line in lines]    except FileNotFoundError:        print('index file not found')        exit()    except Exception as e:        print(e)        exit()train_indexes_list = read_file_return_list(train_index)val_indexes_list = read_file_return_list(val_index)trainval_indexes_list = read_file_return_list(trainval_index)test_indexes_list = read_file_return_list(test_index)def copy_file(src_file, dst_dir):    try:        os.makedirs(dst_dir, exist_ok=True)        shutil.copy(src_file, dst_dir)        return True    except Exception as e:        print(e)        return Falsedef cp_file_in_list(src_dir, dst_dir, index_list, target_ext='.jpg', msg='copy file...'):    if not os.path.exists(src_dir):        print('Source directory does not exist!')        return    if not os.path.exists(dst_dir):        os.makedirs(dst_dir)    with tqdm(index_list, desc=msg, unit='file', total=len(index_list), dynamic_ncols=True,              ncols=100, mininterval=0.1,              bar_format=\"&#123;l_bar&#125;&#123;bar&#125;| &#123;n_fmt&#125;/&#123;total_fmt&#125; [&#123;elapsed&#125; &lt; &#123;remaining&#125;, &#123;rate_fmt&#125;]\") as pbar:        for index in pbar:            src_file = os.path.join(src_dir, index + target_ext)            if copy_file(src_file, dst_dir):                pbar.set_postfix(file=index, color='green')            else:                pbar.set_postfix(file=index, color='red')            pbar.update(1)def boot_split():    if split_mode == 0:        # train ä¸ val æ¨¡å¼        cp_file_in_list(root_img_dir, 'images/train', train_indexes_list, msg='copy train file...')        cp_file_in_list(root_img_dir, 'images/val', val_indexes_list, msg='copy val file...')        cp_file_in_list(root_img_dir, 'images/test', test_indexes_list, msg='copy test file...')        cp_file_in_list(root_label_dir, 'labels/train', train_indexes_list, target_ext='.txt', msg='copy train label...')        cp_file_in_list(root_label_dir, 'labels/val', val_indexes_list, target_ext='.txt', msg='copy val label...')        cp_file_in_list(root_label_dir, 'labels/test', test_indexes_list, target_ext='.txt', msg='copy test label...')    elif split_mode == 1:        # trainval æ¨¡å¼        cp_file_in_list(root_img_dir, 'images/trainval', trainval_indexes_list, msg='copy trainval file...')        cp_file_in_list(root_img_dir, 'images/test', test_indexes_list, msg='copy test file...')        cp_file_in_list(root_label_dir, 'labels/trainval', trainval_indexes_list, target_ext='.txt', msg='copy trainval label...')        cp_file_in_list(root_label_dir, 'labels/test', test_indexes_list, target_ext='.txt', msg='copy test label...')# ----if __name__ == '__main__':    start_time = time.time()    boot_split()    print('Time used: %.2f' % (time.time() - start_time))å¯ä»¥æ ¹æ®éœ€è¦çš„æ¨¡å¼è¿›è¡Œä¿®æ”¹è¿è¡Œæ¨¡å¼ã€‚\næ‰§è¡Œåï¼š\n\nä¼šç”Ÿæˆï¼š\n\n# å¦‚ä½•è®­ç»ƒæ¨¡å‹\nä¸€èˆ¬è®­ç»ƒéœ€è¦ä¿®æ”¹è¿™å‡ ä¸ªå‚æ•°å°±è¶³å¤Ÿäº†\n\nè®¾ç½®å¥½æ•°æ®é›†è·¯å¾„ï¼š\n\nä¿®æ”¹ç±»åˆ«æ•°ï¼š\n\næœ€å¥½æ ¹æ®è‡ªå·±çš„æ•°æ®é›†è®¾ç½®æ£€æµ‹æ¡†é‚£æ ·æœ€å¥½ã€‚\nå¼€å§‹è®­ç»ƒï¼š\n\n\n# å‚æ•°è¯¦è§£\n# rect çŸ©å½¢è®­ç»ƒ\nåœ¨è®­ç»ƒæ—¶ï¼ŒæŒ‰ç…§å›¾ç‰‡çš„åŸå§‹å®½é«˜æ¯”è¿›è¡Œåˆ†ç»„ï¼Œå¹¶å°½é‡å‡å°‘ paddingï¼Œè€Œä¸æ˜¯æŠŠæ‰€æœ‰å›¾ç‰‡å¼ºè¡Œ resize æˆæ­£æ–¹å½¢ã€‚\n# resume æ–­ç‚¹ç»­è®­\nå½“è®­ç»ƒè¢«ä¸­æ–­æ¯”å¦‚å…³æœºã€Ctrl+Cã€æ˜¾å­˜ä¸è¶³æˆ–å´©æºƒåï¼Œ ä»ä¸Šä¸€æ¬¡ä¿å­˜çš„ checkpoint ç»§ç»­è®­ç»ƒï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹ã€‚\n# å¦‚ä½•ä¸Šé‡‡æ ·ï¼Ÿ\n[-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n\n\nå‚æ•°\nè§£é‡Š\n\n\n\n\nNone\nä¸æŒ‡å®šç›®æ ‡å°ºå¯¸\n\n\n2\nscale_factor=2 ï¼Œå®½å’Œé«˜æ”¾å¤§ 2 å€\n\n\n&quot;nearest&quot;\nä½¿ç”¨ æœ€è¿‘é‚»æ’å€¼\n\n\n\n# ä¸ºä»€ä¹ˆ yaml å®šä¹‰ç»“æ„ä¸­çš„è¾“å‡ºé€šé“å¹¶ä¸æ˜¯ 255ï¼Ÿï¼ˆå¯¹äº Cocoï¼‰\nhead: [    [-1, 1, Bottleneck, [1024, False]],    [-1, 1, Conv, [512, 1, 1]],    [-1, 1, Conv, [1024, 3, 1]],    [-1, 1, Conv, [512, 1, 1]],    [-1, 1, Conv, [1024, 3, 1]], # 15 (P5/32-large)    [-2, 1, Conv, [256, 1, 1]],    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],    [[-1, 8], 1, Concat, [1]], # cat backbone P4    [-1, 1, Bottleneck, [512, False]],    [-1, 1, Bottleneck, [512, False]],    [-1, 1, Conv, [256, 1, 1]],    [-1, 1, Conv, [512, 3, 1]], # 22 (P4/16-medium)    [-2, 1, Conv, [128, 1, 1]],    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],    [[-1, 6], 1, Concat, [1]], # cat backbone P3    [-1, 1, Bottleneck, [256, False]],    [-1, 2, Bottleneck, [256, False]], # 27 (P3/8-small)    [[27, 22, 15], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)  ]å› ä¸º YAML é‡Œå®šä¹‰çš„æ˜¯ç‰¹å¾æå–ä¸èåˆè¿‡ç¨‹ä¸­çš„ä¸­é—´ç‰¹å¾é€šé“æ•°ï¼ŒçœŸæ­£çš„ 255 é€šé“æ˜¯åœ¨  Detect  æ¨¡å—å†…éƒ¨ï¼Œé€šè¿‡ 1Ã—1 å·ç§¯åŠ¨æ€ç”Ÿæˆçš„ï¼Œè€Œä¸æ˜¯åœ¨ YAML ä¸­æ˜¾å¼å†™å‡ºæ¥çš„ã€‚\n\n# æºç ç§è¿™æ ·å†™åˆ°â€¦\nself.nc = nc  # number of classesself.no = nc + 5  # number of outputs per anchorself.nl = len(anchors)  # number of detection layersself.na = len(anchors[0]) // 2  # number of anchorsself.grid = [torch.empty(0) for _ in range(self.nl)]  # init gridself.anchor_grid = [torch.empty(0) for _ in range(self.nl)]  # init anchor gridself.register_buffer(\"anchors\", torch.tensor(anchors).float().view(self.nl, -1, 2))  # shape(nl,na,2)self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv255 = 3 Ã— (80 + 5)\n255 ä¸  nc  å¼ºç›¸å…³ï¼Œ nc  æ”¹äº†ï¼Œè¾“å‡ºé€šé“ç«‹åˆ»å˜ï¼ŒYAML ä¸å¯èƒ½å†™æ­» 255ã€‚\n","categories":["æ·±åº¦å­¦ä¹ ","YOLO","é¡¹ç›®ä¸å®æˆ˜"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","YOLO"]},{"title":"YOLO-V3","url":"/python/YOLO/YOLO_V3/","content":"# YOLOv3\n# åŸæ–‡\nYOLOv3: An Incremental Improvement(YOLOv3): [https://arxiv.org/abs/1804.02767]\n# ç½‘ç»œç»“æ„\n\nåœ¨æ£€æµ‹å¤´ï¼Œä»–è¿™ä¸ªæ•°å€¼æ ‡é”™äº†ã€‚\n\n\nä»–è¿™ä¸ªç”¨æ­¥å¹…ä¸º 2 çš„å·ç§¯å¸¦ä»£æ›¿æ± åŒ–æ“ä½œäº†ï¼Œå¯ä»¥çœ‹åˆ°ä»–åˆæŠŠå…¨è¿æ¥æ‹¿å›æ¥äº†ã€‚\n\n# å›¾åƒé‡‘å­—å¡” FPN\n\nç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ FPNï¼Œè¿™æ˜¯å®ƒç›¸æ¯” YOLOv2 æœ€é‡å¤§çš„æ”¹è¿›ä¹‹ä¸€ã€‚è¿™ä¸€è®¾è®¡æå¤§åœ°æå‡äº†æ¨¡å‹å¯¹å¤šå°ºåº¦ç›®æ ‡å°¤å…¶æ˜¯å°ç›®æ ‡çš„æ£€æµ‹èƒ½åŠ›ã€‚\nYOLOv3 åœ¨ä¸»å¹²ç½‘ç»œ Darknet-53 çš„åŸºç¡€ä¸Šï¼Œæå–äº†ä¸‰ä¸ªä¸åŒè·¨åº¦çš„ç‰¹å¾å›¾è¿›è¡Œé¢„æµ‹ï¼š\n\n13Ã—1313 \\times 1313Ã—13 è¾“å‡ºå±‚ï¼š å¯¹åº”æ·±å±‚ç‰¹å¾ï¼Œæ„Ÿå—é‡æœ€å¤§ï¼Œè´Ÿè´£æ£€æµ‹å¤§å°ºå¯¸ç‰©ä½“ã€‚\n26Ã—2626 \\times 2626Ã—26 è¾“å‡ºå±‚ï¼š å¯¹åº”ä¸­å±‚ç‰¹å¾ï¼Œè´Ÿè´£æ£€æµ‹ä¸­ç­‰å°ºå¯¸ç‰©ä½“ã€‚\n52Ã—5252 \\times 5252Ã—52 è¾“å‡ºå±‚ï¼š å¯¹åº”æµ…å±‚ç‰¹å¾ï¼Œæ„Ÿå—é‡è¾ƒå°ï¼Œè´Ÿè´£æ£€æµ‹å°å°ºå¯¸ç‰©ä½“ã€‚\n\nä¸ºäº†è®©æµ…å±‚ä¹Ÿæ‹¥æœ‰æ·±å±‚çš„è¯­ä¹‰ä¿¡æ¯ï¼ŒYOLOv3 æ‰§è¡Œäº†ä»¥ä¸‹æ“ä½œï¼š\n\nä¸Šé‡‡æ ·ï¼š å°† 13Ã—1313 \\times 1313Ã—13 çš„ç‰¹å¾å›¾é€šè¿‡ä¸Šé‡‡æ ·æ”¾å¤§ 2 å€ï¼Œå˜ä¸º 26Ã—2626 \\times 2626Ã—26ã€‚\næ‹¼æ¥ï¼š å°†ä¸Šé‡‡æ ·åçš„ç‰¹å¾å›¾ä¸ Darknet-53 ä¸­å¯¹åº”çš„ 26Ã—2626 \\times 2626Ã—26 åŸå§‹ç‰¹å¾å›¾è¿›è¡Œé€šé“æ‹¼æ¥ï¼ŒåŸå§‹ FPN æ˜¯é€å…ƒç´ ç›¸åŠ ï¼Œè€Œ YOLOv3 æ˜¯æ²¿é€šé“ç»´åº¦çš„ Concatï¼Œè¿™ç‚¹éå¸¸é‡è¦ã€‚\nå¾ªç¯æ“ä½œï¼š åŒæ ·çš„é€»è¾‘ä¹Ÿåº”ç”¨åœ¨ 26Ã—2626 \\times 2626Ã—26 åˆ° 52Ã—5252 \\times 5252Ã—52 çš„è¿‡ç¨‹ä¸­ã€‚\n\nåœ¨æ·±åº¦å­¦ä¹ çš„ç‰¹å¾èåˆä¸­ï¼Œä¸»è¦æœ‰ä¸¤ç§æ–¹å¼ï¼šAdd é€å…ƒç´ ç›¸åŠ  å’Œ Concat é€šé“æ‹¼æ¥ã€‚YOLOv3 çš„ FPN ç»“æ„æ˜ç¡®ä½¿ç”¨äº† Concatã€‚\nä¸Šé‡‡æ ·åï¼Œå¯¹äºåŸå§‹æ ¼å­æ¥è¯´ç›¸å½“äºå˜å¤šäº†ï¼Œè¿™æ„å‘³è¿™æ„Ÿå—é‡ä¸‹é™ï¼Œä½†æ›´èšç„¦äºå°ç›®æ ‡ã€‚\n# ä¸ºä»€ä¹ˆè¦ç”¨ Concat è€Œä¸æ˜¯ Addï¼Ÿ\nConcat ä¸ä¼šæ”¹å˜åŸå§‹ç‰¹å¾å›¾çš„æ•°å€¼ï¼Œå®ƒåªæ˜¯æŠŠæ·±å±‚çš„ â€œè¯­ä¹‰ä¿¡æ¯â€ å’Œæµ…å±‚çš„ â€œä½ç½®ä¿¡æ¯â€ æ”¾åœ¨ä¸€èµ·ï¼Œäº¤ç»™åé¢çš„å·ç§¯å±‚å»è‡ªåŠ¨å­¦ä¹ å¦‚ä½•åŠ æƒåˆ©ç”¨ã€‚é€šè¿‡å¢åŠ é€šé“æ•°ï¼Œç½‘ç»œå¯ä»¥åŒæ—¶çœ‹åˆ°æ¥è‡ªä¸åŒå°ºåº¦çš„ç‰¹å¾è¡¨è¾¾ã€‚\n# å¥½åƒ U-Netï¼Ÿ\nYOLOv3 çš„ FPN æ„å»ºäº†ä¸€ä¸ªç±»ä¼¼çš„æµç¨‹ï¼š\n\nå·¦ä¾§ä¸‹é‡‡æ · / ç¼–ç å™¨ï¼šåœ¨ YOLOv3 ä¸­æ˜¯ Darknet-53 ä¸»å¹²ç½‘ç»œï¼Œè´Ÿè´£æå–ç‰¹å¾ã€‚\nå³ä¾§ä¸Šé‡‡æ · / è§£ç å™¨ï¼šYOLOv3 é€šè¿‡ä¸Šé‡‡æ ·ä¸æ–­æ¢å¤åˆ†è¾¨ç‡ã€‚\nä¸­é—´ä½¿ç”¨è·³è·ƒè¿æ¥ï¼šä¸¤è€…éƒ½å°†å·¦ä¾§çš„ç‰¹å¾å›¾ç›´æ¥ä¼ é€’åˆ°å³ä¾§ï¼Œä¸ä¸Šé‡‡æ ·åçš„ç‰¹å¾è¿›è¡Œ Concatã€‚\n\n# Concat\nåœ¨ YOLO é‡Œï¼Œè¿™ä¸ª Concat æœ¬è´¨ä¸Šå°±æ˜¯å †å é€šé“\nä¸Šé‡‡æ ·åçš„é«˜å±‚ç‰¹å¾: (B, 256, 26, 26)æµ…å±‚ç‰¹å¾:           (B, 256, 26, 26)----------------------------------Concat(dim=1)â†“è¾“å‡ºç‰¹å¾:           (B, 512, 26, 26)# æ£€æµ‹å¤´\n \nå¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒYOLOv3 ä¸€å…±æœ‰ 9 ä¸ª Anchorï¼Œä½†åœ¨æ¯ä¸€ä¸ªé¢„æµ‹å±‚ä¸Šï¼Œå®ƒåªä½¿ç”¨å…¶ä¸­çš„ 3 ä¸ªã€‚\n\n\n\né¢„æµ‹å±‚å°ºåº¦\nè´Ÿè´£ç›®æ ‡\nåˆ†é…çš„ Anchor æ•°é‡\nè¯´æ˜\n\n\n\n\n13Ã—1313 \\times 1313Ã—13\nå¤§ç‰©ä½“\n3 ä¸ª\næ„Ÿå—é‡å¤§ï¼Œé€‚åˆæŠ“å¤§ä¸ªå­ã€‚\n\n\n26Ã—2626 \\times 2626Ã—26\nä¸­ç‰©ä½“\n3 ä¸ª\nå…¼é¡¾è¯­ä¹‰å’Œç»†èŠ‚ã€‚\n\n\n52Ã—5252 \\times 5252Ã—52\nå°ç‰©ä½“\n3 ä¸ª\nåˆ†è¾¨ç‡é«˜ï¼Œä¸“é—¨æŠ“ç»†å°ç›®æ ‡ã€‚\n\n\n\nå¦‚æœåªè¯´èšç±»å‡ºæ¥çš„ï¼Œä¸ºä»€ä¹ˆä¸èšç±»æˆ 6 ä¸ªæˆ– 12 ä¸ªï¼Ÿæˆ‘æƒ³è¿™æ˜¯ç»éªŒç§‘å­¦ä¸è®¡ç®—æ•ˆç‡å¦¥åçš„ç»“æœã€‚\nYOLOv3 çš„ç‰¹å¾é‡‘å­—å¡”æœ‰ 3 ä¸ªè¾“å‡ºå±‚ã€‚ä¸ºäº†ä¿è¯æ¨¡å‹çš„å¯¹ç§°æ€§å’Œä»£ç å®ç°çš„ç®€æ´æ€§ï¼Œä½œè€…ç»™æ¯ä¸ªå±‚åˆ†é…äº†ç›¸åŒæ•°é‡çš„ Anchorã€‚å¦‚æœæ¯å±‚åªç»™ 1 ä¸ª Anchorï¼Œè¦†ç›–çš„å½¢çŠ¶å¤ªå°‘ï¼Œå¦‚æœæ¯å±‚ç»™ 5 ä¸ªï¼Œæ€»å…± 15 ä¸ªï¼Œæ¨¡å‹æœ€åä¸€å±‚çš„é€šé“æ•°ä¼šå˜å¾—éå¸¸è‡ƒè‚¿ï¼Œæ¨ç†é€Ÿåº¦å¤§å¹…ä¸‹é™ã€‚ä¹Ÿå¯èƒ½æ˜¯è¶…è¿‡ 9 ä¸ªä»¥åï¼Œå‡†ç¡®ç‡çš„æå‡å·²ç»å¾®ä¹å…¶å¾®ï¼Œä½†è®¡ç®—é‡å´åœ¨æŒç»­çº¿æ€§å¢åŠ ï¼Œè¿™æ˜¯è¦†ç›–ç‡çš„è¾¹é™…æ•ˆç›Šã€‚\n# é‡æ x,y,w,h,c\n\n\n\nå­—æ¯\nå…¨ç§°\nå«ä¹‰\n\n\n\n\nx,yx, yx,y\nCoordinates\né¢„æµ‹æ¡†çš„ä¸­å¿ƒç‚¹åæ ‡ç›¸å¯¹äºå½“å‰æ ¼å­çš„åç§»é‡ã€‚\n\n\nw,hw, hw,h\nWidth / Height\né¢„æµ‹æ¡†çš„å®½åº¦å’Œé«˜åº¦ç›¸å¯¹äº Anchor å°ºå¯¸çš„ç¼©æ”¾æ¯”ä¾‹ã€‚\n\n\nccc\nConfidence\nç½®ä¿¡åº¦ï¼Œä»£è¡¨è¿™ä¸ªæ¡†é‡Œ â€œæœ‰ç‰©ä½“â€ çš„æ¦‚ç‡ä»¥åŠæ¡†å¾— â€œå‡†ä¸å‡†â€ã€‚\n\n\n\n# æŸå¤±å‡½æ•°\nLoss=Losscoordinate+Lossconfidence+LossclassificationLoss = Loss_{coordinate} + Loss_{confidence} + Loss_{classification}\nLoss=Losscoordinateâ€‹+Lossconfidenceâ€‹+Lossclassificationâ€‹\nCoordinate Loss åæ ‡æŸå¤± ï¼šè¿™éƒ¨åˆ†è´Ÿè´£è®©æ¡†ç”»å¾—æ›´å‡†ã€‚å®ƒåªé’ˆå¯¹æ­£æ ·æœ¬è®¡ç®—ã€‚ç»Ÿä¸€ä½¿ç”¨ BCE Lossã€‚\nConfidence Loss ç½®ä¿¡åº¦æŸå¤±ï¼šè¿™éƒ¨åˆ†è´Ÿè´£åˆ¤æ–­ â€œæœ‰æ²¡æœ‰ç‰©ä½“â€ã€‚å®ƒæ˜¯è®­ç»ƒä¸­æœ€å…³é”®çš„éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒè¦å¤„ç†ä¸¥é‡çš„æ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡ã€‚ç»Ÿä¸€ä½¿ç”¨ BCE Lossã€‚\nClassification Lossï¼šè¿™éƒ¨åˆ†è´Ÿè´£åˆ¤æ–­ â€œæ˜¯ä»€ä¹ˆç‰©ä½“â€ã€‚ç»Ÿä¸€ä½¿ç”¨ BCE Lossã€‚\nL=Î»coordâˆ‘i=0G2âˆ‘j=0B1ijobj[BCE(x,x^)+BCE(y,y^)+MSE(w,w^)+MSE(h,h^)]+âˆ‘i=0G2âˆ‘j=0B1ijobj[BCE(c,1)]+Î»noobjâˆ‘i=0G2âˆ‘j=0B1ijnoobj[BCE(c,0)]+âˆ‘i=0G2âˆ‘j=0B1ijobjâˆ‘kâˆˆclassesBCE(pk,p^k)\\begin{aligned}\nL = \\lambda_{coord} \\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{obj} \\left[ BCE(x, \\hat{x}) + BCE(y, \\hat{y}) + MSE(w, \\hat{w}) + MSE(h, \\hat{h}) \\right] \\\\\n+ \\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{obj} \\left[ BCE(c, 1) \\right] + \\lambda_{noobj} \\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{noobj} \\left[ BCE(c, 0) \\right] \\\\\n+ \\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{obj} \\sum_{k \\in classes} BCE(p_k, \\hat{p}_k)\n\\end{aligned}\nL=Î»coordâ€‹i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijobjâ€‹[BCE(x,x^)+BCE(y,y^â€‹)+MSE(w,w^)+MSE(h,h^)]+i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijobjâ€‹[BCE(c,1)]+Î»noobjâ€‹i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijnoobjâ€‹[BCE(c,0)]+i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijobjâ€‹kâˆˆclassesâˆ‘â€‹BCE(pkâ€‹,p^â€‹kâ€‹)â€‹\nç½®ä¿¡åº¦æŸå¤±åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šæœ‰ç‰©ä½“çš„ç½‘æ ¼ï¼ˆæ­£æ ·æœ¬ï¼‰ å’Œ æ²¡æœ‰ç‰©ä½“çš„ç½‘æ ¼ï¼ˆè´Ÿæ ·æœ¬ï¼‰ã€‚\näºŒå€¼äº¤å‰ç†µ BCE å…¬å¼ï¼š\nBCE(y,y^)=âˆ’[ylogâ¡(y^)+(1âˆ’y)logâ¡(1âˆ’y^)]BCE(y, \\hat{y}) = - [y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})]\nBCE(y,y^â€‹)=âˆ’[ylog(y^â€‹)+(1âˆ’y)log(1âˆ’y^â€‹)]\næœ€ç»ˆçš„å±•å¼€ï¼š\nLossconf=âˆ‘i=0G2âˆ‘j=0B1ijobj[BCE(c,1)]+Î»noobjâˆ‘i=0G2âˆ‘j=0B1ijnoobj[BCE(c,0)]=âˆ’âˆ‘i=0G2âˆ‘j=0B1ijobj[c^ijlogâ¡(cij)+(1âˆ’c^ij)logâ¡(1âˆ’cij)]âˆ’Î»noobjâˆ‘i=0G2âˆ‘j=0B1ijnoobj[c^ijlogâ¡(cij)+(1âˆ’c^ij)logâ¡(1âˆ’cij)]\\begin{aligned} Loss_{conf} =\\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{obj} \\left[ BCE(c, 1) \\right] + \\lambda_{noobj} \\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{noobj} \\left[ BCE(c, 0) \\right]\\\\\n=-\\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{obj} \\left[ \\hat{c}_{ij} \\log(c_{ij}) + (1 - \\hat{c}_{ij}) \\log(1 - c_{ij}) \\right] \\\\ - \\lambda_{noobj} \\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{noobj} \\left[ \\hat{c}_{ij} \\log(c_{ij}) + (1 - \\hat{c}_{ij}) \\log(1 - c_{ij}) \\right] \\end{aligned}\nLossconfâ€‹=i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijobjâ€‹[BCE(c,1)]+Î»noobjâ€‹i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijnoobjâ€‹[BCE(c,0)]=âˆ’i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijobjâ€‹[c^ijâ€‹log(cijâ€‹)+(1âˆ’c^ijâ€‹)log(1âˆ’cijâ€‹)]âˆ’Î»noobjâ€‹i=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijnoobjâ€‹[c^ijâ€‹log(cijâ€‹)+(1âˆ’c^ijâ€‹)log(1âˆ’cijâ€‹)]â€‹\n1ijobj\\mathbb{1}_{ij}^{obj}1ijobjâ€‹ï¼šè¿™æ˜¯ä¸€ä¸ª â€œå¼€å…³â€ã€‚åªæœ‰å½“ç¬¬ iii ä¸ªç½‘æ ¼çš„ç¬¬ jjj ä¸ª Anchor è¢«åˆ†é…ä¸ºæ­£æ ·æœ¬æ—¶ï¼Œç¬¬ä¸€è¡Œå…¬å¼æ‰ç”Ÿæ•ˆã€‚\n1ijnoobj\\mathbb{1}_{ij}^{noobj}1ijnoobjâ€‹ï¼šåªæœ‰å½“ Anchor æ˜¯è´Ÿæ ·æœ¬æ—¶ï¼Œç¬¬äºŒè¡Œå…¬å¼æ‰ç”Ÿæ•ˆã€‚\ncijc_{ij}cijâ€‹ï¼šæ¨¡å‹é¢„æµ‹å‡ºçš„ç½®ä¿¡åº¦å€¼ï¼Œç»è¿‡ Sigmoid æ¿€æ´»ï¼Œåœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚\nc^ij\\hat{c}_{ij}c^ijâ€‹â€‹ï¼šçœŸå®å€¼ï¼ˆLabelï¼‰å¯¹äºæ­£æ ·æœ¬ï¼Œc^ij=1\\hat{c}_{ij} = 1c^ijâ€‹=1ï¼Œå¯¹äºè´Ÿæ ·æœ¬ï¼Œc^ij=0\\hat{c}_{ij} = 0c^ijâ€‹=0ã€‚\nÎ»noobj\\lambda_{noobj}Î»noobjâ€‹ï¼šæƒé‡æƒ©ç½šç³»æ•°ï¼ˆé€šå¸¸è®¾ä¸º 0.5ï¼‰ã€‚\n# æˆ‘è¦å†è§£é‡Šä¸€éï¼Œè¿™æ˜¯æ±‚ä»€ä¹ˆï¼Ÿ\nâˆ‘i=0G2âˆ‘j=0B\\sum_{i=0}^{G^2} \\sum_{j=0}^{B}\ni=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹\nç¬¬ä¸€ä¸ª $ \\sum_i=0}ã€{G^2ã€‘$ï¼šéå†æ‰€æœ‰ç½‘æ ¼ï¼Œç¬¬äºŒä¸ª âˆ‘j=0B\\sum_{j=0}^{B}âˆ‘j=0Bâ€‹ï¼šéå†æ¯ä¸ªç½‘æ ¼é‡Œçš„ Anchor\nG2G^2G2ï¼šæŒ‡çš„æ˜¯ç‰¹å¾å›¾ä¸Šçš„ç½‘æ ¼æ€»æ•°ï¼Œæ¯”å¦‚åœ¨ 13Ã—1313 \\times 1313Ã—13 çš„å°ºåº¦ä¸‹ï¼Œè¿™ä¸ªæ±‚å’Œç¬¦å·å°±ä¼šä»ç¬¬ 1 ä¸ªæ–¹æ ¼ä¸€ç›´æ•°åˆ°ç¬¬ 169 ä¸ªæ–¹æ ¼ã€‚\nåœ¨ YOLOv3 ä¸­ï¼ŒB=3B = 3B=3ï¼Œæ¯ä¸ªç½‘æ ¼é‡Œæœ‰ 3 ä¸ªä¸åŒå½¢çŠ¶çš„ Anchorã€‚è¿™ä¸ªæ±‚å’Œç¬¦å·å°±æ˜¯è¦åœ¨æ¯ä¸€ä¸ªæ ¼å­é‡Œï¼ŒæŠŠè¿™ 3 ä¸ª Anchor æŒ¨ä¸ªæ‹å‡ºæ¥ç®—ä¸€é Lossã€‚\nè¿™ä¸ªæ€»æŸå¤±å‘Šè¯‰æ¨¡å‹ï¼šâ€œåœ¨è¿™ä¸€å¼ å›¾ä¸­ï¼Œä½ ä¸€å…±çŠ¯äº†å¤šå°‘é”™ï¼Ÿâ€\næŸä¸ªæ ¼å­çš„ Anchor 1 æ²¡å¯¹å‡†ï¼Œäº§ç”Ÿå®šä½æŸå¤±ã€‚\næŸä¸ªæ ¼å­çš„ Anchor 2 æŠŠèƒŒæ™¯çœ‹æˆäº†è½¦ï¼Œäº§ç”Ÿç½®ä¿¡åº¦æŸå¤±ã€‚\næ‰€æœ‰çš„é”™è¯¯åŠ åœ¨ä¸€èµ·ï¼Œæ¨¡å‹å†æ ¹æ®è¿™ä¸ªæ€»åˆ†è¿›è¡Œåå‘ä¼ æ’­ï¼Œå»è°ƒæ•´å…¨å›¾çš„æƒé‡ã€‚\n# ä¸ºä»€ä¹ˆ YOLOv3 ç”¨ BCE è€Œä¸æ˜¯å¤šåˆ†ç±»äº¤å‰ç†µï¼Ÿ\nè¿™æ˜¯ YOLOv3 çš„ä¸€ä¸ªé‡è¦è¿›æ­¥ï¼š\n\nå¤šæ ‡ç­¾åˆ†ç±»ï¼šYOLOv3 è®¤ä¸ºä¸€ä¸ªç‰©ä½“å¯ä»¥åŒæ—¶å±äºå¤šä¸ªç±»ï¼Œæ¯”å¦‚å®ƒæ˜¯ â€œå¡è½¦â€ ä¹Ÿæ˜¯ â€œæ±½è½¦â€ã€‚\nSoftmax çš„ç¼ºé™·ï¼šSoftmax ä¼šå¼ºè¿«æ¨¡å‹åªèƒ½é€‰å‡ºä¸€ä¸ªæœ€é«˜åˆ†ï¼Œè¿™åœ¨å¤„ç†é‡å æ ‡ç­¾æ—¶æ•ˆæœä¸å¥½ã€‚\nBCE çš„ä¼˜åŠ¿ï¼šYOLOv3 å¯¹æ¯ä¸ªç±»åˆ«éƒ½ç‹¬ç«‹è¿è¡Œä¸€ä¸ª Sigmoid + BCEã€‚è¿™æ„å‘³ç€æ¯ä¸ªç±»åˆ«éƒ½åœ¨åšä¸€ä¸ª â€œæ˜¯æˆ–ä¸æ˜¯è¯¥ç±»â€ çš„äºŒå…ƒåˆ¤æ–­ï¼Œä»è€Œæ”¯æŒäº†å¤šæ ‡ç­¾åˆ†ç±»ã€‚æ³¨æ„å®ƒæ˜¯å¯¹æ¯ä¸€ä¸ªæ ‡ç­¾ç‹¬ç«‹åšçš„ï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ã€‚\n\n\nåœ¨å®é™…å†™ YOLOv3 ä»£ç æ—¶ï¼Œé€šå¸¸ä¸ä¼šç›´æ¥æ‰‹å†™è¿™ä¸ª logâ¡\\loglog å…¬å¼ï¼Œè€Œæ˜¯è°ƒç”¨ï¼š torch.nn.BCEWithLogitsLoss()\n# è¿™ä¸ªå‡½æ•°åé‡Œä¸ºä»€ä¹ˆå¤šäº†ä¸€ä¸ª â€œWithLogitsâ€ï¼Ÿ\n\nLogits æ˜¯æŒ‡å·ç§¯å±‚è¾“å‡ºçš„åŸå§‹æ•°å€¼ã€‚\nè¿™ä¸ªå‡½æ•°ä¼šè‡ªåŠ¨åœ¨å†…éƒ¨å¸®ä½ åšä¸€é Sigmoidï¼Œç„¶åå†ç®— BCEã€‚\nå¥½å¤„ï¼šç”±äº logâ¡\\loglog å‡½æ•°åœ¨è‡ªå˜é‡æ¥è¿‘ 0 æ—¶æå…¶ä¸ç¨³å®šï¼Œå®˜æ–¹è¿™ç§åˆå¹¶å†™æ³•åœ¨æ•°å­¦ä¸Šåšäº†ä¼˜åŒ–ï¼Œæ¯”ä½ è‡ªå·±å…ˆå†™  Sigmoid  å†å†™  BCE  è¦æ›´æ•°å€¼ç¨³å®šã€‚\n\n# å¼ºå¤§çš„ç±»åˆ«æŸå¤±ï¼Œä½†æ˜¯è°åœ¨è´¡çŒ®æŸå¤±ï¼Ÿ\nâˆ‘i=0G2âˆ‘j=0B1ijobjâˆ‘kâˆˆclassesBCE(pk,p^k)\\sum_{i=0}^{G^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{obj} \\sum_{k \\in classes} BCE(p_k, \\hat{p}_k)\ni=0âˆ‘G2â€‹j=0âˆ‘Bâ€‹1ijobjâ€‹kâˆˆclassesâˆ‘â€‹BCE(pkâ€‹,p^â€‹kâ€‹)\nå°±åƒæˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„å‰ä¸¤ä¸ªæ±‚å’Œç¬¦å·è´Ÿè´£éå†å…¨å›¾æ‰€æœ‰çš„ç½‘æ ¼å’Œæ‰€æœ‰çš„ Anchorã€‚\næŒ‡ç¤ºå‡½æ•° 1ijobj\\mathbb{1}_{ij}^{obj}1ijobjâ€‹ï¼šè¿™æ˜¯æœ€å…³é”®çš„è¿‡æ»¤å™¨ï¼Œåªæœ‰å½“è¿™ä¸ªæ¡†æ˜¯æ­£æ ·æœ¬å³è´Ÿè´£é¢„æµ‹æŸä¸ªçœŸå®ç‰©ä½“çš„é‚£ä¸ªæ¡†æ—¶ï¼Œåé¢çš„ç±»åˆ«æŸå¤±æ‰ä¼šè¢«è®¡ç®—ï¼Œè´Ÿæ ·æœ¬æˆ–è€…è¯´æ˜¯èƒŒæ™¯ä¸è®¡ç®—ç±»åˆ«æŸå¤±ã€‚\næ ¸å¿ƒå…¬å¼ï¼š\nâˆ‘kâˆˆclassesBCE(pk,p^k)\\sum_{k \\in classes} BCE(p_k, \\hat{p}_k)\nkâˆˆclassesâˆ‘â€‹BCE(pkâ€‹,p^â€‹kâ€‹)\nè¿™éƒ¨åˆ†æ˜¯ YOLOv3 ç›¸æ¯” YOLOv2 çš„é‡å¤§æ”¹è¿›ï¼Œä»–å¯¹æ¯ä¸€ä¸ªç±»åˆ«è¿›è¡Œè®¡ç®—ï¼Œ\næ€»ç»“æ¥è¯´å°±æ˜¯è¦æ‰¾å‡ºæ‰€æœ‰çš„æ­£æ ·æœ¬ï¼Œå¯¹å®ƒä»¬é¢„æµ‹çš„æ¯ä¸€ä¸ªç±»åˆ«éƒ½è¿›è¡Œä¸€æ¬¡å¯¹é”™æ£€æŸ¥ï¼Œç„¶åæŠŠè¿™äº›æ£€æŸ¥ç»“æœå…¨éƒ¨ç´¯åŠ ã€‚\n# é€šä¿—ç†è§£è¿™ä¸ªè¿‡ç¨‹\næœ‰ä¸€ä¸ªæ­£æ ·æœ¬ Anchorï¼š\n\nå®ƒå¯¹åº”çš„çœŸå®ç‰©ä½“æ˜¯ä¸€åª â€œç‹—â€ã€‚\nç±»åˆ«æ ‡ç­¾ï¼ˆp^\\hat{p}p^â€‹ï¼‰å°±æ˜¯ï¼š [0, 0, 1, 0, ... 0]  å‡è®¾ç¬¬ 3 ä½æ˜¯ç‹—ï¼Œå‡è®¾ä¸€å…±æœ‰ 80 ä¸ªåˆ†ç±»ã€‚\næ¨¡å‹é¢„æµ‹ï¼ˆpppï¼‰å¯èƒ½æ˜¯ï¼š [0.1, 0.1, 0.8, 0.2, ... 0.05] ã€‚\nè®¡ç®— Loss æ—¶ï¼š\n\nç¬¬ 3 ä½ç®—ä¸€æ¬¡ BCE(0.8,1)BCE(0.8, 1)BCE(0.8,1) â€”â€” â€œè®©ä½ åƒç‹—ï¼Œä½ åšå¾—è¿˜ä¸å¤Ÿå¥½ï¼Œæ‰£åˆ†ã€‚â€\nå…¶ä½™ 79 ä½åˆ†åˆ«ç®— BCE(pk,0)BCE(p_k, 0)BCE(pkâ€‹,0) â€”â€” â€œä½ è™½ç„¶ä¸æ˜¯çŒ«ï¼Œä½†ç»™äº† 0.1 çš„æ¦‚ç‡ï¼Œä¹Ÿè¦æ‰£ä¸€ç‚¹åˆ†ã€‚â€\n\n\næŠŠè¿™ 80 ä¸ªåˆ†æ•°å€¼å…¨éƒ¨åŠ èµ·æ¥ï¼Œå°±æ˜¯è¿™ä¸ª Anchor çš„ç±»åˆ«æ€»æŸå¤±ã€‚\n\n# è§†é¢‘ä¸­çš„æŸå¤±å‡½æ•°\nloss=Î»coordâˆ‘i=0S2âˆ‘j=0B1i,jobjâ‹…[(bxâˆ’b^x)2+(byâˆ’b^y)2+(bwâˆ’b^w)2+(bhâˆ’b^h)2](2âˆ’wiÃ—hi)+âˆ‘i=0S2âˆ‘j=0B1i,jobjâ‹…[âˆ’logâ¡(pc)+âˆ‘i=1nBCE(c^i,ci)]+Î»noobjâˆ‘i=0S2âˆ‘j=0B1i,jnoobjâ‹…[âˆ’logâ¡(1âˆ’pc)]\\begin{aligned}\nloss = &amp; \\lambda_{\\text{coord}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{i,j}^{obj} \\cdot \\left[ (b_x - \\hat{b}_x)^2 + (b_y - \\hat{b}_y)^2 + (b_w - \\hat{b}_w)^2 + (b_h - \\hat{b}_h)^2 \\right] (2 - w_i \\times h_i) \\\\\n&amp; + \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{i,j}^{obj} \\cdot \\left[ -\\log(p_c) + \\sum_{i=1}^{n} BCE(\\hat{c}_i, c_i) \\right] \\\\\n&amp; + \\lambda_{\\text{noobj}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{i,j}^{\\text{noobj}} \\cdot \\left[ -\\log(1 - p_c) \\right]\n\\end{aligned}\nloss=â€‹Î»coordâ€‹i=0âˆ‘S2â€‹j=0âˆ‘Bâ€‹1i,jobjâ€‹â‹…[(bxâ€‹âˆ’b^xâ€‹)2+(byâ€‹âˆ’b^yâ€‹)2+(bwâ€‹âˆ’b^wâ€‹)2+(bhâ€‹âˆ’b^hâ€‹)2](2âˆ’wiâ€‹Ã—hiâ€‹)+i=0âˆ‘S2â€‹j=0âˆ‘Bâ€‹1i,jobjâ€‹â‹…[âˆ’log(pcâ€‹)+i=1âˆ‘nâ€‹BCE(c^iâ€‹,ciâ€‹)]+Î»noobjâ€‹i=0âˆ‘S2â€‹j=0âˆ‘Bâ€‹1i,jnoobjâ€‹â‹…[âˆ’log(1âˆ’pcâ€‹)]â€‹\n# ä½ç½®æŸå¤±\nÎ»coordâˆ‘i=0S2âˆ‘j=0B1i,jobjâ‹…[(bxâˆ’b^x)2+(byâˆ’b^y)2+(bwâˆ’b^w)2+(bhâˆ’b^h)2](2âˆ’wiÃ—hi)\\lambda_{\\text{coord}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{i,j}^{obj} \\cdot \\left[ (b_x - \\hat{b}_x)^2 + (b_y - \\hat{b}_y)^2 + (b_w - \\hat{b}_w)^2 + (b_h - \\hat{b}_h)^2 \\right] (2 - w_i \\times h_i) \nÎ»coordâ€‹i=0âˆ‘S2â€‹j=0âˆ‘Bâ€‹1i,jobjâ€‹â‹…[(bxâ€‹âˆ’b^xâ€‹)2+(byâ€‹âˆ’b^yâ€‹)2+(bwâ€‹âˆ’b^wâ€‹)2+(bhâ€‹âˆ’b^hâ€‹)2](2âˆ’wiâ€‹Ã—hiâ€‹)\nè¿™ä¸€è¡Œè´Ÿè´£è®©é¢„æµ‹æ¡†ç”»å¾—æ›´å‡†ã€‚\n\n(bx,by,bw,bh)(b_x, b_y, b_w, b_h)(bxâ€‹,byâ€‹,bwâ€‹,bhâ€‹)ï¼šæ¨¡å‹é¢„æµ‹çš„å››ä¸ªåæ ‡å€¼ã€‚\n(b^x,b^y,b^w,b^h)(\\hat{b}_x, \\hat{b}_y, \\hat{b}_w, \\hat{b}_h)(b^xâ€‹,b^yâ€‹,b^wâ€‹,b^hâ€‹)ï¼šçœŸå®ç›®æ ‡çš„åæ ‡å€¼ã€‚\n(2âˆ’wiÃ—hi)(2 - w_i \\times h_i)(2âˆ’wiâ€‹Ã—hiâ€‹)ï¼šå°ç›®æ ‡å¢å¼ºæƒé‡ã€‚ç‰©ä½“é¢ç§¯è¶Šå°ï¼Œè¿™ä¸ªå€¼è¶Šå¤§ï¼Œä»è€Œè¡¥å¿å¤§æ¡†å’Œå°æ¡†åœ¨ MSE æŸå¤±ä¸Šçš„ä¸å¹³è¡¡ã€‚\nÎ»coord\\lambda_{\\text{coord}}Î»coordâ€‹ï¼šåæ ‡æŸå¤±æƒé‡ç³»æ•°ï¼Œç”¨æ¥æé«˜å®šä½çš„ä¼˜å…ˆçº§ã€‚\n\n# æ­£æ ·æœ¬ç½®ä¿¡åº¦ä¸ç±»åˆ«æŸå¤±\nâˆ‘i=0S2âˆ‘j=0B1i,jobjâ‹…[âˆ’logâ¡(pc)+âˆ‘i=1nBCE(c^i,ci)]\\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{i,j}^{obj} \\cdot \\left[ -\\log(p_c) + \\sum_{i=1}^{n} BCE(\\hat{c}_i, c_i) \\right]\ni=0âˆ‘S2â€‹j=0âˆ‘Bâ€‹1i,jobjâ€‹â‹…[âˆ’log(pcâ€‹)+i=1âˆ‘nâ€‹BCE(c^iâ€‹,ciâ€‹)]\nè¿™ä¸€è¡Œåªé’ˆå¯¹æ­£æ ·æœ¬å³åŒ…å«ç‰©ä½“çš„æ¡†çš„è®¡ç®—ã€‚\n\nâˆ’logâ¡(pc)-\\log(p_c)âˆ’log(pcâ€‹)ï¼šç‰©ä½“å­˜åœ¨çš„ç½®ä¿¡åº¦æŸå¤±ã€‚å½“é¢„æµ‹æ¦‚ç‡ pcp_cpcâ€‹ è¶Šæ¥è¿‘ 1ï¼ŒæŸå¤±è¶Šå°ã€‚\nâˆ‘i=1nBCE(c^i,ci)\\sum_{i=1}^{n} BCE(\\hat{c}_i, c_i)âˆ‘i=1nâ€‹BCE(c^iâ€‹,ciâ€‹)ï¼šåˆ†ç±»æŸå¤±ã€‚å¯¹ nnn ä¸ªç±»åˆ«ä¸­çš„æ¯ä¸€ä¸ªéƒ½è¿›è¡ŒäºŒå€¼äº¤å‰ç†µè®¡ç®—ï¼Œæ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»ã€‚\n\n# è´Ÿæ ·æœ¬ç½®ä¿¡åº¦æŸå¤±\nÎ»noobjâˆ‘i=0S2âˆ‘j=0B1i,jnoobjâ‹…[âˆ’logâ¡(1âˆ’pc)]\\lambda_{\\text{noobj}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{i,j}^{\\text{noobj}} \\cdot \\left[ -\\log(1 - p_c) \\right]\nÎ»noobjâ€‹i=0âˆ‘S2â€‹j=0âˆ‘Bâ€‹1i,jnoobjâ€‹â‹…[âˆ’log(1âˆ’pcâ€‹)]\nè¿™ä¸€è¡Œåªé’ˆå¯¹è´Ÿæ ·æœ¬å³èƒŒæ™¯è®¡ç®—ã€‚\n\nâˆ’logâ¡(1âˆ’pc)-\\log(1 - p_c)âˆ’log(1âˆ’pcâ€‹)ï¼šèƒŒæ™¯çš„ç½®ä¿¡åº¦æŸå¤±ã€‚å½“é¢„æµ‹æ¦‚ç‡ pcp_cpcâ€‹ è¶Šæ¥è¿‘ 0ï¼ŒæŸå¤±è¶Šå°ã€‚\nÎ»noobj\\lambda_{\\text{noobj}}Î»noobjâ€‹ï¼šèƒŒæ™¯æƒ©ç½šç³»æ•°ã€‚å› ä¸ºèƒŒæ™¯æ¡†è¿œå¤šäºç‰©ä½“æ¡†ï¼Œæ‰€ä»¥é€šå¸¸ä¼šè®¾ç½®ä¸€ä¸ªè¾ƒå°çš„å€¼æ¥é˜²æ­¢æ¨¡å‹è¢«èƒŒæ™¯æ·¹æ²¡ã€‚\n\n# å›æœ›\nYOLOv3 æ˜¯ç›®æ ‡æ£€æµ‹é¢†åŸŸçš„ç»å…¸ä¹‹ä½œï¼Œå®ƒåœ¨ YOLOv2 çš„åŸºç¡€ä¸Šè¿›è¡Œäº†å¤§å¹…åº¦æ”¹è¿›ï¼Œèˆå¼ƒäº†ä¹‹å‰çš„ Darknet-19ï¼Œé‡‡ç”¨äº†æ‹¥æœ‰ 53 å±‚å·ç§¯å±‚çš„ Darknet-53ã€‚å®ƒå¼•å…¥äº†å¤§é‡çš„æ®‹å·®ç»“æ„ï¼Œæœ‰æ•ˆè§£å†³äº†æ·±å±‚ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦åˆ°æ›´å¤æ‚çš„ç‰¹å¾ã€‚å— FPN å¯å‘ï¼ŒYOLOv3 åˆ†åˆ«åœ¨ 13Ã—1313 \\times 1313Ã—13ã€26Ã—2626 \\times 2626Ã—26 å’Œ 52Ã—5252 \\times 5252Ã—52 ä¸‰ä¸ªå°ºåº¦è¿›è¡Œé¢„æµ‹ã€‚åˆ†ç±»æ–¹å¼æ”¾å¼ƒäº† Softmaxï¼Œæ”¹ç”¨å¤šä¸ªç‹¬ç«‹çš„ Logistic åˆ†ç±»å™¨å³ BCE æŸå¤±ï¼Œè¿™ä½¿å¾— YOLOv3 èƒ½å¤Ÿæ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»ã€‚\n# å‚è€ƒ\n\nã€YOLOv1ã€YOLOv2ã€YOLOv3 ç›®æ ‡æ£€æµ‹ç®—æ³•åŸç†ä¸å®æˆ˜ã€‘https://www.bilibili.com/video/BV1WT421r72w\n\n","categories":["æ·±åº¦å­¦ä¹ ","YOLO"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","YOLO"]},{"title":"æ¨¡å‹è¯„ä»·æŒ‡æ ‡","url":"/python/YOLO/evaluation_indicators/","content":"# ä»€ä¹ˆæ˜¯æ¨¡å‹è¯„ä»·æŒ‡æ ‡\næ¨¡å‹è¯„ä»·æŒ‡æ ‡æ˜¯ç”¨æ¥å®šé‡è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„ä¸€å¥—æ ‡å‡†å’Œåº¦é‡æ–¹æ³•ã€‚å®ƒä»¬å°†æ¨¡å‹çš„é¢„æµ‹ç»“æœä¸çœŸå®æƒ…å†µè¿›è¡Œæ¯”è¾ƒï¼Œç»™å‡ºä¸€ä¸ªæ•°å€¼åŒ–çš„åˆ†æ•°ã€‚\n# å‡†ç¡®ç‡\nç®€å•æ¥è¯´ï¼Œå‡†ç¡®ç‡å›ç­”äº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šâ€œåœ¨æ¨¡å‹åšå‡ºçš„æ‰€æœ‰åˆ¤æ–­ä¸­ï¼Œæœ‰å¤šå°‘æ¬¡æ˜¯çŒœå¯¹çš„ï¼Ÿâ€\nåœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨æ··æ·†çŸ©é˜µä¸­çš„å››ä¸ªæŒ‡æ ‡æ¥å®šä¹‰å‡†ç¡®ç‡ï¼š\n\nTP (True Positive)ï¼šçœŸæ­£ä¾‹ï¼Œå®é™…ä¸ºæ­£ï¼Œæ¨¡å‹ä¹Ÿé¢„æµ‹ä¸ºæ­£ã€‚\nTN (True Negative)ï¼šçœŸè´Ÿä¾‹ï¼Œå®é™…ä¸ºè´Ÿï¼Œæ¨¡å‹ä¹Ÿé¢„æµ‹ä¸ºè´Ÿã€‚\nFP (False Positive)ï¼šå‡æ­£ä¾‹ï¼Œå®é™…ä¸ºè´Ÿï¼Œæ¨¡å‹å´é¢„æµ‹ä¸ºæ­£ã€‚\nFN (False Negative)ï¼šå‡è´Ÿä¾‹ï¼Œå®é™…ä¸ºæ­£ï¼Œæ¨¡å‹å´é¢„æµ‹ä¸ºè´Ÿã€‚\n\nAccuracy=TP+TNTP+TN+FP+FN=é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°æ€»æ ·æœ¬æ•°\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{\\text{é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°}}{\\text{æ€»æ ·æœ¬æ•°}}\nAccuracy=TP+TN+FP+FNTP+TNâ€‹=æ€»æ ·æœ¬æ•°é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°â€‹\nä¸‰åˆ†ç±»åŠå…¶ä»¥ä¸Šçš„ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œæˆ‘ä»¬å…³æ³¨çš„å°±æ˜¯æ•´ç†ï¼Œå…¶ä»–çš„å°±æ˜¯åä¾‹ã€‚\n# æ··æ·†çŸ©é˜µ\næ··æ·†çŸ©é˜µ å°±æ˜¯ä¸€å¼  â€œå¯¹æ¯”è¡¨â€ã€‚å®ƒæŠŠæ¨¡å‹é¢„æµ‹çš„ç»“æœå’Œå®é™…çš„çœŸå®æƒ…å†µæ’åœ¨ä¸€èµ·ï¼Œè®©ä½ ä¸€çœ¼çœ‹å‡ºæ¨¡å‹åœ¨å“ªäº›åœ°æ–¹æ··æ·†äº†ï¼Œè€Œå®ƒçš„æ ·å­å–å†³äºä½ æœ‰å¤šå°‘ä¸ªç±»åˆ«ã€‚\næ— è®ºæ˜¯äºŒåˆ†ç±»è¿˜æ˜¯å¤šåˆ†ç±»ï¼Œæ··æ·†çŸ©é˜µçš„ç»“æ„é€šå¸¸å¦‚ä¸‹ï¼š\n\nè¡Œï¼šä»£è¡¨æ ·æœ¬çš„çœŸå®ç±»åˆ«ã€‚\nåˆ—ï¼šä»£è¡¨æ¨¡å‹é¢„æµ‹çš„ç±»åˆ«ã€‚\nå¯¹è§’çº¿ï¼šä»å·¦ä¸Šè§’åˆ°å³ä¸‹è§’çš„æ ¼å­ï¼Œä»£è¡¨é¢„æµ‹æ­£ç¡®çš„æ•°é‡ã€‚\n\nå‡è®¾ä½ æœ‰ä¸€ä¸ªè¯†åˆ«åŠ¨ç‰©çš„æ¨¡å‹ï¼Œæµ‹è¯•äº† 27 åªåŠ¨ç‰©ï¼Œç»“æœå¯èƒ½é•¿è¿™æ ·ï¼š\n\n\n\n\né¢„æµ‹ï¼šçŒ«\né¢„æµ‹ï¼šç‹—\né¢„æµ‹ï¼šå…”\næ€»è®¡ï¼ˆå®é™…ï¼‰\n\n\n\n\nå®é™…ï¼šçŒ«\n5 (TP)\n2\n1\n8\n\n\nå®é™…ï¼šç‹—\n0\n6 (TP)\n0\n6\n\n\nå®é™…ï¼šå…”\n2\n1\n10 (TP)\n13\n\n\næ€»è®¡ï¼ˆé¢„æµ‹ï¼‰\n7\n9\n11\n27\n\n\n\nimport seaborn as snsfrom sklearn.metrics import confusion_matrixy_true = [0]*8 + [1]*6 + [2]*13y_pred = ([0]*5 + [1]*2 + [2]*1) + ([1]*6) + ([0]*2 + [1]*1 + [2]*10)print(f\"å®é™…æ ‡ç­¾: &#123;y_true&#125;\")print(f\"é¢„æµ‹ç»“æœ: &#123;y_pred&#125;\")cm = confusion_matrix(y_true, y_pred)sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n# ç²¾ç¡®ç‡ / æŸ¥å‡†ç‡\nPrecision=TPTP+FP=é¢„æµ‹å¯¹çš„æ­£ä¾‹æ‰€æœ‰é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ•°\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{\\text{é¢„æµ‹å¯¹çš„æ­£ä¾‹}}{\\text{æ‰€æœ‰é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ•°}}\nPrecision=TP+FPTPâ€‹=æ‰€æœ‰é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ•°é¢„æµ‹å¯¹çš„æ­£ä¾‹â€‹\nå®ƒçš„æ ¸å¿ƒé—®é¢˜åœ¨äºï¼Œæ¨¡å‹è¯´ â€œæ˜¯â€ çš„æ—¶å€™ï¼Œå®ƒæœ‰å¤šå¯ä¿¡ï¼Ÿ\n# å¬å›ç‡ / æŸ¥å…¨ç‡\nRecall=TPTP+FN=é¢„æµ‹å¯¹çš„æ­£ä¾‹æ‰€æœ‰å®é™…ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ•°\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{\\text{é¢„æµ‹å¯¹çš„æ­£ä¾‹}}{\\text{æ‰€æœ‰å®é™…ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ•°}}\nRecall=TP+FNTPâ€‹=æ‰€æœ‰å®é™…ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ•°é¢„æµ‹å¯¹çš„æ­£ä¾‹â€‹\nå®ƒå…³æ³¨çš„æ˜¯æ¨¡å‹å‘ç°æ­£ä¾‹çš„èƒ½åŠ›ï¼Œæˆ–è€…è¯´è¦†ç›–ç‡ã€‚\n# ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„è¿›ä¸€æ­¥ç†è§£\nå‡è®¾ä¸€ä¸ªå°é•‡ä¸Šæœ‰ 10 ä¸ªåäºº å’Œ 90 ä¸ªå¥½äººã€‚\n# ç­–ç•¥ä¸€ï¼šæç«¯è°¨æ…ï¼Œæ²¡æŠŠæ¡ç»ä¸åŠ¨æ‰‹\nåœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼Œè­¦å¯Ÿéå¸¸æ‹…å¿ƒå†¤æ‰å¥½äººã€‚ä»–ä»¬åªåœ¨æŒæ¡äº†ç™¾åˆ†ä¹‹ç™¾è¯æ®çš„æƒ…å†µä¸‹æ‰æŠ“äººã€‚\nç»“æœï¼šè­¦å¯ŸåªæŠ“äº† 1 ä¸ªäººï¼Œè€Œè¿™ä¸ªäººç¡®å®æ˜¯åäººã€‚\n\nç²¾ç¡®ç‡ï¼š1/1=100%1 / 1 = \\mathbf{100\\%}1/1=100%ã€‚å› ä¸ºæŠ“çš„äººé‡Œæ²¡æœ‰ä¸€ä¸ªæ˜¯å†¤æ‰çš„ã€‚\nå¬å›ç‡ï¼š1/10=10%1 / 10 = \\mathbf{10\\%}1/10=10%ã€‚è™½ç„¶æŠ“å¾—å‡†ï¼Œä½†å‰©ä¸‹çš„ 9 ä¸ªåäººè¿˜åœ¨å¤–é¢é€é¥æ³•å¤–ã€‚\n\nâ€œè™½ç„¶ä»ä¸å†¤æ‰å¥½äººï¼Œä½†åŠäº‹æ•ˆç‡å¤ªä½ï¼Œåäººéƒ½æ¼æ‰äº†ã€‚â€\n# ç­–ç•¥äºŒï¼šå®å¯é”™æ€ä¸€åƒï¼Œä¸å¯æ”¾è¿‡ä¸€ä¸ª\nåœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼Œè­¦å¯Ÿä¸ºäº†å½»åº•è‚ƒæ¸…åäººï¼Œå†³å®šæŠŠæ‰€æœ‰æœ‰å«Œç–‘çš„äººå…¨éƒ¨æŠ“èµ·æ¥ã€‚\nç»“æœï¼šè­¦å¯ŸæŠ“äº† 50 ä¸ªäººã€‚å…¶ä¸­åŒ…å«äº†å…¨éƒ¨ 10 ä¸ªåäººï¼Œä½†ä¹Ÿè¯¯æŠ“äº† 40 ä¸ªå¥½äººã€‚\n\nå¬å›ç‡ï¼š10/10=100%10 / 10 = \\mathbf{100\\%}10/10=100%ã€‚æ‰€æœ‰çš„åäººéƒ½è¢«æŠ“è¿›äº†ç›‘ç‹±ï¼Œä¸€ä¸ªæ²¡æ¼ã€‚\nç²¾ç¡®ç‡ï¼š10/50=20%10 / 50 = \\mathbf{20\\%}10/50=20%ã€‚è™½ç„¶åäººæŠ“å®Œäº†ï¼Œä½†æŠ“çš„äººé‡Œæœ‰ 80% éƒ½æ˜¯å†¤æ‰çš„å¥½äººã€‚\n\nâ€œè™½ç„¶åäººä¸€ä¸ªæ²¡è·‘ï¼Œä½†æ»¥æ€æ— è¾œï¼Œé€ æˆäº†å¤§é‡çš„è¯¯æŠ¥ã€‚â€\n# ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„ç›¸äº’åˆ¶è¡¡\n\n\n\nç»´åº¦\nç²¾ç¡®ç‡é«˜ / å¬å›ç‡ä½\nç²¾ç¡®ç‡ä½ / å¬å›ç‡é«˜\n\n\n\n\næ ¸å¿ƒé€»è¾‘\nè¿½æ±‚ â€œçœŸâ€ï¼Œæ€•è¯¯æŠ¥\nè¿½æ±‚ â€œå…¨â€ï¼Œæ€•æ¼æŠ¥\n\n\næ¨¡å‹è¡¨ç°\nè¡¨ç°å¾—éå¸¸ä¿å®ˆ\nè¡¨ç°å¾—éå¸¸æ¿€è¿›\n\n\nåé¢åæœ\næ¼ç½‘ä¹‹é±¼å¤ªå¤š\nå†¤å‡é”™æ¡ˆå¤ªå¤š\n\n\n\nåœ¨æ¨¡å‹è°ƒæ•´ä¸­ï¼Œå½“ä½ è°ƒä½é˜ˆå€¼æ—¶ï¼Œä½ æŠ“åˆ°çš„åäººä¼šå˜å¤šï¼Œä½†éšä¹‹è€Œæ¥çš„è¯¯ä¼¤ä¹Ÿä¼šå˜å¤šã€‚è¿™å°±æ˜¯æœºå™¨å­¦ä¹ ä¸­è‘—åçš„ P-R æƒè¡¡ã€‚\nPï¼šPrecision  Rï¼šRecall\n\n# F1-score å€¼\nF1-Score ä½¿ç”¨çš„æ˜¯è°ƒå’Œå¹³å‡æ•°ï¼Œå®ƒçš„å…¬å¼æ˜¯ï¼š\nF1=2Ã—PrecisionÃ—RecallPrecision+RecallF1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\nF1=2Ã—Precision+RecallPrecisionÃ—Recallâ€‹\nè°ƒå’Œå¹³å‡æ•°çš„ç‰¹ç‚¹ï¼š å®ƒå¯¹ â€œæå°å€¼â€ éå¸¸æ•æ„Ÿã€‚å¦‚æœ Precision æˆ– Recall å…¶ä¸­ä¸€ä¸ªéå¸¸ä½ï¼Œæ•´ä¸ª F1-Score å°±ä¼šè¢«æ‹‰å¾—å¾ˆä½ï¼Œå–å€¼èŒƒå›´æ˜¯ 0~1ã€‚\n# IOU äº¤å¹¶æ¯”\nIoU è¡¡é‡çš„æ˜¯æ¨¡å‹é¢„æµ‹çš„è¾¹ç•Œæ¡†ä¸çœŸå®çš„è¾¹ç•Œæ¡†ä¹‹é—´çš„é‡å ç¨‹åº¦ã€‚\nIoU=AreaÂ ofÂ OverlapAreaÂ ofÂ UnionIoU = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}}\nIoU=AreaÂ ofÂ UnionAreaÂ ofÂ Overlapâ€‹\n# NMS éæå¤§å€¼æŠ‘åˆ¶\nå½“ä½ è¿è¡Œä¸€ä¸ªæ£€æµ‹æ¨¡å‹æ—¶ï¼Œæ¨¡å‹å¾€å¾€éå¸¸çƒ­å¿ƒï¼Œä¼šåœ¨åŒä¸€ä¸ªç‰©ä½“å‘¨å›´ç”»å‡ºæˆç™¾ä¸Šåƒä¸ªé‡å çš„å€™é€‰æ¡†ã€‚NMS çš„ä½œç”¨å°±æ˜¯ï¼šåœ¨è¿™ä¸€å †æ¡†é‡Œï¼Œåªé€‰å‡ºæœ€å‡†çš„é‚£ä¸€ä¸ªï¼ŒæŠŠå‰©ä¸‹çš„åˆ æ‰ã€‚\n\næ’åºï¼šå°†æ‰€æœ‰å€™é€‰æ¡†æŒ‰ç½®ä¿¡åº¦å¾—åˆ†ä»é«˜åˆ°ä½æ’åºã€‚\né€‰ä¸­ï¼šæŒ‘é€‰å¾—åˆ†æœ€é«˜çš„æ¡†ï¼ŒæŠŠå®ƒä½œä¸ºæœ€ç»ˆç»“æœä¿å­˜ã€‚\næ¯”è¾ƒä¸åˆ é™¤ï¼šè®¡ç®—å‰©ä¸‹çš„æ‰€æœ‰æ¡†ä¸ AAA çš„ IoUã€‚å¦‚æœæŸä¸ªæ¡†ä¸ AAA çš„ IoUIoUIoU è¶…è¿‡äº†é¢„è®¾çš„é˜ˆå€¼ï¼ˆæ¯”å¦‚ 0.5ï¼‰ï¼Œå°±è®¤ä¸ºè¿™ä¸ªæ¡†å’Œ AAA é¢„æµ‹çš„æ˜¯åŒä¸€ä¸ªç‰©ä½“ï¼Œç›´æ¥æŠŠå®ƒåˆ æ‰ã€‚\nå¾ªç¯ï¼šåœ¨å‰©ä¸‹çš„æ¡†ä¸­ç»§ç»­æ‰¾å¾—åˆ†æœ€é«˜çš„ï¼Œé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´åˆ°å¤„ç†å®Œæ‰€æœ‰æ¡†ã€‚\n\nä¸ºä»€ä¹ˆä¸æ‰¾ä¸€ä¸ªç½®ä¿¡åº¦æœ€é«˜çš„çš„ä¸€ä¸ªæ¡†å°±å®Œäº‹äº†å‘¢ï¼Œé‚£æ˜¯å› ä¸ºï¼Œæˆ‘ä»¬åœ¨ä¸€å¼ å›¾ç‰‡é‡Œæœ‰å¥½å¤šè¦æ£€æµ‹çš„ç›®æ ‡ï¼Œå¦‚æœåªé€‰æ‹©æœ€å¤§çš„é‚£å°±åªä¿ç•™äº†ä¸€ä¸ªï¼Œè¿™æ˜¯ä¸åˆç†çš„ã€‚\nè¿™å°±æ˜¯ NMS ç®—æ³•è®¾è®¡çš„ç²¾å¦™ä¹‹å¤„ï¼šå®ƒä¸æ˜¯ç®€å•çš„å…¨åœºé€‰æœ€é«˜ï¼Œè€Œæ˜¯å±€éƒ¨é€‰æœ€é«˜ã€‚\n# Confidence ç½®ä¿¡åº¦\nConfidence=Pr(Object)Ã—IoUpredtruth\\text{Confidence} = Pr(Object) \\times \\text{IoU}_{pred}^{truth}\nConfidence=Pr(Object)Ã—IoUpredtruthâ€‹\nPr(Object)Pr(Object)Pr(Object)ï¼šæ˜¯ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œå–å€¼èŒƒå›´åœ¨ [0,1][0, 1][0,1] ä¹‹é—´ã€‚\n\nå¦‚æœæ¡†å†…åŒ…å«ç‰©ä½“çš„ä¸­å¿ƒç‚¹ï¼ŒPr(Object)=1Pr(Object) = 1Pr(Object)=1ã€‚\nå¦‚æœæ¡†å†…åªæœ‰èƒŒæ™¯ï¼Œæ²¡æœ‰ä»»ä½•ç‰©ä½“ä¸­å¿ƒç‚¹ï¼ŒPr(Object)=0Pr(Object) = 0Pr(Object)=0ã€‚\n\nIoUpredtruth\\text{IoU}_{pred}^{truth}IoUpredtruthâ€‹ï¼šé¢„æµ‹æ¡†ä¸çœŸå®æ¡†ä¹‹é—´çš„é‡å ç¨‹åº¦ã€‚\n# ç‰¹å®šç±»åˆ«å¾—åˆ†\nScore=Pr(Object)Ã—IoUÃ—Pr(Classiâˆ£Object)\\text{Score} = Pr(Object) \\times \\text{IoU} \\times Pr(Class_i | Object)\nScore=Pr(Object)Ã—IoUÃ—Pr(Classiâ€‹âˆ£Object)\nPr(Classiâˆ£Object)Pr(Class_i | Object)Pr(Classiâ€‹âˆ£Object)ï¼šè¿™æ˜¯æ¡ä»¶ç±»åˆ«æ¦‚ç‡ï¼Œå³åœ¨å·²ç»ç¡®å®šæœ‰ç‰©ä½“çš„å‰æä¸‹ï¼Œå®ƒæ˜¯ç‹—çš„æ¦‚ç‡ã€‚\næœ€ç»ˆå¾—åˆ†ï¼šç»¼åˆäº†æœ‰æ²¡æœ‰ä¸œè¥¿ã€æ¡†å¾—å‡†ä¸å‡†ä»¥åŠæ˜¯ä»€ä¹ˆä¸œè¥¿è¿™ä¸‰ä¸ªå› ç´ ã€‚\n# PR æ›²çº¿\nPR æ›²çº¿ æ˜¯è¡¡é‡åˆ†ç±»æ¨¡å‹æ€§èƒ½çš„å¦ä¸€æŠŠå°ºã€‚å®ƒå±•ç¤ºäº†åœ¨ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼ä¸‹ï¼Œç²¾ç¡®ç‡ å’Œ å¬å›ç‡ ä¹‹é—´çš„åšå¼ˆå…³ç³»ã€‚\nå½“æˆ‘ä»¬ä½¿ç”¨æ¨¡å‹é¢„æµ‹æ—¶ï¼Œé€šå¸¸ä¼šå¾—åˆ°ä¸€ä¸ªæ¦‚ç‡å€¼ã€‚æˆ‘ä»¬éœ€è¦è®¾å®šä¸€ä¸ªé˜ˆå€¼æ¥å†³å®šå®ƒæ˜¯æ­£è¿˜æ˜¯è´Ÿã€‚\n\nå¦‚æœé˜ˆå€¼è®¾ä¸º 0.9 å¾ˆä¸¥è‹›ï¼šåªæœ‰ææœ‰æŠŠæ¡çš„æ‰ç®—æ­£ä¾‹ï¼Œç²¾ç¡®ç‡ä¼šå¾ˆé«˜ï¼Œä½†ä¼šæ¼æ‰å¾ˆå¤šï¼Œå¬å›ç‡ä½ã€‚\nå¦‚æœé˜ˆå€¼è®¾ä¸º 0.1 å¾ˆå®½æ¾ï¼šå®å¯é”™æŠ“ä¸å¯æ”¾è¿‡ï¼Œå¬å›ç‡ä¼šå¾ˆé«˜ï¼Œä½†è¯¯æŠ¥ä¹Ÿå¤šï¼Œç²¾ç¡®ç‡ä½ã€‚\n\nPR æ›²çº¿å°±æ˜¯æŠŠé˜ˆå€¼ä» 0 å˜åˆ° 1 çš„è¿‡ç¨‹ä¸­ï¼Œæ‰€æœ‰çš„ Recall ä¸ Precision åæ ‡ç‚¹è¿æˆçš„çº¿ã€‚\næ¨ªè½´æ˜¯ Recall å¬å›ç‡ï¼Œçºµè½´æ˜¯ Precision ç²¾ç¡®ç‡ã€‚å®ƒå¸¸æ˜¯ä¸€æ¡å‘å³ä¸‹æ–¹å€¾æ–œçš„æ›²çº¿ã€‚å½“å¬å›ç‡ä¸Šå‡æ—¶ï¼Œç²¾ç¡®ç‡å¾€å¾€ä¼šä¸‹é™ã€‚\nç†æƒ³ä½ç½®ï¼šæ›²çº¿è¶Šé è¿‘å³ä¸Šè§’ï¼ˆ1, 1ï¼‰è¶Šå¥½ã€‚è¿™æ„å‘³ç€æ¨¡å‹èƒ½åŒæ—¶ä¿æŒé«˜ç²¾ç¡®ç‡å’Œé«˜å¬å›ç‡ã€‚\n# mAP\nmAP: mean Average Precision\nAP: Average Precisionï¼Œ AP æ˜¯ PR æ›²çº¿ä¸‹æ–¹çš„é¢ç§¯ã€‚\nm: mean\nmAP=1Nâˆ‘i=1NAPi\\text{mAP} = \\frac{1}{N} \\sum_{i=1}^{N} AP_i\nmAP=N1â€‹i=1âˆ‘Nâ€‹APiâ€‹\nmAP åæ˜ äº†æ¨¡å‹çš„å…¨èƒ½ç¨‹åº¦ã€‚å¦‚æœä¸€ä¸ªæ¨¡å‹åªä¼šè®¤çŒ«ï¼Œä¸è®¤è¯†ç‹—ï¼Œé‚£ä¹ˆå®ƒçš„ mAP å°±ä¼šè¢«æ‹‰ä½ã€‚mAP æ˜¯è¡¡é‡æ¨¡å‹å¥½åçš„ç»ˆææ ‡å‡†ã€‚å®ƒä¸ä»…çœ‹æ¨¡å‹èƒ½ä¸èƒ½åˆ†ç±»æ­£ç¡®ï¼Œè¿˜çœ‹æ¨¡å‹æ¡†å¾—å‡†ä¸å‡†ã€‚\n# FPS\nåœ¨æ¨¡å‹è¯„ä»·æŒ‡æ ‡ä¸­ï¼Œå¦‚æœè¯´ mAP è¡¡é‡çš„æ˜¯æ¨¡å‹èªä¸èªæ˜ï¼Œé‚£ä¹ˆ FPS è¡¡é‡çš„å°±æ˜¯æ¨¡å‹å¿«ä¸å¿«ã€‚FPS å³æ¯ç§’ä¼ è¾“å¸§æ•°ï¼Œæ˜¯è¡¡é‡æ¨¡å‹æ¨ç†é€Ÿåº¦çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚\n","categories":["æ·±åº¦å­¦ä¹ ","åŸºç¡€"],"tags":["python","æ·±åº¦å­¦ä¹ ","CNN","YOLO"]},{"title":"YOLOç³»åˆ—","url":"/python/YOLO/index/","content":"\n          \n          YOLO-V1\n          ä¸€åˆ‡çš„å¼€å§‹\n          \n          \n          YOLO-V2\n          ä¸€æ¬¡å…³é”®çš„ä¸”å¤©æ‰çš„æ”¹è¿›\n          \n          \n          YOLO-V3\n          Joseph Redmonåœ¨YOLOçš„æœ€åä¸€èˆ\n          \n","categories":["æ·±åº¦å­¦ä¹ ","YOLO"],"tags":["YOLO"]}]